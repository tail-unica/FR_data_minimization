Training: 2025-08-31 04:55:36,670-rank_id: 0
Training: 2025-08-31 04:55:36,670-Dataset: /data/Synthetic/GAN_Control_class_images/images
Training: 2025-08-31 04:55:37,435-Classes: 6000 synthetic, 0 real - 359945 images - eval: 2812
Training: 2025-08-31 04:55:38,060-Total Step is: 112482
Training: 2025-08-31 04:56:09,294-Reducer buckets have been rebuilt in this iteration.
Training: 2025-08-31 04:56:09,395-Reducer buckets have been rebuilt in this iteration.
Training: 2025-08-31 04:56:43,529-Speed 368.30 samples/sec   Loss 35.0758 Epoch: 0   Global Step: 100   Required: 12 hours
Training: 2025-08-31 04:57:00,980-Speed 366.74 samples/sec   Loss 33.5124 Epoch: 0   Global Step: 150   Required: 12 hours
Training: 2025-08-31 04:57:18,469-Speed 365.94 samples/sec   Loss 32.2717 Epoch: 0   Global Step: 200   Required: 11 hours
Training: 2025-08-31 04:57:35,963-Speed 365.84 samples/sec   Loss 31.0524 Epoch: 0   Global Step: 250   Required: 11 hours
Training: 2025-08-31 04:57:53,459-Speed 365.81 samples/sec   Loss 29.9147 Epoch: 0   Global Step: 300   Required: 11 hours
Training: 2025-08-31 04:58:10,956-Speed 365.78 samples/sec   Loss 28.7680 Epoch: 0   Global Step: 350   Required: 11 hours
Training: 2025-08-31 04:58:28,456-Speed 365.72 samples/sec   Loss 27.7588 Epoch: 0   Global Step: 400   Required: 11 hours
Training: 2025-08-31 04:58:45,956-Speed 365.72 samples/sec   Loss 26.7848 Epoch: 0   Global Step: 450   Required: 11 hours
Training: 2025-08-31 04:59:03,467-Speed 365.47 samples/sec   Loss 25.7722 Epoch: 0   Global Step: 500   Required: 11 hours
Training: 2025-08-31 04:59:20,980-Speed 365.45 samples/sec   Loss 25.0195 Epoch: 0   Global Step: 550   Required: 11 hours
Training: 2025-08-31 04:59:38,497-Speed 365.37 samples/sec   Loss 24.0322 Epoch: 0   Global Step: 600   Required: 11 hours
Training: 2025-08-31 04:59:56,011-Speed 365.42 samples/sec   Loss 23.3792 Epoch: 0   Global Step: 650   Required: 11 hours
Training: 2025-08-31 05:00:13,531-Speed 365.31 samples/sec   Loss 22.5455 Epoch: 0   Global Step: 700   Required: 11 hours
Training: 2025-08-31 05:00:31,049-Speed 365.34 samples/sec   Loss 21.8224 Epoch: 0   Global Step: 750   Required: 11 hours
Training: 2025-08-31 05:00:48,573-Speed 365.22 samples/sec   Loss 20.9550 Epoch: 0   Global Step: 800   Required: 11 hours
Training: 2025-08-31 05:01:06,091-Speed 365.34 samples/sec   Loss 20.2596 Epoch: 0   Global Step: 850   Required: 11 hours
Training: 2025-08-31 05:01:23,610-Speed 365.32 samples/sec   Loss 19.8143 Epoch: 0   Global Step: 900   Required: 11 hours
Training: 2025-08-31 05:01:41,117-Speed 365.58 samples/sec   Loss 19.0200 Epoch: 0   Global Step: 950   Required: 11 hours
Training: 2025-08-31 05:01:58,625-Speed 365.54 samples/sec   Loss 18.4243 Epoch: 0   Global Step: 1000   Required: 11 hours
Training: 2025-08-31 05:02:16,126-Speed 365.69 samples/sec   Loss 17.8488 Epoch: 0   Global Step: 1050   Required: 11 hours
Training: 2025-08-31 05:02:33,628-Speed 365.68 samples/sec   Loss 17.3823 Epoch: 0   Global Step: 1100   Required: 11 hours
Training: 2025-08-31 05:02:51,135-Speed 365.56 samples/sec   Loss 16.9377 Epoch: 0   Global Step: 1150   Required: 11 hours
Training: 2025-08-31 05:03:08,640-Speed 365.61 samples/sec   Loss 16.3494 Epoch: 0   Global Step: 1200   Required: 11 hours
Training: 2025-08-31 05:03:26,147-Speed 365.59 samples/sec   Loss 15.8697 Epoch: 0   Global Step: 1250   Required: 11 hours
Training: 2025-08-31 05:03:43,654-Speed 365.55 samples/sec   Loss 15.4866 Epoch: 0   Global Step: 1300   Required: 11 hours
Training: 2025-08-31 05:04:01,162-Speed 365.55 samples/sec   Loss 14.8787 Epoch: 0   Global Step: 1350   Required: 11 hours
Training: 2025-08-31 05:04:18,666-Speed 365.63 samples/sec   Loss 14.5940 Epoch: 0   Global Step: 1400   Required: 11 hours
Training: 2025-08-31 05:04:36,169-Speed 365.66 samples/sec   Loss 14.0248 Epoch: 0   Global Step: 1450   Required: 11 hours
Training: 2025-08-31 05:04:53,675-Speed 365.60 samples/sec   Loss 13.6408 Epoch: 0   Global Step: 1500   Required: 11 hours
Training: 2025-08-31 05:05:11,177-Speed 365.67 samples/sec   Loss 13.2467 Epoch: 0   Global Step: 1550   Required: 11 hours
Training: 2025-08-31 05:05:28,674-Speed 365.78 samples/sec   Loss 12.8607 Epoch: 0   Global Step: 1600   Required: 11 hours
Training: 2025-08-31 05:05:46,172-Speed 365.77 samples/sec   Loss 12.6107 Epoch: 0   Global Step: 1650   Required: 11 hours
Training: 2025-08-31 05:06:03,681-Speed 365.52 samples/sec   Loss 12.3025 Epoch: 0   Global Step: 1700   Required: 11 hours
Training: 2025-08-31 05:06:21,191-Speed 365.52 samples/sec   Loss 11.7701 Epoch: 0   Global Step: 1750   Required: 11 hours
Training: 2025-08-31 05:06:38,698-Speed 365.55 samples/sec   Loss 11.5931 Epoch: 0   Global Step: 1800   Required: 11 hours
Training: 2025-08-31 05:06:56,208-Speed 365.51 samples/sec   Loss 11.1671 Epoch: 0   Global Step: 1850   Required: 11 hours
Training: 2025-08-31 05:07:13,716-Speed 365.55 samples/sec   Loss 10.8637 Epoch: 0   Global Step: 1900   Required: 11 hours
Training: 2025-08-31 05:07:31,223-Speed 365.58 samples/sec   Loss 10.6585 Epoch: 0   Global Step: 1950   Required: 11 hours
Training: 2025-08-31 05:07:48,730-Speed 365.57 samples/sec   Loss 10.3209 Epoch: 0   Global Step: 2000   Required: 11 hours
Training: 2025-08-31 05:08:06,233-Speed 365.65 samples/sec   Loss 10.1297 Epoch: 0   Global Step: 2050   Required: 11 hours
Training: 2025-08-31 05:08:23,737-Speed 365.63 samples/sec   Loss 9.7390 Epoch: 0   Global Step: 2100   Required: 11 hours
Training: 2025-08-31 05:08:41,242-Speed 365.62 samples/sec   Loss 9.5756 Epoch: 0   Global Step: 2150   Required: 11 hours
Training: 2025-08-31 05:08:58,743-Speed 365.69 samples/sec   Loss 9.4535 Epoch: 0   Global Step: 2200   Required: 11 hours
Training: 2025-08-31 05:09:16,241-Speed 365.77 samples/sec   Loss 8.9588 Epoch: 0   Global Step: 2250   Required: 11 hours
Training: 2025-08-31 05:09:33,743-Speed 365.66 samples/sec   Loss 8.9982 Epoch: 0   Global Step: 2300   Required: 11 hours
Training: 2025-08-31 05:09:51,239-Speed 365.81 samples/sec   Loss 8.5073 Epoch: 0   Global Step: 2350   Required: 11 hours
Training: 2025-08-31 05:10:08,743-Speed 365.63 samples/sec   Loss 8.5689 Epoch: 0   Global Step: 2400   Required: 11 hours
Training: 2025-08-31 05:10:26,244-Speed 365.70 samples/sec   Loss 8.2247 Epoch: 0   Global Step: 2450   Required: 11 hours
Training: 2025-08-31 05:10:43,750-Speed 365.59 samples/sec   Loss 8.0147 Epoch: 0   Global Step: 2500   Required: 11 hours
Training: 2025-08-31 05:11:01,254-Speed 365.63 samples/sec   Loss 7.7477 Epoch: 0   Global Step: 2550   Required: 11 hours
Training: 2025-08-31 05:11:18,758-Speed 365.64 samples/sec   Loss 7.6432 Epoch: 0   Global Step: 2600   Required: 11 hours
Training: 2025-08-31 05:11:36,260-Speed 365.67 samples/sec   Loss 7.4350 Epoch: 0   Global Step: 2650   Required: 11 hours
Training: 2025-08-31 05:11:53,764-Speed 365.63 samples/sec   Loss 7.1341 Epoch: 0   Global Step: 2700   Required: 11 hours
Training: 2025-08-31 05:12:11,275-Speed 365.49 samples/sec   Loss 7.2033 Epoch: 0   Global Step: 2750   Required: 11 hours
Training: 2025-08-31 05:12:28,779-Speed 365.63 samples/sec   Loss 7.0072 Epoch: 0   Global Step: 2800   Required: 11 hours
Training: 2025-08-31 05:12:57,578-[lfw][2812]XNorm: 22.097036
Training: 2025-08-31 05:12:57,578-[lfw][2812]Accuracy-Flip: 0.79550+-0.01195
Training: 2025-08-31 05:12:57,578-[lfw][2812]Accuracy-Highest: 0.79550
Training: 2025-08-31 05:13:25,875-[cfp_fp][2812]XNorm: 21.745205
Training: 2025-08-31 05:13:25,875-[cfp_fp][2812]Accuracy-Flip: 0.61571+-0.01746
Training: 2025-08-31 05:13:25,875-[cfp_fp][2812]Accuracy-Highest: 0.61571
Training: 2025-08-31 05:13:50,221-[agedb_30][2812]XNorm: 19.326678
Training: 2025-08-31 05:13:50,221-[agedb_30][2812]Accuracy-Flip: 0.50383+-0.01207
Training: 2025-08-31 05:13:50,221-[agedb_30][2812]Accuracy-Highest: 0.50383
Training: 2025-08-31 05:14:14,653-[calfw][2812]XNorm: 22.477632
Training: 2025-08-31 05:14:14,653-[calfw][2812]Accuracy-Flip: 0.62683+-0.01210
Training: 2025-08-31 05:14:14,653-[calfw][2812]Accuracy-Highest: 0.62683
Training: 2025-08-31 05:14:39,078-[cplfw][2812]XNorm: 20.068265
Training: 2025-08-31 05:14:39,078-[cplfw][2812]Accuracy-Flip: 0.60467+-0.00718
Training: 2025-08-31 05:14:39,078-[cplfw][2812]Accuracy-Highest: 0.60467
Training: 2025-08-31 05:14:52,567-Speed 44.51 samples/sec   Loss 6.3294 Epoch: 1   Global Step: 2850   Required: 12 hours
Training: 2025-08-31 05:15:10,064-Speed 365.80 samples/sec   Loss 6.0980 Epoch: 1   Global Step: 2900   Required: 12 hours
Training: 2025-08-31 05:15:27,558-Speed 365.84 samples/sec   Loss 5.8999 Epoch: 1   Global Step: 2950   Required: 12 hours
Training: 2025-08-31 05:15:45,052-Speed 365.83 samples/sec   Loss 5.8589 Epoch: 1   Global Step: 3000   Required: 12 hours
Training: 2025-08-31 05:16:02,547-Speed 365.83 samples/sec   Loss 5.8269 Epoch: 1   Global Step: 3050   Required: 12 hours
Training: 2025-08-31 05:16:20,046-Speed 365.73 samples/sec   Loss 5.5553 Epoch: 1   Global Step: 3100   Required: 12 hours
Training: 2025-08-31 05:16:37,554-Speed 365.55 samples/sec   Loss 5.6305 Epoch: 1   Global Step: 3150   Required: 12 hours
Training: 2025-08-31 05:16:55,068-Speed 365.43 samples/sec   Loss 5.4935 Epoch: 1   Global Step: 3200   Required: 12 hours
Training: 2025-08-31 05:17:12,577-Speed 365.53 samples/sec   Loss 5.4638 Epoch: 1   Global Step: 3250   Required: 12 hours
Training: 2025-08-31 05:17:30,081-Speed 365.63 samples/sec   Loss 5.3429 Epoch: 1   Global Step: 3300   Required: 12 hours
Training: 2025-08-31 05:17:47,597-Speed 365.37 samples/sec   Loss 5.2438 Epoch: 1   Global Step: 3350   Required: 12 hours
Training: 2025-08-31 05:18:05,111-Speed 365.44 samples/sec   Loss 5.1286 Epoch: 1   Global Step: 3400   Required: 12 hours
Training: 2025-08-31 05:18:22,626-Speed 365.39 samples/sec   Loss 5.1191 Epoch: 1   Global Step: 3450   Required: 12 hours
Training: 2025-08-31 05:18:40,146-Speed 365.30 samples/sec   Loss 5.0426 Epoch: 1   Global Step: 3500   Required: 12 hours
Training: 2025-08-31 05:18:57,657-Speed 365.50 samples/sec   Loss 4.9186 Epoch: 1   Global Step: 3550   Required: 12 hours
Training: 2025-08-31 05:19:15,164-Speed 365.57 samples/sec   Loss 4.7833 Epoch: 1   Global Step: 3600   Required: 12 hours
Training: 2025-08-31 05:19:32,673-Speed 365.52 samples/sec   Loss 4.6525 Epoch: 1   Global Step: 3650   Required: 12 hours
Training: 2025-08-31 05:19:50,180-Speed 365.58 samples/sec   Loss 4.6936 Epoch: 1   Global Step: 3700   Required: 12 hours
Training: 2025-08-31 05:20:07,689-Speed 365.52 samples/sec   Loss 4.6384 Epoch: 1   Global Step: 3750   Required: 12 hours
Training: 2025-08-31 05:20:25,194-Speed 365.62 samples/sec   Loss 4.5272 Epoch: 1   Global Step: 3800   Required: 12 hours
Training: 2025-08-31 05:20:42,700-Speed 365.59 samples/sec   Loss 4.5188 Epoch: 1   Global Step: 3850   Required: 12 hours
Training: 2025-08-31 05:21:00,215-Speed 365.41 samples/sec   Loss 4.4262 Epoch: 1   Global Step: 3900   Required: 12 hours
Training: 2025-08-31 05:21:17,726-Speed 365.47 samples/sec   Loss 4.4257 Epoch: 1   Global Step: 3950   Required: 12 hours
Training: 2025-08-31 05:21:35,233-Speed 365.57 samples/sec   Loss 4.2000 Epoch: 1   Global Step: 4000   Required: 12 hours
Training: 2025-08-31 05:21:52,744-Speed 365.49 samples/sec   Loss 4.2143 Epoch: 1   Global Step: 4050   Required: 12 hours
Training: 2025-08-31 05:22:10,239-Speed 365.83 samples/sec   Loss 4.1142 Epoch: 1   Global Step: 4100   Required: 11 hours
Training: 2025-08-31 05:22:27,734-Speed 365.82 samples/sec   Loss 4.0866 Epoch: 1   Global Step: 4150   Required: 11 hours
Training: 2025-08-31 05:22:45,227-Speed 365.85 samples/sec   Loss 3.9033 Epoch: 1   Global Step: 4200   Required: 11 hours
Training: 2025-08-31 05:23:02,721-Speed 365.84 samples/sec   Loss 3.9938 Epoch: 1   Global Step: 4250   Required: 11 hours
Training: 2025-08-31 05:23:20,216-Speed 365.84 samples/sec   Loss 3.8444 Epoch: 1   Global Step: 4300   Required: 11 hours
Training: 2025-08-31 05:23:37,710-Speed 365.84 samples/sec   Loss 3.8353 Epoch: 1   Global Step: 4350   Required: 11 hours
Training: 2025-08-31 05:23:55,206-Speed 365.79 samples/sec   Loss 3.6795 Epoch: 1   Global Step: 4400   Required: 11 hours
Training: 2025-08-31 05:24:12,708-Speed 365.67 samples/sec   Loss 3.7168 Epoch: 1   Global Step: 4450   Required: 11 hours
Training: 2025-08-31 05:24:30,203-Speed 365.83 samples/sec   Loss 3.6829 Epoch: 1   Global Step: 4500   Required: 11 hours
Training: 2025-08-31 05:24:47,700-Speed 365.78 samples/sec   Loss 3.5545 Epoch: 1   Global Step: 4550   Required: 11 hours
Training: 2025-08-31 05:25:05,207-Speed 365.57 samples/sec   Loss 3.5684 Epoch: 1   Global Step: 4600   Required: 11 hours
Training: 2025-08-31 05:25:22,716-Speed 365.51 samples/sec   Loss 3.5238 Epoch: 1   Global Step: 4650   Required: 11 hours
Training: 2025-08-31 05:25:40,217-Speed 365.71 samples/sec   Loss 3.4839 Epoch: 1   Global Step: 4700   Required: 11 hours
Training: 2025-08-31 05:25:57,718-Speed 365.68 samples/sec   Loss 3.4385 Epoch: 1   Global Step: 4750   Required: 11 hours
Training: 2025-08-31 05:26:15,213-Speed 365.83 samples/sec   Loss 3.3269 Epoch: 1   Global Step: 4800   Required: 11 hours
Training: 2025-08-31 05:26:32,715-Speed 365.68 samples/sec   Loss 3.3258 Epoch: 1   Global Step: 4850   Required: 11 hours
Training: 2025-08-31 05:26:50,208-Speed 365.86 samples/sec   Loss 3.2481 Epoch: 1   Global Step: 4900   Required: 11 hours
Training: 2025-08-31 05:27:07,709-Speed 365.70 samples/sec   Loss 3.2419 Epoch: 1   Global Step: 4950   Required: 11 hours
Training: 2025-08-31 05:27:25,211-Speed 365.67 samples/sec   Loss 3.2205 Epoch: 1   Global Step: 5000   Required: 11 hours
Training: 2025-08-31 05:27:42,711-Speed 365.72 samples/sec   Loss 3.1566 Epoch: 1   Global Step: 5050   Required: 11 hours
Training: 2025-08-31 05:28:00,216-Speed 365.62 samples/sec   Loss 3.0552 Epoch: 1   Global Step: 5100   Required: 11 hours
Training: 2025-08-31 05:28:17,713-Speed 365.77 samples/sec   Loss 3.0651 Epoch: 1   Global Step: 5150   Required: 11 hours
Training: 2025-08-31 05:28:35,211-Speed 365.76 samples/sec   Loss 3.0793 Epoch: 1   Global Step: 5200   Required: 11 hours
Training: 2025-08-31 05:28:52,711-Speed 365.72 samples/sec   Loss 2.9513 Epoch: 1   Global Step: 5250   Required: 11 hours
Training: 2025-08-31 05:29:10,208-Speed 365.79 samples/sec   Loss 2.9517 Epoch: 1   Global Step: 5300   Required: 11 hours
Training: 2025-08-31 05:29:27,707-Speed 365.73 samples/sec   Loss 2.9033 Epoch: 1   Global Step: 5350   Required: 11 hours
Training: 2025-08-31 05:29:45,201-Speed 365.84 samples/sec   Loss 2.8130 Epoch: 1   Global Step: 5400   Required: 11 hours
Training: 2025-08-31 05:30:02,696-Speed 365.84 samples/sec   Loss 2.8796 Epoch: 1   Global Step: 5450   Required: 11 hours
Training: 2025-08-31 05:30:20,190-Speed 365.84 samples/sec   Loss 2.8835 Epoch: 1   Global Step: 5500   Required: 11 hours
Training: 2025-08-31 05:30:37,684-Speed 365.83 samples/sec   Loss 2.7854 Epoch: 1   Global Step: 5550   Required: 11 hours
Training: 2025-08-31 05:30:55,178-Speed 365.84 samples/sec   Loss 2.6790 Epoch: 1   Global Step: 5600   Required: 11 hours
Training: 2025-08-31 05:31:27,931-[lfw][5624]XNorm: 19.769123
Training: 2025-08-31 05:31:27,931-[lfw][5624]Accuracy-Flip: 0.79283+-0.01502
Training: 2025-08-31 05:31:27,931-[lfw][5624]Accuracy-Highest: 0.79550
Training: 2025-08-31 05:31:56,213-[cfp_fp][5624]XNorm: 17.987895
Training: 2025-08-31 05:31:56,213-[cfp_fp][5624]Accuracy-Flip: 0.63186+-0.01875
Training: 2025-08-31 05:31:56,213-[cfp_fp][5624]Accuracy-Highest: 0.63186
Training: 2025-08-31 05:32:20,553-[agedb_30][5624]XNorm: 17.003965
Training: 2025-08-31 05:32:20,554-[agedb_30][5624]Accuracy-Flip: 0.50867+-0.01487
Training: 2025-08-31 05:32:20,554-[agedb_30][5624]Accuracy-Highest: 0.50867
Training: 2025-08-31 05:32:44,967-[calfw][5624]XNorm: 19.751060
Training: 2025-08-31 05:32:44,967-[calfw][5624]Accuracy-Flip: 0.63233+-0.01601
Training: 2025-08-31 05:32:44,968-[calfw][5624]Accuracy-Highest: 0.63233
Training: 2025-08-31 05:33:09,376-[cplfw][5624]XNorm: 17.233516
Training: 2025-08-31 05:33:09,376-[cplfw][5624]Accuracy-Flip: 0.61083+-0.01313
Training: 2025-08-31 05:33:09,376-[cplfw][5624]Accuracy-Highest: 0.61083
Training: 2025-08-31 05:33:18,631-Speed 44.61 samples/sec   Loss 2.5973 Epoch: 2   Global Step: 5650   Required: 12 hours
Training: 2025-08-31 05:33:36,124-Speed 365.87 samples/sec   Loss 2.2005 Epoch: 2   Global Step: 5700   Required: 12 hours
Training: 2025-08-31 05:33:53,621-Speed 365.78 samples/sec   Loss 2.2682 Epoch: 2   Global Step: 5750   Required: 12 hours
Training: 2025-08-31 05:34:11,115-Speed 365.83 samples/sec   Loss 2.1746 Epoch: 2   Global Step: 5800   Required: 12 hours
Training: 2025-08-31 05:34:28,609-Speed 365.83 samples/sec   Loss 2.2560 Epoch: 2   Global Step: 5850   Required: 12 hours
Training: 2025-08-31 05:34:46,104-Speed 365.83 samples/sec   Loss 2.3115 Epoch: 2   Global Step: 5900   Required: 12 hours
Training: 2025-08-31 05:35:03,600-Speed 365.81 samples/sec   Loss 2.1843 Epoch: 2   Global Step: 5950   Required: 12 hours
Training: 2025-08-31 05:35:21,097-Speed 365.77 samples/sec   Loss 2.2447 Epoch: 2   Global Step: 6000   Required: 12 hours
Training: 2025-08-31 05:35:38,593-Speed 365.80 samples/sec   Loss 2.2201 Epoch: 2   Global Step: 6050   Required: 12 hours
Training: 2025-08-31 05:35:56,087-Speed 365.85 samples/sec   Loss 2.2413 Epoch: 2   Global Step: 6100   Required: 12 hours
Training: 2025-08-31 05:36:13,590-Speed 365.65 samples/sec   Loss 2.1888 Epoch: 2   Global Step: 6150   Required: 12 hours
Training: 2025-08-31 05:36:31,085-Speed 365.82 samples/sec   Loss 2.2245 Epoch: 2   Global Step: 6200   Required: 12 hours
Training: 2025-08-31 05:36:48,589-Speed 365.62 samples/sec   Loss 2.2193 Epoch: 2   Global Step: 6250   Required: 12 hours
Training: 2025-08-31 05:37:06,096-Speed 365.57 samples/sec   Loss 2.2050 Epoch: 2   Global Step: 6300   Required: 12 hours
Training: 2025-08-31 05:37:23,593-Speed 365.78 samples/sec   Loss 2.1452 Epoch: 2   Global Step: 6350   Required: 12 hours
Training: 2025-08-31 05:37:41,088-Speed 365.83 samples/sec   Loss 2.1201 Epoch: 2   Global Step: 6400   Required: 11 hours
Training: 2025-08-31 05:37:58,582-Speed 365.83 samples/sec   Loss 2.0850 Epoch: 2   Global Step: 6450   Required: 11 hours
Training: 2025-08-31 05:38:16,077-Speed 365.82 samples/sec   Loss 2.0993 Epoch: 2   Global Step: 6500   Required: 11 hours
Training: 2025-08-31 05:38:33,572-Speed 365.84 samples/sec   Loss 2.1654 Epoch: 2   Global Step: 6550   Required: 11 hours
Training: 2025-08-31 05:38:51,068-Speed 365.78 samples/sec   Loss 1.9857 Epoch: 2   Global Step: 6600   Required: 11 hours
Training: 2025-08-31 05:39:08,573-Speed 365.63 samples/sec   Loss 2.0430 Epoch: 2   Global Step: 6650   Required: 11 hours
Training: 2025-08-31 05:39:26,068-Speed 365.82 samples/sec   Loss 2.0693 Epoch: 2   Global Step: 6700   Required: 11 hours
Training: 2025-08-31 05:39:43,569-Speed 365.68 samples/sec   Loss 2.0828 Epoch: 2   Global Step: 6750   Required: 11 hours
Training: 2025-08-31 05:40:01,066-Speed 365.78 samples/sec   Loss 1.9983 Epoch: 2   Global Step: 6800   Required: 11 hours
Training: 2025-08-31 05:40:18,558-Speed 365.88 samples/sec   Loss 1.9922 Epoch: 2   Global Step: 6850   Required: 11 hours
Training: 2025-08-31 05:40:36,053-Speed 365.83 samples/sec   Loss 2.0278 Epoch: 2   Global Step: 6900   Required: 11 hours
Training: 2025-08-31 05:40:53,547-Speed 365.83 samples/sec   Loss 1.9433 Epoch: 2   Global Step: 6950   Required: 11 hours
Training: 2025-08-31 05:41:11,044-Speed 365.80 samples/sec   Loss 1.9288 Epoch: 2   Global Step: 7000   Required: 11 hours
Training: 2025-08-31 05:41:28,538-Speed 365.83 samples/sec   Loss 1.9480 Epoch: 2   Global Step: 7050   Required: 11 hours
Training: 2025-08-31 05:41:46,035-Speed 365.78 samples/sec   Loss 1.8875 Epoch: 2   Global Step: 7100   Required: 11 hours
Training: 2025-08-31 05:42:03,542-Speed 365.58 samples/sec   Loss 1.8842 Epoch: 2   Global Step: 7150   Required: 11 hours
Training: 2025-08-31 05:42:21,041-Speed 365.72 samples/sec   Loss 1.9076 Epoch: 2   Global Step: 7200   Required: 11 hours
Training: 2025-08-31 05:42:38,544-Speed 365.67 samples/sec   Loss 1.8549 Epoch: 2   Global Step: 7250   Required: 11 hours
Training: 2025-08-31 05:42:56,046-Speed 365.66 samples/sec   Loss 1.8956 Epoch: 2   Global Step: 7300   Required: 11 hours
Training: 2025-08-31 05:43:13,541-Speed 365.83 samples/sec   Loss 1.8505 Epoch: 2   Global Step: 7350   Required: 11 hours
Training: 2025-08-31 05:43:31,035-Speed 365.83 samples/sec   Loss 1.8378 Epoch: 2   Global Step: 7400   Required: 11 hours
Training: 2025-08-31 05:43:48,530-Speed 365.82 samples/sec   Loss 1.8538 Epoch: 2   Global Step: 7450   Required: 11 hours
Training: 2025-08-31 05:44:06,028-Speed 365.76 samples/sec   Loss 1.8679 Epoch: 2   Global Step: 7500   Required: 11 hours
Training: 2025-08-31 05:44:23,523-Speed 365.81 samples/sec   Loss 1.7858 Epoch: 2   Global Step: 7550   Required: 11 hours
Training: 2025-08-31 05:44:41,016-Speed 365.86 samples/sec   Loss 1.7697 Epoch: 2   Global Step: 7600   Required: 11 hours
Training: 2025-08-31 05:44:58,519-Speed 365.66 samples/sec   Loss 1.8051 Epoch: 2   Global Step: 7650   Required: 11 hours
Training: 2025-08-31 05:45:16,026-Speed 365.57 samples/sec   Loss 1.8195 Epoch: 2   Global Step: 7700   Required: 11 hours
Training: 2025-08-31 05:45:33,527-Speed 365.71 samples/sec   Loss 1.7329 Epoch: 2   Global Step: 7750   Required: 11 hours
Training: 2025-08-31 05:45:51,025-Speed 365.74 samples/sec   Loss 1.7223 Epoch: 2   Global Step: 7800   Required: 11 hours
Training: 2025-08-31 05:46:08,533-Speed 365.55 samples/sec   Loss 1.7452 Epoch: 2   Global Step: 7850   Required: 11 hours
Training: 2025-08-31 05:46:26,036-Speed 365.67 samples/sec   Loss 1.7621 Epoch: 2   Global Step: 7900   Required: 11 hours
Training: 2025-08-31 05:46:43,537-Speed 365.68 samples/sec   Loss 1.6236 Epoch: 2   Global Step: 7950   Required: 11 hours
Training: 2025-08-31 05:47:01,045-Speed 365.55 samples/sec   Loss 1.6802 Epoch: 2   Global Step: 8000   Required: 11 hours
Training: 2025-08-31 05:47:18,546-Speed 365.71 samples/sec   Loss 1.7020 Epoch: 2   Global Step: 8050   Required: 11 hours
Training: 2025-08-31 05:47:36,041-Speed 365.83 samples/sec   Loss 1.6717 Epoch: 2   Global Step: 8100   Required: 11 hours
Training: 2025-08-31 05:47:53,549-Speed 365.53 samples/sec   Loss 1.6462 Epoch: 2   Global Step: 8150   Required: 11 hours
Training: 2025-08-31 05:48:11,045-Speed 365.81 samples/sec   Loss 1.6190 Epoch: 2   Global Step: 8200   Required: 11 hours
Training: 2025-08-31 05:48:28,539-Speed 365.84 samples/sec   Loss 1.6240 Epoch: 2   Global Step: 8250   Required: 11 hours
Training: 2025-08-31 05:48:46,033-Speed 365.84 samples/sec   Loss 1.6392 Epoch: 2   Global Step: 8300   Required: 11 hours
Training: 2025-08-31 05:49:03,528-Speed 365.83 samples/sec   Loss 1.6443 Epoch: 2   Global Step: 8350   Required: 11 hours
Training: 2025-08-31 05:49:21,027-Speed 365.74 samples/sec   Loss 1.6319 Epoch: 2   Global Step: 8400   Required: 11 hours
Training: 2025-08-31 05:49:57,985-[lfw][8436]XNorm: 22.689215
Training: 2025-08-31 05:49:57,985-[lfw][8436]Accuracy-Flip: 0.80267+-0.01713
Training: 2025-08-31 05:49:57,985-[lfw][8436]Accuracy-Highest: 0.80267
Training: 2025-08-31 05:50:26,278-[cfp_fp][8436]XNorm: 19.252284
Training: 2025-08-31 05:50:26,278-[cfp_fp][8436]Accuracy-Flip: 0.63086+-0.02172
Training: 2025-08-31 05:50:26,278-[cfp_fp][8436]Accuracy-Highest: 0.63186
Training: 2025-08-31 05:50:50,610-[agedb_30][8436]XNorm: 17.366606
Training: 2025-08-31 05:50:50,610-[agedb_30][8436]Accuracy-Flip: 0.51550+-0.01892
Training: 2025-08-31 05:50:50,610-[agedb_30][8436]Accuracy-Highest: 0.51550
Training: 2025-08-31 05:51:15,023-[calfw][8436]XNorm: 21.396104
Training: 2025-08-31 05:51:15,023-[calfw][8436]Accuracy-Flip: 0.64833+-0.01593
Training: 2025-08-31 05:51:15,023-[calfw][8436]Accuracy-Highest: 0.64833
Training: 2025-08-31 05:51:39,431-[cplfw][8436]XNorm: 18.881427
Training: 2025-08-31 05:51:39,431-[cplfw][8436]Accuracy-Flip: 0.62450+-0.01472
Training: 2025-08-31 05:51:39,431-[cplfw][8436]Accuracy-Highest: 0.62450
Training: 2025-08-31 05:51:44,470-Speed 44.62 samples/sec   Loss 1.4962 Epoch: 3   Global Step: 8450   Required: 11 hours
Training: 2025-08-31 05:52:01,955-Speed 366.01 samples/sec   Loss 1.2471 Epoch: 3   Global Step: 8500   Required: 11 hours
Training: 2025-08-31 05:52:19,443-Speed 365.97 samples/sec   Loss 1.2703 Epoch: 3   Global Step: 8550   Required: 11 hours
Training: 2025-08-31 05:52:36,939-Speed 365.81 samples/sec   Loss 1.2892 Epoch: 3   Global Step: 8600   Required: 11 hours
Training: 2025-08-31 05:52:54,433-Speed 365.85 samples/sec   Loss 1.3183 Epoch: 3   Global Step: 8650   Required: 11 hours
Training: 2025-08-31 05:53:11,928-Speed 365.81 samples/sec   Loss 1.3248 Epoch: 3   Global Step: 8700   Required: 11 hours
Training: 2025-08-31 05:53:29,423-Speed 365.83 samples/sec   Loss 1.3155 Epoch: 3   Global Step: 8750   Required: 11 hours
Training: 2025-08-31 05:53:46,917-Speed 365.84 samples/sec   Loss 1.3292 Epoch: 3   Global Step: 8800   Required: 11 hours
Training: 2025-08-31 05:54:04,411-Speed 365.82 samples/sec   Loss 1.3071 Epoch: 3   Global Step: 8850   Required: 11 hours
Training: 2025-08-31 05:54:21,909-Speed 365.76 samples/sec   Loss 1.3513 Epoch: 3   Global Step: 8900   Required: 11 hours
Training: 2025-08-31 05:54:39,413-Speed 365.63 samples/sec   Loss 1.3378 Epoch: 3   Global Step: 8950   Required: 11 hours
Training: 2025-08-31 05:54:56,914-Speed 365.71 samples/sec   Loss 1.2959 Epoch: 3   Global Step: 9000   Required: 11 hours
Training: 2025-08-31 05:55:14,413-Speed 365.74 samples/sec   Loss 1.3286 Epoch: 3   Global Step: 9050   Required: 11 hours
Training: 2025-08-31 05:55:31,906-Speed 365.86 samples/sec   Loss 1.3223 Epoch: 3   Global Step: 9100   Required: 11 hours
Training: 2025-08-31 05:55:49,400-Speed 365.84 samples/sec   Loss 1.3160 Epoch: 3   Global Step: 9150   Required: 11 hours
Training: 2025-08-31 05:56:06,896-Speed 365.80 samples/sec   Loss 1.2657 Epoch: 3   Global Step: 9200   Required: 11 hours
Training: 2025-08-31 05:56:24,392-Speed 365.80 samples/sec   Loss 1.2628 Epoch: 3   Global Step: 9250   Required: 11 hours
Training: 2025-08-31 05:56:41,897-Speed 365.60 samples/sec   Loss 1.2907 Epoch: 3   Global Step: 9300   Required: 11 hours
Training: 2025-08-31 05:56:59,405-Speed 365.56 samples/sec   Loss 1.2841 Epoch: 3   Global Step: 9350   Required: 11 hours
Training: 2025-08-31 05:57:16,908-Speed 365.66 samples/sec   Loss 1.3483 Epoch: 3   Global Step: 9400   Required: 11 hours
Training: 2025-08-31 05:57:34,405-Speed 365.78 samples/sec   Loss 1.3137 Epoch: 3   Global Step: 9450   Required: 11 hours
Training: 2025-08-31 05:57:51,901-Speed 365.80 samples/sec   Loss 1.2789 Epoch: 3   Global Step: 9500   Required: 11 hours
Training: 2025-08-31 05:58:09,402-Speed 365.69 samples/sec   Loss 1.3294 Epoch: 3   Global Step: 9550   Required: 11 hours
Training: 2025-08-31 05:58:26,897-Speed 365.83 samples/sec   Loss 1.2847 Epoch: 3   Global Step: 9600   Required: 11 hours
Training: 2025-08-31 05:58:44,391-Speed 365.83 samples/sec   Loss 1.2879 Epoch: 3   Global Step: 9650   Required: 11 hours
Training: 2025-08-31 05:59:01,885-Speed 365.84 samples/sec   Loss 1.2641 Epoch: 3   Global Step: 9700   Required: 11 hours
Training: 2025-08-31 05:59:19,380-Speed 365.82 samples/sec   Loss 1.2607 Epoch: 3   Global Step: 9750   Required: 11 hours
Training: 2025-08-31 05:59:36,878-Speed 365.75 samples/sec   Loss 1.3001 Epoch: 3   Global Step: 9800   Required: 11 hours
Training: 2025-08-31 05:59:54,374-Speed 365.81 samples/sec   Loss 1.2654 Epoch: 3   Global Step: 9850   Required: 11 hours
Training: 2025-08-31 06:00:11,877-Speed 365.66 samples/sec   Loss 1.2634 Epoch: 3   Global Step: 9900   Required: 11 hours
Training: 2025-08-31 06:00:29,371-Speed 365.83 samples/sec   Loss 1.2089 Epoch: 3   Global Step: 9950   Required: 11 hours
Training: 2025-08-31 06:00:46,866-Speed 365.83 samples/sec   Loss 1.2801 Epoch: 3   Global Step: 10000   Required: 11 hours
Training: 2025-08-31 06:01:04,360-Speed 365.83 samples/sec   Loss 1.2601 Epoch: 3   Global Step: 10050   Required: 11 hours
Training: 2025-08-31 06:01:21,854-Speed 365.84 samples/sec   Loss 1.3101 Epoch: 3   Global Step: 10100   Required: 11 hours
Training: 2025-08-31 06:01:39,357-Speed 365.64 samples/sec   Loss 1.2783 Epoch: 3   Global Step: 10150   Required: 11 hours
Training: 2025-08-31 06:01:56,853-Speed 365.81 samples/sec   Loss 1.2406 Epoch: 3   Global Step: 10200   Required: 11 hours
Training: 2025-08-31 06:02:14,346-Speed 365.85 samples/sec   Loss 1.2049 Epoch: 3   Global Step: 10250   Required: 11 hours
Training: 2025-08-31 06:02:31,841-Speed 365.82 samples/sec   Loss 1.2588 Epoch: 3   Global Step: 10300   Required: 11 hours
Training: 2025-08-31 06:02:49,335-Speed 365.85 samples/sec   Loss 1.2288 Epoch: 3   Global Step: 10350   Required: 11 hours
Training: 2025-08-31 06:03:06,827-Speed 365.90 samples/sec   Loss 1.3020 Epoch: 3   Global Step: 10400   Required: 11 hours
Training: 2025-08-31 06:03:24,323-Speed 365.80 samples/sec   Loss 1.2641 Epoch: 3   Global Step: 10450   Required: 11 hours
Training: 2025-08-31 06:03:41,818-Speed 365.81 samples/sec   Loss 1.1981 Epoch: 3   Global Step: 10500   Required: 11 hours
Training: 2025-08-31 06:03:59,309-Speed 365.90 samples/sec   Loss 1.2698 Epoch: 3   Global Step: 10550   Required: 11 hours
Training: 2025-08-31 06:04:16,806-Speed 365.78 samples/sec   Loss 1.2338 Epoch: 3   Global Step: 10600   Required: 11 hours
Training: 2025-08-31 06:04:34,303-Speed 365.80 samples/sec   Loss 1.2060 Epoch: 3   Global Step: 10650   Required: 11 hours
Training: 2025-08-31 06:04:51,795-Speed 365.87 samples/sec   Loss 1.1604 Epoch: 3   Global Step: 10700   Required: 11 hours
Training: 2025-08-31 06:05:09,291-Speed 365.81 samples/sec   Loss 1.1412 Epoch: 3   Global Step: 10750   Required: 11 hours
Training: 2025-08-31 06:05:26,784-Speed 365.86 samples/sec   Loss 1.1910 Epoch: 3   Global Step: 10800   Required: 11 hours
Training: 2025-08-31 06:05:44,284-Speed 365.70 samples/sec   Loss 1.2096 Epoch: 3   Global Step: 10850   Required: 11 hours
Training: 2025-08-31 06:06:01,784-Speed 365.72 samples/sec   Loss 1.2500 Epoch: 3   Global Step: 10900   Required: 11 hours
Training: 2025-08-31 06:06:19,285-Speed 365.71 samples/sec   Loss 1.1479 Epoch: 3   Global Step: 10950   Required: 11 hours
Training: 2025-08-31 06:06:36,788-Speed 365.64 samples/sec   Loss 1.1542 Epoch: 3   Global Step: 11000   Required: 11 hours
Training: 2025-08-31 06:06:54,288-Speed 365.73 samples/sec   Loss 1.1895 Epoch: 3   Global Step: 11050   Required: 11 hours
Training: 2025-08-31 06:07:11,791-Speed 365.66 samples/sec   Loss 1.1013 Epoch: 3   Global Step: 11100   Required: 11 hours
Training: 2025-08-31 06:07:29,286-Speed 365.82 samples/sec   Loss 1.1201 Epoch: 3   Global Step: 11150   Required: 11 hours
Training: 2025-08-31 06:07:46,791-Speed 365.60 samples/sec   Loss 1.1492 Epoch: 3   Global Step: 11200   Required: 11 hours
Training: 2025-08-31 06:08:27,938-[lfw][11248]XNorm: 18.446319
Training: 2025-08-31 06:08:27,938-[lfw][11248]Accuracy-Flip: 0.81533+-0.02030
Training: 2025-08-31 06:08:27,938-[lfw][11248]Accuracy-Highest: 0.81533
Training: 2025-08-31 06:08:56,293-[cfp_fp][11248]XNorm: 16.132176
Training: 2025-08-31 06:08:56,293-[cfp_fp][11248]Accuracy-Flip: 0.65129+-0.02246
Training: 2025-08-31 06:08:56,293-[cfp_fp][11248]Accuracy-Highest: 0.65129
Training: 2025-08-31 06:09:20,629-[agedb_30][11248]XNorm: 15.613917
Training: 2025-08-31 06:09:20,629-[agedb_30][11248]Accuracy-Flip: 0.51750+-0.02343
Training: 2025-08-31 06:09:20,629-[agedb_30][11248]Accuracy-Highest: 0.51750
Training: 2025-08-31 06:09:45,048-[calfw][11248]XNorm: 18.389429
Training: 2025-08-31 06:09:45,048-[calfw][11248]Accuracy-Flip: 0.66350+-0.02009
Training: 2025-08-31 06:09:45,049-[calfw][11248]Accuracy-Highest: 0.66350
Training: 2025-08-31 06:10:09,463-[cplfw][11248]XNorm: 15.518269
Training: 2025-08-31 06:10:09,463-[cplfw][11248]Accuracy-Flip: 0.62900+-0.01344
Training: 2025-08-31 06:10:09,463-[cplfw][11248]Accuracy-Highest: 0.62900
Training: 2025-08-31 06:10:10,328-Speed 44.59 samples/sec   Loss 1.1562 Epoch: 4   Global Step: 11250   Required: 11 hours
Training: 2025-08-31 06:10:27,823-Speed 365.81 samples/sec   Loss 0.9664 Epoch: 4   Global Step: 11300   Required: 11 hours
Training: 2025-08-31 06:10:45,317-Speed 365.85 samples/sec   Loss 0.9778 Epoch: 4   Global Step: 11350   Required: 11 hours
Training: 2025-08-31 06:11:02,812-Speed 365.81 samples/sec   Loss 0.9477 Epoch: 4   Global Step: 11400   Required: 11 hours
Training: 2025-08-31 06:11:20,307-Speed 365.81 samples/sec   Loss 0.9601 Epoch: 4   Global Step: 11450   Required: 11 hours
Training: 2025-08-31 06:11:37,801-Speed 365.85 samples/sec   Loss 0.9043 Epoch: 4   Global Step: 11500   Required: 11 hours
Training: 2025-08-31 06:11:55,297-Speed 365.81 samples/sec   Loss 0.9529 Epoch: 4   Global Step: 11550   Required: 11 hours
Training: 2025-08-31 06:12:12,791-Speed 365.83 samples/sec   Loss 0.9459 Epoch: 4   Global Step: 11600   Required: 11 hours
Training: 2025-08-31 06:12:30,288-Speed 365.80 samples/sec   Loss 0.9510 Epoch: 4   Global Step: 11650   Required: 11 hours
Training: 2025-08-31 06:12:47,782-Speed 365.83 samples/sec   Loss 1.0281 Epoch: 4   Global Step: 11700   Required: 11 hours
Training: 2025-08-31 06:13:05,277-Speed 365.83 samples/sec   Loss 0.9615 Epoch: 4   Global Step: 11750   Required: 11 hours
Training: 2025-08-31 06:13:22,771-Speed 365.83 samples/sec   Loss 0.9560 Epoch: 4   Global Step: 11800   Required: 11 hours
Training: 2025-08-31 06:13:40,265-Speed 365.85 samples/sec   Loss 0.9636 Epoch: 4   Global Step: 11850   Required: 11 hours
Training: 2025-08-31 06:13:57,759-Speed 365.84 samples/sec   Loss 0.9854 Epoch: 4   Global Step: 11900   Required: 11 hours
Training: 2025-08-31 06:14:15,251-Speed 365.89 samples/sec   Loss 0.9658 Epoch: 4   Global Step: 11950   Required: 11 hours
Training: 2025-08-31 06:14:32,747-Speed 365.81 samples/sec   Loss 1.0046 Epoch: 4   Global Step: 12000   Required: 11 hours
Training: 2025-08-31 06:14:50,243-Speed 365.79 samples/sec   Loss 0.9899 Epoch: 4   Global Step: 12050   Required: 11 hours
Training: 2025-08-31 06:15:07,737-Speed 365.85 samples/sec   Loss 0.9738 Epoch: 4   Global Step: 12100   Required: 11 hours
Training: 2025-08-31 06:15:25,232-Speed 365.82 samples/sec   Loss 1.0143 Epoch: 4   Global Step: 12150   Required: 11 hours
Training: 2025-08-31 06:15:42,727-Speed 365.82 samples/sec   Loss 0.9807 Epoch: 4   Global Step: 12200   Required: 11 hours
Training: 2025-08-31 06:16:00,231-Speed 365.63 samples/sec   Loss 0.9600 Epoch: 4   Global Step: 12250   Required: 11 hours
Training: 2025-08-31 06:16:17,735-Speed 365.64 samples/sec   Loss 0.9844 Epoch: 4   Global Step: 12300   Required: 11 hours
Training: 2025-08-31 06:16:35,235-Speed 365.72 samples/sec   Loss 1.0002 Epoch: 4   Global Step: 12350   Required: 11 hours
Training: 2025-08-31 06:16:52,733-Speed 365.76 samples/sec   Loss 1.0104 Epoch: 4   Global Step: 12400   Required: 11 hours
Training: 2025-08-31 06:17:10,233-Speed 365.73 samples/sec   Loss 0.9808 Epoch: 4   Global Step: 12450   Required: 11 hours
Training: 2025-08-31 06:17:27,732-Speed 365.74 samples/sec   Loss 0.9853 Epoch: 4   Global Step: 12500   Required: 11 hours
Training: 2025-08-31 06:17:45,223-Speed 365.90 samples/sec   Loss 0.9794 Epoch: 4   Global Step: 12550   Required: 11 hours
Training: 2025-08-31 06:18:02,721-Speed 365.77 samples/sec   Loss 0.9770 Epoch: 4   Global Step: 12600   Required: 11 hours
Training: 2025-08-31 06:18:20,215-Speed 365.84 samples/sec   Loss 1.0213 Epoch: 4   Global Step: 12650   Required: 11 hours
Training: 2025-08-31 06:18:37,710-Speed 365.81 samples/sec   Loss 1.0557 Epoch: 4   Global Step: 12700   Required: 11 hours
Training: 2025-08-31 06:18:55,204-Speed 365.84 samples/sec   Loss 0.9794 Epoch: 4   Global Step: 12750   Required: 11 hours
Training: 2025-08-31 06:19:12,696-Speed 365.90 samples/sec   Loss 1.0055 Epoch: 4   Global Step: 12800   Required: 11 hours
Training: 2025-08-31 06:19:30,189-Speed 365.86 samples/sec   Loss 0.9609 Epoch: 4   Global Step: 12850   Required: 11 hours
Training: 2025-08-31 06:19:47,684-Speed 365.81 samples/sec   Loss 1.0517 Epoch: 4   Global Step: 12900   Required: 11 hours
Training: 2025-08-31 06:20:05,177-Speed 365.86 samples/sec   Loss 0.9983 Epoch: 4   Global Step: 12950   Required: 11 hours
Training: 2025-08-31 06:20:22,672-Speed 365.83 samples/sec   Loss 0.9492 Epoch: 4   Global Step: 13000   Required: 11 hours
Training: 2025-08-31 06:20:40,167-Speed 365.81 samples/sec   Loss 1.0062 Epoch: 4   Global Step: 13050   Required: 11 hours
Training: 2025-08-31 06:20:57,661-Speed 365.85 samples/sec   Loss 0.9871 Epoch: 4   Global Step: 13100   Required: 11 hours
Training: 2025-08-31 06:21:15,155-Speed 365.84 samples/sec   Loss 1.0062 Epoch: 4   Global Step: 13150   Required: 11 hours
Training: 2025-08-31 06:21:32,650-Speed 365.82 samples/sec   Loss 0.9451 Epoch: 4   Global Step: 13200   Required: 11 hours
Training: 2025-08-31 06:21:50,143-Speed 365.86 samples/sec   Loss 0.9580 Epoch: 4   Global Step: 13250   Required: 11 hours
Training: 2025-08-31 06:22:07,639-Speed 365.81 samples/sec   Loss 0.9742 Epoch: 4   Global Step: 13300   Required: 11 hours
Training: 2025-08-31 06:22:25,135-Speed 365.80 samples/sec   Loss 0.9889 Epoch: 4   Global Step: 13350   Required: 11 hours
Training: 2025-08-31 06:22:42,630-Speed 365.82 samples/sec   Loss 0.9706 Epoch: 4   Global Step: 13400   Required: 11 hours
Training: 2025-08-31 06:23:00,124-Speed 365.84 samples/sec   Loss 0.9953 Epoch: 4   Global Step: 13450   Required: 11 hours
Training: 2025-08-31 06:23:17,618-Speed 365.85 samples/sec   Loss 0.9417 Epoch: 4   Global Step: 13500   Required: 11 hours
Training: 2025-08-31 06:23:35,110-Speed 365.88 samples/sec   Loss 0.9522 Epoch: 4   Global Step: 13550   Required: 11 hours
Training: 2025-08-31 06:23:52,605-Speed 365.83 samples/sec   Loss 0.9613 Epoch: 4   Global Step: 13600   Required: 11 hours
Training: 2025-08-31 06:24:10,098-Speed 365.85 samples/sec   Loss 0.9150 Epoch: 4   Global Step: 13650   Required: 11 hours
Training: 2025-08-31 06:24:27,595-Speed 365.79 samples/sec   Loss 0.9824 Epoch: 4   Global Step: 13700   Required: 11 hours
Training: 2025-08-31 06:24:45,087-Speed 365.88 samples/sec   Loss 0.9446 Epoch: 4   Global Step: 13750   Required: 11 hours
Training: 2025-08-31 06:25:02,582-Speed 365.83 samples/sec   Loss 0.9333 Epoch: 4   Global Step: 13800   Required: 11 hours
Training: 2025-08-31 06:25:20,076-Speed 365.85 samples/sec   Loss 0.9673 Epoch: 4   Global Step: 13850   Required: 11 hours
Training: 2025-08-31 06:25:37,572-Speed 365.80 samples/sec   Loss 0.9208 Epoch: 4   Global Step: 13900   Required: 11 hours
Training: 2025-08-31 06:25:55,065-Speed 365.85 samples/sec   Loss 0.9321 Epoch: 4   Global Step: 13950   Required: 11 hours
Training: 2025-08-31 06:26:12,559-Speed 365.85 samples/sec   Loss 0.9091 Epoch: 4   Global Step: 14000   Required: 11 hours
Training: 2025-08-31 06:26:30,054-Speed 365.82 samples/sec   Loss 0.9706 Epoch: 4   Global Step: 14050   Required: 11 hours
Training: 2025-08-31 06:26:57,900-[lfw][14060]XNorm: 18.067450
Training: 2025-08-31 06:26:57,900-[lfw][14060]Accuracy-Flip: 0.81633+-0.02077
Training: 2025-08-31 06:26:57,900-[lfw][14060]Accuracy-Highest: 0.81633
Training: 2025-08-31 06:27:26,236-[cfp_fp][14060]XNorm: 16.085686
Training: 2025-08-31 06:27:26,237-[cfp_fp][14060]Accuracy-Flip: 0.64271+-0.01392
Training: 2025-08-31 06:27:26,237-[cfp_fp][14060]Accuracy-Highest: 0.65129
Training: 2025-08-31 06:27:50,573-[agedb_30][14060]XNorm: 16.627052
Training: 2025-08-31 06:27:50,573-[agedb_30][14060]Accuracy-Flip: 0.52100+-0.01795
Training: 2025-08-31 06:27:50,573-[agedb_30][14060]Accuracy-Highest: 0.52100
Training: 2025-08-31 06:28:14,998-[calfw][14060]XNorm: 18.165317
Training: 2025-08-31 06:28:14,998-[calfw][14060]Accuracy-Flip: 0.65217+-0.01578
Training: 2025-08-31 06:28:14,998-[calfw][14060]Accuracy-Highest: 0.66350
Training: 2025-08-31 06:28:39,405-[cplfw][14060]XNorm: 15.268021
Training: 2025-08-31 06:28:39,406-[cplfw][14060]Accuracy-Flip: 0.62500+-0.01118
Training: 2025-08-31 06:28:39,406-[cplfw][14060]Accuracy-Highest: 0.62900
Training: 2025-08-31 06:28:53,550-Speed 44.60 samples/sec   Loss 0.7873 Epoch: 5   Global Step: 14100   Required: 11 hours
Training: 2025-08-31 06:29:11,040-Speed 365.91 samples/sec   Loss 0.7529 Epoch: 5   Global Step: 14150   Required: 11 hours
Training: 2025-08-31 06:29:28,535-Speed 365.83 samples/sec   Loss 0.7714 Epoch: 5   Global Step: 14200   Required: 11 hours
Training: 2025-08-31 06:29:46,030-Speed 365.82 samples/sec   Loss 0.7648 Epoch: 5   Global Step: 14250   Required: 11 hours
Training: 2025-08-31 06:30:03,525-Speed 365.82 samples/sec   Loss 0.7825 Epoch: 5   Global Step: 14300   Required: 11 hours
Training: 2025-08-31 06:30:21,019-Speed 365.84 samples/sec   Loss 0.8039 Epoch: 5   Global Step: 14350   Required: 11 hours
Training: 2025-08-31 06:30:38,514-Speed 365.83 samples/sec   Loss 0.8123 Epoch: 5   Global Step: 14400   Required: 11 hours
Training: 2025-08-31 06:30:56,008-Speed 365.84 samples/sec   Loss 0.7850 Epoch: 5   Global Step: 14450   Required: 11 hours
Training: 2025-08-31 06:31:13,502-Speed 365.84 samples/sec   Loss 0.8315 Epoch: 5   Global Step: 14500   Required: 11 hours
Training: 2025-08-31 06:31:31,007-Speed 365.61 samples/sec   Loss 0.8191 Epoch: 5   Global Step: 14550   Required: 11 hours
Training: 2025-08-31 06:31:48,504-Speed 365.78 samples/sec   Loss 0.7923 Epoch: 5   Global Step: 14600   Required: 11 hours
Training: 2025-08-31 06:32:06,000-Speed 365.81 samples/sec   Loss 0.8394 Epoch: 5   Global Step: 14650   Required: 11 hours
Training: 2025-08-31 06:32:23,494-Speed 365.83 samples/sec   Loss 0.7918 Epoch: 5   Global Step: 14700   Required: 11 hours
Training: 2025-08-31 06:32:40,988-Speed 365.84 samples/sec   Loss 0.8198 Epoch: 5   Global Step: 14750   Required: 11 hours
Training: 2025-08-31 06:32:58,483-Speed 365.83 samples/sec   Loss 0.7996 Epoch: 5   Global Step: 14800   Required: 11 hours
Training: 2025-08-31 06:33:15,977-Speed 365.85 samples/sec   Loss 0.8347 Epoch: 5   Global Step: 14850   Required: 11 hours
Training: 2025-08-31 06:33:33,478-Speed 365.68 samples/sec   Loss 0.8183 Epoch: 5   Global Step: 14900   Required: 11 hours
Training: 2025-08-31 06:33:50,975-Speed 365.79 samples/sec   Loss 0.8316 Epoch: 5   Global Step: 14950   Required: 11 hours
Training: 2025-08-31 06:34:08,470-Speed 365.83 samples/sec   Loss 0.8487 Epoch: 5   Global Step: 15000   Required: 11 hours
Training: 2025-08-31 06:34:25,963-Speed 365.85 samples/sec   Loss 0.8453 Epoch: 5   Global Step: 15050   Required: 11 hours
Training: 2025-08-31 06:34:43,458-Speed 365.83 samples/sec   Loss 0.7971 Epoch: 5   Global Step: 15100   Required: 11 hours
Training: 2025-08-31 06:35:00,950-Speed 365.88 samples/sec   Loss 0.8508 Epoch: 5   Global Step: 15150   Required: 11 hours
Training: 2025-08-31 06:35:18,447-Speed 365.78 samples/sec   Loss 0.8418 Epoch: 5   Global Step: 15200   Required: 11 hours
Training: 2025-08-31 06:35:35,941-Speed 365.84 samples/sec   Loss 0.8412 Epoch: 5   Global Step: 15250   Required: 11 hours
Training: 2025-08-31 06:35:53,443-Speed 365.67 samples/sec   Loss 0.8234 Epoch: 5   Global Step: 15300   Required: 11 hours
Training: 2025-08-31 06:36:10,940-Speed 365.78 samples/sec   Loss 0.8020 Epoch: 5   Global Step: 15350   Required: 11 hours
Training: 2025-08-31 06:36:28,440-Speed 365.72 samples/sec   Loss 0.8523 Epoch: 5   Global Step: 15400   Required: 11 hours
Training: 2025-08-31 06:36:45,938-Speed 365.76 samples/sec   Loss 0.8451 Epoch: 5   Global Step: 15450   Required: 11 hours
Training: 2025-08-31 06:37:03,433-Speed 365.83 samples/sec   Loss 0.9209 Epoch: 5   Global Step: 15500   Required: 11 hours
Training: 2025-08-31 06:37:20,927-Speed 365.84 samples/sec   Loss 0.8417 Epoch: 5   Global Step: 15550   Required: 11 hours
Training: 2025-08-31 06:37:38,425-Speed 365.76 samples/sec   Loss 0.8376 Epoch: 5   Global Step: 15600   Required: 11 hours
Training: 2025-08-31 06:37:55,923-Speed 365.75 samples/sec   Loss 0.8410 Epoch: 5   Global Step: 15650   Required: 11 hours
Training: 2025-08-31 06:38:13,418-Speed 365.82 samples/sec   Loss 0.8329 Epoch: 5   Global Step: 15700   Required: 10 hours
Training: 2025-08-31 06:38:30,911-Speed 365.86 samples/sec   Loss 0.8325 Epoch: 5   Global Step: 15750   Required: 10 hours
Training: 2025-08-31 06:38:48,409-Speed 365.77 samples/sec   Loss 0.8080 Epoch: 5   Global Step: 15800   Required: 10 hours
Training: 2025-08-31 06:39:05,907-Speed 365.75 samples/sec   Loss 0.8274 Epoch: 5   Global Step: 15850   Required: 10 hours
Training: 2025-08-31 06:39:23,405-Speed 365.76 samples/sec   Loss 0.7928 Epoch: 5   Global Step: 15900   Required: 10 hours
Training: 2025-08-31 06:39:40,899-Speed 365.83 samples/sec   Loss 0.8459 Epoch: 5   Global Step: 15950   Required: 10 hours
Training: 2025-08-31 06:39:58,394-Speed 365.84 samples/sec   Loss 0.8406 Epoch: 5   Global Step: 16000   Required: 10 hours
Training: 2025-08-31 06:40:15,887-Speed 365.85 samples/sec   Loss 0.8034 Epoch: 5   Global Step: 16050   Required: 10 hours
Training: 2025-08-31 06:40:33,383-Speed 365.82 samples/sec   Loss 0.8270 Epoch: 5   Global Step: 16100   Required: 10 hours
Training: 2025-08-31 06:40:50,876-Speed 365.85 samples/sec   Loss 0.8292 Epoch: 5   Global Step: 16150   Required: 10 hours
Training: 2025-08-31 06:41:08,371-Speed 365.82 samples/sec   Loss 0.8092 Epoch: 5   Global Step: 16200   Required: 10 hours
Training: 2025-08-31 06:41:25,865-Speed 365.85 samples/sec   Loss 0.8203 Epoch: 5   Global Step: 16250   Required: 10 hours
Training: 2025-08-31 06:41:43,359-Speed 365.84 samples/sec   Loss 0.8724 Epoch: 5   Global Step: 16300   Required: 10 hours
Training: 2025-08-31 06:42:00,854-Speed 365.82 samples/sec   Loss 0.8133 Epoch: 5   Global Step: 16350   Required: 10 hours
Training: 2025-08-31 06:42:18,349-Speed 365.83 samples/sec   Loss 0.8056 Epoch: 5   Global Step: 16400   Required: 10 hours
Training: 2025-08-31 06:42:35,842-Speed 365.86 samples/sec   Loss 0.8204 Epoch: 5   Global Step: 16450   Required: 10 hours
Training: 2025-08-31 06:42:53,337-Speed 365.82 samples/sec   Loss 0.7968 Epoch: 5   Global Step: 16500   Required: 10 hours
Training: 2025-08-31 06:43:10,831-Speed 365.84 samples/sec   Loss 0.8075 Epoch: 5   Global Step: 16550   Required: 10 hours
Training: 2025-08-31 06:43:28,325-Speed 365.84 samples/sec   Loss 0.8073 Epoch: 5   Global Step: 16600   Required: 10 hours
Training: 2025-08-31 06:43:45,820-Speed 365.83 samples/sec   Loss 0.8088 Epoch: 5   Global Step: 16650   Required: 10 hours
Training: 2025-08-31 06:44:03,315-Speed 365.81 samples/sec   Loss 0.7763 Epoch: 5   Global Step: 16700   Required: 10 hours
Training: 2025-08-31 06:44:20,821-Speed 365.61 samples/sec   Loss 0.8368 Epoch: 5   Global Step: 16750   Required: 10 hours
Training: 2025-08-31 06:44:38,317-Speed 365.79 samples/sec   Loss 0.8185 Epoch: 5   Global Step: 16800   Required: 10 hours
Training: 2025-08-31 06:44:55,811-Speed 365.85 samples/sec   Loss 0.8286 Epoch: 5   Global Step: 16850   Required: 10 hours
Training: 2025-08-31 06:45:27,961-[lfw][16872]XNorm: 17.177469
Training: 2025-08-31 06:45:27,961-[lfw][16872]Accuracy-Flip: 0.81167+-0.01894
Training: 2025-08-31 06:45:27,961-[lfw][16872]Accuracy-Highest: 0.81633
Training: 2025-08-31 06:45:56,357-[cfp_fp][16872]XNorm: 14.992739
Training: 2025-08-31 06:45:56,357-[cfp_fp][16872]Accuracy-Flip: 0.65614+-0.01625
Training: 2025-08-31 06:45:56,357-[cfp_fp][16872]Accuracy-Highest: 0.65614
Training: 2025-08-31 06:46:20,686-[agedb_30][16872]XNorm: 14.212611
Training: 2025-08-31 06:46:20,686-[agedb_30][16872]Accuracy-Flip: 0.52933+-0.01680
Training: 2025-08-31 06:46:20,686-[agedb_30][16872]Accuracy-Highest: 0.52933
Training: 2025-08-31 06:46:45,095-[calfw][16872]XNorm: 16.912171
Training: 2025-08-31 06:46:45,095-[calfw][16872]Accuracy-Flip: 0.65133+-0.01845
Training: 2025-08-31 06:46:45,095-[calfw][16872]Accuracy-Highest: 0.66350
Training: 2025-08-31 06:47:09,500-[cplfw][16872]XNorm: 14.105131
Training: 2025-08-31 06:47:09,500-[cplfw][16872]Accuracy-Flip: 0.62500+-0.01098
Training: 2025-08-31 06:47:09,500-[cplfw][16872]Accuracy-Highest: 0.62900
Training: 2025-08-31 06:47:19,479-Speed 44.55 samples/sec   Loss 0.7423 Epoch: 6   Global Step: 16900   Required: 10 hours
Training: 2025-08-31 06:47:36,965-Speed 366.00 samples/sec   Loss 0.7039 Epoch: 6   Global Step: 16950   Required: 10 hours
Training: 2025-08-31 06:47:54,460-Speed 365.82 samples/sec   Loss 0.6676 Epoch: 6   Global Step: 17000   Required: 10 hours
Training: 2025-08-31 06:48:11,954-Speed 365.85 samples/sec   Loss 0.6560 Epoch: 6   Global Step: 17050   Required: 10 hours
Training: 2025-08-31 06:48:29,449-Speed 365.83 samples/sec   Loss 0.7016 Epoch: 6   Global Step: 17100   Required: 10 hours
Training: 2025-08-31 06:48:46,945-Speed 365.78 samples/sec   Loss 0.6935 Epoch: 6   Global Step: 17150   Required: 10 hours
Training: 2025-08-31 06:49:04,451-Speed 365.60 samples/sec   Loss 0.6752 Epoch: 6   Global Step: 17200   Required: 10 hours
Training: 2025-08-31 06:49:21,959-Speed 365.54 samples/sec   Loss 0.6600 Epoch: 6   Global Step: 17250   Required: 10 hours
Training: 2025-08-31 06:49:39,470-Speed 365.49 samples/sec   Loss 0.6976 Epoch: 6   Global Step: 17300   Required: 10 hours
Training: 2025-08-31 06:49:56,982-Speed 365.47 samples/sec   Loss 0.6785 Epoch: 6   Global Step: 17350   Required: 10 hours
Training: 2025-08-31 06:50:14,495-Speed 365.45 samples/sec   Loss 0.6871 Epoch: 6   Global Step: 17400   Required: 10 hours
Training: 2025-08-31 06:50:32,003-Speed 365.55 samples/sec   Loss 0.7339 Epoch: 6   Global Step: 17450   Required: 10 hours
Training: 2025-08-31 06:50:49,516-Speed 365.44 samples/sec   Loss 0.6952 Epoch: 6   Global Step: 17500   Required: 10 hours
Training: 2025-08-31 06:51:07,024-Speed 365.56 samples/sec   Loss 0.7031 Epoch: 6   Global Step: 17550   Required: 10 hours
Training: 2025-08-31 06:51:24,524-Speed 365.71 samples/sec   Loss 0.7530 Epoch: 6   Global Step: 17600   Required: 10 hours
Training: 2025-08-31 06:51:42,029-Speed 365.62 samples/sec   Loss 0.7169 Epoch: 6   Global Step: 17650   Required: 10 hours
Training: 2025-08-31 06:51:59,523-Speed 365.82 samples/sec   Loss 0.6754 Epoch: 6   Global Step: 17700   Required: 10 hours
Training: 2025-08-31 06:52:17,018-Speed 365.82 samples/sec   Loss 0.7501 Epoch: 6   Global Step: 17750   Required: 10 hours
Training: 2025-08-31 06:52:34,513-Speed 365.83 samples/sec   Loss 0.7674 Epoch: 6   Global Step: 17800   Required: 10 hours
Training: 2025-08-31 06:52:52,007-Speed 365.83 samples/sec   Loss 0.7119 Epoch: 6   Global Step: 17850   Required: 10 hours
Training: 2025-08-31 06:53:09,501-Speed 365.84 samples/sec   Loss 0.7266 Epoch: 6   Global Step: 17900   Required: 10 hours
Training: 2025-08-31 06:53:26,995-Speed 365.84 samples/sec   Loss 0.7327 Epoch: 6   Global Step: 17950   Required: 10 hours
Training: 2025-08-31 06:53:44,489-Speed 365.85 samples/sec   Loss 0.7573 Epoch: 6   Global Step: 18000   Required: 10 hours
Training: 2025-08-31 06:54:01,984-Speed 365.83 samples/sec   Loss 0.7180 Epoch: 6   Global Step: 18050   Required: 10 hours
Training: 2025-08-31 06:54:19,478-Speed 365.84 samples/sec   Loss 0.7702 Epoch: 6   Global Step: 18100   Required: 10 hours
Training: 2025-08-31 06:54:36,981-Speed 365.66 samples/sec   Loss 0.7487 Epoch: 6   Global Step: 18150   Required: 10 hours
Training: 2025-08-31 06:54:54,484-Speed 365.64 samples/sec   Loss 0.7191 Epoch: 6   Global Step: 18200   Required: 10 hours
Training: 2025-08-31 06:55:11,981-Speed 365.78 samples/sec   Loss 0.8026 Epoch: 6   Global Step: 18250   Required: 10 hours
Training: 2025-08-31 06:55:29,484-Speed 365.66 samples/sec   Loss 0.7290 Epoch: 6   Global Step: 18300   Required: 10 hours
Training: 2025-08-31 06:55:46,977-Speed 365.87 samples/sec   Loss 0.7929 Epoch: 6   Global Step: 18350   Required: 10 hours
Training: 2025-08-31 06:56:04,474-Speed 365.76 samples/sec   Loss 0.7261 Epoch: 6   Global Step: 18400   Required: 10 hours
Training: 2025-08-31 06:56:21,972-Speed 365.76 samples/sec   Loss 0.7759 Epoch: 6   Global Step: 18450   Required: 10 hours
Training: 2025-08-31 06:56:39,479-Speed 365.59 samples/sec   Loss 0.7776 Epoch: 6   Global Step: 18500   Required: 10 hours
Training: 2025-08-31 06:56:56,989-Speed 365.50 samples/sec   Loss 0.6971 Epoch: 6   Global Step: 18550   Required: 10 hours
Training: 2025-08-31 06:57:14,491-Speed 365.68 samples/sec   Loss 0.7172 Epoch: 6   Global Step: 18600   Required: 10 hours
Training: 2025-08-31 06:57:31,991-Speed 365.71 samples/sec   Loss 0.7587 Epoch: 6   Global Step: 18650   Required: 10 hours
Training: 2025-08-31 06:57:49,490-Speed 365.73 samples/sec   Loss 0.7314 Epoch: 6   Global Step: 18700   Required: 10 hours
Training: 2025-08-31 06:58:06,985-Speed 365.83 samples/sec   Loss 0.7410 Epoch: 6   Global Step: 18750   Required: 10 hours
Training: 2025-08-31 06:58:24,488-Speed 365.65 samples/sec   Loss 0.7584 Epoch: 6   Global Step: 18800   Required: 10 hours
Training: 2025-08-31 06:58:41,991-Speed 365.66 samples/sec   Loss 0.7680 Epoch: 6   Global Step: 18850   Required: 10 hours
Training: 2025-08-31 06:58:59,489-Speed 365.77 samples/sec   Loss 0.7290 Epoch: 6   Global Step: 18900   Required: 10 hours
Training: 2025-08-31 06:59:16,992-Speed 365.65 samples/sec   Loss 0.7434 Epoch: 6   Global Step: 18950   Required: 10 hours
Training: 2025-08-31 06:59:34,493-Speed 365.69 samples/sec   Loss 0.7176 Epoch: 6   Global Step: 19000   Required: 10 hours
Training: 2025-08-31 06:59:51,989-Speed 365.80 samples/sec   Loss 0.7492 Epoch: 6   Global Step: 19050   Required: 10 hours
Training: 2025-08-31 07:00:09,486-Speed 365.79 samples/sec   Loss 0.7255 Epoch: 6   Global Step: 19100   Required: 10 hours
Training: 2025-08-31 07:00:26,981-Speed 365.83 samples/sec   Loss 0.6951 Epoch: 6   Global Step: 19150   Required: 10 hours
Training: 2025-08-31 07:00:44,481-Speed 365.71 samples/sec   Loss 0.7557 Epoch: 6   Global Step: 19200   Required: 10 hours
Training: 2025-08-31 07:01:01,975-Speed 365.84 samples/sec   Loss 0.7419 Epoch: 6   Global Step: 19250   Required: 10 hours
Training: 2025-08-31 07:01:19,473-Speed 365.75 samples/sec   Loss 0.7519 Epoch: 6   Global Step: 19300   Required: 10 hours
Training: 2025-08-31 07:01:36,967-Speed 365.85 samples/sec   Loss 0.7561 Epoch: 6   Global Step: 19350   Required: 10 hours
Training: 2025-08-31 07:01:54,460-Speed 365.87 samples/sec   Loss 0.7379 Epoch: 6   Global Step: 19400   Required: 10 hours
Training: 2025-08-31 07:02:11,952-Speed 365.88 samples/sec   Loss 0.7502 Epoch: 6   Global Step: 19450   Required: 10 hours
Training: 2025-08-31 07:02:29,447-Speed 365.82 samples/sec   Loss 0.7211 Epoch: 6   Global Step: 19500   Required: 10 hours
Training: 2025-08-31 07:02:46,945-Speed 365.77 samples/sec   Loss 0.7518 Epoch: 6   Global Step: 19550   Required: 10 hours
Training: 2025-08-31 07:03:04,443-Speed 365.75 samples/sec   Loss 0.7015 Epoch: 6   Global Step: 19600   Required: 10 hours
Training: 2025-08-31 07:03:21,940-Speed 365.77 samples/sec   Loss 0.7116 Epoch: 6   Global Step: 19650   Required: 10 hours
Training: 2025-08-31 07:03:58,184-[lfw][19684]XNorm: 18.558826
Training: 2025-08-31 07:03:58,184-[lfw][19684]Accuracy-Flip: 0.82300+-0.01496
Training: 2025-08-31 07:03:58,184-[lfw][19684]Accuracy-Highest: 0.82300
Training: 2025-08-31 07:04:26,531-[cfp_fp][19684]XNorm: 15.972217
Training: 2025-08-31 07:04:26,532-[cfp_fp][19684]Accuracy-Flip: 0.66086+-0.01765
Training: 2025-08-31 07:04:26,532-[cfp_fp][19684]Accuracy-Highest: 0.66086
Training: 2025-08-31 07:04:50,859-[agedb_30][19684]XNorm: 15.502007
Training: 2025-08-31 07:04:50,859-[agedb_30][19684]Accuracy-Flip: 0.53717+-0.01116
Training: 2025-08-31 07:04:50,859-[agedb_30][19684]Accuracy-Highest: 0.53717
Training: 2025-08-31 07:05:15,285-[calfw][19684]XNorm: 18.433608
Training: 2025-08-31 07:05:15,285-[calfw][19684]Accuracy-Flip: 0.66317+-0.01469
Training: 2025-08-31 07:05:15,285-[calfw][19684]Accuracy-Highest: 0.66350
Training: 2025-08-31 07:05:39,693-[cplfw][19684]XNorm: 15.093215
Training: 2025-08-31 07:05:39,693-[cplfw][19684]Accuracy-Flip: 0.62783+-0.01389
Training: 2025-08-31 07:05:39,693-[cplfw][19684]Accuracy-Highest: 0.62900
Training: 2025-08-31 07:05:45,483-Speed 44.59 samples/sec   Loss 0.6762 Epoch: 7   Global Step: 19700   Required: 10 hours
Training: 2025-08-31 07:06:02,977-Speed 365.84 samples/sec   Loss 0.6065 Epoch: 7   Global Step: 19750   Required: 10 hours
Training: 2025-08-31 07:06:20,472-Speed 365.83 samples/sec   Loss 0.5839 Epoch: 7   Global Step: 19800   Required: 10 hours
Training: 2025-08-31 07:06:37,965-Speed 365.85 samples/sec   Loss 0.6607 Epoch: 7   Global Step: 19850   Required: 10 hours
Training: 2025-08-31 07:06:55,461-Speed 365.81 samples/sec   Loss 0.6200 Epoch: 7   Global Step: 19900   Required: 10 hours
Training: 2025-08-31 07:07:12,955-Speed 365.84 samples/sec   Loss 0.6292 Epoch: 7   Global Step: 19950   Required: 10 hours
Training: 2025-08-31 07:07:30,450-Speed 365.81 samples/sec   Loss 0.6250 Epoch: 7   Global Step: 20000   Required: 10 hours
Training: 2025-08-31 07:07:47,948-Speed 365.76 samples/sec   Loss 0.5970 Epoch: 7   Global Step: 20050   Required: 10 hours
Training: 2025-08-31 07:08:05,449-Speed 365.71 samples/sec   Loss 0.6323 Epoch: 7   Global Step: 20100   Required: 10 hours
Training: 2025-08-31 07:08:22,946-Speed 365.77 samples/sec   Loss 0.5991 Epoch: 7   Global Step: 20150   Required: 10 hours
Training: 2025-08-31 07:08:40,441-Speed 365.83 samples/sec   Loss 0.6445 Epoch: 7   Global Step: 20200   Required: 10 hours
Training: 2025-08-31 07:08:57,936-Speed 365.82 samples/sec   Loss 0.6228 Epoch: 7   Global Step: 20250   Required: 10 hours
Training: 2025-08-31 07:09:15,430-Speed 365.84 samples/sec   Loss 0.6020 Epoch: 7   Global Step: 20300   Required: 10 hours
Training: 2025-08-31 07:09:32,924-Speed 365.85 samples/sec   Loss 0.6528 Epoch: 7   Global Step: 20350   Required: 10 hours
Training: 2025-08-31 07:09:50,423-Speed 365.73 samples/sec   Loss 0.6668 Epoch: 7   Global Step: 20400   Required: 10 hours
Training: 2025-08-31 07:10:07,923-Speed 365.72 samples/sec   Loss 0.6652 Epoch: 7   Global Step: 20450   Required: 10 hours
Training: 2025-08-31 07:10:25,418-Speed 365.82 samples/sec   Loss 0.6609 Epoch: 7   Global Step: 20500   Required: 10 hours
Training: 2025-08-31 07:10:42,919-Speed 365.70 samples/sec   Loss 0.6209 Epoch: 7   Global Step: 20550   Required: 10 hours
Training: 2025-08-31 07:11:00,426-Speed 365.57 samples/sec   Loss 0.6291 Epoch: 7   Global Step: 20600   Required: 10 hours
Training: 2025-08-31 07:11:17,929-Speed 365.65 samples/sec   Loss 0.6414 Epoch: 7   Global Step: 20650   Required: 10 hours
Training: 2025-08-31 07:11:35,435-Speed 365.60 samples/sec   Loss 0.6279 Epoch: 7   Global Step: 20700   Required: 10 hours
Training: 2025-08-31 07:11:52,939-Speed 365.63 samples/sec   Loss 0.6639 Epoch: 7   Global Step: 20750   Required: 10 hours
Training: 2025-08-31 07:12:10,442-Speed 365.66 samples/sec   Loss 0.6357 Epoch: 7   Global Step: 20800   Required: 10 hours
Training: 2025-08-31 07:12:27,946-Speed 365.62 samples/sec   Loss 0.6561 Epoch: 7   Global Step: 20850   Required: 10 hours
Training: 2025-08-31 07:12:45,449-Speed 365.65 samples/sec   Loss 0.6606 Epoch: 7   Global Step: 20900   Required: 10 hours
Training: 2025-08-31 07:13:02,943-Speed 365.84 samples/sec   Loss 0.6875 Epoch: 7   Global Step: 20950   Required: 10 hours
Training: 2025-08-31 07:13:20,439-Speed 365.80 samples/sec   Loss 0.6700 Epoch: 7   Global Step: 21000   Required: 10 hours
Training: 2025-08-31 07:13:37,935-Speed 365.81 samples/sec   Loss 0.6419 Epoch: 7   Global Step: 21050   Required: 10 hours
Training: 2025-08-31 07:13:55,430-Speed 365.82 samples/sec   Loss 0.6700 Epoch: 7   Global Step: 21100   Required: 10 hours
Training: 2025-08-31 07:14:12,924-Speed 365.85 samples/sec   Loss 0.6442 Epoch: 7   Global Step: 21150   Required: 10 hours
Training: 2025-08-31 07:14:30,419-Speed 365.81 samples/sec   Loss 0.6561 Epoch: 7   Global Step: 21200   Required: 10 hours
Training: 2025-08-31 07:14:47,919-Speed 365.71 samples/sec   Loss 0.7178 Epoch: 7   Global Step: 21250   Required: 10 hours
Training: 2025-08-31 07:15:05,418-Speed 365.74 samples/sec   Loss 0.6000 Epoch: 7   Global Step: 21300   Required: 10 hours
Training: 2025-08-31 07:15:22,922-Speed 365.64 samples/sec   Loss 0.6951 Epoch: 7   Global Step: 21350   Required: 10 hours
Training: 2025-08-31 07:15:40,415-Speed 365.85 samples/sec   Loss 0.6525 Epoch: 7   Global Step: 21400   Required: 10 hours
Training: 2025-08-31 07:15:57,911-Speed 365.82 samples/sec   Loss 0.6336 Epoch: 7   Global Step: 21450   Required: 10 hours
Training: 2025-08-31 07:16:15,405-Speed 365.84 samples/sec   Loss 0.6737 Epoch: 7   Global Step: 21500   Required: 10 hours
Training: 2025-08-31 07:16:32,908-Speed 365.65 samples/sec   Loss 0.6597 Epoch: 7   Global Step: 21550   Required: 10 hours
Training: 2025-08-31 07:16:50,413-Speed 365.60 samples/sec   Loss 0.6933 Epoch: 7   Global Step: 21600   Required: 10 hours
Training: 2025-08-31 07:17:07,915-Speed 365.69 samples/sec   Loss 0.6570 Epoch: 7   Global Step: 21650   Required: 10 hours
Training: 2025-08-31 07:17:25,419-Speed 365.61 samples/sec   Loss 0.6599 Epoch: 7   Global Step: 21700   Required: 10 hours
Training: 2025-08-31 07:17:42,924-Speed 365.63 samples/sec   Loss 0.6455 Epoch: 7   Global Step: 21750   Required: 10 hours
Training: 2025-08-31 07:18:00,432-Speed 365.54 samples/sec   Loss 0.6694 Epoch: 7   Global Step: 21800   Required: 10 hours
Training: 2025-08-31 07:18:17,941-Speed 365.52 samples/sec   Loss 0.6755 Epoch: 7   Global Step: 21850   Required: 10 hours
Training: 2025-08-31 07:18:35,446-Speed 365.61 samples/sec   Loss 0.6573 Epoch: 7   Global Step: 21900   Required: 10 hours
Training: 2025-08-31 07:18:52,946-Speed 365.73 samples/sec   Loss 0.6575 Epoch: 7   Global Step: 21950   Required: 10 hours
Training: 2025-08-31 07:19:10,454-Speed 365.55 samples/sec   Loss 0.6900 Epoch: 7   Global Step: 22000   Required: 10 hours
Training: 2025-08-31 07:19:27,963-Speed 365.52 samples/sec   Loss 0.6843 Epoch: 7   Global Step: 22050   Required: 10 hours
Training: 2025-08-31 07:19:45,473-Speed 365.52 samples/sec   Loss 0.6492 Epoch: 7   Global Step: 22100   Required: 10 hours
Training: 2025-08-31 07:20:02,973-Speed 365.71 samples/sec   Loss 0.6801 Epoch: 7   Global Step: 22150   Required: 10 hours
Training: 2025-08-31 07:20:20,476-Speed 365.66 samples/sec   Loss 0.6477 Epoch: 7   Global Step: 22200   Required: 10 hours
Training: 2025-08-31 07:20:37,976-Speed 365.71 samples/sec   Loss 0.6701 Epoch: 7   Global Step: 22250   Required: 10 hours
Training: 2025-08-31 07:20:55,475-Speed 365.73 samples/sec   Loss 0.6498 Epoch: 7   Global Step: 22300   Required: 10 hours
Training: 2025-08-31 07:21:12,981-Speed 365.60 samples/sec   Loss 0.6529 Epoch: 7   Global Step: 22350   Required: 10 hours
Training: 2025-08-31 07:21:30,492-Speed 365.48 samples/sec   Loss 0.6713 Epoch: 7   Global Step: 22400   Required: 10 hours
Training: 2025-08-31 07:21:47,995-Speed 365.65 samples/sec   Loss 0.6463 Epoch: 7   Global Step: 22450   Required: 10 hours
Training: 2025-08-31 07:22:28,448-[lfw][22496]XNorm: 19.428256
Training: 2025-08-31 07:22:28,448-[lfw][22496]Accuracy-Flip: 0.81767+-0.01710
Training: 2025-08-31 07:22:28,448-[lfw][22496]Accuracy-Highest: 0.82300
Training: 2025-08-31 07:22:56,726-[cfp_fp][22496]XNorm: 16.393088
Training: 2025-08-31 07:22:56,726-[cfp_fp][22496]Accuracy-Flip: 0.63986+-0.02260
Training: 2025-08-31 07:22:56,726-[cfp_fp][22496]Accuracy-Highest: 0.66086
Training: 2025-08-31 07:23:21,061-[agedb_30][22496]XNorm: 16.777623
Training: 2025-08-31 07:23:21,061-[agedb_30][22496]Accuracy-Flip: 0.53750+-0.01832
Training: 2025-08-31 07:23:21,061-[agedb_30][22496]Accuracy-Highest: 0.53750
Training: 2025-08-31 07:23:45,486-[calfw][22496]XNorm: 19.215095
Training: 2025-08-31 07:23:45,486-[calfw][22496]Accuracy-Flip: 0.65733+-0.02140
Training: 2025-08-31 07:23:45,487-[calfw][22496]Accuracy-Highest: 0.66350
Training: 2025-08-31 07:24:09,905-[cplfw][22496]XNorm: 15.648487
Training: 2025-08-31 07:24:09,905-[cplfw][22496]Accuracy-Flip: 0.63500+-0.00882
Training: 2025-08-31 07:24:09,905-[cplfw][22496]Accuracy-Highest: 0.63500
Training: 2025-08-31 07:24:11,510-Speed 44.59 samples/sec   Loss 0.6792 Epoch: 8   Global Step: 22500   Required: 10 hours
Training: 2025-08-31 07:24:29,002-Speed 365.89 samples/sec   Loss 0.5348 Epoch: 8   Global Step: 22550   Required: 10 hours
Training: 2025-08-31 07:24:46,497-Speed 365.82 samples/sec   Loss 0.5228 Epoch: 8   Global Step: 22600   Required: 10 hours
Training: 2025-08-31 07:25:03,991-Speed 365.86 samples/sec   Loss 0.5773 Epoch: 8   Global Step: 22650   Required: 10 hours
Training: 2025-08-31 07:25:21,491-Speed 365.72 samples/sec   Loss 0.5356 Epoch: 8   Global Step: 22700   Required: 10 hours
Training: 2025-08-31 07:25:38,989-Speed 365.76 samples/sec   Loss 0.5842 Epoch: 8   Global Step: 22750   Required: 10 hours
Training: 2025-08-31 07:25:56,484-Speed 365.82 samples/sec   Loss 0.5218 Epoch: 8   Global Step: 22800   Required: 10 hours
Training: 2025-08-31 07:26:13,981-Speed 365.78 samples/sec   Loss 0.5912 Epoch: 8   Global Step: 22850   Required: 10 hours
Training: 2025-08-31 07:26:31,484-Speed 365.66 samples/sec   Loss 0.5897 Epoch: 8   Global Step: 22900   Required: 10 hours
Training: 2025-08-31 07:26:48,990-Speed 365.59 samples/sec   Loss 0.5638 Epoch: 8   Global Step: 22950   Required: 10 hours
Training: 2025-08-31 07:27:06,491-Speed 365.69 samples/sec   Loss 0.5627 Epoch: 8   Global Step: 23000   Required: 10 hours
Training: 2025-08-31 07:27:24,003-Speed 365.47 samples/sec   Loss 0.5969 Epoch: 8   Global Step: 23050   Required: 10 hours
Training: 2025-08-31 07:27:41,515-Speed 365.46 samples/sec   Loss 0.6048 Epoch: 8   Global Step: 23100   Required: 10 hours
Training: 2025-08-31 07:27:59,029-Speed 365.43 samples/sec   Loss 0.6090 Epoch: 8   Global Step: 23150   Required: 10 hours
Training: 2025-08-31 07:28:16,547-Speed 365.34 samples/sec   Loss 0.6067 Epoch: 8   Global Step: 23200   Required: 10 hours
Training: 2025-08-31 07:28:34,065-Speed 365.35 samples/sec   Loss 0.5687 Epoch: 8   Global Step: 23250   Required: 10 hours
Training: 2025-08-31 07:28:51,573-Speed 365.54 samples/sec   Loss 0.5556 Epoch: 8   Global Step: 23300   Required: 10 hours
Training: 2025-08-31 07:29:09,087-Speed 365.43 samples/sec   Loss 0.5927 Epoch: 8   Global Step: 23350   Required: 10 hours
Training: 2025-08-31 07:29:26,606-Speed 365.31 samples/sec   Loss 0.6006 Epoch: 8   Global Step: 23400   Required: 10 hours
Training: 2025-08-31 07:29:44,122-Speed 365.38 samples/sec   Loss 0.5842 Epoch: 8   Global Step: 23450   Required: 10 hours
Training: 2025-08-31 07:30:01,643-Speed 365.29 samples/sec   Loss 0.6495 Epoch: 8   Global Step: 23500   Required: 10 hours
Training: 2025-08-31 07:30:19,162-Speed 365.31 samples/sec   Loss 0.6006 Epoch: 8   Global Step: 23550   Required: 10 hours
Training: 2025-08-31 07:30:36,676-Speed 365.42 samples/sec   Loss 0.5731 Epoch: 8   Global Step: 23600   Required: 10 hours
Training: 2025-08-31 07:30:54,193-Speed 365.37 samples/sec   Loss 0.5927 Epoch: 8   Global Step: 23650   Required: 10 hours
Training: 2025-08-31 07:31:11,710-Speed 365.35 samples/sec   Loss 0.5938 Epoch: 8   Global Step: 23700   Required: 10 hours
Training: 2025-08-31 07:31:29,225-Speed 365.40 samples/sec   Loss 0.6038 Epoch: 8   Global Step: 23750   Required: 10 hours
Training: 2025-08-31 07:31:46,745-Speed 365.30 samples/sec   Loss 0.6007 Epoch: 8   Global Step: 23800   Required: 10 hours
Training: 2025-08-31 07:32:04,266-Speed 365.28 samples/sec   Loss 0.5986 Epoch: 8   Global Step: 23850   Required: 10 hours
Training: 2025-08-31 07:32:21,784-Speed 365.34 samples/sec   Loss 0.6090 Epoch: 8   Global Step: 23900   Required: 10 hours
Training: 2025-08-31 07:32:39,303-Speed 365.32 samples/sec   Loss 0.5960 Epoch: 8   Global Step: 23950   Required: 10 hours
Training: 2025-08-31 07:32:56,819-Speed 365.38 samples/sec   Loss 0.6208 Epoch: 8   Global Step: 24000   Required: 10 hours
Training: 2025-08-31 07:33:14,332-Speed 365.46 samples/sec   Loss 0.5891 Epoch: 8   Global Step: 24050   Required: 10 hours
Training: 2025-08-31 07:33:31,843-Speed 365.48 samples/sec   Loss 0.6578 Epoch: 8   Global Step: 24100   Required: 10 hours
Training: 2025-08-31 07:33:49,355-Speed 365.48 samples/sec   Loss 0.5911 Epoch: 8   Global Step: 24150   Required: 10 hours
Training: 2025-08-31 07:34:06,866-Speed 365.48 samples/sec   Loss 0.6160 Epoch: 8   Global Step: 24200   Required: 10 hours
Training: 2025-08-31 07:34:24,376-Speed 365.50 samples/sec   Loss 0.6092 Epoch: 8   Global Step: 24250   Required: 10 hours
Training: 2025-08-31 07:34:41,886-Speed 365.51 samples/sec   Loss 0.6204 Epoch: 8   Global Step: 24300   Required: 10 hours
Training: 2025-08-31 07:34:59,397-Speed 365.50 samples/sec   Loss 0.5945 Epoch: 8   Global Step: 24350   Required: 10 hours
Training: 2025-08-31 07:35:16,908-Speed 365.48 samples/sec   Loss 0.6037 Epoch: 8   Global Step: 24400   Required: 10 hours
Training: 2025-08-31 07:35:34,421-Speed 365.44 samples/sec   Loss 0.6382 Epoch: 8   Global Step: 24450   Required: 10 hours
Training: 2025-08-31 07:35:51,933-Speed 365.48 samples/sec   Loss 0.5988 Epoch: 8   Global Step: 24500   Required: 10 hours
Training: 2025-08-31 07:36:09,440-Speed 365.56 samples/sec   Loss 0.5735 Epoch: 8   Global Step: 24550   Required: 10 hours
Training: 2025-08-31 07:36:26,954-Speed 365.43 samples/sec   Loss 0.6037 Epoch: 8   Global Step: 24600   Required: 10 hours
Training: 2025-08-31 07:36:44,468-Speed 365.41 samples/sec   Loss 0.6174 Epoch: 8   Global Step: 24650   Required: 10 hours
Training: 2025-08-31 07:37:01,980-Speed 365.47 samples/sec   Loss 0.6390 Epoch: 8   Global Step: 24700   Required: 10 hours
Training: 2025-08-31 07:37:19,488-Speed 365.55 samples/sec   Loss 0.6429 Epoch: 8   Global Step: 24750   Required: 10 hours
Training: 2025-08-31 07:37:36,992-Speed 365.64 samples/sec   Loss 0.5997 Epoch: 8   Global Step: 24800   Required: 10 hours
Training: 2025-08-31 07:37:54,506-Speed 365.42 samples/sec   Loss 0.6068 Epoch: 8   Global Step: 24850   Required: 10 hours
Training: 2025-08-31 07:38:12,020-Speed 365.43 samples/sec   Loss 0.6276 Epoch: 8   Global Step: 24900   Required: 10 hours
Training: 2025-08-31 07:38:29,540-Speed 365.29 samples/sec   Loss 0.5947 Epoch: 8   Global Step: 24950   Required: 9 hours
Training: 2025-08-31 07:38:47,052-Speed 365.46 samples/sec   Loss 0.6511 Epoch: 8   Global Step: 25000   Required: 9 hours
Training: 2025-08-31 07:39:04,562-Speed 365.52 samples/sec   Loss 0.6124 Epoch: 8   Global Step: 25050   Required: 9 hours
Training: 2025-08-31 07:39:22,075-Speed 365.45 samples/sec   Loss 0.6136 Epoch: 8   Global Step: 25100   Required: 9 hours
Training: 2025-08-31 07:39:39,588-Speed 365.44 samples/sec   Loss 0.6286 Epoch: 8   Global Step: 25150   Required: 9 hours
Training: 2025-08-31 07:39:57,098-Speed 365.52 samples/sec   Loss 0.5741 Epoch: 8   Global Step: 25200   Required: 9 hours
Training: 2025-08-31 07:40:14,610-Speed 365.45 samples/sec   Loss 0.6234 Epoch: 8   Global Step: 25250   Required: 9 hours
Training: 2025-08-31 07:40:32,127-Speed 365.36 samples/sec   Loss 0.6085 Epoch: 8   Global Step: 25300   Required: 9 hours
Training: 2025-08-31 07:40:59,303-[lfw][25308]XNorm: 17.599066
Training: 2025-08-31 07:40:59,303-[lfw][25308]Accuracy-Flip: 0.83600+-0.02017
Training: 2025-08-31 07:40:59,303-[lfw][25308]Accuracy-Highest: 0.83600
Training: 2025-08-31 07:41:27,643-[cfp_fp][25308]XNorm: 15.442123
Training: 2025-08-31 07:41:27,643-[cfp_fp][25308]Accuracy-Flip: 0.64157+-0.01896
Training: 2025-08-31 07:41:27,643-[cfp_fp][25308]Accuracy-Highest: 0.66086
Training: 2025-08-31 07:41:51,999-[agedb_30][25308]XNorm: 17.415465
Training: 2025-08-31 07:41:51,999-[agedb_30][25308]Accuracy-Flip: 0.53533+-0.01778
Training: 2025-08-31 07:41:51,999-[agedb_30][25308]Accuracy-Highest: 0.53750
Training: 2025-08-31 07:42:16,434-[calfw][25308]XNorm: 18.165677
Training: 2025-08-31 07:42:16,434-[calfw][25308]Accuracy-Flip: 0.67117+-0.02037
Training: 2025-08-31 07:42:16,434-[calfw][25308]Accuracy-Highest: 0.67117
Training: 2025-08-31 07:42:40,854-[cplfw][25308]XNorm: 14.098171
Training: 2025-08-31 07:42:40,854-[cplfw][25308]Accuracy-Flip: 0.61600+-0.01424
Training: 2025-08-31 07:42:40,854-[cplfw][25308]Accuracy-Highest: 0.63500
Training: 2025-08-31 07:42:55,764-Speed 44.56 samples/sec   Loss 0.5739 Epoch: 9   Global Step: 25350   Required: 10 hours
Training: 2025-08-31 07:43:13,259-Speed 365.83 samples/sec   Loss 0.4853 Epoch: 9   Global Step: 25400   Required: 10 hours
Training: 2025-08-31 07:43:30,753-Speed 365.83 samples/sec   Loss 0.4854 Epoch: 9   Global Step: 25450   Required: 10 hours
Training: 2025-08-31 07:43:48,247-Speed 365.84 samples/sec   Loss 0.5303 Epoch: 9   Global Step: 25500   Required: 10 hours
Training: 2025-08-31 07:44:05,752-Speed 365.63 samples/sec   Loss 0.4893 Epoch: 9   Global Step: 25550   Required: 10 hours
Training: 2025-08-31 07:44:23,260-Speed 365.53 samples/sec   Loss 0.4953 Epoch: 9   Global Step: 25600   Required: 10 hours
Training: 2025-08-31 07:44:40,770-Speed 365.51 samples/sec   Loss 0.5161 Epoch: 9   Global Step: 25650   Required: 10 hours
Training: 2025-08-31 07:44:58,281-Speed 365.50 samples/sec   Loss 0.5027 Epoch: 9   Global Step: 25700   Required: 10 hours
Training: 2025-08-31 07:45:15,788-Speed 365.57 samples/sec   Loss 0.4934 Epoch: 9   Global Step: 25750   Required: 9 hours
Training: 2025-08-31 07:45:33,304-Speed 365.38 samples/sec   Loss 0.5106 Epoch: 9   Global Step: 25800   Required: 9 hours
Training: 2025-08-31 07:45:50,817-Speed 365.44 samples/sec   Loss 0.5146 Epoch: 9   Global Step: 25850   Required: 9 hours
Training: 2025-08-31 07:46:08,318-Speed 365.71 samples/sec   Loss 0.5313 Epoch: 9   Global Step: 25900   Required: 9 hours
Training: 2025-08-31 07:46:25,824-Speed 365.59 samples/sec   Loss 0.5417 Epoch: 9   Global Step: 25950   Required: 9 hours
Training: 2025-08-31 07:46:43,332-Speed 365.55 samples/sec   Loss 0.5391 Epoch: 9   Global Step: 26000   Required: 9 hours
Training: 2025-08-31 07:47:00,842-Speed 365.50 samples/sec   Loss 0.5392 Epoch: 9   Global Step: 26050   Required: 9 hours
Training: 2025-08-31 07:47:18,354-Speed 365.48 samples/sec   Loss 0.5396 Epoch: 9   Global Step: 26100   Required: 9 hours
Training: 2025-08-31 07:47:35,864-Speed 365.50 samples/sec   Loss 0.5601 Epoch: 9   Global Step: 26150   Required: 9 hours
Training: 2025-08-31 07:47:53,368-Speed 365.63 samples/sec   Loss 0.5379 Epoch: 9   Global Step: 26200   Required: 9 hours
Training: 2025-08-31 07:48:10,874-Speed 365.60 samples/sec   Loss 0.5866 Epoch: 9   Global Step: 26250   Required: 9 hours
Training: 2025-08-31 07:48:28,381-Speed 365.56 samples/sec   Loss 0.5360 Epoch: 9   Global Step: 26300   Required: 9 hours
Training: 2025-08-31 07:48:45,896-Speed 365.42 samples/sec   Loss 0.5669 Epoch: 9   Global Step: 26350   Required: 9 hours
Training: 2025-08-31 07:49:03,404-Speed 365.55 samples/sec   Loss 0.5930 Epoch: 9   Global Step: 26400   Required: 9 hours
Training: 2025-08-31 07:49:20,913-Speed 365.53 samples/sec   Loss 0.5366 Epoch: 9   Global Step: 26450   Required: 9 hours
Training: 2025-08-31 07:49:38,419-Speed 365.58 samples/sec   Loss 0.5302 Epoch: 9   Global Step: 26500   Required: 9 hours
Training: 2025-08-31 07:49:55,927-Speed 365.55 samples/sec   Loss 0.5780 Epoch: 9   Global Step: 26550   Required: 9 hours
Training: 2025-08-31 07:50:13,434-Speed 365.57 samples/sec   Loss 0.5352 Epoch: 9   Global Step: 26600   Required: 9 hours
Training: 2025-08-31 07:50:30,937-Speed 365.67 samples/sec   Loss 0.5799 Epoch: 9   Global Step: 26650   Required: 9 hours
Training: 2025-08-31 07:50:48,452-Speed 365.40 samples/sec   Loss 0.5188 Epoch: 9   Global Step: 26700   Required: 9 hours
Training: 2025-08-31 07:51:05,960-Speed 365.55 samples/sec   Loss 0.5723 Epoch: 9   Global Step: 26750   Required: 9 hours
Training: 2025-08-31 07:51:23,460-Speed 365.72 samples/sec   Loss 0.5656 Epoch: 9   Global Step: 26800   Required: 9 hours
Training: 2025-08-31 07:51:40,959-Speed 365.72 samples/sec   Loss 0.5371 Epoch: 9   Global Step: 26850   Required: 9 hours
Training: 2025-08-31 07:51:58,476-Speed 365.37 samples/sec   Loss 0.5788 Epoch: 9   Global Step: 26900   Required: 9 hours
Training: 2025-08-31 07:52:15,994-Speed 365.33 samples/sec   Loss 0.5894 Epoch: 9   Global Step: 26950   Required: 9 hours
Training: 2025-08-31 07:52:33,509-Speed 365.41 samples/sec   Loss 0.5977 Epoch: 9   Global Step: 27000   Required: 9 hours
Training: 2025-08-31 07:52:51,024-Speed 365.41 samples/sec   Loss 0.6230 Epoch: 9   Global Step: 27050   Required: 9 hours
Training: 2025-08-31 07:53:08,541-Speed 365.36 samples/sec   Loss 0.5727 Epoch: 9   Global Step: 27100   Required: 9 hours
Training: 2025-08-31 07:53:26,057-Speed 365.38 samples/sec   Loss 0.5770 Epoch: 9   Global Step: 27150   Required: 9 hours
Training: 2025-08-31 07:53:43,569-Speed 365.47 samples/sec   Loss 0.5677 Epoch: 9   Global Step: 27200   Required: 9 hours
Training: 2025-08-31 07:54:01,074-Speed 365.61 samples/sec   Loss 0.5513 Epoch: 9   Global Step: 27250   Required: 9 hours
Training: 2025-08-31 07:54:18,578-Speed 365.63 samples/sec   Loss 0.5957 Epoch: 9   Global Step: 27300   Required: 9 hours
Training: 2025-08-31 07:54:36,089-Speed 365.49 samples/sec   Loss 0.5557 Epoch: 9   Global Step: 27350   Required: 9 hours
Training: 2025-08-31 07:54:53,587-Speed 365.75 samples/sec   Loss 0.5835 Epoch: 9   Global Step: 27400   Required: 9 hours
Training: 2025-08-31 07:55:11,098-Speed 365.49 samples/sec   Loss 0.5651 Epoch: 9   Global Step: 27450   Required: 9 hours
Training: 2025-08-31 07:55:28,613-Speed 365.41 samples/sec   Loss 0.5601 Epoch: 9   Global Step: 27500   Required: 9 hours
Training: 2025-08-31 07:55:46,127-Speed 365.42 samples/sec   Loss 0.5673 Epoch: 9   Global Step: 27550   Required: 9 hours
Training: 2025-08-31 07:56:03,644-Speed 365.36 samples/sec   Loss 0.5222 Epoch: 9   Global Step: 27600   Required: 9 hours
Training: 2025-08-31 07:56:21,160-Speed 365.39 samples/sec   Loss 0.5557 Epoch: 9   Global Step: 27650   Required: 9 hours
Training: 2025-08-31 07:56:38,674-Speed 365.42 samples/sec   Loss 0.6090 Epoch: 9   Global Step: 27700   Required: 9 hours
Training: 2025-08-31 07:56:56,191-Speed 365.37 samples/sec   Loss 0.5472 Epoch: 9   Global Step: 27750   Required: 9 hours
Training: 2025-08-31 07:57:13,707-Speed 365.37 samples/sec   Loss 0.5814 Epoch: 9   Global Step: 27800   Required: 9 hours
Training: 2025-08-31 07:57:31,214-Speed 365.58 samples/sec   Loss 0.5667 Epoch: 9   Global Step: 27850   Required: 9 hours
Training: 2025-08-31 07:57:48,721-Speed 365.56 samples/sec   Loss 0.5386 Epoch: 9   Global Step: 27900   Required: 9 hours
Training: 2025-08-31 07:58:06,235-Speed 365.43 samples/sec   Loss 0.5482 Epoch: 9   Global Step: 27950   Required: 9 hours
Training: 2025-08-31 07:58:23,753-Speed 365.35 samples/sec   Loss 0.5599 Epoch: 9   Global Step: 28000   Required: 9 hours
Training: 2025-08-31 07:58:41,266-Speed 365.43 samples/sec   Loss 0.5656 Epoch: 9   Global Step: 28050   Required: 9 hours
Training: 2025-08-31 07:58:58,779-Speed 365.46 samples/sec   Loss 0.5621 Epoch: 9   Global Step: 28100   Required: 9 hours
Training: 2025-08-31 07:59:30,186-[lfw][28120]XNorm: 17.617349
Training: 2025-08-31 07:59:30,186-[lfw][28120]Accuracy-Flip: 0.80117+-0.01944
Training: 2025-08-31 07:59:30,186-[lfw][28120]Accuracy-Highest: 0.83600
Training: 2025-08-31 07:59:58,525-[cfp_fp][28120]XNorm: 15.935322
Training: 2025-08-31 07:59:58,525-[cfp_fp][28120]Accuracy-Flip: 0.63457+-0.02240
Training: 2025-08-31 07:59:58,525-[cfp_fp][28120]Accuracy-Highest: 0.66086
Training: 2025-08-31 08:00:22,866-[agedb_30][28120]XNorm: 16.215431
Training: 2025-08-31 08:00:22,866-[agedb_30][28120]Accuracy-Flip: 0.56500+-0.02041
Training: 2025-08-31 08:00:22,866-[agedb_30][28120]Accuracy-Highest: 0.56500
Training: 2025-08-31 08:00:47,303-[calfw][28120]XNorm: 17.807684
Training: 2025-08-31 08:00:47,303-[calfw][28120]Accuracy-Flip: 0.65517+-0.01136
Training: 2025-08-31 08:00:47,303-[calfw][28120]Accuracy-Highest: 0.67117
Training: 2025-08-31 08:01:11,730-[cplfw][28120]XNorm: 14.316060
Training: 2025-08-31 08:01:11,730-[cplfw][28120]Accuracy-Flip: 0.61700+-0.01341
Training: 2025-08-31 08:01:11,730-[cplfw][28120]Accuracy-Highest: 0.63500
Training: 2025-08-31 08:01:22,388-Speed 44.57 samples/sec   Loss 0.5105 Epoch: 10   Global Step: 28150   Required: 9 hours
Training: 2025-08-31 08:01:39,882-Speed 365.85 samples/sec   Loss 0.4830 Epoch: 10   Global Step: 28200   Required: 9 hours
Training: 2025-08-31 08:01:57,387-Speed 365.61 samples/sec   Loss 0.4643 Epoch: 10   Global Step: 28250   Required: 9 hours
Training: 2025-08-31 08:02:14,890-Speed 365.64 samples/sec   Loss 0.4845 Epoch: 10   Global Step: 28300   Required: 9 hours
Training: 2025-08-31 08:02:32,396-Speed 365.60 samples/sec   Loss 0.4917 Epoch: 10   Global Step: 28350   Required: 9 hours
Training: 2025-08-31 08:02:49,904-Speed 365.55 samples/sec   Loss 0.4929 Epoch: 10   Global Step: 28400   Required: 9 hours
Training: 2025-08-31 08:03:07,408-Speed 365.63 samples/sec   Loss 0.4852 Epoch: 10   Global Step: 28450   Required: 9 hours
Training: 2025-08-31 08:03:24,918-Speed 365.50 samples/sec   Loss 0.4689 Epoch: 10   Global Step: 28500   Required: 9 hours
Training: 2025-08-31 08:03:42,424-Speed 365.60 samples/sec   Loss 0.4981 Epoch: 10   Global Step: 28550   Required: 9 hours
Training: 2025-08-31 08:03:59,930-Speed 365.58 samples/sec   Loss 0.5079 Epoch: 10   Global Step: 28600   Required: 9 hours
Training: 2025-08-31 08:04:17,435-Speed 365.61 samples/sec   Loss 0.4752 Epoch: 10   Global Step: 28650   Required: 9 hours
Training: 2025-08-31 08:04:34,946-Speed 365.49 samples/sec   Loss 0.4714 Epoch: 10   Global Step: 28700   Required: 9 hours
Training: 2025-08-31 08:04:52,445-Speed 365.74 samples/sec   Loss 0.4727 Epoch: 10   Global Step: 28750   Required: 9 hours
Training: 2025-08-31 08:05:09,945-Speed 365.72 samples/sec   Loss 0.5435 Epoch: 10   Global Step: 28800   Required: 9 hours
Training: 2025-08-31 08:05:27,441-Speed 365.79 samples/sec   Loss 0.5137 Epoch: 10   Global Step: 28850   Required: 9 hours
Training: 2025-08-31 08:05:44,943-Speed 365.68 samples/sec   Loss 0.5116 Epoch: 10   Global Step: 28900   Required: 9 hours
Training: 2025-08-31 08:06:02,441-Speed 365.75 samples/sec   Loss 0.4928 Epoch: 10   Global Step: 28950   Required: 9 hours
Training: 2025-08-31 08:06:19,943-Speed 365.69 samples/sec   Loss 0.5018 Epoch: 10   Global Step: 29000   Required: 9 hours
Training: 2025-08-31 08:06:37,450-Speed 365.56 samples/sec   Loss 0.5447 Epoch: 10   Global Step: 29050   Required: 9 hours
Training: 2025-08-31 08:06:54,945-Speed 365.82 samples/sec   Loss 0.5262 Epoch: 10   Global Step: 29100   Required: 9 hours
Training: 2025-08-31 08:07:12,446-Speed 365.69 samples/sec   Loss 0.5627 Epoch: 10   Global Step: 29150   Required: 9 hours
Training: 2025-08-31 08:07:29,943-Speed 365.78 samples/sec   Loss 0.5266 Epoch: 10   Global Step: 29200   Required: 9 hours
Training: 2025-08-31 08:07:47,445-Speed 365.67 samples/sec   Loss 0.5259 Epoch: 10   Global Step: 29250   Required: 9 hours
Training: 2025-08-31 08:08:04,942-Speed 365.79 samples/sec   Loss 0.5541 Epoch: 10   Global Step: 29300   Required: 9 hours
Training: 2025-08-31 08:08:22,449-Speed 365.57 samples/sec   Loss 0.5166 Epoch: 10   Global Step: 29350   Required: 9 hours
Training: 2025-08-31 08:08:39,959-Speed 365.50 samples/sec   Loss 0.4861 Epoch: 10   Global Step: 29400   Required: 9 hours
Training: 2025-08-31 08:08:57,455-Speed 365.81 samples/sec   Loss 0.5924 Epoch: 10   Global Step: 29450   Required: 9 hours
Training: 2025-08-31 08:09:14,955-Speed 365.70 samples/sec   Loss 0.5365 Epoch: 10   Global Step: 29500   Required: 9 hours
Training: 2025-08-31 08:09:32,453-Speed 365.77 samples/sec   Loss 0.5383 Epoch: 10   Global Step: 29550   Required: 9 hours
Training: 2025-08-31 08:09:49,954-Speed 365.69 samples/sec   Loss 0.5376 Epoch: 10   Global Step: 29600   Required: 9 hours
Training: 2025-08-31 08:10:07,452-Speed 365.75 samples/sec   Loss 0.5304 Epoch: 10   Global Step: 29650   Required: 9 hours
Training: 2025-08-31 08:10:24,957-Speed 365.61 samples/sec   Loss 0.5433 Epoch: 10   Global Step: 29700   Required: 9 hours
Training: 2025-08-31 08:10:42,462-Speed 365.62 samples/sec   Loss 0.5068 Epoch: 10   Global Step: 29750   Required: 9 hours
Training: 2025-08-31 08:10:59,961-Speed 365.73 samples/sec   Loss 0.5460 Epoch: 10   Global Step: 29800   Required: 9 hours
Training: 2025-08-31 08:11:17,466-Speed 365.62 samples/sec   Loss 0.5082 Epoch: 10   Global Step: 29850   Required: 9 hours
Training: 2025-08-31 08:11:34,970-Speed 365.63 samples/sec   Loss 0.5353 Epoch: 10   Global Step: 29900   Required: 9 hours
Training: 2025-08-31 08:11:52,474-Speed 365.63 samples/sec   Loss 0.5469 Epoch: 10   Global Step: 29950   Required: 9 hours
Training: 2025-08-31 08:12:09,980-Speed 365.59 samples/sec   Loss 0.5430 Epoch: 10   Global Step: 30000   Required: 9 hours
Training: 2025-08-31 08:12:27,478-Speed 365.77 samples/sec   Loss 0.5176 Epoch: 10   Global Step: 30050   Required: 9 hours
Training: 2025-08-31 08:12:44,976-Speed 365.74 samples/sec   Loss 0.5563 Epoch: 10   Global Step: 30100   Required: 9 hours
Training: 2025-08-31 08:13:02,472-Speed 365.81 samples/sec   Loss 0.5488 Epoch: 10   Global Step: 30150   Required: 9 hours
Training: 2025-08-31 08:13:19,970-Speed 365.76 samples/sec   Loss 0.5639 Epoch: 10   Global Step: 30200   Required: 9 hours
Training: 2025-08-31 08:13:37,475-Speed 365.61 samples/sec   Loss 0.5598 Epoch: 10   Global Step: 30250   Required: 9 hours
Training: 2025-08-31 08:13:54,975-Speed 365.72 samples/sec   Loss 0.5230 Epoch: 10   Global Step: 30300   Required: 9 hours
Training: 2025-08-31 08:14:12,469-Speed 365.83 samples/sec   Loss 0.5719 Epoch: 10   Global Step: 30350   Required: 9 hours
Training: 2025-08-31 08:14:29,964-Speed 365.83 samples/sec   Loss 0.5478 Epoch: 10   Global Step: 30400   Required: 9 hours
Training: 2025-08-31 08:14:47,457-Speed 365.86 samples/sec   Loss 0.4909 Epoch: 10   Global Step: 30450   Required: 9 hours
Training: 2025-08-31 08:15:04,951-Speed 365.83 samples/sec   Loss 0.5656 Epoch: 10   Global Step: 30500   Required: 9 hours
Training: 2025-08-31 08:15:22,447-Speed 365.82 samples/sec   Loss 0.5890 Epoch: 10   Global Step: 30550   Required: 9 hours
Training: 2025-08-31 08:15:39,944-Speed 365.77 samples/sec   Loss 0.5465 Epoch: 10   Global Step: 30600   Required: 9 hours
Training: 2025-08-31 08:15:57,439-Speed 365.82 samples/sec   Loss 0.5194 Epoch: 10   Global Step: 30650   Required: 9 hours
Training: 2025-08-31 08:16:14,933-Speed 365.85 samples/sec   Loss 0.5195 Epoch: 10   Global Step: 30700   Required: 9 hours
Training: 2025-08-31 08:16:32,427-Speed 365.84 samples/sec   Loss 0.5493 Epoch: 10   Global Step: 30750   Required: 9 hours
Training: 2025-08-31 08:16:49,922-Speed 365.81 samples/sec   Loss 0.5396 Epoch: 10   Global Step: 30800   Required: 9 hours
Training: 2025-08-31 08:17:07,416-Speed 365.84 samples/sec   Loss 0.5504 Epoch: 10   Global Step: 30850   Required: 9 hours
Training: 2025-08-31 08:17:24,910-Speed 365.84 samples/sec   Loss 0.5224 Epoch: 10   Global Step: 30900   Required: 9 hours
Training: 2025-08-31 08:18:00,447-[lfw][30932]XNorm: 16.874466
Training: 2025-08-31 08:18:00,447-[lfw][30932]Accuracy-Flip: 0.81600+-0.01795
Training: 2025-08-31 08:18:00,447-[lfw][30932]Accuracy-Highest: 0.83600
Training: 2025-08-31 08:18:28,776-[cfp_fp][30932]XNorm: 14.034974
Training: 2025-08-31 08:18:28,776-[cfp_fp][30932]Accuracy-Flip: 0.64757+-0.02131
Training: 2025-08-31 08:18:28,776-[cfp_fp][30932]Accuracy-Highest: 0.66086
Training: 2025-08-31 08:18:53,108-[agedb_30][30932]XNorm: 15.781159
Training: 2025-08-31 08:18:53,108-[agedb_30][30932]Accuracy-Flip: 0.53400+-0.01465
Training: 2025-08-31 08:18:53,108-[agedb_30][30932]Accuracy-Highest: 0.56500
Training: 2025-08-31 08:19:17,529-[calfw][30932]XNorm: 16.971969
Training: 2025-08-31 08:19:17,529-[calfw][30932]Accuracy-Flip: 0.66067+-0.01968
Training: 2025-08-31 08:19:17,529-[calfw][30932]Accuracy-Highest: 0.67117
Training: 2025-08-31 08:19:41,943-[cplfw][30932]XNorm: 13.715709
Training: 2025-08-31 08:19:41,944-[cplfw][30932]Accuracy-Flip: 0.62167+-0.01854
Training: 2025-08-31 08:19:41,944-[cplfw][30932]Accuracy-Highest: 0.63500
Training: 2025-08-31 08:19:48,429-Speed 44.59 samples/sec   Loss 0.4752 Epoch: 11   Global Step: 30950   Required: 9 hours
Training: 2025-08-31 08:20:05,924-Speed 365.80 samples/sec   Loss 0.4639 Epoch: 11   Global Step: 31000   Required: 9 hours
Training: 2025-08-31 08:20:23,419-Speed 365.83 samples/sec   Loss 0.4228 Epoch: 11   Global Step: 31050   Required: 9 hours
Training: 2025-08-31 08:20:40,915-Speed 365.81 samples/sec   Loss 0.4821 Epoch: 11   Global Step: 31100   Required: 9 hours
Training: 2025-08-31 08:20:58,418-Speed 365.64 samples/sec   Loss 0.4635 Epoch: 11   Global Step: 31150   Required: 9 hours
Training: 2025-08-31 08:21:15,916-Speed 365.77 samples/sec   Loss 0.4965 Epoch: 11   Global Step: 31200   Required: 9 hours
Training: 2025-08-31 08:21:33,418-Speed 365.68 samples/sec   Loss 0.4345 Epoch: 11   Global Step: 31250   Required: 9 hours
Training: 2025-08-31 08:21:50,913-Speed 365.82 samples/sec   Loss 0.4744 Epoch: 11   Global Step: 31300   Required: 9 hours
Training: 2025-08-31 08:22:08,414-Speed 365.68 samples/sec   Loss 0.4731 Epoch: 11   Global Step: 31350   Required: 9 hours
Training: 2025-08-31 08:22:25,914-Speed 365.73 samples/sec   Loss 0.4797 Epoch: 11   Global Step: 31400   Required: 9 hours
Training: 2025-08-31 08:22:43,407-Speed 365.87 samples/sec   Loss 0.4894 Epoch: 11   Global Step: 31450   Required: 9 hours
Training: 2025-08-31 08:23:00,903-Speed 365.79 samples/sec   Loss 0.4843 Epoch: 11   Global Step: 31500   Required: 9 hours
Training: 2025-08-31 08:23:18,413-Speed 365.51 samples/sec   Loss 0.4565 Epoch: 11   Global Step: 31550   Required: 9 hours
Training: 2025-08-31 08:23:35,917-Speed 365.62 samples/sec   Loss 0.4603 Epoch: 11   Global Step: 31600   Required: 9 hours
Training: 2025-08-31 08:23:53,422-Speed 365.63 samples/sec   Loss 0.4737 Epoch: 11   Global Step: 31650   Required: 9 hours
Training: 2025-08-31 08:24:10,916-Speed 365.83 samples/sec   Loss 0.4803 Epoch: 11   Global Step: 31700   Required: 9 hours
Training: 2025-08-31 08:24:28,414-Speed 365.77 samples/sec   Loss 0.4427 Epoch: 11   Global Step: 31750   Required: 9 hours
Training: 2025-08-31 08:24:45,908-Speed 365.84 samples/sec   Loss 0.4666 Epoch: 11   Global Step: 31800   Required: 9 hours
Training: 2025-08-31 08:25:03,402-Speed 365.83 samples/sec   Loss 0.4985 Epoch: 11   Global Step: 31850   Required: 9 hours
Training: 2025-08-31 08:25:20,894-Speed 365.88 samples/sec   Loss 0.4718 Epoch: 11   Global Step: 31900   Required: 9 hours
Training: 2025-08-31 08:25:38,388-Speed 365.86 samples/sec   Loss 0.4963 Epoch: 11   Global Step: 31950   Required: 9 hours
Training: 2025-08-31 08:25:55,883-Speed 365.82 samples/sec   Loss 0.5022 Epoch: 11   Global Step: 32000   Required: 9 hours
Training: 2025-08-31 08:26:13,377-Speed 365.83 samples/sec   Loss 0.4760 Epoch: 11   Global Step: 32050   Required: 9 hours
Training: 2025-08-31 08:26:30,872-Speed 365.83 samples/sec   Loss 0.4797 Epoch: 11   Global Step: 32100   Required: 9 hours
Training: 2025-08-31 08:26:48,374-Speed 365.67 samples/sec   Loss 0.5178 Epoch: 11   Global Step: 32150   Required: 9 hours
Training: 2025-08-31 08:27:05,872-Speed 365.77 samples/sec   Loss 0.4735 Epoch: 11   Global Step: 32200   Required: 9 hours
Training: 2025-08-31 08:27:23,364-Speed 365.87 samples/sec   Loss 0.4970 Epoch: 11   Global Step: 32250   Required: 9 hours
Training: 2025-08-31 08:27:40,859-Speed 365.83 samples/sec   Loss 0.5074 Epoch: 11   Global Step: 32300   Required: 9 hours
Training: 2025-08-31 08:27:58,353-Speed 365.85 samples/sec   Loss 0.4812 Epoch: 11   Global Step: 32350   Required: 9 hours
Training: 2025-08-31 08:28:15,851-Speed 365.75 samples/sec   Loss 0.4939 Epoch: 11   Global Step: 32400   Required: 9 hours
Training: 2025-08-31 08:28:33,345-Speed 365.85 samples/sec   Loss 0.4629 Epoch: 11   Global Step: 32450   Required: 9 hours
Training: 2025-08-31 08:28:50,840-Speed 365.82 samples/sec   Loss 0.5064 Epoch: 11   Global Step: 32500   Required: 9 hours
Training: 2025-08-31 08:29:08,333-Speed 365.86 samples/sec   Loss 0.4754 Epoch: 11   Global Step: 32550   Required: 9 hours
Training: 2025-08-31 08:29:25,828-Speed 365.82 samples/sec   Loss 0.5121 Epoch: 11   Global Step: 32600   Required: 9 hours
Training: 2025-08-31 08:29:43,324-Speed 365.82 samples/sec   Loss 0.5633 Epoch: 11   Global Step: 32650   Required: 9 hours
Training: 2025-08-31 08:30:00,817-Speed 365.85 samples/sec   Loss 0.4979 Epoch: 11   Global Step: 32700   Required: 9 hours
Training: 2025-08-31 08:30:18,312-Speed 365.83 samples/sec   Loss 0.5192 Epoch: 11   Global Step: 32750   Required: 9 hours
Training: 2025-08-31 08:30:35,805-Speed 365.85 samples/sec   Loss 0.4452 Epoch: 11   Global Step: 32800   Required: 9 hours
Training: 2025-08-31 08:30:53,299-Speed 365.85 samples/sec   Loss 0.5162 Epoch: 11   Global Step: 32850   Required: 9 hours
Training: 2025-08-31 08:31:10,794-Speed 365.83 samples/sec   Loss 0.5601 Epoch: 11   Global Step: 32900   Required: 9 hours
Training: 2025-08-31 08:31:28,295-Speed 365.68 samples/sec   Loss 0.5277 Epoch: 11   Global Step: 32950   Required: 9 hours
Training: 2025-08-31 08:31:45,792-Speed 365.78 samples/sec   Loss 0.5294 Epoch: 11   Global Step: 33000   Required: 9 hours
Training: 2025-08-31 08:32:03,297-Speed 365.62 samples/sec   Loss 0.4718 Epoch: 11   Global Step: 33050   Required: 9 hours
Training: 2025-08-31 08:32:20,798-Speed 365.69 samples/sec   Loss 0.5344 Epoch: 11   Global Step: 33100   Required: 9 hours
Training: 2025-08-31 08:32:38,295-Speed 365.78 samples/sec   Loss 0.4923 Epoch: 11   Global Step: 33150   Required: 9 hours
Training: 2025-08-31 08:32:55,791-Speed 365.82 samples/sec   Loss 0.5271 Epoch: 11   Global Step: 33200   Required: 9 hours
Training: 2025-08-31 08:33:13,285-Speed 365.84 samples/sec   Loss 0.5557 Epoch: 11   Global Step: 33250   Required: 9 hours
Training: 2025-08-31 08:33:30,778-Speed 365.85 samples/sec   Loss 0.5146 Epoch: 11   Global Step: 33300   Required: 9 hours
Training: 2025-08-31 08:33:48,274-Speed 365.81 samples/sec   Loss 0.5390 Epoch: 11   Global Step: 33350   Required: 9 hours
Training: 2025-08-31 08:34:05,775-Speed 365.71 samples/sec   Loss 0.5462 Epoch: 11   Global Step: 33400   Required: 9 hours
Training: 2025-08-31 08:34:23,273-Speed 365.75 samples/sec   Loss 0.5490 Epoch: 11   Global Step: 33450   Required: 9 hours
Training: 2025-08-31 08:34:40,776-Speed 365.66 samples/sec   Loss 0.5040 Epoch: 11   Global Step: 33500   Required: 9 hours
Training: 2025-08-31 08:34:58,272-Speed 365.80 samples/sec   Loss 0.5284 Epoch: 11   Global Step: 33550   Required: 9 hours
Training: 2025-08-31 08:35:15,765-Speed 365.85 samples/sec   Loss 0.5067 Epoch: 11   Global Step: 33600   Required: 9 hours
Training: 2025-08-31 08:35:33,260-Speed 365.83 samples/sec   Loss 0.5203 Epoch: 11   Global Step: 33650   Required: 9 hours
Training: 2025-08-31 08:35:50,754-Speed 365.84 samples/sec   Loss 0.5383 Epoch: 11   Global Step: 33700   Required: 9 hours
Training: 2025-08-31 08:36:30,509-[lfw][33744]XNorm: 15.945840
Training: 2025-08-31 08:36:30,509-[lfw][33744]Accuracy-Flip: 0.79850+-0.02023
Training: 2025-08-31 08:36:30,509-[lfw][33744]Accuracy-Highest: 0.83600
Training: 2025-08-31 08:36:58,799-[cfp_fp][33744]XNorm: 13.506596
Training: 2025-08-31 08:36:58,799-[cfp_fp][33744]Accuracy-Flip: 0.64057+-0.01697
Training: 2025-08-31 08:36:58,799-[cfp_fp][33744]Accuracy-Highest: 0.66086
Training: 2025-08-31 08:37:23,134-[agedb_30][33744]XNorm: 15.487511
Training: 2025-08-31 08:37:23,134-[agedb_30][33744]Accuracy-Flip: 0.53317+-0.02479
Training: 2025-08-31 08:37:23,134-[agedb_30][33744]Accuracy-Highest: 0.56500
Training: 2025-08-31 08:37:47,563-[calfw][33744]XNorm: 16.545285
Training: 2025-08-31 08:37:47,563-[calfw][33744]Accuracy-Flip: 0.66000+-0.02084
Training: 2025-08-31 08:37:47,563-[calfw][33744]Accuracy-Highest: 0.67117
Training: 2025-08-31 08:38:11,976-[cplfw][33744]XNorm: 12.698661
Training: 2025-08-31 08:38:11,976-[cplfw][33744]Accuracy-Flip: 0.61850+-0.01874
Training: 2025-08-31 08:38:11,976-[cplfw][33744]Accuracy-Highest: 0.63500
Training: 2025-08-31 08:38:14,226-Speed 44.61 samples/sec   Loss 0.5083 Epoch: 12   Global Step: 33750   Required: 9 hours
Training: 2025-08-31 08:38:31,718-Speed 365.89 samples/sec   Loss 0.4217 Epoch: 12   Global Step: 33800   Required: 9 hours
Training: 2025-08-31 08:38:49,213-Speed 365.82 samples/sec   Loss 0.4215 Epoch: 12   Global Step: 33850   Required: 9 hours
Training: 2025-08-31 08:39:06,708-Speed 365.82 samples/sec   Loss 0.4566 Epoch: 12   Global Step: 33900   Required: 9 hours
Training: 2025-08-31 08:39:24,202-Speed 365.84 samples/sec   Loss 0.4058 Epoch: 12   Global Step: 33950   Required: 9 hours
Training: 2025-08-31 08:39:41,699-Speed 365.77 samples/sec   Loss 0.4524 Epoch: 12   Global Step: 34000   Required: 9 hours
Training: 2025-08-31 08:39:59,199-Speed 365.73 samples/sec   Loss 0.4537 Epoch: 12   Global Step: 34050   Required: 9 hours
Training: 2025-08-31 08:40:16,704-Speed 365.60 samples/sec   Loss 0.4420 Epoch: 12   Global Step: 34100   Required: 9 hours
Training: 2025-08-31 08:40:34,207-Speed 365.66 samples/sec   Loss 0.4891 Epoch: 12   Global Step: 34150   Required: 9 hours
Training: 2025-08-31 08:40:51,713-Speed 365.59 samples/sec   Loss 0.4232 Epoch: 12   Global Step: 34200   Required: 9 hours
Training: 2025-08-31 08:41:09,212-Speed 365.76 samples/sec   Loss 0.4377 Epoch: 12   Global Step: 34250   Required: 9 hours
Training: 2025-08-31 08:41:26,721-Speed 365.53 samples/sec   Loss 0.4685 Epoch: 12   Global Step: 34300   Required: 9 hours
Training: 2025-08-31 08:41:44,224-Speed 365.64 samples/sec   Loss 0.4424 Epoch: 12   Global Step: 34350   Required: 9 hours
Training: 2025-08-31 08:42:01,732-Speed 365.56 samples/sec   Loss 0.4525 Epoch: 12   Global Step: 34400   Required: 9 hours
Training: 2025-08-31 08:42:19,235-Speed 365.65 samples/sec   Loss 0.4425 Epoch: 12   Global Step: 34450   Required: 9 hours
Training: 2025-08-31 08:42:36,742-Speed 365.58 samples/sec   Loss 0.4403 Epoch: 12   Global Step: 34500   Required: 9 hours
Training: 2025-08-31 08:42:54,247-Speed 365.60 samples/sec   Loss 0.4872 Epoch: 12   Global Step: 34550   Required: 9 hours
Training: 2025-08-31 08:43:11,749-Speed 365.68 samples/sec   Loss 0.4812 Epoch: 12   Global Step: 34600   Required: 9 hours
Training: 2025-08-31 08:43:29,245-Speed 365.79 samples/sec   Loss 0.4517 Epoch: 12   Global Step: 34650   Required: 9 hours
Training: 2025-08-31 08:43:46,740-Speed 365.83 samples/sec   Loss 0.5110 Epoch: 12   Global Step: 34700   Required: 9 hours
Training: 2025-08-31 08:44:04,245-Speed 365.61 samples/sec   Loss 0.4659 Epoch: 12   Global Step: 34750   Required: 8 hours
Training: 2025-08-31 08:44:21,740-Speed 365.82 samples/sec   Loss 0.4675 Epoch: 12   Global Step: 34800   Required: 8 hours
Training: 2025-08-31 08:44:39,248-Speed 365.54 samples/sec   Loss 0.4510 Epoch: 12   Global Step: 34850   Required: 8 hours
Training: 2025-08-31 08:44:56,748-Speed 365.72 samples/sec   Loss 0.4599 Epoch: 12   Global Step: 34900   Required: 8 hours
Training: 2025-08-31 08:45:14,252-Speed 365.64 samples/sec   Loss 0.4449 Epoch: 12   Global Step: 34950   Required: 8 hours
Training: 2025-08-31 08:45:31,747-Speed 365.82 samples/sec   Loss 0.4705 Epoch: 12   Global Step: 35000   Required: 8 hours
Training: 2025-08-31 08:45:49,242-Speed 365.82 samples/sec   Loss 0.4699 Epoch: 12   Global Step: 35050   Required: 8 hours
Training: 2025-08-31 08:46:06,743-Speed 365.69 samples/sec   Loss 0.4450 Epoch: 12   Global Step: 35100   Required: 8 hours
Training: 2025-08-31 08:46:24,246-Speed 365.66 samples/sec   Loss 0.4701 Epoch: 12   Global Step: 35150   Required: 8 hours
Training: 2025-08-31 08:46:41,744-Speed 365.75 samples/sec   Loss 0.4559 Epoch: 12   Global Step: 35200   Required: 8 hours
Training: 2025-08-31 08:46:59,235-Speed 365.90 samples/sec   Loss 0.4431 Epoch: 12   Global Step: 35250   Required: 8 hours
Training: 2025-08-31 08:47:16,732-Speed 365.78 samples/sec   Loss 0.5042 Epoch: 12   Global Step: 35300   Required: 8 hours
Training: 2025-08-31 08:47:34,224-Speed 365.87 samples/sec   Loss 0.4609 Epoch: 12   Global Step: 35350   Required: 8 hours
Training: 2025-08-31 08:47:51,719-Speed 365.82 samples/sec   Loss 0.4966 Epoch: 12   Global Step: 35400   Required: 8 hours
Training: 2025-08-31 08:48:09,220-Speed 365.70 samples/sec   Loss 0.4748 Epoch: 12   Global Step: 35450   Required: 8 hours
Training: 2025-08-31 08:48:26,720-Speed 365.72 samples/sec   Loss 0.4977 Epoch: 12   Global Step: 35500   Required: 8 hours
Training: 2025-08-31 08:48:44,214-Speed 365.83 samples/sec   Loss 0.4963 Epoch: 12   Global Step: 35550   Required: 8 hours
Training: 2025-08-31 08:49:01,708-Speed 365.85 samples/sec   Loss 0.4773 Epoch: 12   Global Step: 35600   Required: 8 hours
Training: 2025-08-31 08:49:19,202-Speed 365.83 samples/sec   Loss 0.4972 Epoch: 12   Global Step: 35650   Required: 8 hours
Training: 2025-08-31 08:49:36,697-Speed 365.83 samples/sec   Loss 0.5506 Epoch: 12   Global Step: 35700   Required: 8 hours
Training: 2025-08-31 08:49:54,192-Speed 365.82 samples/sec   Loss 0.4863 Epoch: 12   Global Step: 35750   Required: 8 hours
Training: 2025-08-31 08:50:11,686-Speed 365.84 samples/sec   Loss 0.4995 Epoch: 12   Global Step: 35800   Required: 8 hours
Training: 2025-08-31 08:50:29,180-Speed 365.84 samples/sec   Loss 0.4854 Epoch: 12   Global Step: 35850   Required: 8 hours
Training: 2025-08-31 08:50:46,674-Speed 365.85 samples/sec   Loss 0.4616 Epoch: 12   Global Step: 35900   Required: 8 hours
Training: 2025-08-31 08:51:04,165-Speed 365.91 samples/sec   Loss 0.4994 Epoch: 12   Global Step: 35950   Required: 8 hours
Training: 2025-08-31 08:51:21,660-Speed 365.82 samples/sec   Loss 0.5384 Epoch: 12   Global Step: 36000   Required: 8 hours
Training: 2025-08-31 08:51:39,155-Speed 365.82 samples/sec   Loss 0.4932 Epoch: 12   Global Step: 36050   Required: 8 hours
Training: 2025-08-31 08:51:56,651-Speed 365.81 samples/sec   Loss 0.4891 Epoch: 12   Global Step: 36100   Required: 8 hours
Training: 2025-08-31 08:52:14,144-Speed 365.85 samples/sec   Loss 0.5087 Epoch: 12   Global Step: 36150   Required: 8 hours
Training: 2025-08-31 08:52:31,637-Speed 365.86 samples/sec   Loss 0.4871 Epoch: 12   Global Step: 36200   Required: 8 hours
Training: 2025-08-31 08:52:49,132-Speed 365.83 samples/sec   Loss 0.4823 Epoch: 12   Global Step: 36250   Required: 8 hours
Training: 2025-08-31 08:53:06,629-Speed 365.78 samples/sec   Loss 0.5141 Epoch: 12   Global Step: 36300   Required: 8 hours
Training: 2025-08-31 08:53:24,124-Speed 365.82 samples/sec   Loss 0.4795 Epoch: 12   Global Step: 36350   Required: 8 hours
Training: 2025-08-31 08:53:41,618-Speed 365.84 samples/sec   Loss 0.4659 Epoch: 12   Global Step: 36400   Required: 8 hours
Training: 2025-08-31 08:53:59,112-Speed 365.84 samples/sec   Loss 0.5147 Epoch: 12   Global Step: 36450   Required: 8 hours
Training: 2025-08-31 08:54:16,605-Speed 365.85 samples/sec   Loss 0.5038 Epoch: 12   Global Step: 36500   Required: 8 hours
Training: 2025-08-31 08:54:34,101-Speed 365.80 samples/sec   Loss 0.5056 Epoch: 12   Global Step: 36550   Required: 8 hours
Training: 2025-08-31 08:55:00,546-[lfw][36556]XNorm: 15.430799
Training: 2025-08-31 08:55:00,546-[lfw][36556]Accuracy-Flip: 0.83400+-0.02007
Training: 2025-08-31 08:55:00,546-[lfw][36556]Accuracy-Highest: 0.83600
Training: 2025-08-31 08:55:28,891-[cfp_fp][36556]XNorm: 14.536586
Training: 2025-08-31 08:55:28,892-[cfp_fp][36556]Accuracy-Flip: 0.62829+-0.02265
Training: 2025-08-31 08:55:28,892-[cfp_fp][36556]Accuracy-Highest: 0.66086
Training: 2025-08-31 08:55:53,237-[agedb_30][36556]XNorm: 13.508964
Training: 2025-08-31 08:55:53,237-[agedb_30][36556]Accuracy-Flip: 0.54050+-0.01750
Training: 2025-08-31 08:55:53,237-[agedb_30][36556]Accuracy-Highest: 0.56500
Training: 2025-08-31 08:56:17,665-[calfw][36556]XNorm: 15.765426
Training: 2025-08-31 08:56:17,665-[calfw][36556]Accuracy-Flip: 0.66033+-0.01688
Training: 2025-08-31 08:56:17,665-[calfw][36556]Accuracy-Highest: 0.67117
Training: 2025-08-31 08:56:42,082-[cplfw][36556]XNorm: 12.376999
Training: 2025-08-31 08:56:42,082-[cplfw][36556]Accuracy-Flip: 0.61783+-0.01553
Training: 2025-08-31 08:56:42,082-[cplfw][36556]Accuracy-Highest: 0.63500
Training: 2025-08-31 08:56:57,659-Speed 44.58 samples/sec   Loss 0.4576 Epoch: 13   Global Step: 36600   Required: 8 hours
Training: 2025-08-31 08:57:15,154-Speed 365.81 samples/sec   Loss 0.3876 Epoch: 13   Global Step: 36650   Required: 8 hours
Training: 2025-08-31 08:57:32,651-Speed 365.80 samples/sec   Loss 0.4351 Epoch: 13   Global Step: 36700   Required: 8 hours
Training: 2025-08-31 08:57:50,144-Speed 365.85 samples/sec   Loss 0.4006 Epoch: 13   Global Step: 36750   Required: 8 hours
Training: 2025-08-31 08:58:07,639-Speed 365.81 samples/sec   Loss 0.4415 Epoch: 13   Global Step: 36800   Required: 8 hours
Training: 2025-08-31 08:58:25,133-Speed 365.84 samples/sec   Loss 0.4180 Epoch: 13   Global Step: 36850   Required: 8 hours
Training: 2025-08-31 08:58:42,630-Speed 365.78 samples/sec   Loss 0.4301 Epoch: 13   Global Step: 36900   Required: 8 hours
Training: 2025-08-31 08:59:00,126-Speed 365.81 samples/sec   Loss 0.4196 Epoch: 13   Global Step: 36950   Required: 8 hours
Training: 2025-08-31 08:59:17,636-Speed 365.50 samples/sec   Loss 0.4031 Epoch: 13   Global Step: 37000   Required: 8 hours
Training: 2025-08-31 08:59:35,142-Speed 365.59 samples/sec   Loss 0.4367 Epoch: 13   Global Step: 37050   Required: 8 hours
Training: 2025-08-31 08:59:52,649-Speed 365.59 samples/sec   Loss 0.4321 Epoch: 13   Global Step: 37100   Required: 8 hours
Training: 2025-08-31 09:00:10,150-Speed 365.68 samples/sec   Loss 0.4015 Epoch: 13   Global Step: 37150   Required: 8 hours
Training: 2025-08-31 09:00:27,657-Speed 365.57 samples/sec   Loss 0.4292 Epoch: 13   Global Step: 37200   Required: 8 hours
Training: 2025-08-31 09:00:45,165-Speed 365.55 samples/sec   Loss 0.4621 Epoch: 13   Global Step: 37250   Required: 8 hours
Training: 2025-08-31 09:01:02,666-Speed 365.70 samples/sec   Loss 0.3993 Epoch: 13   Global Step: 37300   Required: 8 hours
Training: 2025-08-31 09:01:20,177-Speed 365.48 samples/sec   Loss 0.4459 Epoch: 13   Global Step: 37350   Required: 8 hours
Training: 2025-08-31 09:01:37,685-Speed 365.56 samples/sec   Loss 0.4195 Epoch: 13   Global Step: 37400   Required: 8 hours
Training: 2025-08-31 09:01:55,189-Speed 365.63 samples/sec   Loss 0.4633 Epoch: 13   Global Step: 37450   Required: 8 hours
Training: 2025-08-31 09:02:12,694-Speed 365.60 samples/sec   Loss 0.4401 Epoch: 13   Global Step: 37500   Required: 8 hours
Training: 2025-08-31 09:02:30,198-Speed 365.64 samples/sec   Loss 0.4634 Epoch: 13   Global Step: 37550   Required: 8 hours
Training: 2025-08-31 09:02:47,709-Speed 365.48 samples/sec   Loss 0.4575 Epoch: 13   Global Step: 37600   Required: 8 hours
Training: 2025-08-31 09:03:05,213-Speed 365.65 samples/sec   Loss 0.4527 Epoch: 13   Global Step: 37650   Required: 8 hours
Training: 2025-08-31 09:03:22,717-Speed 365.63 samples/sec   Loss 0.4432 Epoch: 13   Global Step: 37700   Required: 8 hours
Training: 2025-08-31 09:03:40,214-Speed 365.79 samples/sec   Loss 0.4277 Epoch: 13   Global Step: 37750   Required: 8 hours
Training: 2025-08-31 09:03:57,709-Speed 365.81 samples/sec   Loss 0.4572 Epoch: 13   Global Step: 37800   Required: 8 hours
Training: 2025-08-31 09:04:15,211-Speed 365.68 samples/sec   Loss 0.4661 Epoch: 13   Global Step: 37850   Required: 8 hours
Training: 2025-08-31 09:04:32,708-Speed 365.78 samples/sec   Loss 0.4373 Epoch: 13   Global Step: 37900   Required: 8 hours
Training: 2025-08-31 09:04:50,203-Speed 365.83 samples/sec   Loss 0.4646 Epoch: 13   Global Step: 37950   Required: 8 hours
Training: 2025-08-31 09:05:07,700-Speed 365.77 samples/sec   Loss 0.4574 Epoch: 13   Global Step: 38000   Required: 8 hours
Training: 2025-08-31 09:05:25,201-Speed 365.70 samples/sec   Loss 0.4656 Epoch: 13   Global Step: 38050   Required: 8 hours
Training: 2025-08-31 09:05:42,702-Speed 365.69 samples/sec   Loss 0.4575 Epoch: 13   Global Step: 38100   Required: 8 hours
Training: 2025-08-31 09:06:00,205-Speed 365.67 samples/sec   Loss 0.4633 Epoch: 13   Global Step: 38150   Required: 8 hours
Training: 2025-08-31 09:06:17,704-Speed 365.72 samples/sec   Loss 0.5223 Epoch: 13   Global Step: 38200   Required: 8 hours
Training: 2025-08-31 09:06:35,205-Speed 365.71 samples/sec   Loss 0.4910 Epoch: 13   Global Step: 38250   Required: 8 hours
Training: 2025-08-31 09:06:52,705-Speed 365.72 samples/sec   Loss 0.4829 Epoch: 13   Global Step: 38300   Required: 8 hours
Training: 2025-08-31 09:07:10,213-Speed 365.54 samples/sec   Loss 0.4843 Epoch: 13   Global Step: 38350   Required: 8 hours
Training: 2025-08-31 09:07:27,719-Speed 365.60 samples/sec   Loss 0.4653 Epoch: 13   Global Step: 38400   Required: 8 hours
Training: 2025-08-31 09:07:45,223-Speed 365.63 samples/sec   Loss 0.4623 Epoch: 13   Global Step: 38450   Required: 8 hours
Training: 2025-08-31 09:08:02,728-Speed 365.61 samples/sec   Loss 0.4671 Epoch: 13   Global Step: 38500   Required: 8 hours
Training: 2025-08-31 09:08:20,226-Speed 365.76 samples/sec   Loss 0.5136 Epoch: 13   Global Step: 38550   Required: 8 hours
Training: 2025-08-31 09:08:37,729-Speed 365.64 samples/sec   Loss 0.4210 Epoch: 13   Global Step: 38600   Required: 8 hours
Training: 2025-08-31 09:08:55,232-Speed 365.67 samples/sec   Loss 0.4455 Epoch: 13   Global Step: 38650   Required: 8 hours
Training: 2025-08-31 09:09:12,728-Speed 365.78 samples/sec   Loss 0.4761 Epoch: 13   Global Step: 38700   Required: 8 hours
Training: 2025-08-31 09:09:30,232-Speed 365.64 samples/sec   Loss 0.4895 Epoch: 13   Global Step: 38750   Required: 8 hours
Training: 2025-08-31 09:09:47,742-Speed 365.51 samples/sec   Loss 0.4841 Epoch: 13   Global Step: 38800   Required: 8 hours
Training: 2025-08-31 09:10:05,250-Speed 365.56 samples/sec   Loss 0.4827 Epoch: 13   Global Step: 38850   Required: 8 hours
Training: 2025-08-31 09:10:22,745-Speed 365.81 samples/sec   Loss 0.4793 Epoch: 13   Global Step: 38900   Required: 8 hours
Training: 2025-08-31 09:10:40,251-Speed 365.59 samples/sec   Loss 0.4822 Epoch: 13   Global Step: 38950   Required: 8 hours
Training: 2025-08-31 09:10:57,761-Speed 365.51 samples/sec   Loss 0.4925 Epoch: 13   Global Step: 39000   Required: 8 hours
Training: 2025-08-31 09:11:15,269-Speed 365.55 samples/sec   Loss 0.4970 Epoch: 13   Global Step: 39050   Required: 8 hours
Training: 2025-08-31 09:11:32,774-Speed 365.60 samples/sec   Loss 0.4739 Epoch: 13   Global Step: 39100   Required: 8 hours
Training: 2025-08-31 09:11:50,282-Speed 365.55 samples/sec   Loss 0.4711 Epoch: 13   Global Step: 39150   Required: 8 hours
Training: 2025-08-31 09:12:07,786-Speed 365.63 samples/sec   Loss 0.4465 Epoch: 13   Global Step: 39200   Required: 8 hours
Training: 2025-08-31 09:12:25,283-Speed 365.78 samples/sec   Loss 0.4502 Epoch: 13   Global Step: 39250   Required: 8 hours
Training: 2025-08-31 09:12:42,777-Speed 365.85 samples/sec   Loss 0.4704 Epoch: 13   Global Step: 39300   Required: 8 hours
Training: 2025-08-31 09:13:00,271-Speed 365.84 samples/sec   Loss 0.4742 Epoch: 13   Global Step: 39350   Required: 8 hours
Training: 2025-08-31 09:13:30,920-[lfw][39368]XNorm: 16.278987
Training: 2025-08-31 09:13:30,920-[lfw][39368]Accuracy-Flip: 0.81533+-0.01825
Training: 2025-08-31 09:13:30,920-[lfw][39368]Accuracy-Highest: 0.83600
Training: 2025-08-31 09:13:59,206-[cfp_fp][39368]XNorm: 13.526460
Training: 2025-08-31 09:13:59,206-[cfp_fp][39368]Accuracy-Flip: 0.65329+-0.02116
Training: 2025-08-31 09:13:59,206-[cfp_fp][39368]Accuracy-Highest: 0.66086
Training: 2025-08-31 09:14:23,553-[agedb_30][39368]XNorm: 14.012215
Training: 2025-08-31 09:14:23,554-[agedb_30][39368]Accuracy-Flip: 0.53217+-0.01889
Training: 2025-08-31 09:14:23,554-[agedb_30][39368]Accuracy-Highest: 0.56500
Training: 2025-08-31 09:14:47,978-[calfw][39368]XNorm: 16.037331
Training: 2025-08-31 09:14:47,978-[calfw][39368]Accuracy-Flip: 0.65600+-0.01831
Training: 2025-08-31 09:14:47,978-[calfw][39368]Accuracy-Highest: 0.67117
Training: 2025-08-31 09:15:12,395-[cplfw][39368]XNorm: 12.806201
Training: 2025-08-31 09:15:12,395-[cplfw][39368]Accuracy-Flip: 0.62333+-0.01916
Training: 2025-08-31 09:15:12,395-[cplfw][39368]Accuracy-Highest: 0.63500
Training: 2025-08-31 09:15:23,745-Speed 44.61 samples/sec   Loss 0.4121 Epoch: 14   Global Step: 39400   Required: 8 hours
Training: 2025-08-31 09:15:41,238-Speed 365.86 samples/sec   Loss 0.3766 Epoch: 14   Global Step: 39450   Required: 8 hours
Training: 2025-08-31 09:15:58,733-Speed 365.83 samples/sec   Loss 0.3878 Epoch: 14   Global Step: 39500   Required: 8 hours
Training: 2025-08-31 09:16:16,229-Speed 365.80 samples/sec   Loss 0.4042 Epoch: 14   Global Step: 39550   Required: 8 hours
Training: 2025-08-31 09:16:33,725-Speed 365.80 samples/sec   Loss 0.3987 Epoch: 14   Global Step: 39600   Required: 8 hours
Training: 2025-08-31 09:16:51,217-Speed 365.87 samples/sec   Loss 0.3902 Epoch: 14   Global Step: 39650   Required: 8 hours
Training: 2025-08-31 09:17:08,712-Speed 365.83 samples/sec   Loss 0.4252 Epoch: 14   Global Step: 39700   Required: 8 hours
Training: 2025-08-31 09:17:26,209-Speed 365.78 samples/sec   Loss 0.4304 Epoch: 14   Global Step: 39750   Required: 8 hours
Training: 2025-08-31 09:17:43,703-Speed 365.84 samples/sec   Loss 0.4480 Epoch: 14   Global Step: 39800   Required: 8 hours
Training: 2025-08-31 09:18:01,213-Speed 365.51 samples/sec   Loss 0.4249 Epoch: 14   Global Step: 39850   Required: 8 hours
Training: 2025-08-31 09:18:18,716-Speed 365.65 samples/sec   Loss 0.3985 Epoch: 14   Global Step: 39900   Required: 8 hours
Training: 2025-08-31 09:18:36,214-Speed 365.76 samples/sec   Loss 0.3792 Epoch: 14   Global Step: 39950   Required: 8 hours
Training: 2025-08-31 09:18:53,717-Speed 365.66 samples/sec   Loss 0.4139 Epoch: 14   Global Step: 40000   Required: 8 hours
Training: 2025-08-31 09:19:11,212-Speed 365.84 samples/sec   Loss 0.4612 Epoch: 14   Global Step: 40050   Required: 8 hours
Training: 2025-08-31 09:19:28,707-Speed 365.81 samples/sec   Loss 0.4231 Epoch: 14   Global Step: 40100   Required: 8 hours
Training: 2025-08-31 09:19:46,201-Speed 365.85 samples/sec   Loss 0.4608 Epoch: 14   Global Step: 40150   Required: 8 hours
Training: 2025-08-31 09:20:03,698-Speed 365.77 samples/sec   Loss 0.4593 Epoch: 14   Global Step: 40200   Required: 8 hours
Training: 2025-08-31 09:20:21,193-Speed 365.83 samples/sec   Loss 0.4218 Epoch: 14   Global Step: 40250   Required: 8 hours
Training: 2025-08-31 09:20:38,686-Speed 365.86 samples/sec   Loss 0.4197 Epoch: 14   Global Step: 40300   Required: 8 hours
Training: 2025-08-31 09:20:56,180-Speed 365.83 samples/sec   Loss 0.4412 Epoch: 14   Global Step: 40350   Required: 8 hours
Training: 2025-08-31 09:21:13,673-Speed 365.87 samples/sec   Loss 0.4421 Epoch: 14   Global Step: 40400   Required: 8 hours
Training: 2025-08-31 09:21:31,166-Speed 365.85 samples/sec   Loss 0.4425 Epoch: 14   Global Step: 40450   Required: 8 hours
Training: 2025-08-31 09:21:48,666-Speed 365.73 samples/sec   Loss 0.4293 Epoch: 14   Global Step: 40500   Required: 8 hours
Training: 2025-08-31 09:22:06,169-Speed 365.65 samples/sec   Loss 0.4464 Epoch: 14   Global Step: 40550   Required: 8 hours
Training: 2025-08-31 09:22:23,674-Speed 365.62 samples/sec   Loss 0.4567 Epoch: 14   Global Step: 40600   Required: 8 hours
Training: 2025-08-31 09:22:41,173-Speed 365.74 samples/sec   Loss 0.4478 Epoch: 14   Global Step: 40650   Required: 8 hours
Training: 2025-08-31 09:22:58,668-Speed 365.82 samples/sec   Loss 0.4699 Epoch: 14   Global Step: 40700   Required: 8 hours
Training: 2025-08-31 09:23:16,166-Speed 365.75 samples/sec   Loss 0.4566 Epoch: 14   Global Step: 40750   Required: 8 hours
Training: 2025-08-31 09:23:33,671-Speed 365.63 samples/sec   Loss 0.4366 Epoch: 14   Global Step: 40800   Required: 8 hours
Training: 2025-08-31 09:23:51,171-Speed 365.70 samples/sec   Loss 0.4315 Epoch: 14   Global Step: 40850   Required: 8 hours
Training: 2025-08-31 09:24:08,669-Speed 365.76 samples/sec   Loss 0.4606 Epoch: 14   Global Step: 40900   Required: 8 hours
Training: 2025-08-31 09:24:26,165-Speed 365.81 samples/sec   Loss 0.4278 Epoch: 14   Global Step: 40950   Required: 8 hours
Training: 2025-08-31 09:24:43,658-Speed 365.85 samples/sec   Loss 0.4433 Epoch: 14   Global Step: 41000   Required: 8 hours
Training: 2025-08-31 09:25:01,153-Speed 365.84 samples/sec   Loss 0.4202 Epoch: 14   Global Step: 41050   Required: 8 hours
Training: 2025-08-31 09:25:18,659-Speed 365.58 samples/sec   Loss 0.4241 Epoch: 14   Global Step: 41100   Required: 8 hours
Training: 2025-08-31 09:25:36,166-Speed 365.57 samples/sec   Loss 0.4552 Epoch: 14   Global Step: 41150   Required: 8 hours
Training: 2025-08-31 09:25:53,665-Speed 365.73 samples/sec   Loss 0.4590 Epoch: 14   Global Step: 41200   Required: 8 hours
Training: 2025-08-31 09:26:11,160-Speed 365.82 samples/sec   Loss 0.4686 Epoch: 14   Global Step: 41250   Required: 8 hours
Training: 2025-08-31 09:26:28,662-Speed 365.67 samples/sec   Loss 0.4549 Epoch: 14   Global Step: 41300   Required: 8 hours
Training: 2025-08-31 09:26:46,164-Speed 365.67 samples/sec   Loss 0.4614 Epoch: 14   Global Step: 41350   Required: 8 hours
Training: 2025-08-31 09:27:03,660-Speed 365.81 samples/sec   Loss 0.4659 Epoch: 14   Global Step: 41400   Required: 8 hours
Training: 2025-08-31 09:27:21,157-Speed 365.77 samples/sec   Loss 0.5126 Epoch: 14   Global Step: 41450   Required: 8 hours
Training: 2025-08-31 09:27:38,662-Speed 365.61 samples/sec   Loss 0.4400 Epoch: 14   Global Step: 41500   Required: 8 hours
Training: 2025-08-31 09:27:56,172-Speed 365.50 samples/sec   Loss 0.4482 Epoch: 14   Global Step: 41550   Required: 8 hours
Training: 2025-08-31 09:28:13,673-Speed 365.70 samples/sec   Loss 0.4164 Epoch: 14   Global Step: 41600   Required: 8 hours
Training: 2025-08-31 09:28:31,173-Speed 365.73 samples/sec   Loss 0.4502 Epoch: 14   Global Step: 41650   Required: 8 hours
Training: 2025-08-31 09:28:48,669-Speed 365.80 samples/sec   Loss 0.4549 Epoch: 14   Global Step: 41700   Required: 8 hours
Training: 2025-08-31 09:29:06,170-Speed 365.69 samples/sec   Loss 0.4574 Epoch: 14   Global Step: 41750   Required: 8 hours
Training: 2025-08-31 09:29:23,677-Speed 365.58 samples/sec   Loss 0.5087 Epoch: 14   Global Step: 41800   Required: 8 hours
Training: 2025-08-31 09:29:41,172-Speed 365.81 samples/sec   Loss 0.4795 Epoch: 14   Global Step: 41850   Required: 8 hours
Training: 2025-08-31 09:29:58,666-Speed 365.84 samples/sec   Loss 0.4533 Epoch: 14   Global Step: 41900   Required: 8 hours
Training: 2025-08-31 09:30:16,164-Speed 365.76 samples/sec   Loss 0.4531 Epoch: 14   Global Step: 41950   Required: 8 hours
Training: 2025-08-31 09:30:33,673-Speed 365.53 samples/sec   Loss 0.4716 Epoch: 14   Global Step: 42000   Required: 8 hours
Training: 2025-08-31 09:30:51,170-Speed 365.78 samples/sec   Loss 0.4495 Epoch: 14   Global Step: 42050   Required: 8 hours
Training: 2025-08-31 09:31:08,670-Speed 365.71 samples/sec   Loss 0.4552 Epoch: 14   Global Step: 42100   Required: 8 hours
Training: 2025-08-31 09:31:26,175-Speed 365.61 samples/sec   Loss 0.4922 Epoch: 14   Global Step: 42150   Required: 8 hours
Training: 2025-08-31 09:32:01,048-[lfw][42180]XNorm: 16.188507
Training: 2025-08-31 09:32:01,048-[lfw][42180]Accuracy-Flip: 0.81767+-0.02060
Training: 2025-08-31 09:32:01,048-[lfw][42180]Accuracy-Highest: 0.83600
Training: 2025-08-31 09:32:29,336-[cfp_fp][42180]XNorm: 13.794815
Training: 2025-08-31 09:32:29,336-[cfp_fp][42180]Accuracy-Flip: 0.64000+-0.01946
Training: 2025-08-31 09:32:29,336-[cfp_fp][42180]Accuracy-Highest: 0.66086
Training: 2025-08-31 09:32:53,693-[agedb_30][42180]XNorm: 15.373611
Training: 2025-08-31 09:32:53,693-[agedb_30][42180]Accuracy-Flip: 0.54050+-0.01675
Training: 2025-08-31 09:32:53,693-[agedb_30][42180]Accuracy-Highest: 0.56500
Training: 2025-08-31 09:33:18,134-[calfw][42180]XNorm: 16.797376
Training: 2025-08-31 09:33:18,134-[calfw][42180]Accuracy-Flip: 0.66333+-0.01743
Training: 2025-08-31 09:33:18,134-[calfw][42180]Accuracy-Highest: 0.67117
Training: 2025-08-31 09:33:42,564-[cplfw][42180]XNorm: 12.814166
Training: 2025-08-31 09:33:42,564-[cplfw][42180]Accuracy-Flip: 0.61650+-0.01895
Training: 2025-08-31 09:33:42,564-[cplfw][42180]Accuracy-Highest: 0.63500
Training: 2025-08-31 09:33:49,716-Speed 44.59 samples/sec   Loss 0.4621 Epoch: 15   Global Step: 42200   Required: 8 hours
Training: 2025-08-31 09:34:07,211-Speed 365.82 samples/sec   Loss 0.3369 Epoch: 15   Global Step: 42250   Required: 8 hours
Training: 2025-08-31 09:34:24,707-Speed 365.82 samples/sec   Loss 0.3601 Epoch: 15   Global Step: 42300   Required: 8 hours
Training: 2025-08-31 09:34:42,202-Speed 365.81 samples/sec   Loss 0.4170 Epoch: 15   Global Step: 42350   Required: 8 hours
Training: 2025-08-31 09:34:59,700-Speed 365.77 samples/sec   Loss 0.3730 Epoch: 15   Global Step: 42400   Required: 8 hours
Training: 2025-08-31 09:35:17,203-Speed 365.64 samples/sec   Loss 0.3986 Epoch: 15   Global Step: 42450   Required: 8 hours
Training: 2025-08-31 09:35:34,708-Speed 365.61 samples/sec   Loss 0.3741 Epoch: 15   Global Step: 42500   Required: 8 hours
Training: 2025-08-31 09:35:52,208-Speed 365.72 samples/sec   Loss 0.3910 Epoch: 15   Global Step: 42550   Required: 8 hours
Training: 2025-08-31 09:36:09,712-Speed 365.64 samples/sec   Loss 0.4035 Epoch: 15   Global Step: 42600   Required: 8 hours
Training: 2025-08-31 09:36:27,211-Speed 365.74 samples/sec   Loss 0.4318 Epoch: 15   Global Step: 42650   Required: 8 hours
Training: 2025-08-31 09:36:44,716-Speed 365.62 samples/sec   Loss 0.3756 Epoch: 15   Global Step: 42700   Required: 8 hours
Training: 2025-08-31 09:37:02,230-Speed 365.41 samples/sec   Loss 0.3940 Epoch: 15   Global Step: 42750   Required: 8 hours
Training: 2025-08-31 09:37:19,744-Speed 365.43 samples/sec   Loss 0.3970 Epoch: 15   Global Step: 42800   Required: 8 hours
Training: 2025-08-31 09:37:37,255-Speed 365.49 samples/sec   Loss 0.4267 Epoch: 15   Global Step: 42850   Required: 8 hours
Training: 2025-08-31 09:37:54,770-Speed 365.41 samples/sec   Loss 0.4084 Epoch: 15   Global Step: 42900   Required: 8 hours
Training: 2025-08-31 09:38:12,278-Speed 365.55 samples/sec   Loss 0.4240 Epoch: 15   Global Step: 42950   Required: 8 hours
Training: 2025-08-31 09:38:29,780-Speed 365.68 samples/sec   Loss 0.4139 Epoch: 15   Global Step: 43000   Required: 8 hours
Training: 2025-08-31 09:38:47,284-Speed 365.63 samples/sec   Loss 0.4095 Epoch: 15   Global Step: 43050   Required: 8 hours
Training: 2025-08-31 09:39:04,787-Speed 365.66 samples/sec   Loss 0.4139 Epoch: 15   Global Step: 43100   Required: 8 hours
Training: 2025-08-31 09:39:22,284-Speed 365.77 samples/sec   Loss 0.4016 Epoch: 15   Global Step: 43150   Required: 8 hours
Training: 2025-08-31 09:39:39,796-Speed 365.48 samples/sec   Loss 0.4117 Epoch: 15   Global Step: 43200   Required: 8 hours
Training: 2025-08-31 09:39:57,300-Speed 365.63 samples/sec   Loss 0.4121 Epoch: 15   Global Step: 43250   Required: 8 hours
Training: 2025-08-31 09:40:14,807-Speed 365.57 samples/sec   Loss 0.4349 Epoch: 15   Global Step: 43300   Required: 8 hours
Training: 2025-08-31 09:40:32,312-Speed 365.60 samples/sec   Loss 0.4331 Epoch: 15   Global Step: 43350   Required: 8 hours
Training: 2025-08-31 09:40:49,807-Speed 365.84 samples/sec   Loss 0.4218 Epoch: 15   Global Step: 43400   Required: 8 hours
Training: 2025-08-31 09:41:07,309-Speed 365.67 samples/sec   Loss 0.4237 Epoch: 15   Global Step: 43450   Required: 8 hours
Training: 2025-08-31 09:41:24,809-Speed 365.70 samples/sec   Loss 0.4508 Epoch: 15   Global Step: 43500   Required: 8 hours
Training: 2025-08-31 09:41:42,316-Speed 365.58 samples/sec   Loss 0.4186 Epoch: 15   Global Step: 43550   Required: 8 hours
Training: 2025-08-31 09:41:59,811-Speed 365.82 samples/sec   Loss 0.4398 Epoch: 15   Global Step: 43600   Required: 8 hours
Training: 2025-08-31 09:42:17,307-Speed 365.80 samples/sec   Loss 0.4213 Epoch: 15   Global Step: 43650   Required: 8 hours
Training: 2025-08-31 09:42:34,801-Speed 365.84 samples/sec   Loss 0.4121 Epoch: 15   Global Step: 43700   Required: 8 hours
Training: 2025-08-31 09:42:52,294-Speed 365.87 samples/sec   Loss 0.4428 Epoch: 15   Global Step: 43750   Required: 8 hours
Training: 2025-08-31 09:43:09,787-Speed 365.85 samples/sec   Loss 0.4446 Epoch: 15   Global Step: 43800   Required: 8 hours
Training: 2025-08-31 09:43:27,285-Speed 365.78 samples/sec   Loss 0.4409 Epoch: 15   Global Step: 43850   Required: 7 hours
Training: 2025-08-31 09:43:44,782-Speed 365.78 samples/sec   Loss 0.4519 Epoch: 15   Global Step: 43900   Required: 7 hours
Training: 2025-08-31 09:44:02,285-Speed 365.65 samples/sec   Loss 0.4105 Epoch: 15   Global Step: 43950   Required: 7 hours
Training: 2025-08-31 09:44:19,779-Speed 365.84 samples/sec   Loss 0.4218 Epoch: 15   Global Step: 44000   Required: 7 hours
Training: 2025-08-31 09:44:37,282-Speed 365.65 samples/sec   Loss 0.4413 Epoch: 15   Global Step: 44050   Required: 7 hours
Training: 2025-08-31 09:44:54,782-Speed 365.72 samples/sec   Loss 0.4644 Epoch: 15   Global Step: 44100   Required: 7 hours
Training: 2025-08-31 09:45:12,285-Speed 365.65 samples/sec   Loss 0.4531 Epoch: 15   Global Step: 44150   Required: 7 hours
Training: 2025-08-31 09:45:29,786-Speed 365.70 samples/sec   Loss 0.4170 Epoch: 15   Global Step: 44200   Required: 7 hours
Training: 2025-08-31 09:45:47,280-Speed 365.83 samples/sec   Loss 0.4714 Epoch: 15   Global Step: 44250   Required: 7 hours
Training: 2025-08-31 09:46:04,783-Speed 365.66 samples/sec   Loss 0.4407 Epoch: 15   Global Step: 44300   Required: 7 hours
Training: 2025-08-31 09:46:22,285-Speed 365.67 samples/sec   Loss 0.4322 Epoch: 15   Global Step: 44350   Required: 7 hours
Training: 2025-08-31 09:46:39,782-Speed 365.78 samples/sec   Loss 0.4800 Epoch: 15   Global Step: 44400   Required: 7 hours
Training: 2025-08-31 09:46:57,276-Speed 365.84 samples/sec   Loss 0.4827 Epoch: 15   Global Step: 44450   Required: 7 hours
Training: 2025-08-31 09:47:14,769-Speed 365.88 samples/sec   Loss 0.4797 Epoch: 15   Global Step: 44500   Required: 7 hours
Training: 2025-08-31 09:47:32,263-Speed 365.84 samples/sec   Loss 0.4680 Epoch: 15   Global Step: 44550   Required: 7 hours
Training: 2025-08-31 09:47:49,757-Speed 365.82 samples/sec   Loss 0.4443 Epoch: 15   Global Step: 44600   Required: 7 hours
Training: 2025-08-31 09:48:07,252-Speed 365.84 samples/sec   Loss 0.4676 Epoch: 15   Global Step: 44650   Required: 7 hours
Training: 2025-08-31 09:48:24,748-Speed 365.79 samples/sec   Loss 0.4338 Epoch: 15   Global Step: 44700   Required: 7 hours
Training: 2025-08-31 09:48:42,244-Speed 365.81 samples/sec   Loss 0.4653 Epoch: 15   Global Step: 44750   Required: 7 hours
Training: 2025-08-31 09:48:59,748-Speed 365.63 samples/sec   Loss 0.4447 Epoch: 15   Global Step: 44800   Required: 7 hours
Training: 2025-08-31 09:49:17,250-Speed 365.67 samples/sec   Loss 0.4202 Epoch: 15   Global Step: 44850   Required: 7 hours
Training: 2025-08-31 09:49:34,747-Speed 365.78 samples/sec   Loss 0.4217 Epoch: 15   Global Step: 44900   Required: 7 hours
Training: 2025-08-31 09:49:52,243-Speed 365.80 samples/sec   Loss 0.4449 Epoch: 15   Global Step: 44950   Required: 7 hours
Training: 2025-08-31 09:50:31,289-[lfw][44992]XNorm: 16.971784
Training: 2025-08-31 09:50:31,289-[lfw][44992]Accuracy-Flip: 0.82483+-0.01555
Training: 2025-08-31 09:50:31,289-[lfw][44992]Accuracy-Highest: 0.83600
Training: 2025-08-31 09:50:59,568-[cfp_fp][44992]XNorm: 15.368715
Training: 2025-08-31 09:50:59,568-[cfp_fp][44992]Accuracy-Flip: 0.63614+-0.01980
Training: 2025-08-31 09:50:59,568-[cfp_fp][44992]Accuracy-Highest: 0.66086
Training: 2025-08-31 09:51:23,911-[agedb_30][44992]XNorm: 17.571742
Training: 2025-08-31 09:51:23,911-[agedb_30][44992]Accuracy-Flip: 0.54250+-0.01975
Training: 2025-08-31 09:51:23,911-[agedb_30][44992]Accuracy-Highest: 0.56500
Training: 2025-08-31 09:51:48,339-[calfw][44992]XNorm: 17.493424
Training: 2025-08-31 09:51:48,340-[calfw][44992]Accuracy-Flip: 0.65083+-0.01302
Training: 2025-08-31 09:51:48,340-[calfw][44992]Accuracy-Highest: 0.67117
Training: 2025-08-31 09:52:12,758-[cplfw][44992]XNorm: 13.741970
Training: 2025-08-31 09:52:12,758-[cplfw][44992]Accuracy-Flip: 0.62850+-0.01514
Training: 2025-08-31 09:52:12,758-[cplfw][44992]Accuracy-Highest: 0.63500
Training: 2025-08-31 09:52:15,728-Speed 44.60 samples/sec   Loss 0.4309 Epoch: 16   Global Step: 45000   Required: 7 hours
Training: 2025-08-31 09:52:33,225-Speed 365.78 samples/sec   Loss 0.3882 Epoch: 16   Global Step: 45050   Required: 7 hours
Training: 2025-08-31 09:52:50,719-Speed 365.83 samples/sec   Loss 0.3725 Epoch: 16   Global Step: 45100   Required: 7 hours
Training: 2025-08-31 09:53:08,215-Speed 365.81 samples/sec   Loss 0.3471 Epoch: 16   Global Step: 45150   Required: 7 hours
Training: 2025-08-31 09:53:25,714-Speed 365.74 samples/sec   Loss 0.3901 Epoch: 16   Global Step: 45200   Required: 7 hours
Training: 2025-08-31 09:53:43,223-Speed 365.54 samples/sec   Loss 0.3738 Epoch: 16   Global Step: 45250   Required: 7 hours
Training: 2025-08-31 09:54:00,735-Speed 365.47 samples/sec   Loss 0.3939 Epoch: 16   Global Step: 45300   Required: 7 hours
Training: 2025-08-31 09:54:18,246-Speed 365.49 samples/sec   Loss 0.3865 Epoch: 16   Global Step: 45350   Required: 7 hours
Training: 2025-08-31 09:54:35,756-Speed 365.50 samples/sec   Loss 0.4178 Epoch: 16   Global Step: 45400   Required: 7 hours
Training: 2025-08-31 09:54:53,263-Speed 365.58 samples/sec   Loss 0.3746 Epoch: 16   Global Step: 45450   Required: 7 hours
Training: 2025-08-31 09:55:10,769-Speed 365.58 samples/sec   Loss 0.3989 Epoch: 16   Global Step: 45500   Required: 7 hours
Training: 2025-08-31 09:55:28,279-Speed 365.52 samples/sec   Loss 0.4074 Epoch: 16   Global Step: 45550   Required: 7 hours
Training: 2025-08-31 09:55:45,788-Speed 365.53 samples/sec   Loss 0.4166 Epoch: 16   Global Step: 45600   Required: 7 hours
Training: 2025-08-31 09:56:03,305-Speed 365.35 samples/sec   Loss 0.4094 Epoch: 16   Global Step: 45650   Required: 7 hours
Training: 2025-08-31 09:56:20,817-Speed 365.48 samples/sec   Loss 0.4069 Epoch: 16   Global Step: 45700   Required: 7 hours
Training: 2025-08-31 09:56:38,324-Speed 365.56 samples/sec   Loss 0.3912 Epoch: 16   Global Step: 45750   Required: 7 hours
Training: 2025-08-31 09:56:55,831-Speed 365.57 samples/sec   Loss 0.4367 Epoch: 16   Global Step: 45800   Required: 7 hours
Training: 2025-08-31 09:57:13,339-Speed 365.54 samples/sec   Loss 0.4284 Epoch: 16   Global Step: 45850   Required: 7 hours
Training: 2025-08-31 09:57:30,850-Speed 365.49 samples/sec   Loss 0.4133 Epoch: 16   Global Step: 45900   Required: 7 hours
Training: 2025-08-31 09:57:48,362-Speed 365.47 samples/sec   Loss 0.4119 Epoch: 16   Global Step: 45950   Required: 7 hours
Training: 2025-08-31 09:58:05,863-Speed 365.70 samples/sec   Loss 0.3836 Epoch: 16   Global Step: 46000   Required: 7 hours
Training: 2025-08-31 09:58:23,374-Speed 365.48 samples/sec   Loss 0.3915 Epoch: 16   Global Step: 46050   Required: 7 hours
Training: 2025-08-31 09:58:40,883-Speed 365.53 samples/sec   Loss 0.3976 Epoch: 16   Global Step: 46100   Required: 7 hours
Training: 2025-08-31 09:58:58,391-Speed 365.54 samples/sec   Loss 0.4091 Epoch: 16   Global Step: 46150   Required: 7 hours
Training: 2025-08-31 09:59:15,900-Speed 365.53 samples/sec   Loss 0.3903 Epoch: 16   Global Step: 46200   Required: 7 hours
Training: 2025-08-31 09:59:33,404-Speed 365.64 samples/sec   Loss 0.4422 Epoch: 16   Global Step: 46250   Required: 7 hours
Training: 2025-08-31 09:59:50,907-Speed 365.65 samples/sec   Loss 0.4184 Epoch: 16   Global Step: 46300   Required: 7 hours
Training: 2025-08-31 10:00:08,411-Speed 365.64 samples/sec   Loss 0.4194 Epoch: 16   Global Step: 46350   Required: 7 hours
Training: 2025-08-31 10:00:25,913-Speed 365.66 samples/sec   Loss 0.4100 Epoch: 16   Global Step: 46400   Required: 7 hours
Training: 2025-08-31 10:00:43,411-Speed 365.77 samples/sec   Loss 0.4217 Epoch: 16   Global Step: 46450   Required: 7 hours
Training: 2025-08-31 10:01:00,916-Speed 365.62 samples/sec   Loss 0.4490 Epoch: 16   Global Step: 46500   Required: 7 hours
Training: 2025-08-31 10:01:18,410-Speed 365.84 samples/sec   Loss 0.4284 Epoch: 16   Global Step: 46550   Required: 7 hours
Training: 2025-08-31 10:01:35,904-Speed 365.84 samples/sec   Loss 0.4118 Epoch: 16   Global Step: 46600   Required: 7 hours
Training: 2025-08-31 10:01:53,398-Speed 365.84 samples/sec   Loss 0.4156 Epoch: 16   Global Step: 46650   Required: 7 hours
Training: 2025-08-31 10:02:10,892-Speed 365.85 samples/sec   Loss 0.4463 Epoch: 16   Global Step: 46700   Required: 7 hours
Training: 2025-08-31 10:02:28,388-Speed 365.80 samples/sec   Loss 0.4519 Epoch: 16   Global Step: 46750   Required: 7 hours
Training: 2025-08-31 10:02:45,882-Speed 365.84 samples/sec   Loss 0.4562 Epoch: 16   Global Step: 46800   Required: 7 hours
Training: 2025-08-31 10:03:03,376-Speed 365.85 samples/sec   Loss 0.4423 Epoch: 16   Global Step: 46850   Required: 7 hours
Training: 2025-08-31 10:03:20,871-Speed 365.82 samples/sec   Loss 0.4605 Epoch: 16   Global Step: 46900   Required: 7 hours
Training: 2025-08-31 10:03:38,374-Speed 365.65 samples/sec   Loss 0.4606 Epoch: 16   Global Step: 46950   Required: 7 hours
Training: 2025-08-31 10:03:55,881-Speed 365.57 samples/sec   Loss 0.4419 Epoch: 16   Global Step: 47000   Required: 7 hours
Training: 2025-08-31 10:04:13,385-Speed 365.64 samples/sec   Loss 0.4088 Epoch: 16   Global Step: 47050   Required: 7 hours
Training: 2025-08-31 10:04:30,889-Speed 365.63 samples/sec   Loss 0.4459 Epoch: 16   Global Step: 47100   Required: 7 hours
Training: 2025-08-31 10:04:48,391-Speed 365.68 samples/sec   Loss 0.3847 Epoch: 16   Global Step: 47150   Required: 7 hours
Training: 2025-08-31 10:05:05,889-Speed 365.75 samples/sec   Loss 0.4601 Epoch: 16   Global Step: 47200   Required: 7 hours
Training: 2025-08-31 10:05:23,396-Speed 365.57 samples/sec   Loss 0.4797 Epoch: 16   Global Step: 47250   Required: 7 hours
Training: 2025-08-31 10:05:40,906-Speed 365.51 samples/sec   Loss 0.4338 Epoch: 16   Global Step: 47300   Required: 7 hours
Training: 2025-08-31 10:05:58,409-Speed 365.65 samples/sec   Loss 0.4489 Epoch: 16   Global Step: 47350   Required: 7 hours
Training: 2025-08-31 10:06:15,917-Speed 365.56 samples/sec   Loss 0.4014 Epoch: 16   Global Step: 47400   Required: 7 hours
Training: 2025-08-31 10:06:33,426-Speed 365.51 samples/sec   Loss 0.4642 Epoch: 16   Global Step: 47450   Required: 7 hours
Training: 2025-08-31 10:06:50,938-Speed 365.46 samples/sec   Loss 0.4348 Epoch: 16   Global Step: 47500   Required: 7 hours
Training: 2025-08-31 10:07:08,437-Speed 365.74 samples/sec   Loss 0.4434 Epoch: 16   Global Step: 47550   Required: 7 hours
Training: 2025-08-31 10:07:25,937-Speed 365.72 samples/sec   Loss 0.4640 Epoch: 16   Global Step: 47600   Required: 7 hours
Training: 2025-08-31 10:07:43,436-Speed 365.74 samples/sec   Loss 0.4119 Epoch: 16   Global Step: 47650   Required: 7 hours
Training: 2025-08-31 10:08:00,940-Speed 365.63 samples/sec   Loss 0.4250 Epoch: 16   Global Step: 47700   Required: 7 hours
Training: 2025-08-31 10:08:18,435-Speed 365.82 samples/sec   Loss 0.4457 Epoch: 16   Global Step: 47750   Required: 7 hours
Training: 2025-08-31 10:08:35,939-Speed 365.65 samples/sec   Loss 0.4445 Epoch: 16   Global Step: 47800   Required: 7 hours
Training: 2025-08-31 10:09:01,687-[lfw][47804]XNorm: 15.478384
Training: 2025-08-31 10:09:01,687-[lfw][47804]Accuracy-Flip: 0.80833+-0.02292
Training: 2025-08-31 10:09:01,687-[lfw][47804]Accuracy-Highest: 0.83600
Training: 2025-08-31 10:09:30,044-[cfp_fp][47804]XNorm: 13.801887
Training: 2025-08-31 10:09:30,044-[cfp_fp][47804]Accuracy-Flip: 0.64171+-0.01856
Training: 2025-08-31 10:09:30,044-[cfp_fp][47804]Accuracy-Highest: 0.66086
Training: 2025-08-31 10:09:54,389-[agedb_30][47804]XNorm: 14.665949
Training: 2025-08-31 10:09:54,389-[agedb_30][47804]Accuracy-Flip: 0.52817+-0.01879
Training: 2025-08-31 10:09:54,389-[agedb_30][47804]Accuracy-Highest: 0.56500
Training: 2025-08-31 10:10:18,821-[calfw][47804]XNorm: 16.084402
Training: 2025-08-31 10:10:18,821-[calfw][47804]Accuracy-Flip: 0.66100+-0.02059
Training: 2025-08-31 10:10:18,821-[calfw][47804]Accuracy-Highest: 0.67117
Training: 2025-08-31 10:10:43,247-[cplfw][47804]XNorm: 12.584028
Training: 2025-08-31 10:10:43,247-[cplfw][47804]Accuracy-Flip: 0.61750+-0.01440
Training: 2025-08-31 10:10:43,247-[cplfw][47804]Accuracy-Highest: 0.63500
Training: 2025-08-31 10:10:59,528-Speed 44.57 samples/sec   Loss 0.3602 Epoch: 17   Global Step: 47850   Required: 7 hours
Training: 2025-08-31 10:11:17,027-Speed 365.73 samples/sec   Loss 0.3585 Epoch: 17   Global Step: 47900   Required: 7 hours
Training: 2025-08-31 10:11:34,522-Speed 365.82 samples/sec   Loss 0.3679 Epoch: 17   Global Step: 47950   Required: 7 hours
Training: 2025-08-31 10:11:52,026-Speed 365.64 samples/sec   Loss 0.3666 Epoch: 17   Global Step: 48000   Required: 7 hours
Training: 2025-08-31 10:12:09,529-Speed 365.65 samples/sec   Loss 0.3826 Epoch: 17   Global Step: 48050   Required: 7 hours
Training: 2025-08-31 10:12:27,036-Speed 365.58 samples/sec   Loss 0.3640 Epoch: 17   Global Step: 48100   Required: 7 hours
Training: 2025-08-31 10:12:44,543-Speed 365.57 samples/sec   Loss 0.3741 Epoch: 17   Global Step: 48150   Required: 7 hours
Training: 2025-08-31 10:13:02,053-Speed 365.50 samples/sec   Loss 0.3940 Epoch: 17   Global Step: 48200   Required: 7 hours
Training: 2025-08-31 10:13:19,557-Speed 365.64 samples/sec   Loss 0.3938 Epoch: 17   Global Step: 48250   Required: 7 hours
Training: 2025-08-31 10:13:37,066-Speed 365.53 samples/sec   Loss 0.3977 Epoch: 17   Global Step: 48300   Required: 7 hours
Training: 2025-08-31 10:13:54,574-Speed 365.55 samples/sec   Loss 0.3796 Epoch: 17   Global Step: 48350   Required: 7 hours
Training: 2025-08-31 10:14:12,082-Speed 365.57 samples/sec   Loss 0.3876 Epoch: 17   Global Step: 48400   Required: 7 hours
Training: 2025-08-31 10:14:29,586-Speed 365.63 samples/sec   Loss 0.4052 Epoch: 17   Global Step: 48450   Required: 7 hours
Training: 2025-08-31 10:14:47,092-Speed 365.59 samples/sec   Loss 0.4129 Epoch: 17   Global Step: 48500   Required: 7 hours
Training: 2025-08-31 10:15:04,600-Speed 365.55 samples/sec   Loss 0.4169 Epoch: 17   Global Step: 48550   Required: 7 hours
Training: 2025-08-31 10:15:22,104-Speed 365.63 samples/sec   Loss 0.4178 Epoch: 17   Global Step: 48600   Required: 7 hours
Training: 2025-08-31 10:15:39,603-Speed 365.74 samples/sec   Loss 0.4082 Epoch: 17   Global Step: 48650   Required: 7 hours
Training: 2025-08-31 10:15:57,107-Speed 365.62 samples/sec   Loss 0.3486 Epoch: 17   Global Step: 48700   Required: 7 hours
Training: 2025-08-31 10:16:14,611-Speed 365.63 samples/sec   Loss 0.4335 Epoch: 17   Global Step: 48750   Required: 7 hours
Training: 2025-08-31 10:16:32,116-Speed 365.62 samples/sec   Loss 0.4143 Epoch: 17   Global Step: 48800   Required: 7 hours
Training: 2025-08-31 10:16:49,610-Speed 365.83 samples/sec   Loss 0.3983 Epoch: 17   Global Step: 48850   Required: 7 hours
Training: 2025-08-31 10:17:07,104-Speed 365.85 samples/sec   Loss 0.4153 Epoch: 17   Global Step: 48900   Required: 7 hours
Training: 2025-08-31 10:17:24,609-Speed 365.62 samples/sec   Loss 0.4007 Epoch: 17   Global Step: 48950   Required: 7 hours
Training: 2025-08-31 10:17:42,108-Speed 365.73 samples/sec   Loss 0.4013 Epoch: 17   Global Step: 49000   Required: 7 hours
Training: 2025-08-31 10:17:59,613-Speed 365.61 samples/sec   Loss 0.3879 Epoch: 17   Global Step: 49050   Required: 7 hours
Training: 2025-08-31 10:18:17,112-Speed 365.75 samples/sec   Loss 0.3915 Epoch: 17   Global Step: 49100   Required: 7 hours
Training: 2025-08-31 10:18:34,617-Speed 365.61 samples/sec   Loss 0.4055 Epoch: 17   Global Step: 49150   Required: 7 hours
Training: 2025-08-31 10:18:52,120-Speed 365.65 samples/sec   Loss 0.4414 Epoch: 17   Global Step: 49200   Required: 7 hours
Training: 2025-08-31 10:19:09,625-Speed 365.62 samples/sec   Loss 0.4006 Epoch: 17   Global Step: 49250   Required: 7 hours
Training: 2025-08-31 10:19:27,119-Speed 365.82 samples/sec   Loss 0.4081 Epoch: 17   Global Step: 49300   Required: 7 hours
Training: 2025-08-31 10:19:44,614-Speed 365.84 samples/sec   Loss 0.4052 Epoch: 17   Global Step: 49350   Required: 7 hours
Training: 2025-08-31 10:20:02,108-Speed 365.84 samples/sec   Loss 0.4254 Epoch: 17   Global Step: 49400   Required: 7 hours
Training: 2025-08-31 10:20:19,602-Speed 365.83 samples/sec   Loss 0.3915 Epoch: 17   Global Step: 49450   Required: 7 hours
Training: 2025-08-31 10:20:37,105-Speed 365.66 samples/sec   Loss 0.3995 Epoch: 17   Global Step: 49500   Required: 7 hours
Training: 2025-08-31 10:20:54,607-Speed 365.68 samples/sec   Loss 0.4014 Epoch: 17   Global Step: 49550   Required: 7 hours
Training: 2025-08-31 10:21:12,104-Speed 365.78 samples/sec   Loss 0.4216 Epoch: 17   Global Step: 49600   Required: 7 hours
Training: 2025-08-31 10:21:29,606-Speed 365.66 samples/sec   Loss 0.4375 Epoch: 17   Global Step: 49650   Required: 7 hours
Training: 2025-08-31 10:21:47,105-Speed 365.75 samples/sec   Loss 0.4653 Epoch: 17   Global Step: 49700   Required: 7 hours
Training: 2025-08-31 10:22:04,609-Speed 365.63 samples/sec   Loss 0.4366 Epoch: 17   Global Step: 49750   Required: 7 hours
Training: 2025-08-31 10:22:22,118-Speed 365.52 samples/sec   Loss 0.3866 Epoch: 17   Global Step: 49800   Required: 7 hours
Training: 2025-08-31 10:22:39,623-Speed 365.61 samples/sec   Loss 0.4316 Epoch: 17   Global Step: 49850   Required: 7 hours
Training: 2025-08-31 10:22:57,120-Speed 365.79 samples/sec   Loss 0.4464 Epoch: 17   Global Step: 49900   Required: 7 hours
Training: 2025-08-31 10:23:14,621-Speed 365.69 samples/sec   Loss 0.4188 Epoch: 17   Global Step: 49950   Required: 7 hours
Training: 2025-08-31 10:23:32,119-Speed 365.76 samples/sec   Loss 0.4504 Epoch: 17   Global Step: 50000   Required: 7 hours
Training: 2025-08-31 10:23:49,617-Speed 365.77 samples/sec   Loss 0.4491 Epoch: 17   Global Step: 50050   Required: 7 hours
Training: 2025-08-31 10:24:07,118-Speed 365.69 samples/sec   Loss 0.4140 Epoch: 17   Global Step: 50100   Required: 7 hours
Training: 2025-08-31 10:24:24,610-Speed 365.88 samples/sec   Loss 0.4255 Epoch: 17   Global Step: 50150   Required: 7 hours
Training: 2025-08-31 10:24:42,104-Speed 365.84 samples/sec   Loss 0.4550 Epoch: 17   Global Step: 50200   Required: 7 hours
Training: 2025-08-31 10:24:59,602-Speed 365.77 samples/sec   Loss 0.4408 Epoch: 17   Global Step: 50250   Required: 7 hours
Training: 2025-08-31 10:25:17,106-Speed 365.63 samples/sec   Loss 0.4369 Epoch: 17   Global Step: 50300   Required: 7 hours
Training: 2025-08-31 10:25:34,610-Speed 365.63 samples/sec   Loss 0.4116 Epoch: 17   Global Step: 50350   Required: 7 hours
Training: 2025-08-31 10:25:52,114-Speed 365.64 samples/sec   Loss 0.4373 Epoch: 17   Global Step: 50400   Required: 7 hours
Training: 2025-08-31 10:26:09,617-Speed 365.64 samples/sec   Loss 0.4207 Epoch: 17   Global Step: 50450   Required: 7 hours
Training: 2025-08-31 10:26:27,114-Speed 365.79 samples/sec   Loss 0.3863 Epoch: 17   Global Step: 50500   Required: 7 hours
Training: 2025-08-31 10:26:44,618-Speed 365.63 samples/sec   Loss 0.4488 Epoch: 17   Global Step: 50550   Required: 7 hours
Training: 2025-08-31 10:27:02,122-Speed 365.64 samples/sec   Loss 0.4416 Epoch: 17   Global Step: 50600   Required: 7 hours
Training: 2025-08-31 10:27:32,083-[lfw][50616]XNorm: 15.657363
Training: 2025-08-31 10:27:32,084-[lfw][50616]Accuracy-Flip: 0.83100+-0.01467
Training: 2025-08-31 10:27:32,084-[lfw][50616]Accuracy-Highest: 0.83600
Training: 2025-08-31 10:28:00,389-[cfp_fp][50616]XNorm: 13.258618
Training: 2025-08-31 10:28:00,389-[cfp_fp][50616]Accuracy-Flip: 0.63157+-0.01550
Training: 2025-08-31 10:28:00,389-[cfp_fp][50616]Accuracy-Highest: 0.66086
Training: 2025-08-31 10:28:24,781-[agedb_30][50616]XNorm: 14.650772
Training: 2025-08-31 10:28:24,781-[agedb_30][50616]Accuracy-Flip: 0.53233+-0.01654
Training: 2025-08-31 10:28:24,781-[agedb_30][50616]Accuracy-Highest: 0.56500
Training: 2025-08-31 10:28:49,206-[calfw][50616]XNorm: 15.740559
Training: 2025-08-31 10:28:49,206-[calfw][50616]Accuracy-Flip: 0.65300+-0.01090
Training: 2025-08-31 10:28:49,207-[calfw][50616]Accuracy-Highest: 0.67117
Training: 2025-08-31 10:29:13,697-[cplfw][50616]XNorm: 12.568187
Training: 2025-08-31 10:29:13,697-[cplfw][50616]Accuracy-Flip: 0.62783+-0.01706
Training: 2025-08-31 10:29:13,698-[cplfw][50616]Accuracy-Highest: 0.63500
Training: 2025-08-31 10:29:25,741-Speed 44.56 samples/sec   Loss 0.4036 Epoch: 18   Global Step: 50650   Required: 7 hours
Training: 2025-08-31 10:29:43,236-Speed 365.83 samples/sec   Loss 0.3759 Epoch: 18   Global Step: 50700   Required: 7 hours
Training: 2025-08-31 10:30:00,730-Speed 365.84 samples/sec   Loss 0.3637 Epoch: 18   Global Step: 50750   Required: 7 hours
Training: 2025-08-31 10:30:18,225-Speed 365.83 samples/sec   Loss 0.3874 Epoch: 18   Global Step: 50800   Required: 7 hours
Training: 2025-08-31 10:30:35,719-Speed 365.84 samples/sec   Loss 0.3660 Epoch: 18   Global Step: 50850   Required: 7 hours
Training: 2025-08-31 10:30:53,214-Speed 365.82 samples/sec   Loss 0.3639 Epoch: 18   Global Step: 50900   Required: 7 hours
Training: 2025-08-31 10:31:10,708-Speed 365.84 samples/sec   Loss 0.3959 Epoch: 18   Global Step: 50950   Required: 7 hours
Training: 2025-08-31 10:31:28,206-Speed 365.77 samples/sec   Loss 0.3835 Epoch: 18   Global Step: 51000   Required: 7 hours
Training: 2025-08-31 10:31:45,706-Speed 365.72 samples/sec   Loss 0.3463 Epoch: 18   Global Step: 51050   Required: 7 hours
Training: 2025-08-31 10:32:03,206-Speed 365.72 samples/sec   Loss 0.3769 Epoch: 18   Global Step: 51100   Required: 7 hours
Training: 2025-08-31 10:32:20,698-Speed 365.88 samples/sec   Loss 0.3896 Epoch: 18   Global Step: 51150   Required: 7 hours
Training: 2025-08-31 10:32:38,193-Speed 365.81 samples/sec   Loss 0.3996 Epoch: 18   Global Step: 51200   Required: 7 hours
Training: 2025-08-31 10:32:55,684-Speed 365.91 samples/sec   Loss 0.3741 Epoch: 18   Global Step: 51250   Required: 7 hours
Training: 2025-08-31 10:33:13,179-Speed 365.84 samples/sec   Loss 0.3837 Epoch: 18   Global Step: 51300   Required: 7 hours
Training: 2025-08-31 10:33:30,674-Speed 365.82 samples/sec   Loss 0.3472 Epoch: 18   Global Step: 51350   Required: 7 hours
Training: 2025-08-31 10:33:48,168-Speed 365.84 samples/sec   Loss 0.3793 Epoch: 18   Global Step: 51400   Required: 7 hours
Training: 2025-08-31 10:34:05,662-Speed 365.83 samples/sec   Loss 0.3729 Epoch: 18   Global Step: 51450   Required: 7 hours
Training: 2025-08-31 10:34:23,160-Speed 365.76 samples/sec   Loss 0.3676 Epoch: 18   Global Step: 51500   Required: 7 hours
Training: 2025-08-31 10:34:40,654-Speed 365.84 samples/sec   Loss 0.3627 Epoch: 18   Global Step: 51550   Required: 7 hours
Training: 2025-08-31 10:34:58,160-Speed 365.59 samples/sec   Loss 0.4042 Epoch: 18   Global Step: 51600   Required: 7 hours
Training: 2025-08-31 10:35:15,666-Speed 365.58 samples/sec   Loss 0.3840 Epoch: 18   Global Step: 51650   Required: 7 hours
Training: 2025-08-31 10:35:33,178-Speed 365.48 samples/sec   Loss 0.4079 Epoch: 18   Global Step: 51700   Required: 7 hours
Training: 2025-08-31 10:35:50,682-Speed 365.63 samples/sec   Loss 0.4114 Epoch: 18   Global Step: 51750   Required: 7 hours
Training: 2025-08-31 10:36:08,178-Speed 365.80 samples/sec   Loss 0.3907 Epoch: 18   Global Step: 51800   Required: 7 hours
Training: 2025-08-31 10:36:25,680-Speed 365.68 samples/sec   Loss 0.3897 Epoch: 18   Global Step: 51850   Required: 7 hours
Training: 2025-08-31 10:36:43,174-Speed 365.83 samples/sec   Loss 0.3926 Epoch: 18   Global Step: 51900   Required: 7 hours
Training: 2025-08-31 10:37:00,669-Speed 365.83 samples/sec   Loss 0.4276 Epoch: 18   Global Step: 51950   Required: 7 hours
Training: 2025-08-31 10:37:18,164-Speed 365.83 samples/sec   Loss 0.4336 Epoch: 18   Global Step: 52000   Required: 7 hours
Training: 2025-08-31 10:37:35,658-Speed 365.84 samples/sec   Loss 0.4054 Epoch: 18   Global Step: 52050   Required: 7 hours
Training: 2025-08-31 10:37:53,152-Speed 365.82 samples/sec   Loss 0.4341 Epoch: 18   Global Step: 52100   Required: 7 hours
Training: 2025-08-31 10:38:10,646-Speed 365.85 samples/sec   Loss 0.4141 Epoch: 18   Global Step: 52150   Required: 7 hours
Training: 2025-08-31 10:38:28,141-Speed 365.83 samples/sec   Loss 0.3849 Epoch: 18   Global Step: 52200   Required: 7 hours
Training: 2025-08-31 10:38:45,635-Speed 365.83 samples/sec   Loss 0.4351 Epoch: 18   Global Step: 52250   Required: 7 hours
Training: 2025-08-31 10:39:03,141-Speed 365.59 samples/sec   Loss 0.4163 Epoch: 18   Global Step: 52300   Required: 7 hours
Training: 2025-08-31 10:39:20,643-Speed 365.67 samples/sec   Loss 0.4102 Epoch: 18   Global Step: 52350   Required: 7 hours
Training: 2025-08-31 10:39:38,139-Speed 365.82 samples/sec   Loss 0.4277 Epoch: 18   Global Step: 52400   Required: 7 hours
Training: 2025-08-31 10:39:55,640-Speed 365.70 samples/sec   Loss 0.4027 Epoch: 18   Global Step: 52450   Required: 7 hours
Training: 2025-08-31 10:40:13,142-Speed 365.66 samples/sec   Loss 0.4327 Epoch: 18   Global Step: 52500   Required: 7 hours
Training: 2025-08-31 10:40:30,638-Speed 365.80 samples/sec   Loss 0.4534 Epoch: 18   Global Step: 52550   Required: 7 hours
Training: 2025-08-31 10:40:48,133-Speed 365.83 samples/sec   Loss 0.4240 Epoch: 18   Global Step: 52600   Required: 7 hours
Training: 2025-08-31 10:41:05,629-Speed 365.79 samples/sec   Loss 0.4073 Epoch: 18   Global Step: 52650   Required: 7 hours
Training: 2025-08-31 10:41:23,133-Speed 365.64 samples/sec   Loss 0.4195 Epoch: 18   Global Step: 52700   Required: 7 hours
Training: 2025-08-31 10:41:40,629-Speed 365.79 samples/sec   Loss 0.4029 Epoch: 18   Global Step: 52750   Required: 7 hours
Training: 2025-08-31 10:41:58,123-Speed 365.84 samples/sec   Loss 0.4527 Epoch: 18   Global Step: 52800   Required: 7 hours
Training: 2025-08-31 10:42:15,624-Speed 365.70 samples/sec   Loss 0.4432 Epoch: 18   Global Step: 52850   Required: 7 hours
Training: 2025-08-31 10:42:33,119-Speed 365.81 samples/sec   Loss 0.4242 Epoch: 18   Global Step: 52900   Required: 7 hours
Training: 2025-08-31 10:42:50,616-Speed 365.79 samples/sec   Loss 0.4181 Epoch: 18   Global Step: 52950   Required: 6 hours
Training: 2025-08-31 10:43:08,116-Speed 365.72 samples/sec   Loss 0.4213 Epoch: 18   Global Step: 53000   Required: 6 hours
Training: 2025-08-31 10:43:25,617-Speed 365.69 samples/sec   Loss 0.4062 Epoch: 18   Global Step: 53050   Required: 6 hours
Training: 2025-08-31 10:43:43,116-Speed 365.74 samples/sec   Loss 0.4539 Epoch: 18   Global Step: 53100   Required: 6 hours
Training: 2025-08-31 10:44:00,611-Speed 365.82 samples/sec   Loss 0.4178 Epoch: 18   Global Step: 53150   Required: 6 hours
Training: 2025-08-31 10:44:18,108-Speed 365.78 samples/sec   Loss 0.4749 Epoch: 18   Global Step: 53200   Required: 6 hours
Training: 2025-08-31 10:44:35,607-Speed 365.72 samples/sec   Loss 0.4447 Epoch: 18   Global Step: 53250   Required: 6 hours
Training: 2025-08-31 10:44:53,107-Speed 365.73 samples/sec   Loss 0.4112 Epoch: 18   Global Step: 53300   Required: 6 hours
Training: 2025-08-31 10:45:10,611-Speed 365.62 samples/sec   Loss 0.4438 Epoch: 18   Global Step: 53350   Required: 6 hours
Training: 2025-08-31 10:45:28,122-Speed 365.50 samples/sec   Loss 0.4423 Epoch: 18   Global Step: 53400   Required: 6 hours
Training: 2025-08-31 10:46:02,288-[lfw][53428]XNorm: 15.225408
Training: 2025-08-31 10:46:02,288-[lfw][53428]Accuracy-Flip: 0.82567+-0.01647
Training: 2025-08-31 10:46:02,288-[lfw][53428]Accuracy-Highest: 0.83600
Training: 2025-08-31 10:46:30,591-[cfp_fp][53428]XNorm: 12.736302
Training: 2025-08-31 10:46:30,591-[cfp_fp][53428]Accuracy-Flip: 0.64086+-0.01680
Training: 2025-08-31 10:46:30,591-[cfp_fp][53428]Accuracy-Highest: 0.66086
Training: 2025-08-31 10:46:54,931-[agedb_30][53428]XNorm: 13.142640
Training: 2025-08-31 10:46:54,931-[agedb_30][53428]Accuracy-Flip: 0.54817+-0.02208
Training: 2025-08-31 10:46:54,931-[agedb_30][53428]Accuracy-Highest: 0.56500
Training: 2025-08-31 10:47:19,363-[calfw][53428]XNorm: 15.035469
Training: 2025-08-31 10:47:19,363-[calfw][53428]Accuracy-Flip: 0.67283+-0.01546
Training: 2025-08-31 10:47:19,364-[calfw][53428]Accuracy-Highest: 0.67283
Training: 2025-08-31 10:47:43,790-[cplfw][53428]XNorm: 12.022856
Training: 2025-08-31 10:47:43,790-[cplfw][53428]Accuracy-Flip: 0.61650+-0.01523
Training: 2025-08-31 10:47:43,790-[cplfw][53428]Accuracy-Highest: 0.63500
Training: 2025-08-31 10:47:51,644-Speed 44.59 samples/sec   Loss 0.3752 Epoch: 19   Global Step: 53450   Required: 6 hours
Training: 2025-08-31 10:48:09,139-Speed 365.82 samples/sec   Loss 0.3427 Epoch: 19   Global Step: 53500   Required: 6 hours
Training: 2025-08-31 10:48:26,633-Speed 365.83 samples/sec   Loss 0.3364 Epoch: 19   Global Step: 53550   Required: 6 hours
Training: 2025-08-31 10:48:44,127-Speed 365.84 samples/sec   Loss 0.3928 Epoch: 19   Global Step: 53600   Required: 6 hours
Training: 2025-08-31 10:49:01,622-Speed 365.83 samples/sec   Loss 0.3162 Epoch: 19   Global Step: 53650   Required: 6 hours
Training: 2025-08-31 10:49:19,116-Speed 365.84 samples/sec   Loss 0.3418 Epoch: 19   Global Step: 53700   Required: 6 hours
Training: 2025-08-31 10:49:36,611-Speed 365.83 samples/sec   Loss 0.3868 Epoch: 19   Global Step: 53750   Required: 6 hours
Training: 2025-08-31 10:49:54,105-Speed 365.83 samples/sec   Loss 0.3548 Epoch: 19   Global Step: 53800   Required: 6 hours
Training: 2025-08-31 10:50:11,605-Speed 365.73 samples/sec   Loss 0.3605 Epoch: 19   Global Step: 53850   Required: 6 hours
Training: 2025-08-31 10:50:29,104-Speed 365.73 samples/sec   Loss 0.3770 Epoch: 19   Global Step: 53900   Required: 6 hours
Training: 2025-08-31 10:50:46,603-Speed 365.75 samples/sec   Loss 0.3786 Epoch: 19   Global Step: 53950   Required: 6 hours
Training: 2025-08-31 10:51:04,113-Speed 365.49 samples/sec   Loss 0.4123 Epoch: 19   Global Step: 54000   Required: 6 hours
Training: 2025-08-31 10:51:21,615-Speed 365.68 samples/sec   Loss 0.3709 Epoch: 19   Global Step: 54050   Required: 6 hours
Training: 2025-08-31 10:51:39,122-Speed 365.58 samples/sec   Loss 0.3741 Epoch: 19   Global Step: 54100   Required: 6 hours
Training: 2025-08-31 10:51:56,621-Speed 365.72 samples/sec   Loss 0.3888 Epoch: 19   Global Step: 54150   Required: 6 hours
Training: 2025-08-31 10:52:14,125-Speed 365.64 samples/sec   Loss 0.3904 Epoch: 19   Global Step: 54200   Required: 6 hours
Training: 2025-08-31 10:52:31,619-Speed 365.83 samples/sec   Loss 0.3636 Epoch: 19   Global Step: 54250   Required: 6 hours
Training: 2025-08-31 10:52:49,114-Speed 365.83 samples/sec   Loss 0.3827 Epoch: 19   Global Step: 54300   Required: 6 hours
Training: 2025-08-31 10:53:06,608-Speed 365.85 samples/sec   Loss 0.3628 Epoch: 19   Global Step: 54350   Required: 6 hours
Training: 2025-08-31 10:53:24,112-Speed 365.63 samples/sec   Loss 0.3658 Epoch: 19   Global Step: 54400   Required: 6 hours
Training: 2025-08-31 10:53:41,620-Speed 365.56 samples/sec   Loss 0.3875 Epoch: 19   Global Step: 54450   Required: 6 hours
Training: 2025-08-31 10:53:59,127-Speed 365.56 samples/sec   Loss 0.3648 Epoch: 19   Global Step: 54500   Required: 6 hours
Training: 2025-08-31 10:54:16,632-Speed 365.60 samples/sec   Loss 0.3962 Epoch: 19   Global Step: 54550   Required: 6 hours
Training: 2025-08-31 10:54:34,140-Speed 365.56 samples/sec   Loss 0.3769 Epoch: 19   Global Step: 54600   Required: 6 hours
Training: 2025-08-31 10:54:51,648-Speed 365.56 samples/sec   Loss 0.3749 Epoch: 19   Global Step: 54650   Required: 6 hours
Training: 2025-08-31 10:55:09,154-Speed 365.58 samples/sec   Loss 0.3971 Epoch: 19   Global Step: 54700   Required: 6 hours
Training: 2025-08-31 10:55:26,658-Speed 365.64 samples/sec   Loss 0.3991 Epoch: 19   Global Step: 54750   Required: 6 hours
Training: 2025-08-31 10:55:44,164-Speed 365.58 samples/sec   Loss 0.3885 Epoch: 19   Global Step: 54800   Required: 6 hours
Training: 2025-08-31 10:56:01,671-Speed 365.57 samples/sec   Loss 0.4144 Epoch: 19   Global Step: 54850   Required: 6 hours
Training: 2025-08-31 10:56:19,174-Speed 365.66 samples/sec   Loss 0.3634 Epoch: 19   Global Step: 54900   Required: 6 hours
Training: 2025-08-31 10:56:36,676-Speed 365.66 samples/sec   Loss 0.3826 Epoch: 19   Global Step: 54950   Required: 6 hours
Training: 2025-08-31 10:56:54,175-Speed 365.75 samples/sec   Loss 0.4049 Epoch: 19   Global Step: 55000   Required: 6 hours
Training: 2025-08-31 10:57:11,678-Speed 365.64 samples/sec   Loss 0.4221 Epoch: 19   Global Step: 55050   Required: 6 hours
Training: 2025-08-31 10:57:29,180-Speed 365.68 samples/sec   Loss 0.3944 Epoch: 19   Global Step: 55100   Required: 6 hours
Training: 2025-08-31 10:57:46,683-Speed 365.65 samples/sec   Loss 0.4427 Epoch: 19   Global Step: 55150   Required: 6 hours
Training: 2025-08-31 10:58:04,192-Speed 365.54 samples/sec   Loss 0.4143 Epoch: 19   Global Step: 55200   Required: 6 hours
Training: 2025-08-31 10:58:21,698-Speed 365.59 samples/sec   Loss 0.3939 Epoch: 19   Global Step: 55250   Required: 6 hours
Training: 2025-08-31 10:58:39,201-Speed 365.65 samples/sec   Loss 0.4401 Epoch: 19   Global Step: 55300   Required: 6 hours
Training: 2025-08-31 10:58:56,710-Speed 365.54 samples/sec   Loss 0.3834 Epoch: 19   Global Step: 55350   Required: 6 hours
Training: 2025-08-31 10:59:14,211-Speed 365.70 samples/sec   Loss 0.4350 Epoch: 19   Global Step: 55400   Required: 6 hours
Training: 2025-08-31 10:59:31,720-Speed 365.53 samples/sec   Loss 0.4134 Epoch: 19   Global Step: 55450   Required: 6 hours
Training: 2025-08-31 10:59:49,218-Speed 365.76 samples/sec   Loss 0.4501 Epoch: 19   Global Step: 55500   Required: 6 hours
Training: 2025-08-31 11:00:06,721-Speed 365.63 samples/sec   Loss 0.4163 Epoch: 19   Global Step: 55550   Required: 6 hours
Training: 2025-08-31 11:00:24,216-Speed 365.82 samples/sec   Loss 0.4341 Epoch: 19   Global Step: 55600   Required: 6 hours
Training: 2025-08-31 11:00:41,717-Speed 365.71 samples/sec   Loss 0.4214 Epoch: 19   Global Step: 55650   Required: 6 hours
Training: 2025-08-31 11:00:59,216-Speed 365.74 samples/sec   Loss 0.3834 Epoch: 19   Global Step: 55700   Required: 6 hours
Training: 2025-08-31 11:01:16,713-Speed 365.77 samples/sec   Loss 0.4213 Epoch: 19   Global Step: 55750   Required: 6 hours
Training: 2025-08-31 11:01:34,218-Speed 365.60 samples/sec   Loss 0.4004 Epoch: 19   Global Step: 55800   Required: 6 hours
Training: 2025-08-31 11:01:51,724-Speed 365.60 samples/sec   Loss 0.4006 Epoch: 19   Global Step: 55850   Required: 6 hours
Training: 2025-08-31 11:02:09,230-Speed 365.59 samples/sec   Loss 0.4209 Epoch: 19   Global Step: 55900   Required: 6 hours
Training: 2025-08-31 11:02:26,734-Speed 365.63 samples/sec   Loss 0.3881 Epoch: 19   Global Step: 55950   Required: 6 hours
Training: 2025-08-31 11:02:44,241-Speed 365.56 samples/sec   Loss 0.4002 Epoch: 19   Global Step: 56000   Required: 6 hours
Training: 2025-08-31 11:03:01,744-Speed 365.66 samples/sec   Loss 0.4311 Epoch: 19   Global Step: 56050   Required: 6 hours
Training: 2025-08-31 11:03:19,239-Speed 365.83 samples/sec   Loss 0.3859 Epoch: 19   Global Step: 56100   Required: 6 hours
Training: 2025-08-31 11:03:36,743-Speed 365.62 samples/sec   Loss 0.4085 Epoch: 19   Global Step: 56150   Required: 6 hours
Training: 2025-08-31 11:03:54,239-Speed 365.82 samples/sec   Loss 0.4324 Epoch: 19   Global Step: 56200   Required: 6 hours
Training: 2025-08-31 11:04:32,685-[lfw][56240]XNorm: 16.005750
Training: 2025-08-31 11:04:32,685-[lfw][56240]Accuracy-Flip: 0.81300+-0.01337
Training: 2025-08-31 11:04:32,685-[lfw][56240]Accuracy-Highest: 0.83600
Training: 2025-08-31 11:05:00,972-[cfp_fp][56240]XNorm: 14.135228
Training: 2025-08-31 11:05:00,972-[cfp_fp][56240]Accuracy-Flip: 0.64714+-0.02482
Training: 2025-08-31 11:05:00,972-[cfp_fp][56240]Accuracy-Highest: 0.66086
Training: 2025-08-31 11:05:25,316-[agedb_30][56240]XNorm: 15.235706
Training: 2025-08-31 11:05:25,316-[agedb_30][56240]Accuracy-Flip: 0.51883+-0.01445
Training: 2025-08-31 11:05:25,316-[agedb_30][56240]Accuracy-Highest: 0.56500
Training: 2025-08-31 11:05:49,747-[calfw][56240]XNorm: 16.634719
Training: 2025-08-31 11:05:49,747-[calfw][56240]Accuracy-Flip: 0.66817+-0.01689
Training: 2025-08-31 11:05:49,747-[calfw][56240]Accuracy-Highest: 0.67283
Training: 2025-08-31 11:06:14,210-[cplfw][56240]XNorm: 13.022181
Training: 2025-08-31 11:06:14,210-[cplfw][56240]Accuracy-Flip: 0.61383+-0.02483
Training: 2025-08-31 11:06:14,210-[cplfw][56240]Accuracy-Highest: 0.63500
Training: 2025-08-31 11:06:17,900-Speed 44.55 samples/sec   Loss 0.3627 Epoch: 20   Global Step: 56250   Required: 6 hours
Training: 2025-08-31 11:06:35,393-Speed 365.85 samples/sec   Loss 0.3453 Epoch: 20   Global Step: 56300   Required: 6 hours
Training: 2025-08-31 11:06:52,887-Speed 365.84 samples/sec   Loss 0.3606 Epoch: 20   Global Step: 56350   Required: 6 hours
Training: 2025-08-31 11:07:10,383-Speed 365.81 samples/sec   Loss 0.3568 Epoch: 20   Global Step: 56400   Required: 6 hours
Training: 2025-08-31 11:07:27,879-Speed 365.79 samples/sec   Loss 0.3758 Epoch: 20   Global Step: 56450   Required: 6 hours
Training: 2025-08-31 11:07:45,387-Speed 365.56 samples/sec   Loss 0.3627 Epoch: 20   Global Step: 56500   Required: 6 hours
Training: 2025-08-31 11:08:02,897-Speed 365.50 samples/sec   Loss 0.3704 Epoch: 20   Global Step: 56550   Required: 6 hours
Training: 2025-08-31 11:08:20,410-Speed 365.45 samples/sec   Loss 0.3345 Epoch: 20   Global Step: 56600   Required: 6 hours
Training: 2025-08-31 11:08:37,916-Speed 365.58 samples/sec   Loss 0.3275 Epoch: 20   Global Step: 56650   Required: 6 hours
Training: 2025-08-31 11:08:55,429-Speed 365.46 samples/sec   Loss 0.3744 Epoch: 20   Global Step: 56700   Required: 6 hours
Training: 2025-08-31 11:09:12,933-Speed 365.63 samples/sec   Loss 0.4005 Epoch: 20   Global Step: 56750   Required: 6 hours
Training: 2025-08-31 11:09:30,440-Speed 365.56 samples/sec   Loss 0.3334 Epoch: 20   Global Step: 56800   Required: 6 hours
Training: 2025-08-31 11:09:47,935-Speed 365.82 samples/sec   Loss 0.3192 Epoch: 20   Global Step: 56850   Required: 6 hours
Training: 2025-08-31 11:10:05,430-Speed 365.83 samples/sec   Loss 0.3609 Epoch: 20   Global Step: 56900   Required: 6 hours
Training: 2025-08-31 11:10:22,923-Speed 365.85 samples/sec   Loss 0.3594 Epoch: 20   Global Step: 56950   Required: 6 hours
Training: 2025-08-31 11:10:40,429-Speed 365.61 samples/sec   Loss 0.3433 Epoch: 20   Global Step: 57000   Required: 6 hours
Training: 2025-08-31 11:10:57,922-Speed 365.84 samples/sec   Loss 0.3685 Epoch: 20   Global Step: 57050   Required: 6 hours
Training: 2025-08-31 11:11:15,422-Speed 365.73 samples/sec   Loss 0.3736 Epoch: 20   Global Step: 57100   Required: 6 hours
Training: 2025-08-31 11:11:32,918-Speed 365.79 samples/sec   Loss 0.4088 Epoch: 20   Global Step: 57150   Required: 6 hours
Training: 2025-08-31 11:11:50,422-Speed 365.63 samples/sec   Loss 0.4129 Epoch: 20   Global Step: 57200   Required: 6 hours
Training: 2025-08-31 11:12:07,927-Speed 365.61 samples/sec   Loss 0.3837 Epoch: 20   Global Step: 57250   Required: 6 hours
Training: 2025-08-31 11:12:25,434-Speed 365.58 samples/sec   Loss 0.3521 Epoch: 20   Global Step: 57300   Required: 6 hours
Training: 2025-08-31 11:12:42,935-Speed 365.69 samples/sec   Loss 0.3584 Epoch: 20   Global Step: 57350   Required: 6 hours
Training: 2025-08-31 11:13:00,436-Speed 365.71 samples/sec   Loss 0.3844 Epoch: 20   Global Step: 57400   Required: 6 hours
Training: 2025-08-31 11:13:17,943-Speed 365.57 samples/sec   Loss 0.3795 Epoch: 20   Global Step: 57450   Required: 6 hours
Training: 2025-08-31 11:13:35,446-Speed 365.64 samples/sec   Loss 0.4310 Epoch: 20   Global Step: 57500   Required: 6 hours
Training: 2025-08-31 11:13:52,942-Speed 365.80 samples/sec   Loss 0.4065 Epoch: 20   Global Step: 57550   Required: 6 hours
Training: 2025-08-31 11:14:10,436-Speed 365.85 samples/sec   Loss 0.3877 Epoch: 20   Global Step: 57600   Required: 6 hours
Training: 2025-08-31 11:14:27,931-Speed 365.82 samples/sec   Loss 0.4423 Epoch: 20   Global Step: 57650   Required: 6 hours
Training: 2025-08-31 11:14:45,430-Speed 365.75 samples/sec   Loss 0.3915 Epoch: 20   Global Step: 57700   Required: 6 hours
Training: 2025-08-31 11:15:02,930-Speed 365.70 samples/sec   Loss 0.4229 Epoch: 20   Global Step: 57750   Required: 6 hours
Training: 2025-08-31 11:15:20,428-Speed 365.77 samples/sec   Loss 0.3757 Epoch: 20   Global Step: 57800   Required: 6 hours
Training: 2025-08-31 11:15:37,937-Speed 365.52 samples/sec   Loss 0.3676 Epoch: 20   Global Step: 57850   Required: 6 hours
Training: 2025-08-31 11:15:55,434-Speed 365.79 samples/sec   Loss 0.4117 Epoch: 20   Global Step: 57900   Required: 6 hours
Training: 2025-08-31 11:16:12,930-Speed 365.80 samples/sec   Loss 0.4059 Epoch: 20   Global Step: 57950   Required: 6 hours
Training: 2025-08-31 11:16:30,425-Speed 365.83 samples/sec   Loss 0.3915 Epoch: 20   Global Step: 58000   Required: 6 hours
Training: 2025-08-31 11:16:47,926-Speed 365.68 samples/sec   Loss 0.4260 Epoch: 20   Global Step: 58050   Required: 6 hours
Training: 2025-08-31 11:17:05,421-Speed 365.84 samples/sec   Loss 0.3964 Epoch: 20   Global Step: 58100   Required: 6 hours
Training: 2025-08-31 11:17:22,914-Speed 365.85 samples/sec   Loss 0.3920 Epoch: 20   Global Step: 58150   Required: 6 hours
Training: 2025-08-31 11:17:40,413-Speed 365.75 samples/sec   Loss 0.3934 Epoch: 20   Global Step: 58200   Required: 6 hours
Training: 2025-08-31 11:17:57,912-Speed 365.72 samples/sec   Loss 0.3766 Epoch: 20   Global Step: 58250   Required: 6 hours
Training: 2025-08-31 11:18:15,411-Speed 365.75 samples/sec   Loss 0.3787 Epoch: 20   Global Step: 58300   Required: 6 hours
Training: 2025-08-31 11:18:32,903-Speed 365.89 samples/sec   Loss 0.4145 Epoch: 20   Global Step: 58350   Required: 6 hours
Training: 2025-08-31 11:18:50,399-Speed 365.78 samples/sec   Loss 0.4132 Epoch: 20   Global Step: 58400   Required: 6 hours
Training: 2025-08-31 11:19:07,894-Speed 365.83 samples/sec   Loss 0.3947 Epoch: 20   Global Step: 58450   Required: 6 hours
Training: 2025-08-31 11:19:25,394-Speed 365.71 samples/sec   Loss 0.4100 Epoch: 20   Global Step: 58500   Required: 6 hours
Training: 2025-08-31 11:19:42,890-Speed 365.81 samples/sec   Loss 0.4167 Epoch: 20   Global Step: 58550   Required: 6 hours
Training: 2025-08-31 11:20:00,385-Speed 365.82 samples/sec   Loss 0.3942 Epoch: 20   Global Step: 58600   Required: 6 hours
Training: 2025-08-31 11:20:17,883-Speed 365.76 samples/sec   Loss 0.3916 Epoch: 20   Global Step: 58650   Required: 6 hours
Training: 2025-08-31 11:20:35,386-Speed 365.66 samples/sec   Loss 0.4140 Epoch: 20   Global Step: 58700   Required: 6 hours
Training: 2025-08-31 11:20:52,886-Speed 365.71 samples/sec   Loss 0.3733 Epoch: 20   Global Step: 58750   Required: 6 hours
Training: 2025-08-31 11:21:10,392-Speed 365.59 samples/sec   Loss 0.4017 Epoch: 20   Global Step: 58800   Required: 6 hours
Training: 2025-08-31 11:21:27,895-Speed 365.66 samples/sec   Loss 0.4105 Epoch: 20   Global Step: 58850   Required: 6 hours
Training: 2025-08-31 11:21:45,399-Speed 365.62 samples/sec   Loss 0.4259 Epoch: 20   Global Step: 58900   Required: 6 hours
Training: 2025-08-31 11:22:02,898-Speed 365.74 samples/sec   Loss 0.4381 Epoch: 20   Global Step: 58950   Required: 6 hours
Training: 2025-08-31 11:22:20,398-Speed 365.71 samples/sec   Loss 0.4118 Epoch: 20   Global Step: 59000   Required: 6 hours
Training: 2025-08-31 11:22:37,904-Speed 365.60 samples/sec   Loss 0.4162 Epoch: 20   Global Step: 59050   Required: 6 hours
Training: 2025-08-31 11:23:02,961-[lfw][59052]XNorm: 16.086918
Training: 2025-08-31 11:23:02,962-[lfw][59052]Accuracy-Flip: 0.83417+-0.01732
Training: 2025-08-31 11:23:02,962-[lfw][59052]Accuracy-Highest: 0.83600
Training: 2025-08-31 11:23:31,247-[cfp_fp][59052]XNorm: 14.322583
Training: 2025-08-31 11:23:31,247-[cfp_fp][59052]Accuracy-Flip: 0.65214+-0.01629
Training: 2025-08-31 11:23:31,247-[cfp_fp][59052]Accuracy-Highest: 0.66086
Training: 2025-08-31 11:23:55,591-[agedb_30][59052]XNorm: 16.448787
Training: 2025-08-31 11:23:55,591-[agedb_30][59052]Accuracy-Flip: 0.55733+-0.01800
Training: 2025-08-31 11:23:55,591-[agedb_30][59052]Accuracy-Highest: 0.56500
Training: 2025-08-31 11:24:20,032-[calfw][59052]XNorm: 16.918896
Training: 2025-08-31 11:24:20,032-[calfw][59052]Accuracy-Flip: 0.68100+-0.01613
Training: 2025-08-31 11:24:20,032-[calfw][59052]Accuracy-Highest: 0.68100
Training: 2025-08-31 11:24:44,515-[cplfw][59052]XNorm: 13.155989
Training: 2025-08-31 11:24:44,515-[cplfw][59052]Accuracy-Flip: 0.64067+-0.01719
Training: 2025-08-31 11:24:44,515-[cplfw][59052]Accuracy-Highest: 0.64067
Training: 2025-08-31 11:25:01,496-Speed 44.57 samples/sec   Loss 0.2314 Epoch: 21   Global Step: 59100   Required: 6 hours
Training: 2025-08-31 11:25:18,991-Speed 365.82 samples/sec   Loss 0.1410 Epoch: 21   Global Step: 59150   Required: 6 hours
Training: 2025-08-31 11:25:36,485-Speed 365.85 samples/sec   Loss 0.1111 Epoch: 21   Global Step: 59200   Required: 6 hours
Training: 2025-08-31 11:25:53,981-Speed 365.81 samples/sec   Loss 0.0806 Epoch: 21   Global Step: 59250   Required: 6 hours
Training: 2025-08-31 11:26:11,482-Speed 365.69 samples/sec   Loss 0.0666 Epoch: 21   Global Step: 59300   Required: 6 hours
Training: 2025-08-31 11:26:28,982-Speed 365.71 samples/sec   Loss 0.0815 Epoch: 21   Global Step: 59350   Required: 6 hours
Training: 2025-08-31 11:26:46,476-Speed 365.83 samples/sec   Loss 0.0567 Epoch: 21   Global Step: 59400   Required: 6 hours
Training: 2025-08-31 11:27:03,986-Speed 365.52 samples/sec   Loss 0.0592 Epoch: 21   Global Step: 59450   Required: 6 hours
Training: 2025-08-31 11:27:21,491-Speed 365.61 samples/sec   Loss 0.0579 Epoch: 21   Global Step: 59500   Required: 6 hours
Training: 2025-08-31 11:27:38,989-Speed 365.74 samples/sec   Loss 0.0396 Epoch: 21   Global Step: 59550   Required: 6 hours
Training: 2025-08-31 11:27:56,494-Speed 365.62 samples/sec   Loss 0.0400 Epoch: 21   Global Step: 59600   Required: 6 hours
Training: 2025-08-31 11:28:13,988-Speed 365.85 samples/sec   Loss 0.0407 Epoch: 21   Global Step: 59650   Required: 6 hours
Training: 2025-08-31 11:28:31,492-Speed 365.63 samples/sec   Loss 0.0331 Epoch: 21   Global Step: 59700   Required: 6 hours
Training: 2025-08-31 11:28:49,001-Speed 365.53 samples/sec   Loss 0.0371 Epoch: 21   Global Step: 59750   Required: 6 hours
Training: 2025-08-31 11:29:06,512-Speed 365.48 samples/sec   Loss 0.0360 Epoch: 21   Global Step: 59800   Required: 6 hours
Training: 2025-08-31 11:29:24,027-Speed 365.39 samples/sec   Loss 0.0403 Epoch: 21   Global Step: 59850   Required: 6 hours
Training: 2025-08-31 11:29:41,544-Speed 365.38 samples/sec   Loss 0.0290 Epoch: 21   Global Step: 59900   Required: 6 hours
Training: 2025-08-31 11:29:59,060-Speed 365.38 samples/sec   Loss 0.0270 Epoch: 21   Global Step: 59950   Required: 6 hours
Training: 2025-08-31 11:30:16,564-Speed 365.62 samples/sec   Loss 0.0314 Epoch: 21   Global Step: 60000   Required: 6 hours
Training: 2025-08-31 11:30:34,076-Speed 365.46 samples/sec   Loss 0.0285 Epoch: 21   Global Step: 60050   Required: 6 hours
Training: 2025-08-31 11:30:51,593-Speed 365.37 samples/sec   Loss 0.0298 Epoch: 21   Global Step: 60100   Required: 6 hours
Training: 2025-08-31 11:31:09,107-Speed 365.43 samples/sec   Loss 0.0260 Epoch: 21   Global Step: 60150   Required: 6 hours
Training: 2025-08-31 11:31:26,613-Speed 365.57 samples/sec   Loss 0.0261 Epoch: 21   Global Step: 60200   Required: 6 hours
Training: 2025-08-31 11:31:44,129-Speed 365.40 samples/sec   Loss 0.0275 Epoch: 21   Global Step: 60250   Required: 6 hours
Training: 2025-08-31 11:32:01,635-Speed 365.59 samples/sec   Loss 0.0249 Epoch: 21   Global Step: 60300   Required: 6 hours
Training: 2025-08-31 11:32:19,145-Speed 365.51 samples/sec   Loss 0.0244 Epoch: 21   Global Step: 60350   Required: 6 hours
Training: 2025-08-31 11:32:36,658-Speed 365.46 samples/sec   Loss 0.0242 Epoch: 21   Global Step: 60400   Required: 6 hours
Training: 2025-08-31 11:32:54,165-Speed 365.57 samples/sec   Loss 0.0269 Epoch: 21   Global Step: 60450   Required: 6 hours
Training: 2025-08-31 11:33:11,668-Speed 365.64 samples/sec   Loss 0.0245 Epoch: 21   Global Step: 60500   Required: 6 hours
Training: 2025-08-31 11:33:29,177-Speed 365.55 samples/sec   Loss 0.0304 Epoch: 21   Global Step: 60550   Required: 6 hours
Training: 2025-08-31 11:33:46,671-Speed 365.84 samples/sec   Loss 0.0297 Epoch: 21   Global Step: 60600   Required: 6 hours
Training: 2025-08-31 11:34:04,170-Speed 365.74 samples/sec   Loss 0.0222 Epoch: 21   Global Step: 60650   Required: 6 hours
Training: 2025-08-31 11:34:21,680-Speed 365.50 samples/sec   Loss 0.0244 Epoch: 21   Global Step: 60700   Required: 6 hours
Training: 2025-08-31 11:34:39,190-Speed 365.49 samples/sec   Loss 0.0250 Epoch: 21   Global Step: 60750   Required: 6 hours
Training: 2025-08-31 11:34:56,699-Speed 365.55 samples/sec   Loss 0.0250 Epoch: 21   Global Step: 60800   Required: 6 hours
Training: 2025-08-31 11:35:14,206-Speed 365.56 samples/sec   Loss 0.0162 Epoch: 21   Global Step: 60850   Required: 6 hours
Training: 2025-08-31 11:35:31,712-Speed 365.59 samples/sec   Loss 0.0279 Epoch: 21   Global Step: 60900   Required: 6 hours
Training: 2025-08-31 11:35:49,217-Speed 365.61 samples/sec   Loss 0.0198 Epoch: 21   Global Step: 60950   Required: 6 hours
Training: 2025-08-31 11:36:06,711-Speed 365.84 samples/sec   Loss 0.0182 Epoch: 21   Global Step: 61000   Required: 6 hours
Training: 2025-08-31 11:36:24,205-Speed 365.84 samples/sec   Loss 0.0272 Epoch: 21   Global Step: 61050   Required: 6 hours
Training: 2025-08-31 11:36:41,707-Speed 365.68 samples/sec   Loss 0.0186 Epoch: 21   Global Step: 61100   Required: 6 hours
Training: 2025-08-31 11:36:59,213-Speed 365.59 samples/sec   Loss 0.0141 Epoch: 21   Global Step: 61150   Required: 6 hours
Training: 2025-08-31 11:37:16,720-Speed 365.57 samples/sec   Loss 0.0220 Epoch: 21   Global Step: 61200   Required: 6 hours
Training: 2025-08-31 11:37:34,223-Speed 365.65 samples/sec   Loss 0.0155 Epoch: 21   Global Step: 61250   Required: 6 hours
Training: 2025-08-31 11:37:51,728-Speed 365.60 samples/sec   Loss 0.0150 Epoch: 21   Global Step: 61300   Required: 6 hours
Training: 2025-08-31 11:38:09,233-Speed 365.63 samples/sec   Loss 0.0156 Epoch: 21   Global Step: 61350   Required: 6 hours
Training: 2025-08-31 11:38:26,731-Speed 365.76 samples/sec   Loss 0.0171 Epoch: 21   Global Step: 61400   Required: 6 hours
Training: 2025-08-31 11:38:44,227-Speed 365.80 samples/sec   Loss 0.0161 Epoch: 21   Global Step: 61450   Required: 6 hours
Training: 2025-08-31 11:39:01,726-Speed 365.73 samples/sec   Loss 0.0165 Epoch: 21   Global Step: 61500   Required: 6 hours
Training: 2025-08-31 11:39:19,224-Speed 365.77 samples/sec   Loss 0.0191 Epoch: 21   Global Step: 61550   Required: 6 hours
Training: 2025-08-31 11:39:36,724-Speed 365.71 samples/sec   Loss 0.0162 Epoch: 21   Global Step: 61600   Required: 6 hours
Training: 2025-08-31 11:39:54,219-Speed 365.83 samples/sec   Loss 0.0206 Epoch: 21   Global Step: 61650   Required: 6 hours
Training: 2025-08-31 11:40:11,717-Speed 365.75 samples/sec   Loss 0.0133 Epoch: 21   Global Step: 61700   Required: 6 hours
Training: 2025-08-31 11:40:29,223-Speed 365.60 samples/sec   Loss 0.0117 Epoch: 21   Global Step: 61750   Required: 6 hours
Training: 2025-08-31 11:40:46,725-Speed 365.66 samples/sec   Loss 0.0125 Epoch: 21   Global Step: 61800   Required: 6 hours
Training: 2025-08-31 11:41:04,233-Speed 365.56 samples/sec   Loss 0.0136 Epoch: 21   Global Step: 61850   Required: 6 hours
Training: 2025-08-31 11:41:33,501-[lfw][61864]XNorm: 15.432641
Training: 2025-08-31 11:41:33,501-[lfw][61864]Accuracy-Flip: 0.83350+-0.01592
Training: 2025-08-31 11:41:33,501-[lfw][61864]Accuracy-Highest: 0.83600
Training: 2025-08-31 11:42:01,799-[cfp_fp][61864]XNorm: 13.145592
Training: 2025-08-31 11:42:01,799-[cfp_fp][61864]Accuracy-Flip: 0.65571+-0.01524
Training: 2025-08-31 11:42:01,799-[cfp_fp][61864]Accuracy-Highest: 0.66086
Training: 2025-08-31 11:42:26,143-[agedb_30][61864]XNorm: 14.687825
Training: 2025-08-31 11:42:26,143-[agedb_30][61864]Accuracy-Flip: 0.54617+-0.01278
Training: 2025-08-31 11:42:26,143-[agedb_30][61864]Accuracy-Highest: 0.56500
Training: 2025-08-31 11:42:50,581-[calfw][61864]XNorm: 15.906430
Training: 2025-08-31 11:42:50,582-[calfw][61864]Accuracy-Flip: 0.68817+-0.02139
Training: 2025-08-31 11:42:50,582-[calfw][61864]Accuracy-Highest: 0.68817
Training: 2025-08-31 11:43:15,013-[cplfw][61864]XNorm: 12.004287
Training: 2025-08-31 11:43:15,013-[cplfw][61864]Accuracy-Flip: 0.64067+-0.01116
Training: 2025-08-31 11:43:15,013-[cplfw][61864]Accuracy-Highest: 0.64067
Training: 2025-08-31 11:43:27,759-Speed 44.59 samples/sec   Loss 0.0086 Epoch: 22   Global Step: 61900   Required: 6 hours
Training: 2025-08-31 11:43:45,254-Speed 365.83 samples/sec   Loss 0.0064 Epoch: 22   Global Step: 61950   Required: 6 hours
Training: 2025-08-31 11:44:02,751-Speed 365.78 samples/sec   Loss 0.0115 Epoch: 22   Global Step: 62000   Required: 6 hours
Training: 2025-08-31 11:44:20,252-Speed 365.69 samples/sec   Loss 0.0093 Epoch: 22   Global Step: 62050   Required: 6 hours
Training: 2025-08-31 11:44:37,751-Speed 365.75 samples/sec   Loss 0.0049 Epoch: 22   Global Step: 62100   Required: 6 hours
Training: 2025-08-31 11:44:55,253-Speed 365.68 samples/sec   Loss 0.0063 Epoch: 22   Global Step: 62150   Required: 6 hours
Training: 2025-08-31 11:45:12,758-Speed 365.60 samples/sec   Loss 0.0047 Epoch: 22   Global Step: 62200   Required: 6 hours
Training: 2025-08-31 11:45:30,263-Speed 365.62 samples/sec   Loss 0.0054 Epoch: 22   Global Step: 62250   Required: 6 hours
Training: 2025-08-31 11:45:47,774-Speed 365.47 samples/sec   Loss 0.0061 Epoch: 22   Global Step: 62300   Required: 6 hours
Training: 2025-08-31 11:46:05,284-Speed 365.52 samples/sec   Loss 0.0105 Epoch: 22   Global Step: 62350   Required: 5 hours
Training: 2025-08-31 11:46:22,796-Speed 365.46 samples/sec   Loss 0.0088 Epoch: 22   Global Step: 62400   Required: 5 hours
Training: 2025-08-31 11:46:40,309-Speed 365.45 samples/sec   Loss 0.0057 Epoch: 22   Global Step: 62450   Required: 5 hours
Training: 2025-08-31 11:46:57,817-Speed 365.53 samples/sec   Loss 0.0071 Epoch: 22   Global Step: 62500   Required: 5 hours
Training: 2025-08-31 11:47:15,328-Speed 365.49 samples/sec   Loss 0.0068 Epoch: 22   Global Step: 62550   Required: 5 hours
Training: 2025-08-31 11:47:32,832-Speed 365.63 samples/sec   Loss 0.0048 Epoch: 22   Global Step: 62600   Required: 5 hours
Training: 2025-08-31 11:47:50,337-Speed 365.62 samples/sec   Loss 0.0084 Epoch: 22   Global Step: 62650   Required: 5 hours
Training: 2025-08-31 11:48:07,834-Speed 365.77 samples/sec   Loss 0.0057 Epoch: 22   Global Step: 62700   Required: 5 hours
Training: 2025-08-31 11:48:25,350-Speed 365.38 samples/sec   Loss 0.0075 Epoch: 22   Global Step: 62750   Required: 5 hours
Training: 2025-08-31 11:48:42,857-Speed 365.57 samples/sec   Loss 0.0079 Epoch: 22   Global Step: 62800   Required: 5 hours
Training: 2025-08-31 11:49:00,363-Speed 365.59 samples/sec   Loss 0.0089 Epoch: 22   Global Step: 62850   Required: 5 hours
Training: 2025-08-31 11:49:17,870-Speed 365.56 samples/sec   Loss 0.0103 Epoch: 22   Global Step: 62900   Required: 5 hours
Training: 2025-08-31 11:49:35,371-Speed 365.71 samples/sec   Loss 0.0094 Epoch: 22   Global Step: 62950   Required: 5 hours
Training: 2025-08-31 11:49:52,875-Speed 365.63 samples/sec   Loss 0.0100 Epoch: 22   Global Step: 63000   Required: 5 hours
Training: 2025-08-31 11:50:10,373-Speed 365.75 samples/sec   Loss 0.0077 Epoch: 22   Global Step: 63050   Required: 5 hours
Training: 2025-08-31 11:50:27,884-Speed 365.48 samples/sec   Loss 0.0089 Epoch: 22   Global Step: 63100   Required: 5 hours
Training: 2025-08-31 11:50:45,393-Speed 365.55 samples/sec   Loss 0.0085 Epoch: 22   Global Step: 63150   Required: 5 hours
Training: 2025-08-31 11:51:02,903-Speed 365.50 samples/sec   Loss 0.0081 Epoch: 22   Global Step: 63200   Required: 5 hours
Training: 2025-08-31 11:51:20,407-Speed 365.62 samples/sec   Loss 0.0095 Epoch: 22   Global Step: 63250   Required: 5 hours
Training: 2025-08-31 11:51:37,909-Speed 365.69 samples/sec   Loss 0.0063 Epoch: 22   Global Step: 63300   Required: 5 hours
Training: 2025-08-31 11:51:55,416-Speed 365.56 samples/sec   Loss 0.0097 Epoch: 22   Global Step: 63350   Required: 5 hours
Training: 2025-08-31 11:52:12,920-Speed 365.62 samples/sec   Loss 0.0079 Epoch: 22   Global Step: 63400   Required: 5 hours
Training: 2025-08-31 11:52:30,429-Speed 365.54 samples/sec   Loss 0.0076 Epoch: 22   Global Step: 63450   Required: 5 hours
Training: 2025-08-31 11:52:47,939-Speed 365.51 samples/sec   Loss 0.0062 Epoch: 22   Global Step: 63500   Required: 5 hours
Training: 2025-08-31 11:53:05,444-Speed 365.60 samples/sec   Loss 0.0090 Epoch: 22   Global Step: 63550   Required: 5 hours
Training: 2025-08-31 11:53:22,957-Speed 365.44 samples/sec   Loss 0.0047 Epoch: 22   Global Step: 63600   Required: 5 hours
Training: 2025-08-31 11:53:40,462-Speed 365.61 samples/sec   Loss 0.0063 Epoch: 22   Global Step: 63650   Required: 5 hours
Training: 2025-08-31 11:53:57,970-Speed 365.56 samples/sec   Loss 0.0066 Epoch: 22   Global Step: 63700   Required: 5 hours
Training: 2025-08-31 11:54:15,480-Speed 365.51 samples/sec   Loss 0.0056 Epoch: 22   Global Step: 63750   Required: 5 hours
Training: 2025-08-31 11:54:32,993-Speed 365.44 samples/sec   Loss 0.0040 Epoch: 22   Global Step: 63800   Required: 5 hours
Training: 2025-08-31 11:54:50,509-Speed 365.38 samples/sec   Loss 0.0088 Epoch: 22   Global Step: 63850   Required: 5 hours
Training: 2025-08-31 11:55:08,028-Speed 365.33 samples/sec   Loss 0.0064 Epoch: 22   Global Step: 63900   Required: 5 hours
Training: 2025-08-31 11:55:25,542-Speed 365.41 samples/sec   Loss 0.0084 Epoch: 22   Global Step: 63950   Required: 5 hours
Training: 2025-08-31 11:55:43,048-Speed 365.60 samples/sec   Loss 0.0075 Epoch: 22   Global Step: 64000   Required: 5 hours
Training: 2025-08-31 11:56:00,560-Speed 365.47 samples/sec   Loss 0.0059 Epoch: 22   Global Step: 64050   Required: 5 hours
Training: 2025-08-31 11:56:18,072-Speed 365.47 samples/sec   Loss 0.0075 Epoch: 22   Global Step: 64100   Required: 5 hours
Training: 2025-08-31 11:56:35,589-Speed 365.36 samples/sec   Loss 0.0072 Epoch: 22   Global Step: 64150   Required: 5 hours
Training: 2025-08-31 11:56:53,100-Speed 365.49 samples/sec   Loss 0.0121 Epoch: 22   Global Step: 64200   Required: 5 hours
Training: 2025-08-31 11:57:10,619-Speed 365.32 samples/sec   Loss 0.0054 Epoch: 22   Global Step: 64250   Required: 5 hours
Training: 2025-08-31 11:57:28,137-Speed 365.34 samples/sec   Loss 0.0085 Epoch: 22   Global Step: 64300   Required: 5 hours
Training: 2025-08-31 11:57:45,649-Speed 365.46 samples/sec   Loss 0.0095 Epoch: 22   Global Step: 64350   Required: 5 hours
Training: 2025-08-31 11:58:03,161-Speed 365.46 samples/sec   Loss 0.0051 Epoch: 22   Global Step: 64400   Required: 5 hours
Training: 2025-08-31 11:58:20,679-Speed 365.35 samples/sec   Loss 0.0054 Epoch: 22   Global Step: 64450   Required: 5 hours
Training: 2025-08-31 11:58:38,194-Speed 365.40 samples/sec   Loss 0.0055 Epoch: 22   Global Step: 64500   Required: 5 hours
Training: 2025-08-31 11:58:55,707-Speed 365.44 samples/sec   Loss 0.0052 Epoch: 22   Global Step: 64550   Required: 5 hours
Training: 2025-08-31 11:59:13,218-Speed 365.49 samples/sec   Loss 0.0073 Epoch: 22   Global Step: 64600   Required: 5 hours
Training: 2025-08-31 11:59:30,728-Speed 365.50 samples/sec   Loss 0.0049 Epoch: 22   Global Step: 64650   Required: 5 hours
Training: 2025-08-31 12:00:04,195-[lfw][64676]XNorm: 15.402708
Training: 2025-08-31 12:00:04,195-[lfw][64676]Accuracy-Flip: 0.83400+-0.01618
Training: 2025-08-31 12:00:04,195-[lfw][64676]Accuracy-Highest: 0.83600
Training: 2025-08-31 12:00:32,497-[cfp_fp][64676]XNorm: 12.903050
Training: 2025-08-31 12:00:32,497-[cfp_fp][64676]Accuracy-Flip: 0.66314+-0.01377
Training: 2025-08-31 12:00:32,497-[cfp_fp][64676]Accuracy-Highest: 0.66314
Training: 2025-08-31 12:00:56,847-[agedb_30][64676]XNorm: 14.699163
Training: 2025-08-31 12:00:56,847-[agedb_30][64676]Accuracy-Flip: 0.54483+-0.01345
Training: 2025-08-31 12:00:56,847-[agedb_30][64676]Accuracy-Highest: 0.56500
Training: 2025-08-31 12:01:21,294-[calfw][64676]XNorm: 15.908188
Training: 2025-08-31 12:01:21,294-[calfw][64676]Accuracy-Flip: 0.68733+-0.01752
Training: 2025-08-31 12:01:21,294-[calfw][64676]Accuracy-Highest: 0.68817
Training: 2025-08-31 12:01:45,719-[cplfw][64676]XNorm: 11.903112
Training: 2025-08-31 12:01:45,719-[cplfw][64676]Accuracy-Flip: 0.64233+-0.01263
Training: 2025-08-31 12:01:45,719-[cplfw][64676]Accuracy-Highest: 0.64233
Training: 2025-08-31 12:01:54,311-Speed 44.57 samples/sec   Loss 0.0070 Epoch: 23   Global Step: 64700   Required: 5 hours
Training: 2025-08-31 12:02:11,806-Speed 365.82 samples/sec   Loss 0.0042 Epoch: 23   Global Step: 64750   Required: 5 hours
Training: 2025-08-31 12:02:29,300-Speed 365.84 samples/sec   Loss 0.0048 Epoch: 23   Global Step: 64800   Required: 5 hours
Training: 2025-08-31 12:02:46,796-Speed 365.80 samples/sec   Loss 0.0039 Epoch: 23   Global Step: 64850   Required: 5 hours
Training: 2025-08-31 12:03:04,301-Speed 365.61 samples/sec   Loss 0.0038 Epoch: 23   Global Step: 64900   Required: 5 hours
Training: 2025-08-31 12:03:21,806-Speed 365.61 samples/sec   Loss 0.0056 Epoch: 23   Global Step: 64950   Required: 5 hours
Training: 2025-08-31 12:03:39,321-Speed 365.42 samples/sec   Loss 0.0050 Epoch: 23   Global Step: 65000   Required: 5 hours
Training: 2025-08-31 12:03:56,831-Speed 365.50 samples/sec   Loss 0.0031 Epoch: 23   Global Step: 65050   Required: 5 hours
Training: 2025-08-31 12:04:14,338-Speed 365.57 samples/sec   Loss 0.0046 Epoch: 23   Global Step: 65100   Required: 5 hours
Training: 2025-08-31 12:04:31,852-Speed 365.42 samples/sec   Loss 0.0028 Epoch: 23   Global Step: 65150   Required: 5 hours
Training: 2025-08-31 12:04:49,355-Speed 365.66 samples/sec   Loss 0.0054 Epoch: 23   Global Step: 65200   Required: 5 hours
Training: 2025-08-31 12:05:06,860-Speed 365.62 samples/sec   Loss 0.0024 Epoch: 23   Global Step: 65250   Required: 5 hours
Training: 2025-08-31 12:05:24,377-Speed 365.35 samples/sec   Loss 0.0041 Epoch: 23   Global Step: 65300   Required: 5 hours
Training: 2025-08-31 12:05:41,890-Speed 365.46 samples/sec   Loss 0.0037 Epoch: 23   Global Step: 65350   Required: 5 hours
Training: 2025-08-31 12:05:59,388-Speed 365.75 samples/sec   Loss 0.0046 Epoch: 23   Global Step: 65400   Required: 5 hours
Training: 2025-08-31 12:06:16,900-Speed 365.46 samples/sec   Loss 0.0053 Epoch: 23   Global Step: 65450   Required: 5 hours
Training: 2025-08-31 12:06:34,413-Speed 365.46 samples/sec   Loss 0.0029 Epoch: 23   Global Step: 65500   Required: 5 hours
Training: 2025-08-31 12:06:51,922-Speed 365.51 samples/sec   Loss 0.0050 Epoch: 23   Global Step: 65550   Required: 5 hours
Training: 2025-08-31 12:07:09,435-Speed 365.45 samples/sec   Loss 0.0031 Epoch: 23   Global Step: 65600   Required: 5 hours
Training: 2025-08-31 12:07:26,948-Speed 365.44 samples/sec   Loss 0.0032 Epoch: 23   Global Step: 65650   Required: 5 hours
Training: 2025-08-31 12:07:44,454-Speed 365.59 samples/sec   Loss 0.0055 Epoch: 23   Global Step: 65700   Required: 5 hours
Training: 2025-08-31 12:08:01,965-Speed 365.49 samples/sec   Loss 0.0025 Epoch: 23   Global Step: 65750   Required: 5 hours
Training: 2025-08-31 12:08:19,480-Speed 365.40 samples/sec   Loss 0.0036 Epoch: 23   Global Step: 65800   Required: 5 hours
Training: 2025-08-31 12:08:36,993-Speed 365.45 samples/sec   Loss 0.0042 Epoch: 23   Global Step: 65850   Required: 5 hours
Training: 2025-08-31 12:08:54,508-Speed 365.41 samples/sec   Loss 0.0042 Epoch: 23   Global Step: 65900   Required: 5 hours
Training: 2025-08-31 12:09:12,021-Speed 365.43 samples/sec   Loss 0.0027 Epoch: 23   Global Step: 65950   Required: 5 hours
Training: 2025-08-31 12:09:29,520-Speed 365.74 samples/sec   Loss 0.0041 Epoch: 23   Global Step: 66000   Required: 5 hours
Training: 2025-08-31 12:09:47,025-Speed 365.62 samples/sec   Loss 0.0030 Epoch: 23   Global Step: 66050   Required: 5 hours
Training: 2025-08-31 12:10:04,534-Speed 365.52 samples/sec   Loss 0.0038 Epoch: 23   Global Step: 66100   Required: 5 hours
Training: 2025-08-31 12:10:22,032-Speed 365.76 samples/sec   Loss 0.0040 Epoch: 23   Global Step: 66150   Required: 5 hours
Training: 2025-08-31 12:10:39,540-Speed 365.56 samples/sec   Loss 0.0022 Epoch: 23   Global Step: 66200   Required: 5 hours
Training: 2025-08-31 12:10:57,042-Speed 365.67 samples/sec   Loss 0.0045 Epoch: 23   Global Step: 66250   Required: 5 hours
Training: 2025-08-31 12:11:14,552-Speed 365.52 samples/sec   Loss 0.0051 Epoch: 23   Global Step: 66300   Required: 5 hours
Training: 2025-08-31 12:11:32,057-Speed 365.60 samples/sec   Loss 0.0053 Epoch: 23   Global Step: 66350   Required: 5 hours
Training: 2025-08-31 12:11:49,561-Speed 365.62 samples/sec   Loss 0.0030 Epoch: 23   Global Step: 66400   Required: 5 hours
Training: 2025-08-31 12:12:07,066-Speed 365.62 samples/sec   Loss 0.0036 Epoch: 23   Global Step: 66450   Required: 5 hours
Training: 2025-08-31 12:12:24,574-Speed 365.56 samples/sec   Loss 0.0033 Epoch: 23   Global Step: 66500   Required: 5 hours
Training: 2025-08-31 12:12:42,078-Speed 365.64 samples/sec   Loss 0.0051 Epoch: 23   Global Step: 66550   Required: 5 hours
Training: 2025-08-31 12:12:59,582-Speed 365.62 samples/sec   Loss 0.0040 Epoch: 23   Global Step: 66600   Required: 5 hours
Training: 2025-08-31 12:13:17,083-Speed 365.71 samples/sec   Loss 0.0030 Epoch: 23   Global Step: 66650   Required: 5 hours
Training: 2025-08-31 12:13:34,579-Speed 365.79 samples/sec   Loss 0.0040 Epoch: 23   Global Step: 66700   Required: 5 hours
Training: 2025-08-31 12:13:52,080-Speed 365.69 samples/sec   Loss 0.0039 Epoch: 23   Global Step: 66750   Required: 5 hours
Training: 2025-08-31 12:14:09,575-Speed 365.83 samples/sec   Loss 0.0027 Epoch: 23   Global Step: 66800   Required: 5 hours
Training: 2025-08-31 12:14:27,084-Speed 365.54 samples/sec   Loss 0.0027 Epoch: 23   Global Step: 66850   Required: 5 hours
Training: 2025-08-31 12:14:44,587-Speed 365.65 samples/sec   Loss 0.0054 Epoch: 23   Global Step: 66900   Required: 5 hours
Training: 2025-08-31 12:15:02,089-Speed 365.67 samples/sec   Loss 0.0036 Epoch: 23   Global Step: 66950   Required: 5 hours
Training: 2025-08-31 12:15:19,586-Speed 365.78 samples/sec   Loss 0.0038 Epoch: 23   Global Step: 67000   Required: 5 hours
Training: 2025-08-31 12:15:37,088-Speed 365.68 samples/sec   Loss 0.0046 Epoch: 23   Global Step: 67050   Required: 5 hours
Training: 2025-08-31 12:15:54,593-Speed 365.61 samples/sec   Loss 0.0026 Epoch: 23   Global Step: 67100   Required: 5 hours
Training: 2025-08-31 12:16:12,090-Speed 365.77 samples/sec   Loss 0.0034 Epoch: 23   Global Step: 67150   Required: 5 hours
Training: 2025-08-31 12:16:29,584-Speed 365.85 samples/sec   Loss 0.0052 Epoch: 23   Global Step: 67200   Required: 5 hours
Training: 2025-08-31 12:16:47,089-Speed 365.62 samples/sec   Loss 0.0035 Epoch: 23   Global Step: 67250   Required: 5 hours
Training: 2025-08-31 12:17:04,591-Speed 365.66 samples/sec   Loss 0.0048 Epoch: 23   Global Step: 67300   Required: 5 hours
Training: 2025-08-31 12:17:22,098-Speed 365.58 samples/sec   Loss 0.0026 Epoch: 23   Global Step: 67350   Required: 5 hours
Training: 2025-08-31 12:17:39,600-Speed 365.67 samples/sec   Loss 0.0026 Epoch: 23   Global Step: 67400   Required: 5 hours
Training: 2025-08-31 12:17:57,094-Speed 365.84 samples/sec   Loss 0.0021 Epoch: 23   Global Step: 67450   Required: 5 hours
Training: 2025-08-31 12:18:34,755-[lfw][67488]XNorm: 15.282902
Training: 2025-08-31 12:18:34,756-[lfw][67488]Accuracy-Flip: 0.83550+-0.01718
Training: 2025-08-31 12:18:34,756-[lfw][67488]Accuracy-Highest: 0.83600
Training: 2025-08-31 12:19:03,057-[cfp_fp][67488]XNorm: 12.863406
Training: 2025-08-31 12:19:03,057-[cfp_fp][67488]Accuracy-Flip: 0.66386+-0.01597
Training: 2025-08-31 12:19:03,057-[cfp_fp][67488]Accuracy-Highest: 0.66386
Training: 2025-08-31 12:19:27,496-[agedb_30][67488]XNorm: 14.484213
Training: 2025-08-31 12:19:27,496-[agedb_30][67488]Accuracy-Flip: 0.54983+-0.01622
Training: 2025-08-31 12:19:27,496-[agedb_30][67488]Accuracy-Highest: 0.56500
Training: 2025-08-31 12:19:51,917-[calfw][67488]XNorm: 15.783550
Training: 2025-08-31 12:19:51,917-[calfw][67488]Accuracy-Flip: 0.68750+-0.01677
Training: 2025-08-31 12:19:51,917-[calfw][67488]Accuracy-Highest: 0.68817
Training: 2025-08-31 12:20:16,335-[cplfw][67488]XNorm: 11.804622
Training: 2025-08-31 12:20:16,335-[cplfw][67488]Accuracy-Flip: 0.63483+-0.01413
Training: 2025-08-31 12:20:16,335-[cplfw][67488]Accuracy-Highest: 0.64233
Training: 2025-08-31 12:20:20,738-Speed 44.55 samples/sec   Loss 0.0039 Epoch: 24   Global Step: 67500   Required: 5 hours
Training: 2025-08-31 12:20:38,229-Speed 365.90 samples/sec   Loss 0.0026 Epoch: 24   Global Step: 67550   Required: 5 hours
Training: 2025-08-31 12:20:55,724-Speed 365.82 samples/sec   Loss 0.0024 Epoch: 24   Global Step: 67600   Required: 5 hours
Training: 2025-08-31 12:21:13,218-Speed 365.83 samples/sec   Loss 0.0025 Epoch: 24   Global Step: 67650   Required: 5 hours
Training: 2025-08-31 12:21:30,725-Speed 365.58 samples/sec   Loss 0.0021 Epoch: 24   Global Step: 67700   Required: 5 hours
Training: 2025-08-31 12:21:48,232-Speed 365.57 samples/sec   Loss 0.0032 Epoch: 24   Global Step: 67750   Required: 5 hours
Training: 2025-08-31 12:22:05,746-Speed 365.42 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 67800   Required: 5 hours
Training: 2025-08-31 12:22:23,256-Speed 365.51 samples/sec   Loss 0.0026 Epoch: 24   Global Step: 67850   Required: 5 hours
Training: 2025-08-31 12:22:40,773-Speed 365.36 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 67900   Required: 5 hours
Training: 2025-08-31 12:22:58,290-Speed 365.36 samples/sec   Loss 0.0021 Epoch: 24   Global Step: 67950   Required: 5 hours
Training: 2025-08-31 12:23:15,803-Speed 365.45 samples/sec   Loss 0.0022 Epoch: 24   Global Step: 68000   Required: 5 hours
Training: 2025-08-31 12:23:33,316-Speed 365.45 samples/sec   Loss 0.0031 Epoch: 24   Global Step: 68050   Required: 5 hours
Training: 2025-08-31 12:23:50,826-Speed 365.50 samples/sec   Loss 0.0021 Epoch: 24   Global Step: 68100   Required: 5 hours
Training: 2025-08-31 12:24:08,332-Speed 365.59 samples/sec   Loss 0.0020 Epoch: 24   Global Step: 68150   Required: 5 hours
Training: 2025-08-31 12:24:25,841-Speed 365.53 samples/sec   Loss 0.0026 Epoch: 24   Global Step: 68200   Required: 5 hours
Training: 2025-08-31 12:24:43,358-Speed 365.36 samples/sec   Loss 0.0020 Epoch: 24   Global Step: 68250   Required: 5 hours
Training: 2025-08-31 12:25:00,868-Speed 365.50 samples/sec   Loss 0.0032 Epoch: 24   Global Step: 68300   Required: 5 hours
Training: 2025-08-31 12:25:18,384-Speed 365.39 samples/sec   Loss 0.0031 Epoch: 24   Global Step: 68350   Required: 5 hours
Training: 2025-08-31 12:25:35,898-Speed 365.42 samples/sec   Loss 0.0028 Epoch: 24   Global Step: 68400   Required: 5 hours
Training: 2025-08-31 12:25:53,407-Speed 365.52 samples/sec   Loss 0.0027 Epoch: 24   Global Step: 68450   Required: 5 hours
Training: 2025-08-31 12:26:10,913-Speed 365.59 samples/sec   Loss 0.0024 Epoch: 24   Global Step: 68500   Required: 5 hours
Training: 2025-08-31 12:26:28,414-Speed 365.70 samples/sec   Loss 0.0021 Epoch: 24   Global Step: 68550   Required: 5 hours
Training: 2025-08-31 12:26:45,915-Speed 365.70 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 68600   Required: 5 hours
Training: 2025-08-31 12:27:03,427-Speed 365.47 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 68650   Required: 5 hours
Training: 2025-08-31 12:27:20,935-Speed 365.56 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 68700   Required: 5 hours
Training: 2025-08-31 12:27:38,445-Speed 365.50 samples/sec   Loss 0.0026 Epoch: 24   Global Step: 68750   Required: 5 hours
Training: 2025-08-31 12:27:55,942-Speed 365.78 samples/sec   Loss 0.0028 Epoch: 24   Global Step: 68800   Required: 5 hours
Training: 2025-08-31 12:28:13,449-Speed 365.57 samples/sec   Loss 0.0028 Epoch: 24   Global Step: 68850   Required: 5 hours
Training: 2025-08-31 12:28:30,958-Speed 365.52 samples/sec   Loss 0.0025 Epoch: 24   Global Step: 68900   Required: 5 hours
Training: 2025-08-31 12:28:48,467-Speed 365.53 samples/sec   Loss 0.0021 Epoch: 24   Global Step: 68950   Required: 5 hours
Training: 2025-08-31 12:29:05,971-Speed 365.64 samples/sec   Loss 0.0024 Epoch: 24   Global Step: 69000   Required: 5 hours
Training: 2025-08-31 12:29:23,476-Speed 365.60 samples/sec   Loss 0.0024 Epoch: 24   Global Step: 69050   Required: 5 hours
Training: 2025-08-31 12:29:40,982-Speed 365.59 samples/sec   Loss 0.0022 Epoch: 24   Global Step: 69100   Required: 5 hours
Training: 2025-08-31 12:29:58,490-Speed 365.55 samples/sec   Loss 0.0032 Epoch: 24   Global Step: 69150   Required: 5 hours
Training: 2025-08-31 12:30:16,002-Speed 365.47 samples/sec   Loss 0.0021 Epoch: 24   Global Step: 69200   Required: 5 hours
Training: 2025-08-31 12:30:33,515-Speed 365.46 samples/sec   Loss 0.0022 Epoch: 24   Global Step: 69250   Required: 5 hours
Training: 2025-08-31 12:30:51,021-Speed 365.58 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 69300   Required: 5 hours
Training: 2025-08-31 12:31:08,525-Speed 365.64 samples/sec   Loss 0.0024 Epoch: 24   Global Step: 69350   Required: 5 hours
Training: 2025-08-31 12:31:26,031-Speed 365.60 samples/sec   Loss 0.0030 Epoch: 24   Global Step: 69400   Required: 5 hours
Training: 2025-08-31 12:31:43,533-Speed 365.66 samples/sec   Loss 0.0035 Epoch: 24   Global Step: 69450   Required: 5 hours
Training: 2025-08-31 12:32:01,046-Speed 365.46 samples/sec   Loss 0.0024 Epoch: 24   Global Step: 69500   Required: 5 hours
Training: 2025-08-31 12:32:18,552-Speed 365.58 samples/sec   Loss 0.0020 Epoch: 24   Global Step: 69550   Required: 5 hours
Training: 2025-08-31 12:32:36,052-Speed 365.73 samples/sec   Loss 0.0036 Epoch: 24   Global Step: 69600   Required: 5 hours
Training: 2025-08-31 12:32:53,554-Speed 365.67 samples/sec   Loss 0.0028 Epoch: 24   Global Step: 69650   Required: 5 hours
Training: 2025-08-31 12:33:11,059-Speed 365.62 samples/sec   Loss 0.0069 Epoch: 24   Global Step: 69700   Required: 5 hours
Training: 2025-08-31 12:33:28,562-Speed 365.65 samples/sec   Loss 0.0029 Epoch: 24   Global Step: 69750   Required: 5 hours
Training: 2025-08-31 12:33:46,063-Speed 365.70 samples/sec   Loss 0.0027 Epoch: 24   Global Step: 69800   Required: 5 hours
Training: 2025-08-31 12:34:03,562-Speed 365.72 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 69850   Required: 5 hours
Training: 2025-08-31 12:34:21,065-Speed 365.66 samples/sec   Loss 0.0015 Epoch: 24   Global Step: 69900   Required: 5 hours
Training: 2025-08-31 12:34:38,568-Speed 365.65 samples/sec   Loss 0.0024 Epoch: 24   Global Step: 69950   Required: 5 hours
Training: 2025-08-31 12:34:56,075-Speed 365.58 samples/sec   Loss 0.0019 Epoch: 24   Global Step: 70000   Required: 5 hours
Training: 2025-08-31 12:35:13,587-Speed 365.47 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 70050   Required: 5 hours
Training: 2025-08-31 12:35:31,104-Speed 365.35 samples/sec   Loss 0.0021 Epoch: 24   Global Step: 70100   Required: 5 hours
Training: 2025-08-31 12:35:48,616-Speed 365.47 samples/sec   Loss 0.0036 Epoch: 24   Global Step: 70150   Required: 5 hours
Training: 2025-08-31 12:36:06,130-Speed 365.42 samples/sec   Loss 0.0025 Epoch: 24   Global Step: 70200   Required: 5 hours
Training: 2025-08-31 12:36:23,644-Speed 365.44 samples/sec   Loss 0.0026 Epoch: 24   Global Step: 70250   Required: 5 hours
Training: 2025-08-31 12:36:41,162-Speed 365.33 samples/sec   Loss 0.0020 Epoch: 24   Global Step: 70300   Required: 5 hours
Training: 2025-08-31 12:37:05,540-[lfw][70300]XNorm: 15.333941
Training: 2025-08-31 12:37:05,540-[lfw][70300]Accuracy-Flip: 0.83883+-0.01538
Training: 2025-08-31 12:37:05,540-[lfw][70300]Accuracy-Highest: 0.83883
Training: 2025-08-31 12:37:33,837-[cfp_fp][70300]XNorm: 13.006268
Training: 2025-08-31 12:37:33,837-[cfp_fp][70300]Accuracy-Flip: 0.65814+-0.01382
Training: 2025-08-31 12:37:33,837-[cfp_fp][70300]Accuracy-Highest: 0.66386
Training: 2025-08-31 12:37:58,195-[agedb_30][70300]XNorm: 14.601934
Training: 2025-08-31 12:37:58,195-[agedb_30][70300]Accuracy-Flip: 0.54800+-0.01431
Training: 2025-08-31 12:37:58,195-[agedb_30][70300]Accuracy-Highest: 0.56500
Training: 2025-08-31 12:38:22,632-[calfw][70300]XNorm: 15.835286
Training: 2025-08-31 12:38:22,632-[calfw][70300]Accuracy-Flip: 0.68883+-0.02044
Training: 2025-08-31 12:38:22,632-[calfw][70300]Accuracy-Highest: 0.68883
Training: 2025-08-31 12:38:47,050-[cplfw][70300]XNorm: 11.882672
Training: 2025-08-31 12:38:47,050-[cplfw][70300]Accuracy-Flip: 0.64567+-0.01184
Training: 2025-08-31 12:38:47,050-[cplfw][70300]Accuracy-Highest: 0.64567
Training: 2025-08-31 12:39:04,697-Speed 44.59 samples/sec   Loss 0.0020 Epoch: 25   Global Step: 70350   Required: 5 hours
Training: 2025-08-31 12:39:22,191-Speed 365.84 samples/sec   Loss 0.0015 Epoch: 25   Global Step: 70400   Required: 5 hours
Training: 2025-08-31 12:39:39,687-Speed 365.80 samples/sec   Loss 0.0017 Epoch: 25   Global Step: 70450   Required: 5 hours
Training: 2025-08-31 12:39:57,183-Speed 365.81 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 70500   Required: 5 hours
Training: 2025-08-31 12:40:14,688-Speed 365.61 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 70550   Required: 5 hours
Training: 2025-08-31 12:40:32,200-Speed 365.47 samples/sec   Loss 0.0017 Epoch: 25   Global Step: 70600   Required: 5 hours
Training: 2025-08-31 12:40:49,718-Speed 365.34 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 70650   Required: 5 hours
Training: 2025-08-31 12:41:07,236-Speed 365.35 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 70700   Required: 5 hours
Training: 2025-08-31 12:41:24,752-Speed 365.37 samples/sec   Loss 0.0023 Epoch: 25   Global Step: 70750   Required: 5 hours
Training: 2025-08-31 12:41:42,269-Speed 365.37 samples/sec   Loss 0.0014 Epoch: 25   Global Step: 70800   Required: 5 hours
Training: 2025-08-31 12:41:59,780-Speed 365.50 samples/sec   Loss 0.0020 Epoch: 25   Global Step: 70850   Required: 5 hours
Training: 2025-08-31 12:42:17,299-Speed 365.31 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 70900   Required: 5 hours
Training: 2025-08-31 12:42:34,814-Speed 365.41 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 70950   Required: 5 hours
Training: 2025-08-31 12:42:52,332-Speed 365.34 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 71000   Required: 5 hours
Training: 2025-08-31 12:43:09,846-Speed 365.42 samples/sec   Loss 0.0026 Epoch: 25   Global Step: 71050   Required: 5 hours
Training: 2025-08-31 12:43:27,364-Speed 365.35 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 71100   Required: 5 hours
Training: 2025-08-31 12:43:44,875-Speed 365.49 samples/sec   Loss 0.0021 Epoch: 25   Global Step: 71150   Required: 5 hours
Training: 2025-08-31 12:44:02,384-Speed 365.52 samples/sec   Loss 0.0023 Epoch: 25   Global Step: 71200   Required: 5 hours
Training: 2025-08-31 12:44:19,893-Speed 365.53 samples/sec   Loss 0.0015 Epoch: 25   Global Step: 71250   Required: 5 hours
Training: 2025-08-31 12:44:37,407-Speed 365.43 samples/sec   Loss 0.0039 Epoch: 25   Global Step: 71300   Required: 5 hours
Training: 2025-08-31 12:44:54,921-Speed 365.43 samples/sec   Loss 0.0017 Epoch: 25   Global Step: 71350   Required: 5 hours
Training: 2025-08-31 12:45:12,437-Speed 365.37 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 71400   Required: 4 hours
Training: 2025-08-31 12:45:29,948-Speed 365.50 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 71450   Required: 4 hours
Training: 2025-08-31 12:45:47,459-Speed 365.47 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 71500   Required: 4 hours
Training: 2025-08-31 12:46:04,965-Speed 365.61 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 71550   Required: 4 hours
Training: 2025-08-31 12:46:22,481-Speed 365.37 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 71600   Required: 4 hours
Training: 2025-08-31 12:46:39,998-Speed 365.38 samples/sec   Loss 0.0014 Epoch: 25   Global Step: 71650   Required: 4 hours
Training: 2025-08-31 12:46:57,514-Speed 365.38 samples/sec   Loss 0.0023 Epoch: 25   Global Step: 71700   Required: 4 hours
Training: 2025-08-31 12:47:15,035-Speed 365.27 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 71750   Required: 4 hours
Training: 2025-08-31 12:47:32,555-Speed 365.31 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 71800   Required: 4 hours
Training: 2025-08-31 12:47:50,069-Speed 365.42 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 71850   Required: 4 hours
Training: 2025-08-31 12:48:07,595-Speed 365.18 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 71900   Required: 4 hours
Training: 2025-08-31 12:48:25,117-Speed 365.25 samples/sec   Loss 0.0017 Epoch: 25   Global Step: 71950   Required: 4 hours
Training: 2025-08-31 12:48:42,634-Speed 365.37 samples/sec   Loss 0.0020 Epoch: 25   Global Step: 72000   Required: 4 hours
Training: 2025-08-31 12:49:00,155-Speed 365.27 samples/sec   Loss 0.0027 Epoch: 25   Global Step: 72050   Required: 4 hours
Training: 2025-08-31 12:49:17,673-Speed 365.34 samples/sec   Loss 0.0015 Epoch: 25   Global Step: 72100   Required: 4 hours
Training: 2025-08-31 12:49:35,183-Speed 365.52 samples/sec   Loss 0.0020 Epoch: 25   Global Step: 72150   Required: 4 hours
Training: 2025-08-31 12:49:52,694-Speed 365.47 samples/sec   Loss 0.0017 Epoch: 25   Global Step: 72200   Required: 4 hours
Training: 2025-08-31 12:50:10,209-Speed 365.40 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 72250   Required: 4 hours
Training: 2025-08-31 12:50:27,725-Speed 365.39 samples/sec   Loss 0.0013 Epoch: 25   Global Step: 72300   Required: 4 hours
Training: 2025-08-31 12:50:45,245-Speed 365.29 samples/sec   Loss 0.0021 Epoch: 25   Global Step: 72350   Required: 4 hours
Training: 2025-08-31 12:51:02,764-Speed 365.32 samples/sec   Loss 0.0023 Epoch: 25   Global Step: 72400   Required: 4 hours
Training: 2025-08-31 12:51:20,279-Speed 365.41 samples/sec   Loss 0.0017 Epoch: 25   Global Step: 72450   Required: 4 hours
Training: 2025-08-31 12:51:37,797-Speed 365.34 samples/sec   Loss 0.0014 Epoch: 25   Global Step: 72500   Required: 4 hours
Training: 2025-08-31 12:51:55,309-Speed 365.47 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 72550   Required: 4 hours
Training: 2025-08-31 12:52:12,826-Speed 365.35 samples/sec   Loss 0.0014 Epoch: 25   Global Step: 72600   Required: 4 hours
Training: 2025-08-31 12:52:30,343-Speed 365.38 samples/sec   Loss 0.0011 Epoch: 25   Global Step: 72650   Required: 4 hours
Training: 2025-08-31 12:52:47,860-Speed 365.35 samples/sec   Loss 0.0017 Epoch: 25   Global Step: 72700   Required: 4 hours
Training: 2025-08-31 12:53:05,376-Speed 365.38 samples/sec   Loss 0.0014 Epoch: 25   Global Step: 72750   Required: 4 hours
Training: 2025-08-31 12:53:22,895-Speed 365.32 samples/sec   Loss 0.0017 Epoch: 25   Global Step: 72800   Required: 4 hours
Training: 2025-08-31 12:53:40,413-Speed 365.35 samples/sec   Loss 0.0014 Epoch: 25   Global Step: 72850   Required: 4 hours
Training: 2025-08-31 12:53:57,931-Speed 365.34 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 72900   Required: 4 hours
Training: 2025-08-31 12:54:15,445-Speed 365.43 samples/sec   Loss 0.0012 Epoch: 25   Global Step: 72950   Required: 4 hours
Training: 2025-08-31 12:54:32,958-Speed 365.44 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 73000   Required: 4 hours
Training: 2025-08-31 12:54:50,470-Speed 365.48 samples/sec   Loss 0.0027 Epoch: 25   Global Step: 73050   Required: 4 hours
Training: 2025-08-31 12:55:07,986-Speed 365.37 samples/sec   Loss 0.0013 Epoch: 25   Global Step: 73100   Required: 4 hours
Training: 2025-08-31 12:55:36,557-[lfw][73112]XNorm: 15.307596
Training: 2025-08-31 12:55:36,557-[lfw][73112]Accuracy-Flip: 0.83600+-0.01625
Training: 2025-08-31 12:55:36,558-[lfw][73112]Accuracy-Highest: 0.83883
Training: 2025-08-31 12:56:04,861-[cfp_fp][73112]XNorm: 12.964574
Training: 2025-08-31 12:56:04,861-[cfp_fp][73112]Accuracy-Flip: 0.66014+-0.01741
Training: 2025-08-31 12:56:04,861-[cfp_fp][73112]Accuracy-Highest: 0.66386
Training: 2025-08-31 12:56:29,228-[agedb_30][73112]XNorm: 14.608549
Training: 2025-08-31 12:56:29,228-[agedb_30][73112]Accuracy-Flip: 0.54317+-0.01431
Training: 2025-08-31 12:56:29,228-[agedb_30][73112]Accuracy-Highest: 0.56500
Training: 2025-08-31 12:56:53,685-[calfw][73112]XNorm: 15.820732
Training: 2025-08-31 12:56:53,685-[calfw][73112]Accuracy-Flip: 0.69200+-0.01838
Training: 2025-08-31 12:56:53,685-[calfw][73112]Accuracy-Highest: 0.69200
Training: 2025-08-31 12:57:18,129-[cplfw][73112]XNorm: 11.851619
Training: 2025-08-31 12:57:18,129-[cplfw][73112]Accuracy-Flip: 0.63983+-0.01421
Training: 2025-08-31 12:57:18,129-[cplfw][73112]Accuracy-Highest: 0.64567
Training: 2025-08-31 12:57:31,625-Speed 44.56 samples/sec   Loss 0.0016 Epoch: 26   Global Step: 73150   Required: 4 hours
Training: 2025-08-31 12:57:49,134-Speed 365.53 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 73200   Required: 4 hours
Training: 2025-08-31 12:58:06,645-Speed 365.48 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 73250   Required: 4 hours
Training: 2025-08-31 12:58:24,162-Speed 365.36 samples/sec   Loss 0.0017 Epoch: 26   Global Step: 73300   Required: 4 hours
Training: 2025-08-31 12:58:41,682-Speed 365.31 samples/sec   Loss 0.0017 Epoch: 26   Global Step: 73350   Required: 4 hours
Training: 2025-08-31 12:58:59,209-Speed 365.15 samples/sec   Loss 0.0019 Epoch: 26   Global Step: 73400   Required: 4 hours
Training: 2025-08-31 12:59:16,731-Speed 365.25 samples/sec   Loss 0.0015 Epoch: 26   Global Step: 73450   Required: 4 hours
Training: 2025-08-31 12:59:34,257-Speed 365.18 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 73500   Required: 4 hours
Training: 2025-08-31 12:59:51,782-Speed 365.20 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 73550   Required: 4 hours
Training: 2025-08-31 13:00:09,304-Speed 365.25 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 73600   Required: 4 hours
Training: 2025-08-31 13:00:26,835-Speed 365.07 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 73650   Required: 4 hours
Training: 2025-08-31 13:00:44,357-Speed 365.26 samples/sec   Loss 0.0015 Epoch: 26   Global Step: 73700   Required: 4 hours
Training: 2025-08-31 13:01:01,882-Speed 365.20 samples/sec   Loss 0.0017 Epoch: 26   Global Step: 73750   Required: 4 hours
Training: 2025-08-31 13:01:19,406-Speed 365.22 samples/sec   Loss 0.0017 Epoch: 26   Global Step: 73800   Required: 4 hours
Training: 2025-08-31 13:01:36,930-Speed 365.20 samples/sec   Loss 0.0018 Epoch: 26   Global Step: 73850   Required: 4 hours
Training: 2025-08-31 13:01:54,457-Speed 365.15 samples/sec   Loss 0.0016 Epoch: 26   Global Step: 73900   Required: 4 hours
Training: 2025-08-31 13:02:11,985-Speed 365.14 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 73950   Required: 4 hours
Training: 2025-08-31 13:02:29,509-Speed 365.23 samples/sec   Loss 0.0015 Epoch: 26   Global Step: 74000   Required: 4 hours
Training: 2025-08-31 13:02:47,034-Speed 365.19 samples/sec   Loss 0.0011 Epoch: 26   Global Step: 74050   Required: 4 hours
Training: 2025-08-31 13:03:04,556-Speed 365.25 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 74100   Required: 4 hours
Training: 2025-08-31 13:03:22,083-Speed 365.16 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 74150   Required: 4 hours
Training: 2025-08-31 13:03:39,607-Speed 365.21 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 74200   Required: 4 hours
Training: 2025-08-31 13:03:57,130-Speed 365.23 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 74250   Required: 4 hours
Training: 2025-08-31 13:04:14,660-Speed 365.11 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 74300   Required: 4 hours
Training: 2025-08-31 13:04:32,189-Speed 365.11 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 74350   Required: 4 hours
Training: 2025-08-31 13:04:49,710-Speed 365.26 samples/sec   Loss 0.0011 Epoch: 26   Global Step: 74400   Required: 4 hours
Training: 2025-08-31 13:05:07,227-Speed 365.37 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 74450   Required: 4 hours
Training: 2025-08-31 13:05:24,745-Speed 365.33 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 74500   Required: 4 hours
Training: 2025-08-31 13:05:42,263-Speed 365.35 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 74550   Required: 4 hours
Training: 2025-08-31 13:05:59,788-Speed 365.19 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 74600   Required: 4 hours
Training: 2025-08-31 13:06:17,314-Speed 365.19 samples/sec   Loss 0.0018 Epoch: 26   Global Step: 74650   Required: 4 hours
Training: 2025-08-31 13:06:34,839-Speed 365.19 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 74700   Required: 4 hours
Training: 2025-08-31 13:06:52,361-Speed 365.26 samples/sec   Loss 0.0023 Epoch: 26   Global Step: 74750   Required: 4 hours
Training: 2025-08-31 13:07:09,891-Speed 365.09 samples/sec   Loss 0.0018 Epoch: 26   Global Step: 74800   Required: 4 hours
Training: 2025-08-31 13:07:27,415-Speed 365.22 samples/sec   Loss 0.0027 Epoch: 26   Global Step: 74850   Required: 4 hours
Training: 2025-08-31 13:07:44,931-Speed 365.38 samples/sec   Loss 0.0015 Epoch: 26   Global Step: 74900   Required: 4 hours
Training: 2025-08-31 13:08:02,455-Speed 365.21 samples/sec   Loss 0.0020 Epoch: 26   Global Step: 74950   Required: 4 hours
Training: 2025-08-31 13:08:19,984-Speed 365.12 samples/sec   Loss 0.0011 Epoch: 26   Global Step: 75000   Required: 4 hours
Training: 2025-08-31 13:08:37,511-Speed 365.14 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 75050   Required: 4 hours
Training: 2025-08-31 13:08:55,034-Speed 365.25 samples/sec   Loss 0.0018 Epoch: 26   Global Step: 75100   Required: 4 hours
Training: 2025-08-31 13:09:12,559-Speed 365.19 samples/sec   Loss 0.0020 Epoch: 26   Global Step: 75150   Required: 4 hours
Training: 2025-08-31 13:09:30,088-Speed 365.11 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 75200   Required: 4 hours
Training: 2025-08-31 13:09:47,614-Speed 365.17 samples/sec   Loss 0.0018 Epoch: 26   Global Step: 75250   Required: 4 hours
Training: 2025-08-31 13:10:05,139-Speed 365.21 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 75300   Required: 4 hours
Training: 2025-08-31 13:10:22,660-Speed 365.27 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 75350   Required: 4 hours
Training: 2025-08-31 13:10:40,180-Speed 365.30 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 75400   Required: 4 hours
Training: 2025-08-31 13:10:57,700-Speed 365.30 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 75450   Required: 4 hours
Training: 2025-08-31 13:11:15,225-Speed 365.19 samples/sec   Loss 0.0016 Epoch: 26   Global Step: 75500   Required: 4 hours
Training: 2025-08-31 13:11:32,751-Speed 365.17 samples/sec   Loss 0.0020 Epoch: 26   Global Step: 75550   Required: 4 hours
Training: 2025-08-31 13:11:50,278-Speed 365.16 samples/sec   Loss 0.0016 Epoch: 26   Global Step: 75600   Required: 4 hours
Training: 2025-08-31 13:12:07,800-Speed 365.25 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 75650   Required: 4 hours
Training: 2025-08-31 13:12:25,326-Speed 365.18 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 75700   Required: 4 hours
Training: 2025-08-31 13:12:42,845-Speed 365.32 samples/sec   Loss 0.0015 Epoch: 26   Global Step: 75750   Required: 4 hours
Training: 2025-08-31 13:13:00,360-Speed 365.40 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 75800   Required: 4 hours
Training: 2025-08-31 13:13:17,885-Speed 365.19 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 75850   Required: 4 hours
Training: 2025-08-31 13:13:35,406-Speed 365.29 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 75900   Required: 4 hours
Training: 2025-08-31 13:14:08,190-[lfw][75924]XNorm: 15.282568
Training: 2025-08-31 13:14:08,190-[lfw][75924]Accuracy-Flip: 0.83683+-0.01692
Training: 2025-08-31 13:14:08,190-[lfw][75924]Accuracy-Highest: 0.83883
Training: 2025-08-31 13:14:36,515-[cfp_fp][75924]XNorm: 12.877877
Training: 2025-08-31 13:14:36,515-[cfp_fp][75924]Accuracy-Flip: 0.66343+-0.01866
Training: 2025-08-31 13:14:36,515-[cfp_fp][75924]Accuracy-Highest: 0.66386
Training: 2025-08-31 13:15:00,881-[agedb_30][75924]XNorm: 14.635841
Training: 2025-08-31 13:15:00,881-[agedb_30][75924]Accuracy-Flip: 0.55217+-0.01696
Training: 2025-08-31 13:15:00,881-[agedb_30][75924]Accuracy-Highest: 0.56500
Training: 2025-08-31 13:15:25,333-[calfw][75924]XNorm: 15.780271
Training: 2025-08-31 13:15:25,333-[calfw][75924]Accuracy-Flip: 0.69050+-0.01838
Training: 2025-08-31 13:15:25,333-[calfw][75924]Accuracy-Highest: 0.69200
Training: 2025-08-31 13:15:49,771-[cplfw][75924]XNorm: 11.823865
Training: 2025-08-31 13:15:49,771-[cplfw][75924]Accuracy-Flip: 0.64483+-0.01334
Training: 2025-08-31 13:15:49,771-[cplfw][75924]Accuracy-Highest: 0.64567
Training: 2025-08-31 13:15:59,016-Speed 44.57 samples/sec   Loss 0.0013 Epoch: 27   Global Step: 75950   Required: 4 hours
Training: 2025-08-31 13:16:16,512-Speed 365.79 samples/sec   Loss 0.0009 Epoch: 27   Global Step: 76000   Required: 4 hours
Training: 2025-08-31 13:16:34,017-Speed 365.61 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 76050   Required: 4 hours
Training: 2025-08-31 13:16:51,533-Speed 365.39 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 76100   Required: 4 hours
Training: 2025-08-31 13:17:09,053-Speed 365.29 samples/sec   Loss 0.0013 Epoch: 27   Global Step: 76150   Required: 4 hours
Training: 2025-08-31 13:17:26,571-Speed 365.35 samples/sec   Loss 0.0013 Epoch: 27   Global Step: 76200   Required: 4 hours
Training: 2025-08-31 13:17:44,091-Speed 365.29 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 76250   Required: 4 hours
Training: 2025-08-31 13:18:01,610-Speed 365.33 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 76300   Required: 4 hours
Training: 2025-08-31 13:18:19,135-Speed 365.20 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 76350   Required: 4 hours
Training: 2025-08-31 13:18:36,662-Speed 365.15 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 76400   Required: 4 hours
Training: 2025-08-31 13:18:54,183-Speed 365.27 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 76450   Required: 4 hours
Training: 2025-08-31 13:19:11,709-Speed 365.18 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 76500   Required: 4 hours
Training: 2025-08-31 13:19:29,229-Speed 365.30 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 76550   Required: 4 hours
Training: 2025-08-31 13:19:46,758-Speed 365.10 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 76600   Required: 4 hours
Training: 2025-08-31 13:20:04,281-Speed 365.25 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 76650   Required: 4 hours
Training: 2025-08-31 13:20:21,805-Speed 365.21 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 76700   Required: 4 hours
Training: 2025-08-31 13:20:39,329-Speed 365.20 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 76750   Required: 4 hours
Training: 2025-08-31 13:20:56,857-Speed 365.14 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 76800   Required: 4 hours
Training: 2025-08-31 13:21:14,381-Speed 365.23 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 76850   Required: 4 hours
Training: 2025-08-31 13:21:31,892-Speed 365.48 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 76900   Required: 4 hours
Training: 2025-08-31 13:21:49,410-Speed 365.34 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 76950   Required: 4 hours
Training: 2025-08-31 13:22:06,930-Speed 365.29 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 77000   Required: 4 hours
Training: 2025-08-31 13:22:24,452-Speed 365.27 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 77050   Required: 4 hours
Training: 2025-08-31 13:22:41,971-Speed 365.32 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 77100   Required: 4 hours
Training: 2025-08-31 13:22:59,491-Speed 365.30 samples/sec   Loss 0.0014 Epoch: 27   Global Step: 77150   Required: 4 hours
Training: 2025-08-31 13:23:17,007-Speed 365.38 samples/sec   Loss 0.0015 Epoch: 27   Global Step: 77200   Required: 4 hours
Training: 2025-08-31 13:23:34,522-Speed 365.41 samples/sec   Loss 0.0013 Epoch: 27   Global Step: 77250   Required: 4 hours
Training: 2025-08-31 13:23:52,042-Speed 365.29 samples/sec   Loss 0.0014 Epoch: 27   Global Step: 77300   Required: 4 hours
Training: 2025-08-31 13:24:09,562-Speed 365.29 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 77350   Required: 4 hours
Training: 2025-08-31 13:24:27,080-Speed 365.34 samples/sec   Loss 0.0015 Epoch: 27   Global Step: 77400   Required: 4 hours
Training: 2025-08-31 13:24:44,593-Speed 365.44 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 77450   Required: 4 hours
Training: 2025-08-31 13:25:02,103-Speed 365.52 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 77500   Required: 4 hours
Training: 2025-08-31 13:25:19,613-Speed 365.50 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 77550   Required: 4 hours
Training: 2025-08-31 13:25:37,122-Speed 365.52 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 77600   Required: 4 hours
Training: 2025-08-31 13:25:54,636-Speed 365.43 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 77650   Required: 4 hours
Training: 2025-08-31 13:26:12,156-Speed 365.30 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 77700   Required: 4 hours
Training: 2025-08-31 13:26:29,670-Speed 365.42 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 77750   Required: 4 hours
Training: 2025-08-31 13:26:47,193-Speed 365.24 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 77800   Required: 4 hours
Training: 2025-08-31 13:27:04,715-Speed 365.25 samples/sec   Loss 0.0009 Epoch: 27   Global Step: 77850   Required: 4 hours
Training: 2025-08-31 13:27:22,234-Speed 365.32 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 77900   Required: 4 hours
Training: 2025-08-31 13:27:39,748-Speed 365.42 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 77950   Required: 4 hours
Training: 2025-08-31 13:27:57,263-Speed 365.42 samples/sec   Loss 0.0013 Epoch: 27   Global Step: 78000   Required: 4 hours
Training: 2025-08-31 13:28:14,786-Speed 365.23 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 78050   Required: 4 hours
Training: 2025-08-31 13:28:32,305-Speed 365.32 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 78100   Required: 4 hours
Training: 2025-08-31 13:28:49,820-Speed 365.40 samples/sec   Loss 0.0014 Epoch: 27   Global Step: 78150   Required: 4 hours
Training: 2025-08-31 13:29:07,332-Speed 365.46 samples/sec   Loss 0.0020 Epoch: 27   Global Step: 78200   Required: 4 hours
Training: 2025-08-31 13:29:24,849-Speed 365.37 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 78250   Required: 4 hours
Training: 2025-08-31 13:29:42,359-Speed 365.50 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 78300   Required: 4 hours
Training: 2025-08-31 13:29:59,872-Speed 365.45 samples/sec   Loss 0.0009 Epoch: 27   Global Step: 78350   Required: 4 hours
Training: 2025-08-31 13:30:17,391-Speed 365.32 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 78400   Required: 4 hours
Training: 2025-08-31 13:30:34,909-Speed 365.34 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 78450   Required: 4 hours
Training: 2025-08-31 13:30:52,424-Speed 365.40 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 78500   Required: 4 hours
Training: 2025-08-31 13:31:09,924-Speed 365.71 samples/sec   Loss 0.0015 Epoch: 27   Global Step: 78550   Required: 4 hours
Training: 2025-08-31 13:31:27,440-Speed 365.39 samples/sec   Loss 0.0013 Epoch: 27   Global Step: 78600   Required: 4 hours
Training: 2025-08-31 13:31:44,962-Speed 365.27 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 78650   Required: 4 hours
Training: 2025-08-31 13:32:02,484-Speed 365.25 samples/sec   Loss 0.0014 Epoch: 27   Global Step: 78700   Required: 4 hours
Training: 2025-08-31 13:32:39,507-[lfw][78736]XNorm: 15.243267
Training: 2025-08-31 13:32:39,507-[lfw][78736]Accuracy-Flip: 0.83933+-0.01539
Training: 2025-08-31 13:32:39,507-[lfw][78736]Accuracy-Highest: 0.83933
Training: 2025-08-31 13:33:07,919-[cfp_fp][78736]XNorm: 12.880956
Training: 2025-08-31 13:33:07,919-[cfp_fp][78736]Accuracy-Flip: 0.66043+-0.01395
Training: 2025-08-31 13:33:07,919-[cfp_fp][78736]Accuracy-Highest: 0.66386
Training: 2025-08-31 13:33:32,310-[agedb_30][78736]XNorm: 14.537649
Training: 2025-08-31 13:33:32,310-[agedb_30][78736]Accuracy-Flip: 0.54467+-0.01809
Training: 2025-08-31 13:33:32,310-[agedb_30][78736]Accuracy-Highest: 0.56500
Training: 2025-08-31 13:33:56,756-[calfw][78736]XNorm: 15.724867
Training: 2025-08-31 13:33:56,756-[calfw][78736]Accuracy-Flip: 0.69083+-0.01906
Training: 2025-08-31 13:33:56,756-[calfw][78736]Accuracy-Highest: 0.69200
Training: 2025-08-31 13:34:21,189-[cplfw][78736]XNorm: 11.797658
Training: 2025-08-31 13:34:21,189-[cplfw][78736]Accuracy-Flip: 0.64167+-0.01472
Training: 2025-08-31 13:34:21,189-[cplfw][78736]Accuracy-Highest: 0.64567
Training: 2025-08-31 13:34:26,286-Speed 44.51 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 78750   Required: 4 hours
Training: 2025-08-31 13:34:43,784-Speed 365.76 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 78800   Required: 4 hours
Training: 2025-08-31 13:35:01,287-Speed 365.64 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 78850   Required: 4 hours
Training: 2025-08-31 13:35:18,797-Speed 365.52 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 78900   Required: 4 hours
Training: 2025-08-31 13:35:36,310-Speed 365.44 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 78950   Required: 4 hours
Training: 2025-08-31 13:35:53,825-Speed 365.41 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 79000   Required: 4 hours
Training: 2025-08-31 13:36:11,341-Speed 365.38 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 79050   Required: 4 hours
Training: 2025-08-31 13:36:28,854-Speed 365.44 samples/sec   Loss 0.0008 Epoch: 28   Global Step: 79100   Required: 4 hours
Training: 2025-08-31 13:36:46,371-Speed 365.36 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 79150   Required: 4 hours
Training: 2025-08-31 13:37:03,889-Speed 365.36 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 79200   Required: 4 hours
Training: 2025-08-31 13:37:21,413-Speed 365.21 samples/sec   Loss 0.0008 Epoch: 28   Global Step: 79250   Required: 4 hours
Training: 2025-08-31 13:37:38,934-Speed 365.28 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 79300   Required: 4 hours
Training: 2025-08-31 13:37:56,458-Speed 365.21 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 79350   Required: 4 hours
Training: 2025-08-31 13:38:13,981-Speed 365.23 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 79400   Required: 4 hours
Training: 2025-08-31 13:38:31,504-Speed 365.24 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 79450   Required: 4 hours
Training: 2025-08-31 13:38:49,022-Speed 365.35 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 79500   Required: 4 hours
Training: 2025-08-31 13:39:06,541-Speed 365.31 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 79550   Required: 4 hours
Training: 2025-08-31 13:39:24,063-Speed 365.26 samples/sec   Loss 0.0014 Epoch: 28   Global Step: 79600   Required: 4 hours
Training: 2025-08-31 13:39:41,585-Speed 365.25 samples/sec   Loss 0.0008 Epoch: 28   Global Step: 79650   Required: 4 hours
Training: 2025-08-31 13:39:59,110-Speed 365.21 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 79700   Required: 4 hours
Training: 2025-08-31 13:40:16,638-Speed 365.13 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 79750   Required: 4 hours
Training: 2025-08-31 13:40:34,161-Speed 365.24 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 79800   Required: 4 hours
Training: 2025-08-31 13:40:51,685-Speed 365.20 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 79850   Required: 4 hours
Training: 2025-08-31 13:41:09,215-Speed 365.09 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 79900   Required: 4 hours
Training: 2025-08-31 13:41:26,739-Speed 365.22 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 79950   Required: 4 hours
Training: 2025-08-31 13:41:44,264-Speed 365.20 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 80000   Required: 4 hours
Training: 2025-08-31 13:42:01,794-Speed 365.08 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 80050   Required: 4 hours
Training: 2025-08-31 13:42:19,318-Speed 365.23 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 80100   Required: 4 hours
Training: 2025-08-31 13:42:36,844-Speed 365.18 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 80150   Required: 4 hours
Training: 2025-08-31 13:42:54,363-Speed 365.31 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 80200   Required: 4 hours
Training: 2025-08-31 13:43:11,879-Speed 365.37 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 80250   Required: 4 hours
Training: 2025-08-31 13:43:29,403-Speed 365.24 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 80300   Required: 4 hours
Training: 2025-08-31 13:43:46,927-Speed 365.21 samples/sec   Loss 0.0007 Epoch: 28   Global Step: 80350   Required: 4 hours
Training: 2025-08-31 13:44:04,447-Speed 365.30 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 80400   Required: 4 hours
Training: 2025-08-31 13:44:21,971-Speed 365.20 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 80450   Required: 4 hours
Training: 2025-08-31 13:44:39,491-Speed 365.31 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 80500   Required: 3 hours
Training: 2025-08-31 13:44:57,020-Speed 365.11 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 80550   Required: 3 hours
Training: 2025-08-31 13:45:14,547-Speed 365.14 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 80600   Required: 3 hours
Training: 2025-08-31 13:45:32,080-Speed 365.03 samples/sec   Loss 0.0014 Epoch: 28   Global Step: 80650   Required: 3 hours
Training: 2025-08-31 13:45:49,617-Speed 364.96 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 80700   Required: 3 hours
Training: 2025-08-31 13:46:07,141-Speed 365.21 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 80750   Required: 3 hours
Training: 2025-08-31 13:46:24,666-Speed 365.19 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 80800   Required: 3 hours
Training: 2025-08-31 13:46:42,185-Speed 365.32 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 80850   Required: 3 hours
Training: 2025-08-31 13:46:59,707-Speed 365.26 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 80900   Required: 3 hours
Training: 2025-08-31 13:47:17,230-Speed 365.24 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 80950   Required: 3 hours
Training: 2025-08-31 13:47:34,753-Speed 365.25 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 81000   Required: 3 hours
Training: 2025-08-31 13:47:52,272-Speed 365.31 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 81050   Required: 3 hours
Training: 2025-08-31 13:48:09,792-Speed 365.29 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 81100   Required: 3 hours
Training: 2025-08-31 13:48:27,323-Speed 365.08 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 81150   Required: 3 hours
Training: 2025-08-31 13:48:44,847-Speed 365.22 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 81200   Required: 3 hours
Training: 2025-08-31 13:49:02,373-Speed 365.16 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 81250   Required: 3 hours
Training: 2025-08-31 13:49:19,898-Speed 365.21 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 81300   Required: 3 hours
Training: 2025-08-31 13:49:37,423-Speed 365.18 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 81350   Required: 3 hours
Training: 2025-08-31 13:49:54,946-Speed 365.24 samples/sec   Loss 0.0008 Epoch: 28   Global Step: 81400   Required: 3 hours
Training: 2025-08-31 13:50:12,472-Speed 365.16 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 81450   Required: 3 hours
Training: 2025-08-31 13:50:30,000-Speed 365.15 samples/sec   Loss 0.0008 Epoch: 28   Global Step: 81500   Required: 3 hours
Training: 2025-08-31 13:51:11,193-[lfw][81548]XNorm: 15.238336
Training: 2025-08-31 13:51:11,193-[lfw][81548]Accuracy-Flip: 0.84233+-0.01698
Training: 2025-08-31 13:51:11,193-[lfw][81548]Accuracy-Highest: 0.84233
Training: 2025-08-31 13:51:39,756-[cfp_fp][81548]XNorm: 12.922899
Training: 2025-08-31 13:51:39,756-[cfp_fp][81548]Accuracy-Flip: 0.65929+-0.01473
Training: 2025-08-31 13:51:39,756-[cfp_fp][81548]Accuracy-Highest: 0.66386
Training: 2025-08-31 13:52:04,114-[agedb_30][81548]XNorm: 14.620226
Training: 2025-08-31 13:52:04,114-[agedb_30][81548]Accuracy-Flip: 0.55583+-0.01592
Training: 2025-08-31 13:52:04,114-[agedb_30][81548]Accuracy-Highest: 0.56500
Training: 2025-08-31 13:52:28,556-[calfw][81548]XNorm: 15.795339
Training: 2025-08-31 13:52:28,557-[calfw][81548]Accuracy-Flip: 0.69150+-0.02034
Training: 2025-08-31 13:52:28,557-[calfw][81548]Accuracy-Highest: 0.69200
Training: 2025-08-31 13:52:52,995-[cplfw][81548]XNorm: 11.786160
Training: 2025-08-31 13:52:52,995-[cplfw][81548]Accuracy-Flip: 0.64233+-0.01361
Training: 2025-08-31 13:52:52,995-[cplfw][81548]Accuracy-Highest: 0.64567
Training: 2025-08-31 13:52:53,836-Speed 44.50 samples/sec   Loss 0.0011 Epoch: 29   Global Step: 81550   Required: 3 hours
Training: 2025-08-31 13:53:11,330-Speed 365.83 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 81600   Required: 3 hours
Training: 2025-08-31 13:53:28,825-Speed 365.83 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 81650   Required: 3 hours
Training: 2025-08-31 13:53:46,330-Speed 365.61 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 81700   Required: 3 hours
Training: 2025-08-31 13:54:03,843-Speed 365.45 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 81750   Required: 3 hours
Training: 2025-08-31 13:54:21,359-Speed 365.38 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 81800   Required: 3 hours
Training: 2025-08-31 13:54:38,880-Speed 365.28 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 81850   Required: 3 hours
Training: 2025-08-31 13:54:56,399-Speed 365.32 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 81900   Required: 3 hours
Training: 2025-08-31 13:55:13,918-Speed 365.32 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 81950   Required: 3 hours
Training: 2025-08-31 13:55:31,434-Speed 365.38 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 82000   Required: 3 hours
Training: 2025-08-31 13:55:48,950-Speed 365.39 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 82050   Required: 3 hours
Training: 2025-08-31 13:56:06,472-Speed 365.25 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 82100   Required: 3 hours
Training: 2025-08-31 13:56:23,994-Speed 365.25 samples/sec   Loss 0.0007 Epoch: 29   Global Step: 82150   Required: 3 hours
Training: 2025-08-31 13:56:41,516-Speed 365.27 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 82200   Required: 3 hours
Training: 2025-08-31 13:56:59,036-Speed 365.30 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 82250   Required: 3 hours
Training: 2025-08-31 13:57:16,554-Speed 365.34 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 82300   Required: 3 hours
Training: 2025-08-31 13:57:34,074-Speed 365.30 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 82350   Required: 3 hours
Training: 2025-08-31 13:57:51,592-Speed 365.35 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 82400   Required: 3 hours
Training: 2025-08-31 13:58:09,112-Speed 365.29 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 82450   Required: 3 hours
Training: 2025-08-31 13:58:26,630-Speed 365.35 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 82500   Required: 3 hours
Training: 2025-08-31 13:58:44,147-Speed 365.35 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 82550   Required: 3 hours
Training: 2025-08-31 13:59:01,666-Speed 365.32 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 82600   Required: 3 hours
Training: 2025-08-31 13:59:19,184-Speed 365.34 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 82650   Required: 3 hours
Training: 2025-08-31 13:59:36,700-Speed 365.38 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 82700   Required: 3 hours
Training: 2025-08-31 13:59:54,221-Speed 365.29 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 82750   Required: 3 hours
Training: 2025-08-31 14:00:11,736-Speed 365.40 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 82800   Required: 3 hours
Training: 2025-08-31 14:00:29,252-Speed 365.38 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 82850   Required: 3 hours
Training: 2025-08-31 14:00:46,771-Speed 365.32 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 82900   Required: 3 hours
Training: 2025-08-31 14:01:04,295-Speed 365.21 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 82950   Required: 3 hours
Training: 2025-08-31 14:01:21,816-Speed 365.29 samples/sec   Loss 0.0011 Epoch: 29   Global Step: 83000   Required: 3 hours
Training: 2025-08-31 14:01:39,330-Speed 365.42 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 83050   Required: 3 hours
Training: 2025-08-31 14:01:56,849-Speed 365.31 samples/sec   Loss 0.0011 Epoch: 29   Global Step: 83100   Required: 3 hours
Training: 2025-08-31 14:02:14,378-Speed 365.12 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 83150   Required: 3 hours
Training: 2025-08-31 14:02:31,906-Speed 365.13 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 83200   Required: 3 hours
Training: 2025-08-31 14:02:49,430-Speed 365.21 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 83250   Required: 3 hours
Training: 2025-08-31 14:03:06,959-Speed 365.11 samples/sec   Loss 0.0011 Epoch: 29   Global Step: 83300   Required: 3 hours
Training: 2025-08-31 14:03:24,482-Speed 365.24 samples/sec   Loss 0.0007 Epoch: 29   Global Step: 83350   Required: 3 hours
Training: 2025-08-31 14:03:42,006-Speed 365.21 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 83400   Required: 3 hours
Training: 2025-08-31 14:03:59,534-Speed 365.13 samples/sec   Loss 0.0006 Epoch: 29   Global Step: 83450   Required: 3 hours
Training: 2025-08-31 14:04:17,061-Speed 365.16 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 83500   Required: 3 hours
Training: 2025-08-31 14:04:34,579-Speed 365.34 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 83550   Required: 3 hours
Training: 2025-08-31 14:04:52,097-Speed 365.35 samples/sec   Loss 0.0011 Epoch: 29   Global Step: 83600   Required: 3 hours
Training: 2025-08-31 14:05:09,619-Speed 365.26 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 83650   Required: 3 hours
Training: 2025-08-31 14:05:27,133-Speed 365.42 samples/sec   Loss 0.0018 Epoch: 29   Global Step: 83700   Required: 3 hours
Training: 2025-08-31 14:05:44,648-Speed 365.40 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 83750   Required: 3 hours
Training: 2025-08-31 14:06:02,163-Speed 365.41 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 83800   Required: 3 hours
Training: 2025-08-31 14:06:19,681-Speed 365.33 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 83850   Required: 3 hours
Training: 2025-08-31 14:06:37,195-Speed 365.43 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 83900   Required: 3 hours
Training: 2025-08-31 14:06:54,716-Speed 365.28 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 83950   Required: 3 hours
Training: 2025-08-31 14:07:12,235-Speed 365.32 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 84000   Required: 3 hours
Training: 2025-08-31 14:07:29,752-Speed 365.36 samples/sec   Loss 0.0007 Epoch: 29   Global Step: 84050   Required: 3 hours
Training: 2025-08-31 14:07:47,270-Speed 365.35 samples/sec   Loss 0.0011 Epoch: 29   Global Step: 84100   Required: 3 hours
Training: 2025-08-31 14:08:04,789-Speed 365.32 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 84150   Required: 3 hours
Training: 2025-08-31 14:08:22,317-Speed 365.12 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 84200   Required: 3 hours
Training: 2025-08-31 14:08:39,840-Speed 365.24 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 84250   Required: 3 hours
Training: 2025-08-31 14:08:57,363-Speed 365.24 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 84300   Required: 3 hours
Training: 2025-08-31 14:09:14,885-Speed 365.25 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 84350   Required: 3 hours
Training: 2025-08-31 14:09:42,772-[lfw][84360]XNorm: 15.203032
Training: 2025-08-31 14:09:42,772-[lfw][84360]Accuracy-Flip: 0.83900+-0.01667
Training: 2025-08-31 14:09:42,773-[lfw][84360]Accuracy-Highest: 0.84233
Training: 2025-08-31 14:10:11,082-[cfp_fp][84360]XNorm: 12.823760
Training: 2025-08-31 14:10:11,082-[cfp_fp][84360]Accuracy-Flip: 0.65986+-0.01296
Training: 2025-08-31 14:10:11,082-[cfp_fp][84360]Accuracy-Highest: 0.66386
Training: 2025-08-31 14:10:35,443-[agedb_30][84360]XNorm: 14.533021
Training: 2025-08-31 14:10:35,443-[agedb_30][84360]Accuracy-Flip: 0.54683+-0.01674
Training: 2025-08-31 14:10:35,443-[agedb_30][84360]Accuracy-Highest: 0.56500
Training: 2025-08-31 14:10:59,890-[calfw][84360]XNorm: 15.737676
Training: 2025-08-31 14:10:59,890-[calfw][84360]Accuracy-Flip: 0.69417+-0.02187
Training: 2025-08-31 14:10:59,890-[calfw][84360]Accuracy-Highest: 0.69417
Training: 2025-08-31 14:11:24,324-[cplfw][84360]XNorm: 11.749946
Training: 2025-08-31 14:11:24,325-[cplfw][84360]Accuracy-Flip: 0.64267+-0.01257
Training: 2025-08-31 14:11:24,325-[cplfw][84360]Accuracy-Highest: 0.64567
Training: 2025-08-31 14:11:38,490-Speed 44.57 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 84400   Required: 3 hours
Training: 2025-08-31 14:11:55,990-Speed 365.71 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 84450   Required: 3 hours
Training: 2025-08-31 14:12:13,495-Speed 365.62 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 84500   Required: 3 hours
Training: 2025-08-31 14:12:31,014-Speed 365.32 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 84550   Required: 3 hours
Training: 2025-08-31 14:12:48,528-Speed 365.41 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 84600   Required: 3 hours
Training: 2025-08-31 14:13:06,045-Speed 365.37 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 84650   Required: 3 hours
Training: 2025-08-31 14:13:23,565-Speed 365.30 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 84700   Required: 3 hours
Training: 2025-08-31 14:13:41,087-Speed 365.26 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 84750   Required: 3 hours
Training: 2025-08-31 14:13:58,611-Speed 365.22 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 84800   Required: 3 hours
Training: 2025-08-31 14:14:16,142-Speed 365.06 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 84850   Required: 3 hours
Training: 2025-08-31 14:14:33,669-Speed 365.15 samples/sec   Loss 0.0007 Epoch: 30   Global Step: 84900   Required: 3 hours
Training: 2025-08-31 14:14:51,198-Speed 365.11 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 84950   Required: 3 hours
Training: 2025-08-31 14:15:08,723-Speed 365.20 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 85000   Required: 3 hours
Training: 2025-08-31 14:15:26,247-Speed 365.21 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 85050   Required: 3 hours
Training: 2025-08-31 14:15:43,770-Speed 365.23 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 85100   Required: 3 hours
Training: 2025-08-31 14:16:01,297-Speed 365.15 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 85150   Required: 3 hours
Training: 2025-08-31 14:16:18,820-Speed 365.25 samples/sec   Loss 0.0007 Epoch: 30   Global Step: 85200   Required: 3 hours
Training: 2025-08-31 14:16:36,344-Speed 365.22 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 85250   Required: 3 hours
Training: 2025-08-31 14:16:53,865-Speed 365.28 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 85300   Required: 3 hours
Training: 2025-08-31 14:17:11,383-Speed 365.34 samples/sec   Loss 0.0007 Epoch: 30   Global Step: 85350   Required: 3 hours
Training: 2025-08-31 14:17:28,903-Speed 365.29 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 85400   Required: 3 hours
Training: 2025-08-31 14:17:46,418-Speed 365.40 samples/sec   Loss 0.0007 Epoch: 30   Global Step: 85450   Required: 3 hours
Training: 2025-08-31 14:18:03,937-Speed 365.33 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 85500   Required: 3 hours
Training: 2025-08-31 14:18:21,459-Speed 365.27 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 85550   Required: 3 hours
Training: 2025-08-31 14:18:38,979-Speed 365.28 samples/sec   Loss 0.0007 Epoch: 30   Global Step: 85600   Required: 3 hours
Training: 2025-08-31 14:18:56,498-Speed 365.33 samples/sec   Loss 0.0007 Epoch: 30   Global Step: 85650   Required: 3 hours
Training: 2025-08-31 14:19:14,024-Speed 365.18 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 85700   Required: 3 hours
Training: 2025-08-31 14:19:31,546-Speed 365.26 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 85750   Required: 3 hours
Training: 2025-08-31 14:19:49,071-Speed 365.18 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 85800   Required: 3 hours
Training: 2025-08-31 14:20:06,592-Speed 365.29 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 85850   Required: 3 hours
Training: 2025-08-31 14:20:24,120-Speed 365.13 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 85900   Required: 3 hours
Training: 2025-08-31 14:20:41,648-Speed 365.13 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 85950   Required: 3 hours
Training: 2025-08-31 14:20:59,174-Speed 365.17 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 86000   Required: 3 hours
Training: 2025-08-31 14:21:16,699-Speed 365.20 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 86050   Required: 3 hours
Training: 2025-08-31 14:21:34,221-Speed 365.26 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 86100   Required: 3 hours
Training: 2025-08-31 14:21:51,745-Speed 365.21 samples/sec   Loss 0.0011 Epoch: 30   Global Step: 86150   Required: 3 hours
Training: 2025-08-31 14:22:09,266-Speed 365.26 samples/sec   Loss 0.0007 Epoch: 30   Global Step: 86200   Required: 3 hours
Training: 2025-08-31 14:22:26,788-Speed 365.27 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 86250   Required: 3 hours
Training: 2025-08-31 14:22:44,314-Speed 365.18 samples/sec   Loss 0.0007 Epoch: 30   Global Step: 86300   Required: 3 hours
Training: 2025-08-31 14:23:01,833-Speed 365.31 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 86350   Required: 3 hours
Training: 2025-08-31 14:23:19,350-Speed 365.37 samples/sec   Loss 0.0011 Epoch: 30   Global Step: 86400   Required: 3 hours
Training: 2025-08-31 14:23:36,870-Speed 365.29 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 86450   Required: 3 hours
Training: 2025-08-31 14:23:54,394-Speed 365.22 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 86500   Required: 3 hours
Training: 2025-08-31 14:24:11,917-Speed 365.23 samples/sec   Loss 0.0007 Epoch: 30   Global Step: 86550   Required: 3 hours
Training: 2025-08-31 14:24:29,440-Speed 365.24 samples/sec   Loss 0.0011 Epoch: 30   Global Step: 86600   Required: 3 hours
Training: 2025-08-31 14:24:46,967-Speed 365.16 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 86650   Required: 3 hours
Training: 2025-08-31 14:25:04,491-Speed 365.21 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 86700   Required: 3 hours
Training: 2025-08-31 14:25:22,017-Speed 365.18 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 86750   Required: 3 hours
Training: 2025-08-31 14:25:39,544-Speed 365.15 samples/sec   Loss 0.0007 Epoch: 30   Global Step: 86800   Required: 3 hours
Training: 2025-08-31 14:25:57,070-Speed 365.17 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 86850   Required: 3 hours
Training: 2025-08-31 14:26:14,598-Speed 365.12 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 86900   Required: 3 hours
Training: 2025-08-31 14:26:32,126-Speed 365.15 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 86950   Required: 3 hours
Training: 2025-08-31 14:26:49,651-Speed 365.20 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 87000   Required: 3 hours
Training: 2025-08-31 14:27:07,176-Speed 365.18 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 87050   Required: 3 hours
Training: 2025-08-31 14:27:24,699-Speed 365.24 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 87100   Required: 3 hours
Training: 2025-08-31 14:27:42,225-Speed 365.18 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 87150   Required: 3 hours
Training: 2025-08-31 14:28:14,310-[lfw][87172]XNorm: 15.250459
Training: 2025-08-31 14:28:14,310-[lfw][87172]Accuracy-Flip: 0.84150+-0.01780
Training: 2025-08-31 14:28:14,310-[lfw][87172]Accuracy-Highest: 0.84233
Training: 2025-08-31 14:28:42,691-[cfp_fp][87172]XNorm: 12.893401
Training: 2025-08-31 14:28:42,691-[cfp_fp][87172]Accuracy-Flip: 0.65971+-0.01594
Training: 2025-08-31 14:28:42,691-[cfp_fp][87172]Accuracy-Highest: 0.66386
Training: 2025-08-31 14:29:07,062-[agedb_30][87172]XNorm: 14.528237
Training: 2025-08-31 14:29:07,062-[agedb_30][87172]Accuracy-Flip: 0.55400+-0.01674
Training: 2025-08-31 14:29:07,062-[agedb_30][87172]Accuracy-Highest: 0.56500
Training: 2025-08-31 14:29:31,501-[calfw][87172]XNorm: 15.758868
Training: 2025-08-31 14:29:31,501-[calfw][87172]Accuracy-Flip: 0.69633+-0.02187
Training: 2025-08-31 14:29:31,501-[calfw][87172]Accuracy-Highest: 0.69633
Training: 2025-08-31 14:29:55,942-[cplfw][87172]XNorm: 11.804344
Training: 2025-08-31 14:29:55,942-[cplfw][87172]Accuracy-Flip: 0.64600+-0.01493
Training: 2025-08-31 14:29:55,942-[cplfw][87172]Accuracy-Highest: 0.64600
Training: 2025-08-31 14:30:05,911-Speed 44.54 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 87200   Required: 3 hours
Training: 2025-08-31 14:30:23,413-Speed 365.67 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 87250   Required: 3 hours
Training: 2025-08-31 14:30:40,927-Speed 365.43 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 87300   Required: 3 hours
Training: 2025-08-31 14:30:58,437-Speed 365.51 samples/sec   Loss 0.0014 Epoch: 31   Global Step: 87350   Required: 3 hours
Training: 2025-08-31 14:31:15,952-Speed 365.40 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 87400   Required: 3 hours
Training: 2025-08-31 14:31:33,473-Speed 365.27 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 87450   Required: 3 hours
Training: 2025-08-31 14:31:50,996-Speed 365.24 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 87500   Required: 3 hours
Training: 2025-08-31 14:32:08,517-Speed 365.28 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 87550   Required: 3 hours
Training: 2025-08-31 14:32:26,047-Speed 365.09 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 87600   Required: 3 hours
Training: 2025-08-31 14:32:43,564-Speed 365.35 samples/sec   Loss 0.0011 Epoch: 31   Global Step: 87650   Required: 3 hours
Training: 2025-08-31 14:33:01,084-Speed 365.32 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 87700   Required: 3 hours
Training: 2025-08-31 14:33:18,601-Speed 365.35 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 87750   Required: 3 hours
Training: 2025-08-31 14:33:36,133-Speed 365.06 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 87800   Required: 3 hours
Training: 2025-08-31 14:33:53,658-Speed 365.18 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 87850   Required: 3 hours
Training: 2025-08-31 14:34:11,183-Speed 365.21 samples/sec   Loss 0.0012 Epoch: 31   Global Step: 87900   Required: 3 hours
Training: 2025-08-31 14:34:28,712-Speed 365.10 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 87950   Required: 3 hours
Training: 2025-08-31 14:34:46,241-Speed 365.12 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 88000   Required: 3 hours
Training: 2025-08-31 14:35:03,770-Speed 365.11 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 88050   Required: 3 hours
Training: 2025-08-31 14:35:21,295-Speed 365.20 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 88100   Required: 3 hours
Training: 2025-08-31 14:35:38,819-Speed 365.21 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 88150   Required: 3 hours
Training: 2025-08-31 14:35:56,341-Speed 365.26 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 88200   Required: 3 hours
Training: 2025-08-31 14:36:13,863-Speed 365.26 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 88250   Required: 3 hours
Training: 2025-08-31 14:36:31,390-Speed 365.15 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 88300   Required: 3 hours
Training: 2025-08-31 14:36:48,912-Speed 365.27 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 88350   Required: 3 hours
Training: 2025-08-31 14:37:06,438-Speed 365.16 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 88400   Required: 3 hours
Training: 2025-08-31 14:37:23,967-Speed 365.12 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 88450   Required: 3 hours
Training: 2025-08-31 14:37:41,499-Speed 365.05 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 88500   Required: 3 hours
Training: 2025-08-31 14:37:59,027-Speed 365.13 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 88550   Required: 3 hours
Training: 2025-08-31 14:38:16,557-Speed 365.10 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 88600   Required: 3 hours
Training: 2025-08-31 14:38:34,085-Speed 365.13 samples/sec   Loss 0.0011 Epoch: 31   Global Step: 88650   Required: 3 hours
Training: 2025-08-31 14:38:51,607-Speed 365.25 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 88700   Required: 3 hours
Training: 2025-08-31 14:39:09,128-Speed 365.28 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 88750   Required: 3 hours
Training: 2025-08-31 14:39:26,644-Speed 365.38 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 88800   Required: 3 hours
Training: 2025-08-31 14:39:44,168-Speed 365.21 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 88850   Required: 3 hours
Training: 2025-08-31 14:40:01,685-Speed 365.38 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 88900   Required: 3 hours
Training: 2025-08-31 14:40:19,206-Speed 365.27 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 88950   Required: 3 hours
Training: 2025-08-31 14:40:36,729-Speed 365.24 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 89000   Required: 3 hours
Training: 2025-08-31 14:40:54,253-Speed 365.23 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 89050   Required: 3 hours
Training: 2025-08-31 14:41:11,775-Speed 365.26 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 89100   Required: 3 hours
Training: 2025-08-31 14:41:29,296-Speed 365.28 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 89150   Required: 3 hours
Training: 2025-08-31 14:41:46,821-Speed 365.18 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 89200   Required: 3 hours
Training: 2025-08-31 14:42:04,349-Speed 365.14 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 89250   Required: 3 hours
Training: 2025-08-31 14:42:21,870-Speed 365.28 samples/sec   Loss 0.0013 Epoch: 31   Global Step: 89300   Required: 3 hours
Training: 2025-08-31 14:42:39,392-Speed 365.25 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 89350   Required: 3 hours
Training: 2025-08-31 14:42:56,919-Speed 365.17 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 89400   Required: 3 hours
Training: 2025-08-31 14:43:14,440-Speed 365.28 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 89450   Required: 3 hours
Training: 2025-08-31 14:43:31,959-Speed 365.31 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 89500   Required: 3 hours
Training: 2025-08-31 14:43:49,478-Speed 365.32 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 89550   Required: 3 hours
Training: 2025-08-31 14:44:07,001-Speed 365.25 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 89600   Required: 3 hours
Training: 2025-08-31 14:44:24,521-Speed 365.29 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 89650   Required: 2 hours
Training: 2025-08-31 14:44:42,047-Speed 365.17 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 89700   Required: 2 hours
Training: 2025-08-31 14:44:59,570-Speed 365.24 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 89750   Required: 2 hours
Training: 2025-08-31 14:45:17,089-Speed 365.32 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 89800   Required: 2 hours
Training: 2025-08-31 14:45:34,607-Speed 365.34 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 89850   Required: 2 hours
Training: 2025-08-31 14:45:52,128-Speed 365.27 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 89900   Required: 2 hours
Training: 2025-08-31 14:46:09,646-Speed 365.35 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 89950   Required: 2 hours
Training: 2025-08-31 14:46:45,939-[lfw][89984]XNorm: 15.300652
Training: 2025-08-31 14:46:45,939-[lfw][89984]Accuracy-Flip: 0.83900+-0.01662
Training: 2025-08-31 14:46:45,939-[lfw][89984]Accuracy-Highest: 0.84233
Training: 2025-08-31 14:47:14,429-[cfp_fp][89984]XNorm: 12.927703
Training: 2025-08-31 14:47:14,429-[cfp_fp][89984]Accuracy-Flip: 0.66000+-0.01490
Training: 2025-08-31 14:47:14,429-[cfp_fp][89984]Accuracy-Highest: 0.66386
Training: 2025-08-31 14:47:38,789-[agedb_30][89984]XNorm: 14.744106
Training: 2025-08-31 14:47:38,789-[agedb_30][89984]Accuracy-Flip: 0.55117+-0.01537
Training: 2025-08-31 14:47:38,789-[agedb_30][89984]Accuracy-Highest: 0.56500
Training: 2025-08-31 14:48:03,228-[calfw][89984]XNorm: 15.847191
Training: 2025-08-31 14:48:03,228-[calfw][89984]Accuracy-Flip: 0.69500+-0.02070
Training: 2025-08-31 14:48:03,228-[calfw][89984]Accuracy-Highest: 0.69633
Training: 2025-08-31 14:48:27,664-[cplfw][89984]XNorm: 11.824570
Training: 2025-08-31 14:48:27,664-[cplfw][89984]Accuracy-Flip: 0.64333+-0.01645
Training: 2025-08-31 14:48:27,664-[cplfw][89984]Accuracy-Highest: 0.64600
Training: 2025-08-31 14:48:33,422-Speed 44.51 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 90000   Required: 2 hours
Training: 2025-08-31 14:48:50,925-Speed 365.67 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 90050   Required: 2 hours
Training: 2025-08-31 14:49:08,435-Speed 365.50 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 90100   Required: 2 hours
Training: 2025-08-31 14:49:25,948-Speed 365.45 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 90150   Required: 2 hours
Training: 2025-08-31 14:49:43,466-Speed 365.34 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 90200   Required: 2 hours
Training: 2025-08-31 14:50:00,984-Speed 365.33 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 90250   Required: 2 hours
Training: 2025-08-31 14:50:18,508-Speed 365.22 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 90300   Required: 2 hours
Training: 2025-08-31 14:50:36,039-Speed 365.08 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 90350   Required: 2 hours
Training: 2025-08-31 14:50:53,566-Speed 365.15 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 90400   Required: 2 hours
Training: 2025-08-31 14:51:11,090-Speed 365.21 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 90450   Required: 2 hours
Training: 2025-08-31 14:51:28,617-Speed 365.16 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 90500   Required: 2 hours
Training: 2025-08-31 14:51:46,146-Speed 365.12 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 90550   Required: 2 hours
Training: 2025-08-31 14:52:03,676-Speed 365.09 samples/sec   Loss 0.0010 Epoch: 32   Global Step: 90600   Required: 2 hours
Training: 2025-08-31 14:52:21,205-Speed 365.11 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 90650   Required: 2 hours
Training: 2025-08-31 14:52:38,731-Speed 365.17 samples/sec   Loss 0.0010 Epoch: 32   Global Step: 90700   Required: 2 hours
Training: 2025-08-31 14:52:56,256-Speed 365.19 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 90750   Required: 2 hours
Training: 2025-08-31 14:53:13,788-Speed 365.05 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 90800   Required: 2 hours
Training: 2025-08-31 14:53:31,312-Speed 365.21 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 90850   Required: 2 hours
Training: 2025-08-31 14:53:48,839-Speed 365.15 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 90900   Required: 2 hours
Training: 2025-08-31 14:54:06,367-Speed 365.13 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 90950   Required: 2 hours
Training: 2025-08-31 14:54:23,891-Speed 365.23 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 91000   Required: 2 hours
Training: 2025-08-31 14:54:41,414-Speed 365.24 samples/sec   Loss 0.0010 Epoch: 32   Global Step: 91050   Required: 2 hours
Training: 2025-08-31 14:54:58,941-Speed 365.14 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 91100   Required: 2 hours
Training: 2025-08-31 14:55:16,477-Speed 364.98 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 91150   Required: 2 hours
Training: 2025-08-31 14:55:34,013-Speed 364.95 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 91200   Required: 2 hours
Training: 2025-08-31 14:55:51,541-Speed 365.14 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 91250   Required: 2 hours
Training: 2025-08-31 14:56:09,076-Speed 364.99 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 91300   Required: 2 hours
Training: 2025-08-31 14:56:26,608-Speed 365.04 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 91350   Required: 2 hours
Training: 2025-08-31 14:56:44,139-Speed 365.08 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 91400   Required: 2 hours
Training: 2025-08-31 14:57:01,676-Speed 364.94 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 91450   Required: 2 hours
Training: 2025-08-31 14:57:19,205-Speed 365.09 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 91500   Required: 2 hours
Training: 2025-08-31 14:57:36,738-Speed 365.04 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 91550   Required: 2 hours
Training: 2025-08-31 14:57:54,271-Speed 365.04 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 91600   Required: 2 hours
Training: 2025-08-31 14:58:11,795-Speed 365.20 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 91650   Required: 2 hours
Training: 2025-08-31 14:58:29,322-Speed 365.16 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 91700   Required: 2 hours
Training: 2025-08-31 14:58:46,841-Speed 365.32 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 91750   Required: 2 hours
Training: 2025-08-31 14:59:04,369-Speed 365.13 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 91800   Required: 2 hours
Training: 2025-08-31 14:59:21,898-Speed 365.11 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 91850   Required: 2 hours
Training: 2025-08-31 14:59:39,426-Speed 365.13 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 91900   Required: 2 hours
Training: 2025-08-31 14:59:56,960-Speed 365.01 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 91950   Required: 2 hours
Training: 2025-08-31 15:00:14,488-Speed 365.13 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 92000   Required: 2 hours
Training: 2025-08-31 15:00:32,012-Speed 365.21 samples/sec   Loss 0.0011 Epoch: 32   Global Step: 92050   Required: 2 hours
Training: 2025-08-31 15:00:49,533-Speed 365.28 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 92100   Required: 2 hours
Training: 2025-08-31 15:01:07,059-Speed 365.17 samples/sec   Loss 0.0010 Epoch: 32   Global Step: 92150   Required: 2 hours
Training: 2025-08-31 15:01:24,580-Speed 365.27 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 92200   Required: 2 hours
Training: 2025-08-31 15:01:42,109-Speed 365.13 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 92250   Required: 2 hours
Training: 2025-08-31 15:01:59,625-Speed 365.37 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 92300   Required: 2 hours
Training: 2025-08-31 15:02:17,140-Speed 365.42 samples/sec   Loss 0.0010 Epoch: 32   Global Step: 92350   Required: 2 hours
Training: 2025-08-31 15:02:34,661-Speed 365.27 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 92400   Required: 2 hours
Training: 2025-08-31 15:02:52,176-Speed 365.40 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 92450   Required: 2 hours
Training: 2025-08-31 15:03:09,699-Speed 365.24 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 92500   Required: 2 hours
Training: 2025-08-31 15:03:27,211-Speed 365.45 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 92550   Required: 2 hours
Training: 2025-08-31 15:03:44,732-Speed 365.29 samples/sec   Loss 0.0010 Epoch: 32   Global Step: 92600   Required: 2 hours
Training: 2025-08-31 15:04:02,250-Speed 365.35 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 92650   Required: 2 hours
Training: 2025-08-31 15:04:19,762-Speed 365.45 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 92700   Required: 2 hours
Training: 2025-08-31 15:04:37,277-Speed 365.40 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 92750   Required: 2 hours
Training: 2025-08-31 15:05:17,757-[lfw][92796]XNorm: 15.257931
Training: 2025-08-31 15:05:17,757-[lfw][92796]Accuracy-Flip: 0.84117+-0.01789
Training: 2025-08-31 15:05:17,757-[lfw][92796]Accuracy-Highest: 0.84233
Training: 2025-08-31 15:05:46,181-[cfp_fp][92796]XNorm: 12.919212
Training: 2025-08-31 15:05:46,181-[cfp_fp][92796]Accuracy-Flip: 0.65914+-0.01397
Training: 2025-08-31 15:05:46,181-[cfp_fp][92796]Accuracy-Highest: 0.66386
Training: 2025-08-31 15:06:10,529-[agedb_30][92796]XNorm: 14.604773
Training: 2025-08-31 15:06:10,529-[agedb_30][92796]Accuracy-Flip: 0.55100+-0.01798
Training: 2025-08-31 15:06:10,529-[agedb_30][92796]Accuracy-Highest: 0.56500
Training: 2025-08-31 15:06:34,969-[calfw][92796]XNorm: 15.784941
Training: 2025-08-31 15:06:34,969-[calfw][92796]Accuracy-Flip: 0.69133+-0.02125
Training: 2025-08-31 15:06:34,969-[calfw][92796]Accuracy-Highest: 0.69633
Training: 2025-08-31 15:06:59,402-[cplfw][92796]XNorm: 11.793340
Training: 2025-08-31 15:06:59,402-[cplfw][92796]Accuracy-Flip: 0.64167+-0.01249
Training: 2025-08-31 15:06:59,402-[cplfw][92796]Accuracy-Highest: 0.64600
Training: 2025-08-31 15:07:01,009-Speed 44.53 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 92800   Required: 2 hours
Training: 2025-08-31 15:07:18,509-Speed 365.72 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 92850   Required: 2 hours
Training: 2025-08-31 15:07:36,018-Speed 365.53 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 92900   Required: 2 hours
Training: 2025-08-31 15:07:53,533-Speed 365.41 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 92950   Required: 2 hours
Training: 2025-08-31 15:08:11,052-Speed 365.32 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 93000   Required: 2 hours
Training: 2025-08-31 15:08:28,571-Speed 365.31 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 93050   Required: 2 hours
Training: 2025-08-31 15:08:46,091-Speed 365.31 samples/sec   Loss 0.0010 Epoch: 33   Global Step: 93100   Required: 2 hours
Training: 2025-08-31 15:09:03,617-Speed 365.17 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 93150   Required: 2 hours
Training: 2025-08-31 15:09:21,138-Speed 365.28 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 93200   Required: 2 hours
Training: 2025-08-31 15:09:38,659-Speed 365.28 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 93250   Required: 2 hours
Training: 2025-08-31 15:09:56,182-Speed 365.25 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 93300   Required: 2 hours
Training: 2025-08-31 15:10:13,708-Speed 365.17 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 93350   Required: 2 hours
Training: 2025-08-31 15:10:31,231-Speed 365.23 samples/sec   Loss 0.0010 Epoch: 33   Global Step: 93400   Required: 2 hours
Training: 2025-08-31 15:10:48,756-Speed 365.21 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 93450   Required: 2 hours
Training: 2025-08-31 15:11:06,279-Speed 365.22 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 93500   Required: 2 hours
Training: 2025-08-31 15:11:23,798-Speed 365.32 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 93550   Required: 2 hours
Training: 2025-08-31 15:11:41,321-Speed 365.23 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 93600   Required: 2 hours
Training: 2025-08-31 15:11:58,843-Speed 365.27 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 93650   Required: 2 hours
Training: 2025-08-31 15:12:16,366-Speed 365.24 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 93700   Required: 2 hours
Training: 2025-08-31 15:12:33,886-Speed 365.29 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 93750   Required: 2 hours
Training: 2025-08-31 15:12:51,405-Speed 365.32 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 93800   Required: 2 hours
Training: 2025-08-31 15:13:08,933-Speed 365.14 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 93850   Required: 2 hours
Training: 2025-08-31 15:13:26,455-Speed 365.26 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 93900   Required: 2 hours
Training: 2025-08-31 15:13:43,976-Speed 365.27 samples/sec   Loss 0.0011 Epoch: 33   Global Step: 93950   Required: 2 hours
Training: 2025-08-31 15:14:01,501-Speed 365.20 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 94000   Required: 2 hours
Training: 2025-08-31 15:14:19,023-Speed 365.25 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 94050   Required: 2 hours
Training: 2025-08-31 15:14:36,546-Speed 365.23 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 94100   Required: 2 hours
Training: 2025-08-31 15:14:54,067-Speed 365.27 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 94150   Required: 2 hours
Training: 2025-08-31 15:15:11,593-Speed 365.19 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 94200   Required: 2 hours
Training: 2025-08-31 15:15:29,117-Speed 365.21 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 94250   Required: 2 hours
Training: 2025-08-31 15:15:46,640-Speed 365.25 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 94300   Required: 2 hours
Training: 2025-08-31 15:16:04,163-Speed 365.24 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 94350   Required: 2 hours
Training: 2025-08-31 15:16:21,690-Speed 365.15 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 94400   Required: 2 hours
Training: 2025-08-31 15:16:39,223-Speed 365.02 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 94450   Required: 2 hours
Training: 2025-08-31 15:16:56,748-Speed 365.20 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 94500   Required: 2 hours
Training: 2025-08-31 15:17:14,272-Speed 365.20 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 94550   Required: 2 hours
Training: 2025-08-31 15:17:31,802-Speed 365.10 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 94600   Required: 2 hours
Training: 2025-08-31 15:17:49,330-Speed 365.12 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 94650   Required: 2 hours
Training: 2025-08-31 15:18:06,856-Speed 365.19 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 94700   Required: 2 hours
Training: 2025-08-31 15:18:24,378-Speed 365.25 samples/sec   Loss 0.0010 Epoch: 33   Global Step: 94750   Required: 2 hours
Training: 2025-08-31 15:18:41,896-Speed 365.33 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 94800   Required: 2 hours
Training: 2025-08-31 15:18:59,418-Speed 365.26 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 94850   Required: 2 hours
Training: 2025-08-31 15:19:16,945-Speed 365.16 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 94900   Required: 2 hours
Training: 2025-08-31 15:19:34,472-Speed 365.16 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 94950   Required: 2 hours
Training: 2025-08-31 15:19:52,000-Speed 365.12 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 95000   Required: 2 hours
Training: 2025-08-31 15:20:09,521-Speed 365.28 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 95050   Required: 2 hours
Training: 2025-08-31 15:20:27,046-Speed 365.20 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 95100   Required: 2 hours
Training: 2025-08-31 15:20:44,572-Speed 365.18 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 95150   Required: 2 hours
Training: 2025-08-31 15:21:02,090-Speed 365.33 samples/sec   Loss 0.0010 Epoch: 33   Global Step: 95200   Required: 2 hours
Training: 2025-08-31 15:21:19,615-Speed 365.19 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 95250   Required: 2 hours
Training: 2025-08-31 15:21:37,139-Speed 365.22 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 95300   Required: 2 hours
Training: 2025-08-31 15:21:54,662-Speed 365.24 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 95350   Required: 2 hours
Training: 2025-08-31 15:22:12,189-Speed 365.16 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 95400   Required: 2 hours
Training: 2025-08-31 15:22:29,717-Speed 365.12 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 95450   Required: 2 hours
Training: 2025-08-31 15:22:47,242-Speed 365.20 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 95500   Required: 2 hours
Training: 2025-08-31 15:23:04,765-Speed 365.23 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 95550   Required: 2 hours
Training: 2025-08-31 15:23:22,287-Speed 365.25 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 95600   Required: 2 hours
Training: 2025-08-31 15:23:49,620-[lfw][95608]XNorm: 15.328717
Training: 2025-08-31 15:23:49,620-[lfw][95608]Accuracy-Flip: 0.84183+-0.01961
Training: 2025-08-31 15:23:49,620-[lfw][95608]Accuracy-Highest: 0.84233
Training: 2025-08-31 15:24:18,036-[cfp_fp][95608]XNorm: 12.965217
Training: 2025-08-31 15:24:18,036-[cfp_fp][95608]Accuracy-Flip: 0.66529+-0.01556
Training: 2025-08-31 15:24:18,036-[cfp_fp][95608]Accuracy-Highest: 0.66529
Training: 2025-08-31 15:24:42,446-[agedb_30][95608]XNorm: 14.663470
Training: 2025-08-31 15:24:42,446-[agedb_30][95608]Accuracy-Flip: 0.55650+-0.01722
Training: 2025-08-31 15:24:42,446-[agedb_30][95608]Accuracy-Highest: 0.56500
Training: 2025-08-31 15:25:06,942-[calfw][95608]XNorm: 15.871720
Training: 2025-08-31 15:25:06,942-[calfw][95608]Accuracy-Flip: 0.69417+-0.01832
Training: 2025-08-31 15:25:06,942-[calfw][95608]Accuracy-Highest: 0.69633
Training: 2025-08-31 15:25:31,436-[cplfw][95608]XNorm: 11.859632
Training: 2025-08-31 15:25:31,436-[cplfw][95608]Accuracy-Flip: 0.63950+-0.01551
Training: 2025-08-31 15:25:31,436-[cplfw][95608]Accuracy-Highest: 0.64600
Training: 2025-08-31 15:25:46,396-Speed 44.41 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 95650   Required: 2 hours
Training: 2025-08-31 15:26:03,908-Speed 365.47 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 95700   Required: 2 hours
Training: 2025-08-31 15:26:21,428-Speed 365.29 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 95750   Required: 2 hours
Training: 2025-08-31 15:26:38,947-Speed 365.32 samples/sec   Loss 0.0006 Epoch: 34   Global Step: 95800   Required: 2 hours
Training: 2025-08-31 15:26:56,473-Speed 365.19 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 95850   Required: 2 hours
Training: 2025-08-31 15:27:14,002-Speed 365.11 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 95900   Required: 2 hours
Training: 2025-08-31 15:27:31,531-Speed 365.11 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 95950   Required: 2 hours
Training: 2025-08-31 15:27:49,057-Speed 365.16 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 96000   Required: 2 hours
Training: 2025-08-31 15:28:06,587-Speed 365.10 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 96050   Required: 2 hours
Training: 2025-08-31 15:28:24,115-Speed 365.15 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 96100   Required: 2 hours
Training: 2025-08-31 15:28:41,645-Speed 365.07 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 96150   Required: 2 hours
Training: 2025-08-31 15:28:59,176-Speed 365.08 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 96200   Required: 2 hours
Training: 2025-08-31 15:29:16,708-Speed 365.05 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 96250   Required: 2 hours
Training: 2025-08-31 15:29:34,243-Speed 364.98 samples/sec   Loss 0.0006 Epoch: 34   Global Step: 96300   Required: 2 hours
Training: 2025-08-31 15:29:51,769-Speed 365.17 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 96350   Required: 2 hours
Training: 2025-08-31 15:30:09,291-Speed 365.27 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 96400   Required: 2 hours
Training: 2025-08-31 15:30:26,815-Speed 365.20 samples/sec   Loss 0.0010 Epoch: 34   Global Step: 96450   Required: 2 hours
Training: 2025-08-31 15:30:44,338-Speed 365.24 samples/sec   Loss 0.0010 Epoch: 34   Global Step: 96500   Required: 2 hours
Training: 2025-08-31 15:31:01,863-Speed 365.20 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 96550   Required: 2 hours
Training: 2025-08-31 15:31:19,393-Speed 365.09 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 96600   Required: 2 hours
Training: 2025-08-31 15:31:36,921-Speed 365.13 samples/sec   Loss 0.0011 Epoch: 34   Global Step: 96650   Required: 2 hours
Training: 2025-08-31 15:31:54,444-Speed 365.24 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 96700   Required: 2 hours
Training: 2025-08-31 15:32:11,970-Speed 365.18 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 96750   Required: 2 hours
Training: 2025-08-31 15:32:29,500-Speed 365.09 samples/sec   Loss 0.0010 Epoch: 34   Global Step: 96800   Required: 2 hours
Training: 2025-08-31 15:32:47,022-Speed 365.24 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 96850   Required: 2 hours
Training: 2025-08-31 15:33:04,552-Speed 365.10 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 96900   Required: 2 hours
Training: 2025-08-31 15:33:22,081-Speed 365.11 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 96950   Required: 2 hours
Training: 2025-08-31 15:33:39,614-Speed 365.04 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 97000   Required: 2 hours
Training: 2025-08-31 15:33:57,144-Speed 365.09 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 97050   Required: 2 hours
Training: 2025-08-31 15:34:14,678-Speed 364.99 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 97100   Required: 2 hours
Training: 2025-08-31 15:34:32,215-Speed 364.96 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 97150   Required: 2 hours
Training: 2025-08-31 15:34:49,750-Speed 364.99 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 97200   Required: 2 hours
Training: 2025-08-31 15:35:07,285-Speed 364.98 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 97250   Required: 2 hours
Training: 2025-08-31 15:35:24,822-Speed 364.94 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 97300   Required: 2 hours
Training: 2025-08-31 15:35:42,361-Speed 364.92 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 97350   Required: 2 hours
Training: 2025-08-31 15:35:59,896-Speed 364.99 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 97400   Required: 2 hours
Training: 2025-08-31 15:36:17,430-Speed 365.01 samples/sec   Loss 0.0010 Epoch: 34   Global Step: 97450   Required: 2 hours
Training: 2025-08-31 15:36:34,961-Speed 365.07 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 97500   Required: 2 hours
Training: 2025-08-31 15:36:52,494-Speed 365.03 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 97550   Required: 2 hours
Training: 2025-08-31 15:37:10,024-Speed 365.09 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 97600   Required: 2 hours
Training: 2025-08-31 15:37:27,555-Speed 365.07 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 97650   Required: 2 hours
Training: 2025-08-31 15:37:45,086-Speed 365.06 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 97700   Required: 2 hours
Training: 2025-08-31 15:38:02,621-Speed 365.00 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 97750   Required: 2 hours
Training: 2025-08-31 15:38:20,158-Speed 364.94 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 97800   Required: 2 hours
Training: 2025-08-31 15:38:37,693-Speed 364.98 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 97850   Required: 2 hours
Training: 2025-08-31 15:38:55,229-Speed 364.97 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 97900   Required: 2 hours
Training: 2025-08-31 15:39:12,761-Speed 365.05 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 97950   Required: 2 hours
Training: 2025-08-31 15:39:30,296-Speed 364.99 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 98000   Required: 2 hours
Training: 2025-08-31 15:39:47,831-Speed 364.98 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 98050   Required: 2 hours
Training: 2025-08-31 15:40:05,376-Speed 364.79 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 98100   Required: 2 hours
Training: 2025-08-31 15:40:22,914-Speed 364.92 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 98150   Required: 2 hours
Training: 2025-08-31 15:40:40,452-Speed 364.93 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 98200   Required: 2 hours
Training: 2025-08-31 15:40:57,992-Speed 364.88 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 98250   Required: 2 hours
Training: 2025-08-31 15:41:15,535-Speed 364.83 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 98300   Required: 2 hours
Training: 2025-08-31 15:41:33,070-Speed 364.98 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 98350   Required: 2 hours
Training: 2025-08-31 15:41:50,607-Speed 364.94 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 98400   Required: 2 hours
Training: 2025-08-31 15:42:22,110-[lfw][98420]XNorm: 15.236147
Training: 2025-08-31 15:42:22,110-[lfw][98420]Accuracy-Flip: 0.84050+-0.01735
Training: 2025-08-31 15:42:22,110-[lfw][98420]Accuracy-Highest: 0.84233
Training: 2025-08-31 15:42:50,475-[cfp_fp][98420]XNorm: 12.868058
Training: 2025-08-31 15:42:50,475-[cfp_fp][98420]Accuracy-Flip: 0.65929+-0.01432
Training: 2025-08-31 15:42:50,475-[cfp_fp][98420]Accuracy-Highest: 0.66529
Training: 2025-08-31 15:43:14,865-[agedb_30][98420]XNorm: 14.581384
Training: 2025-08-31 15:43:14,865-[agedb_30][98420]Accuracy-Flip: 0.54983+-0.01488
Training: 2025-08-31 15:43:14,865-[agedb_30][98420]Accuracy-Highest: 0.56500
Training: 2025-08-31 15:43:39,347-[calfw][98420]XNorm: 15.760062
Training: 2025-08-31 15:43:39,347-[calfw][98420]Accuracy-Flip: 0.69350+-0.02055
Training: 2025-08-31 15:43:39,347-[calfw][98420]Accuracy-Highest: 0.69633
Training: 2025-08-31 15:44:03,808-[cplfw][98420]XNorm: 11.782121
Training: 2025-08-31 15:44:03,808-[cplfw][98420]Accuracy-Flip: 0.63967+-0.01267
Training: 2025-08-31 15:44:03,808-[cplfw][98420]Accuracy-Highest: 0.64600
Training: 2025-08-31 15:44:14,484-Speed 44.48 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 98450   Required: 2 hours
Training: 2025-08-31 15:44:32,010-Speed 365.18 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 98500   Required: 2 hours
Training: 2025-08-31 15:44:49,543-Speed 365.02 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 98550   Required: 2 hours
Training: 2025-08-31 15:45:07,073-Speed 365.09 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 98600   Required: 2 hours
Training: 2025-08-31 15:45:24,606-Speed 365.01 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 98650   Required: 2 hours
Training: 2025-08-31 15:45:42,144-Speed 364.93 samples/sec   Loss 0.0010 Epoch: 35   Global Step: 98700   Required: 2 hours
Training: 2025-08-31 15:45:59,678-Speed 365.01 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 98750   Required: 2 hours
Training: 2025-08-31 15:46:17,211-Speed 365.04 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 98800   Required: 2 hours
Training: 2025-08-31 15:46:34,742-Speed 365.07 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 98850   Required: 1 hours
Training: 2025-08-31 15:46:52,271-Speed 365.10 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 98900   Required: 1 hours
Training: 2025-08-31 15:47:09,802-Speed 365.08 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 98950   Required: 1 hours
Training: 2025-08-31 15:47:27,333-Speed 365.07 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 99000   Required: 1 hours
Training: 2025-08-31 15:47:44,860-Speed 365.15 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 99050   Required: 1 hours
Training: 2025-08-31 15:48:02,388-Speed 365.14 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 99100   Required: 1 hours
Training: 2025-08-31 15:48:19,913-Speed 365.18 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 99150   Required: 1 hours
Training: 2025-08-31 15:48:37,441-Speed 365.14 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 99200   Required: 1 hours
Training: 2025-08-31 15:48:54,970-Speed 365.12 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 99250   Required: 1 hours
Training: 2025-08-31 15:49:12,493-Speed 365.23 samples/sec   Loss 0.0010 Epoch: 35   Global Step: 99300   Required: 1 hours
Training: 2025-08-31 15:49:30,017-Speed 365.22 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 99350   Required: 1 hours
Training: 2025-08-31 15:49:47,541-Speed 365.20 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 99400   Required: 1 hours
Training: 2025-08-31 15:50:05,068-Speed 365.17 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 99450   Required: 1 hours
Training: 2025-08-31 15:50:22,596-Speed 365.13 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 99500   Required: 1 hours
Training: 2025-08-31 15:50:40,123-Speed 365.14 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 99550   Required: 1 hours
Training: 2025-08-31 15:50:57,646-Speed 365.24 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 99600   Required: 1 hours
Training: 2025-08-31 15:51:15,172-Speed 365.18 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 99650   Required: 1 hours
Training: 2025-08-31 15:51:32,702-Speed 365.08 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 99700   Required: 1 hours
Training: 2025-08-31 15:51:50,235-Speed 365.04 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 99750   Required: 1 hours
Training: 2025-08-31 15:52:07,761-Speed 365.16 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 99800   Required: 1 hours
Training: 2025-08-31 15:52:25,291-Speed 365.10 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 99850   Required: 1 hours
Training: 2025-08-31 15:52:42,823-Speed 365.05 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 99900   Required: 1 hours
Training: 2025-08-31 15:53:00,343-Speed 365.31 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 99950   Required: 1 hours
Training: 2025-08-31 15:53:17,868-Speed 365.19 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 100000   Required: 1 hours
Training: 2025-08-31 15:53:35,392-Speed 365.20 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 100050   Required: 1 hours
Training: 2025-08-31 15:53:52,918-Speed 365.18 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 100100   Required: 1 hours
Training: 2025-08-31 15:54:10,441-Speed 365.23 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 100150   Required: 1 hours
Training: 2025-08-31 15:54:27,963-Speed 365.26 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 100200   Required: 1 hours
Training: 2025-08-31 15:54:45,492-Speed 365.11 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 100250   Required: 1 hours
Training: 2025-08-31 15:55:03,022-Speed 365.11 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 100300   Required: 1 hours
Training: 2025-08-31 15:55:20,549-Speed 365.14 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 100350   Required: 1 hours
Training: 2025-08-31 15:55:38,076-Speed 365.17 samples/sec   Loss 0.0010 Epoch: 35   Global Step: 100400   Required: 1 hours
Training: 2025-08-31 15:55:55,603-Speed 365.15 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 100450   Required: 1 hours
Training: 2025-08-31 15:56:13,124-Speed 365.27 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 100500   Required: 1 hours
Training: 2025-08-31 15:56:30,654-Speed 365.09 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 100550   Required: 1 hours
Training: 2025-08-31 15:56:48,183-Speed 365.11 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 100600   Required: 1 hours
Training: 2025-08-31 15:57:05,720-Speed 364.96 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 100650   Required: 1 hours
Training: 2025-08-31 15:57:23,254-Speed 365.00 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 100700   Required: 1 hours
Training: 2025-08-31 15:57:40,789-Speed 364.99 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 100750   Required: 1 hours
Training: 2025-08-31 15:57:58,326-Speed 364.94 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 100800   Required: 1 hours
Training: 2025-08-31 15:58:15,853-Speed 365.16 samples/sec   Loss 0.0006 Epoch: 35   Global Step: 100850   Required: 1 hours
Training: 2025-08-31 15:58:33,383-Speed 365.09 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 100900   Required: 1 hours
Training: 2025-08-31 15:58:50,912-Speed 365.11 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 100950   Required: 1 hours
Training: 2025-08-31 15:59:08,442-Speed 365.10 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 101000   Required: 1 hours
Training: 2025-08-31 15:59:25,973-Speed 365.08 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 101050   Required: 1 hours
Training: 2025-08-31 15:59:43,501-Speed 365.13 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 101100   Required: 1 hours
Training: 2025-08-31 16:00:01,029-Speed 365.13 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 101150   Required: 1 hours
Training: 2025-08-31 16:00:18,552-Speed 365.24 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 101200   Required: 1 hours
Training: 2025-08-31 16:00:54,145-[lfw][101232]XNorm: 15.310761
Training: 2025-08-31 16:00:54,145-[lfw][101232]Accuracy-Flip: 0.84150+-0.01813
Training: 2025-08-31 16:00:54,145-[lfw][101232]Accuracy-Highest: 0.84233
Training: 2025-08-31 16:01:22,519-[cfp_fp][101232]XNorm: 12.911560
Training: 2025-08-31 16:01:22,519-[cfp_fp][101232]Accuracy-Flip: 0.66357+-0.01427
Training: 2025-08-31 16:01:22,519-[cfp_fp][101232]Accuracy-Highest: 0.66529
Training: 2025-08-31 16:01:46,886-[agedb_30][101232]XNorm: 14.658328
Training: 2025-08-31 16:01:46,886-[agedb_30][101232]Accuracy-Flip: 0.55583+-0.01613
Training: 2025-08-31 16:01:46,886-[agedb_30][101232]Accuracy-Highest: 0.56500
Training: 2025-08-31 16:02:11,480-[calfw][101232]XNorm: 15.833709
Training: 2025-08-31 16:02:11,480-[calfw][101232]Accuracy-Flip: 0.68833+-0.01915
Training: 2025-08-31 16:02:11,480-[calfw][101232]Accuracy-Highest: 0.69633
Training: 2025-08-31 16:02:35,932-[cplfw][101232]XNorm: 11.846145
Training: 2025-08-31 16:02:35,932-[cplfw][101232]Accuracy-Flip: 0.64100+-0.01769
Training: 2025-08-31 16:02:35,932-[cplfw][101232]Accuracy-Highest: 0.64600
Training: 2025-08-31 16:02:42,411-Speed 44.49 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 101250   Required: 1 hours
Training: 2025-08-31 16:02:59,923-Speed 365.46 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 101300   Required: 1 hours
Training: 2025-08-31 16:03:17,442-Speed 365.31 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 101350   Required: 1 hours
Training: 2025-08-31 16:03:34,961-Speed 365.32 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 101400   Required: 1 hours
Training: 2025-08-31 16:03:52,489-Speed 365.14 samples/sec   Loss 0.0010 Epoch: 36   Global Step: 101450   Required: 1 hours
Training: 2025-08-31 16:04:10,018-Speed 365.11 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 101500   Required: 1 hours
Training: 2025-08-31 16:04:27,549-Speed 365.06 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 101550   Required: 1 hours
Training: 2025-08-31 16:04:45,086-Speed 364.96 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 101600   Required: 1 hours
Training: 2025-08-31 16:05:02,614-Speed 365.13 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 101650   Required: 1 hours
Training: 2025-08-31 16:05:20,142-Speed 365.13 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 101700   Required: 1 hours
Training: 2025-08-31 16:05:37,679-Speed 364.93 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 101750   Required: 1 hours
Training: 2025-08-31 16:05:55,207-Speed 365.13 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 101800   Required: 1 hours
Training: 2025-08-31 16:06:12,735-Speed 365.14 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 101850   Required: 1 hours
Training: 2025-08-31 16:06:30,267-Speed 365.06 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 101900   Required: 1 hours
Training: 2025-08-31 16:06:47,801-Speed 365.00 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 101950   Required: 1 hours
Training: 2025-08-31 16:07:05,333-Speed 365.05 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 102000   Required: 1 hours
Training: 2025-08-31 16:07:22,869-Speed 364.97 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 102050   Required: 1 hours
Training: 2025-08-31 16:07:40,401-Speed 365.04 samples/sec   Loss 0.0010 Epoch: 36   Global Step: 102100   Required: 1 hours
Training: 2025-08-31 16:07:57,927-Speed 365.17 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 102150   Required: 1 hours
Training: 2025-08-31 16:08:15,458-Speed 365.07 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 102200   Required: 1 hours
Training: 2025-08-31 16:08:32,985-Speed 365.15 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 102250   Required: 1 hours
Training: 2025-08-31 16:08:50,512-Speed 365.15 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 102300   Required: 1 hours
Training: 2025-08-31 16:09:08,039-Speed 365.16 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 102350   Required: 1 hours
Training: 2025-08-31 16:09:25,568-Speed 365.09 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 102400   Required: 1 hours
Training: 2025-08-31 16:09:43,098-Speed 365.09 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 102450   Required: 1 hours
Training: 2025-08-31 16:10:00,636-Speed 364.94 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 102500   Required: 1 hours
Training: 2025-08-31 16:10:18,167-Speed 365.06 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 102550   Required: 1 hours
Training: 2025-08-31 16:10:35,695-Speed 365.13 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 102600   Required: 1 hours
Training: 2025-08-31 16:10:53,222-Speed 365.17 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 102650   Required: 1 hours
Training: 2025-08-31 16:11:10,748-Speed 365.17 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 102700   Required: 1 hours
Training: 2025-08-31 16:11:28,279-Speed 365.06 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 102750   Required: 1 hours
Training: 2025-08-31 16:11:45,809-Speed 365.09 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 102800   Required: 1 hours
Training: 2025-08-31 16:12:03,338-Speed 365.10 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 102850   Required: 1 hours
Training: 2025-08-31 16:12:20,868-Speed 365.10 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 102900   Required: 1 hours
Training: 2025-08-31 16:12:38,392-Speed 365.22 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 102950   Required: 1 hours
Training: 2025-08-31 16:12:55,918-Speed 365.17 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 103000   Required: 1 hours
Training: 2025-08-31 16:13:13,447-Speed 365.11 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 103050   Required: 1 hours
Training: 2025-08-31 16:13:30,976-Speed 365.11 samples/sec   Loss 0.0010 Epoch: 36   Global Step: 103100   Required: 1 hours
Training: 2025-08-31 16:13:48,511-Speed 364.99 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 103150   Required: 1 hours
Training: 2025-08-31 16:14:06,047-Speed 364.98 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 103200   Required: 1 hours
Training: 2025-08-31 16:14:23,578-Speed 365.06 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 103250   Required: 1 hours
Training: 2025-08-31 16:14:41,106-Speed 365.13 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 103300   Required: 1 hours
Training: 2025-08-31 16:14:58,638-Speed 365.06 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 103350   Required: 1 hours
Training: 2025-08-31 16:15:16,169-Speed 365.07 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 103400   Required: 1 hours
Training: 2025-08-31 16:15:33,697-Speed 365.12 samples/sec   Loss 0.0010 Epoch: 36   Global Step: 103450   Required: 1 hours
Training: 2025-08-31 16:15:51,224-Speed 365.16 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 103500   Required: 1 hours
Training: 2025-08-31 16:16:08,754-Speed 365.09 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 103550   Required: 1 hours
Training: 2025-08-31 16:16:26,286-Speed 365.05 samples/sec   Loss 0.0012 Epoch: 36   Global Step: 103600   Required: 1 hours
Training: 2025-08-31 16:16:43,819-Speed 365.03 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 103650   Required: 1 hours
Training: 2025-08-31 16:17:01,356-Speed 364.95 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 103700   Required: 1 hours
Training: 2025-08-31 16:17:18,893-Speed 364.95 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 103750   Required: 1 hours
Training: 2025-08-31 16:17:36,423-Speed 365.09 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 103800   Required: 1 hours
Training: 2025-08-31 16:17:53,954-Speed 365.06 samples/sec   Loss 0.0010 Epoch: 36   Global Step: 103850   Required: 1 hours
Training: 2025-08-31 16:18:11,481-Speed 365.16 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 103900   Required: 1 hours
Training: 2025-08-31 16:18:29,006-Speed 365.19 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 103950   Required: 1 hours
Training: 2025-08-31 16:18:46,530-Speed 365.23 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 104000   Required: 1 hours
Training: 2025-08-31 16:19:26,325-[lfw][104044]XNorm: 15.291569
Training: 2025-08-31 16:19:26,325-[lfw][104044]Accuracy-Flip: 0.84333+-0.01900
Training: 2025-08-31 16:19:26,325-[lfw][104044]Accuracy-Highest: 0.84333
Training: 2025-08-31 16:19:54,661-[cfp_fp][104044]XNorm: 12.893467
Training: 2025-08-31 16:19:54,661-[cfp_fp][104044]Accuracy-Flip: 0.66129+-0.01218
Training: 2025-08-31 16:19:54,661-[cfp_fp][104044]Accuracy-Highest: 0.66529
Training: 2025-08-31 16:20:19,019-[agedb_30][104044]XNorm: 14.595306
Training: 2025-08-31 16:20:19,020-[agedb_30][104044]Accuracy-Flip: 0.55033+-0.01496
Training: 2025-08-31 16:20:19,020-[agedb_30][104044]Accuracy-Highest: 0.56500
Training: 2025-08-31 16:20:43,477-[calfw][104044]XNorm: 15.810169
Training: 2025-08-31 16:20:43,477-[calfw][104044]Accuracy-Flip: 0.69667+-0.02136
Training: 2025-08-31 16:20:43,477-[calfw][104044]Accuracy-Highest: 0.69667
Training: 2025-08-31 16:21:07,925-[cplfw][104044]XNorm: 11.825642
Training: 2025-08-31 16:21:07,925-[cplfw][104044]Accuracy-Flip: 0.64333+-0.01424
Training: 2025-08-31 16:21:07,925-[cplfw][104044]Accuracy-Highest: 0.64600
Training: 2025-08-31 16:21:10,183-Speed 44.55 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 104050   Required: 1 hours
Training: 2025-08-31 16:21:27,694-Speed 365.49 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 104100   Required: 1 hours
Training: 2025-08-31 16:21:45,218-Speed 365.21 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 104150   Required: 1 hours
Training: 2025-08-31 16:22:02,742-Speed 365.22 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 104200   Required: 1 hours
Training: 2025-08-31 16:22:20,270-Speed 365.12 samples/sec   Loss 0.0006 Epoch: 37   Global Step: 104250   Required: 1 hours
Training: 2025-08-31 16:22:37,795-Speed 365.20 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 104300   Required: 1 hours
Training: 2025-08-31 16:22:55,321-Speed 365.18 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 104350   Required: 1 hours
Training: 2025-08-31 16:23:12,843-Speed 365.25 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 104400   Required: 1 hours
Training: 2025-08-31 16:23:30,368-Speed 365.20 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 104450   Required: 1 hours
Training: 2025-08-31 16:23:47,897-Speed 365.10 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 104500   Required: 1 hours
Training: 2025-08-31 16:24:05,425-Speed 365.13 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 104550   Required: 1 hours
Training: 2025-08-31 16:24:22,954-Speed 365.13 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 104600   Required: 1 hours
Training: 2025-08-31 16:24:40,490-Speed 364.97 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 104650   Required: 1 hours
Training: 2025-08-31 16:24:58,022-Speed 365.05 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 104700   Required: 1 hours
Training: 2025-08-31 16:25:15,552-Speed 365.09 samples/sec   Loss 0.0010 Epoch: 37   Global Step: 104750   Required: 1 hours
Training: 2025-08-31 16:25:33,082-Speed 365.10 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 104800   Required: 1 hours
Training: 2025-08-31 16:25:50,606-Speed 365.21 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 104850   Required: 1 hours
Training: 2025-08-31 16:26:08,138-Speed 365.04 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 104900   Required: 1 hours
Training: 2025-08-31 16:26:25,663-Speed 365.20 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 104950   Required: 1 hours
Training: 2025-08-31 16:26:43,194-Speed 365.08 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 105000   Required: 1 hours
Training: 2025-08-31 16:27:00,730-Speed 364.96 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 105050   Required: 1 hours
Training: 2025-08-31 16:27:18,258-Speed 365.12 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 105100   Required: 1 hours
Training: 2025-08-31 16:27:35,790-Speed 365.07 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 105150   Required: 1 hours
Training: 2025-08-31 16:27:53,318-Speed 365.12 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 105200   Required: 1 hours
Training: 2025-08-31 16:28:10,844-Speed 365.17 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 105250   Required: 1 hours
Training: 2025-08-31 16:28:28,375-Speed 365.07 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 105300   Required: 1 hours
Training: 2025-08-31 16:28:45,908-Speed 365.02 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 105350   Required: 1 hours
Training: 2025-08-31 16:29:03,438-Speed 365.10 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 105400   Required: 1 hours
Training: 2025-08-31 16:29:20,966-Speed 365.13 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 105450   Required: 1 hours
Training: 2025-08-31 16:29:38,487-Speed 365.27 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 105500   Required: 1 hours
Training: 2025-08-31 16:29:56,013-Speed 365.19 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 105550   Required: 1 hours
Training: 2025-08-31 16:30:13,541-Speed 365.12 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 105600   Required: 1 hours
Training: 2025-08-31 16:30:31,065-Speed 365.22 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 105650   Required: 1 hours
Training: 2025-08-31 16:30:48,594-Speed 365.12 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 105700   Required: 1 hours
Training: 2025-08-31 16:31:06,117-Speed 365.22 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 105750   Required: 1 hours
Training: 2025-08-31 16:31:23,643-Speed 365.18 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 105800   Required: 1 hours
Training: 2025-08-31 16:31:41,169-Speed 365.16 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 105850   Required: 1 hours
Training: 2025-08-31 16:31:58,694-Speed 365.21 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 105900   Required: 1 hours
Training: 2025-08-31 16:32:16,219-Speed 365.18 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 105950   Required: 1 hours
Training: 2025-08-31 16:32:33,743-Speed 365.22 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 106000   Required: 1 hours
Training: 2025-08-31 16:32:51,266-Speed 365.24 samples/sec   Loss 0.0016 Epoch: 37   Global Step: 106050   Required: 1 hours
Training: 2025-08-31 16:33:08,791-Speed 365.20 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 106100   Required: 1 hours
Training: 2025-08-31 16:33:26,320-Speed 365.11 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 106150   Required: 1 hours
Training: 2025-08-31 16:33:43,844-Speed 365.22 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 106200   Required: 1 hours
Training: 2025-08-31 16:34:01,369-Speed 365.19 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 106250   Required: 1 hours
Training: 2025-08-31 16:34:18,893-Speed 365.21 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 106300   Required: 1 hours
Training: 2025-08-31 16:34:36,417-Speed 365.22 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 106350   Required: 1 hours
Training: 2025-08-31 16:34:53,943-Speed 365.17 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 106400   Required: 1 hours
Training: 2025-08-31 16:35:11,465-Speed 365.27 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 106450   Required: 1 hours
Training: 2025-08-31 16:35:28,987-Speed 365.24 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 106500   Required: 1 hours
Training: 2025-08-31 16:35:46,511-Speed 365.21 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 106550   Required: 1 hours
Training: 2025-08-31 16:36:04,036-Speed 365.19 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 106600   Required: 1 hours
Training: 2025-08-31 16:36:21,563-Speed 365.17 samples/sec   Loss 0.0006 Epoch: 37   Global Step: 106650   Required: 1 hours
Training: 2025-08-31 16:36:39,083-Speed 365.29 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 106700   Required: 1 hours
Training: 2025-08-31 16:36:56,609-Speed 365.19 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 106750   Required: 1 hours
Training: 2025-08-31 16:37:14,130-Speed 365.27 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 106800   Required: 1 hours
Training: 2025-08-31 16:37:31,652-Speed 365.26 samples/sec   Loss 0.0010 Epoch: 37   Global Step: 106850   Required: 1 hours
Training: 2025-08-31 16:37:58,122-[lfw][106856]XNorm: 15.327071
Training: 2025-08-31 16:37:58,122-[lfw][106856]Accuracy-Flip: 0.84367+-0.01865
Training: 2025-08-31 16:37:58,122-[lfw][106856]Accuracy-Highest: 0.84367
Training: 2025-08-31 16:38:26,474-[cfp_fp][106856]XNorm: 12.970173
Training: 2025-08-31 16:38:26,474-[cfp_fp][106856]Accuracy-Flip: 0.66057+-0.01494
Training: 2025-08-31 16:38:26,474-[cfp_fp][106856]Accuracy-Highest: 0.66529
Training: 2025-08-31 16:38:50,835-[agedb_30][106856]XNorm: 14.667630
Training: 2025-08-31 16:38:50,835-[agedb_30][106856]Accuracy-Flip: 0.55150+-0.01389
Training: 2025-08-31 16:38:50,835-[agedb_30][106856]Accuracy-Highest: 0.56500
Training: 2025-08-31 16:39:15,288-[calfw][106856]XNorm: 15.869481
Training: 2025-08-31 16:39:15,288-[calfw][106856]Accuracy-Flip: 0.69183+-0.01980
Training: 2025-08-31 16:39:15,288-[calfw][106856]Accuracy-Highest: 0.69667
Training: 2025-08-31 16:39:39,716-[cplfw][106856]XNorm: 11.835665
Training: 2025-08-31 16:39:39,716-[cplfw][106856]Accuracy-Flip: 0.64300+-0.01229
Training: 2025-08-31 16:39:39,716-[cplfw][106856]Accuracy-Highest: 0.64600
Training: 2025-08-31 16:39:55,265-Speed 44.56 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 106900   Required: 1 hours
Training: 2025-08-31 16:40:12,761-Speed 365.80 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 106950   Required: 1 hours
Training: 2025-08-31 16:40:30,279-Speed 365.35 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 107000   Required: 1 hours
Training: 2025-08-31 16:40:47,799-Speed 365.30 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 107050   Required: 1 hours
Training: 2025-08-31 16:41:05,321-Speed 365.26 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 107100   Required: 1 hours
Training: 2025-08-31 16:41:22,845-Speed 365.22 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 107150   Required: 1 hours
Training: 2025-08-31 16:41:40,368-Speed 365.22 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 107200   Required: 1 hours
Training: 2025-08-31 16:41:57,897-Speed 365.12 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 107250   Required: 1 hours
Training: 2025-08-31 16:42:15,425-Speed 365.12 samples/sec   Loss 0.0010 Epoch: 38   Global Step: 107300   Required: 1 hours
Training: 2025-08-31 16:42:32,952-Speed 365.15 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 107350   Required: 1 hours
Training: 2025-08-31 16:42:50,470-Speed 365.34 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 107400   Required: 1 hours
Training: 2025-08-31 16:43:08,002-Speed 365.06 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 107450   Required: 1 hours
Training: 2025-08-31 16:43:25,533-Speed 365.07 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 107500   Required: 1 hours
Training: 2025-08-31 16:43:43,065-Speed 365.05 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 107550   Required: 1 hours
Training: 2025-08-31 16:44:00,597-Speed 365.05 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 107600   Required: 1 hours
Training: 2025-08-31 16:44:18,128-Speed 365.07 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 107650   Required: 1 hours
Training: 2025-08-31 16:44:35,655-Speed 365.16 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 107700   Required: 1 hours
Training: 2025-08-31 16:44:53,182-Speed 365.14 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 107750   Required: 1 hours
Training: 2025-08-31 16:45:10,714-Speed 365.04 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 107800   Required: 1 hours
Training: 2025-08-31 16:45:28,242-Speed 365.14 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 107850   Required: 1 hours
Training: 2025-08-31 16:45:45,772-Speed 365.10 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 107900   Required: 1 hours
Training: 2025-08-31 16:46:03,302-Speed 365.08 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 107950   Required: 0 hours
Training: 2025-08-31 16:46:20,838-Speed 364.97 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 108000   Required: 0 hours
Training: 2025-08-31 16:46:38,368-Speed 365.09 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 108050   Required: 0 hours
Training: 2025-08-31 16:46:55,901-Speed 365.03 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 108100   Required: 0 hours
Training: 2025-08-31 16:47:13,435-Speed 365.01 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 108150   Required: 0 hours
Training: 2025-08-31 16:47:30,968-Speed 365.02 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 108200   Required: 0 hours
Training: 2025-08-31 16:47:48,494-Speed 365.17 samples/sec   Loss 0.0011 Epoch: 38   Global Step: 108250   Required: 0 hours
Training: 2025-08-31 16:48:06,019-Speed 365.19 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 108300   Required: 0 hours
Training: 2025-08-31 16:48:23,543-Speed 365.23 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 108350   Required: 0 hours
Training: 2025-08-31 16:48:41,067-Speed 365.20 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 108400   Required: 0 hours
Training: 2025-08-31 16:48:58,587-Speed 365.30 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 108450   Required: 0 hours
Training: 2025-08-31 16:49:16,111-Speed 365.22 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 108500   Required: 0 hours
Training: 2025-08-31 16:49:33,634-Speed 365.24 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 108550   Required: 0 hours
Training: 2025-08-31 16:49:51,158-Speed 365.22 samples/sec   Loss 0.0006 Epoch: 38   Global Step: 108600   Required: 0 hours
Training: 2025-08-31 16:50:08,676-Speed 365.34 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 108650   Required: 0 hours
Training: 2025-08-31 16:50:26,203-Speed 365.15 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 108700   Required: 0 hours
Training: 2025-08-31 16:50:43,729-Speed 365.17 samples/sec   Loss 0.0006 Epoch: 38   Global Step: 108750   Required: 0 hours
Training: 2025-08-31 16:51:01,259-Speed 365.09 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 108800   Required: 0 hours
Training: 2025-08-31 16:51:18,787-Speed 365.13 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 108850   Required: 0 hours
Training: 2025-08-31 16:51:36,317-Speed 365.10 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 108900   Required: 0 hours
Training: 2025-08-31 16:51:53,848-Speed 365.07 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 108950   Required: 0 hours
Training: 2025-08-31 16:52:11,377-Speed 365.11 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 109000   Required: 0 hours
Training: 2025-08-31 16:52:28,912-Speed 364.98 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 109050   Required: 0 hours
Training: 2025-08-31 16:52:46,445-Speed 365.04 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 109100   Required: 0 hours
Training: 2025-08-31 16:53:03,973-Speed 365.12 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 109150   Required: 0 hours
Training: 2025-08-31 16:53:21,505-Speed 365.05 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 109200   Required: 0 hours
Training: 2025-08-31 16:53:39,044-Speed 364.89 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 109250   Required: 0 hours
Training: 2025-08-31 16:53:56,576-Speed 365.06 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 109300   Required: 0 hours
Training: 2025-08-31 16:54:14,109-Speed 365.04 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 109350   Required: 0 hours
Training: 2025-08-31 16:54:31,634-Speed 365.18 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 109400   Required: 0 hours
Training: 2025-08-31 16:54:49,163-Speed 365.11 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 109450   Required: 0 hours
Training: 2025-08-31 16:55:06,690-Speed 365.16 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 109500   Required: 0 hours
Training: 2025-08-31 16:55:24,216-Speed 365.18 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 109550   Required: 0 hours
Training: 2025-08-31 16:55:41,741-Speed 365.18 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 109600   Required: 0 hours
Training: 2025-08-31 16:55:59,270-Speed 365.12 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 109650   Required: 0 hours
Training: 2025-08-31 16:56:29,963-[lfw][109668]XNorm: 15.252706
Training: 2025-08-31 16:56:29,963-[lfw][109668]Accuracy-Flip: 0.84483+-0.01608
Training: 2025-08-31 16:56:29,963-[lfw][109668]Accuracy-Highest: 0.84483
Training: 2025-08-31 16:56:58,363-[cfp_fp][109668]XNorm: 12.889482
Training: 2025-08-31 16:56:58,363-[cfp_fp][109668]Accuracy-Flip: 0.66371+-0.01388
Training: 2025-08-31 16:56:58,363-[cfp_fp][109668]Accuracy-Highest: 0.66529
Training: 2025-08-31 16:57:22,743-[agedb_30][109668]XNorm: 14.621365
Training: 2025-08-31 16:57:22,743-[agedb_30][109668]Accuracy-Flip: 0.55350+-0.01676
Training: 2025-08-31 16:57:22,743-[agedb_30][109668]Accuracy-Highest: 0.56500
Training: 2025-08-31 16:57:47,190-[calfw][109668]XNorm: 15.786288
Training: 2025-08-31 16:57:47,190-[calfw][109668]Accuracy-Flip: 0.69450+-0.01997
Training: 2025-08-31 16:57:47,190-[calfw][109668]Accuracy-Highest: 0.69667
Training: 2025-08-31 16:58:11,628-[cplfw][109668]XNorm: 11.790019
Training: 2025-08-31 16:58:11,628-[cplfw][109668]Accuracy-Flip: 0.64467+-0.01621
Training: 2025-08-31 16:58:11,628-[cplfw][109668]Accuracy-Highest: 0.64600
Training: 2025-08-31 16:58:23,022-Speed 44.52 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 109700   Required: 0 hours
Training: 2025-08-31 16:58:40,520-Speed 365.76 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 109750   Required: 0 hours
Training: 2025-08-31 16:58:58,029-Speed 365.54 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 109800   Required: 0 hours
Training: 2025-08-31 16:59:15,547-Speed 365.34 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 109850   Required: 0 hours
Training: 2025-08-31 16:59:33,068-Speed 365.27 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 109900   Required: 0 hours
Training: 2025-08-31 16:59:50,594-Speed 365.18 samples/sec   Loss 0.0006 Epoch: 39   Global Step: 109950   Required: 0 hours
Training: 2025-08-31 17:00:08,119-Speed 365.18 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 110000   Required: 0 hours
Training: 2025-08-31 17:00:25,644-Speed 365.20 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 110050   Required: 0 hours
Training: 2025-08-31 17:00:43,178-Speed 365.01 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 110100   Required: 0 hours
Training: 2025-08-31 17:01:00,700-Speed 365.26 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 110150   Required: 0 hours
Training: 2025-08-31 17:01:18,227-Speed 365.15 samples/sec   Loss 0.0010 Epoch: 39   Global Step: 110200   Required: 0 hours
Training: 2025-08-31 17:01:35,758-Speed 365.07 samples/sec   Loss 0.0010 Epoch: 39   Global Step: 110250   Required: 0 hours
Training: 2025-08-31 17:01:53,282-Speed 365.21 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 110300   Required: 0 hours
Training: 2025-08-31 17:02:10,806-Speed 365.22 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 110350   Required: 0 hours
Training: 2025-08-31 17:02:28,329-Speed 365.23 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 110400   Required: 0 hours
Training: 2025-08-31 17:02:45,858-Speed 365.12 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 110450   Required: 0 hours
Training: 2025-08-31 17:03:03,386-Speed 365.13 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 110500   Required: 0 hours
Training: 2025-08-31 17:03:20,910-Speed 365.21 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 110550   Required: 0 hours
Training: 2025-08-31 17:03:38,441-Speed 365.08 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 110600   Required: 0 hours
Training: 2025-08-31 17:03:55,963-Speed 365.25 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 110650   Required: 0 hours
Training: 2025-08-31 17:04:13,486-Speed 365.25 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 110700   Required: 0 hours
Training: 2025-08-31 17:04:31,009-Speed 365.24 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 110750   Required: 0 hours
Training: 2025-08-31 17:04:48,535-Speed 365.17 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 110800   Required: 0 hours
Training: 2025-08-31 17:05:06,064-Speed 365.12 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 110850   Required: 0 hours
Training: 2025-08-31 17:05:23,585-Speed 365.27 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 110900   Required: 0 hours
Training: 2025-08-31 17:05:41,104-Speed 365.32 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 110950   Required: 0 hours
Training: 2025-08-31 17:05:58,632-Speed 365.13 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 111000   Required: 0 hours
Training: 2025-08-31 17:06:16,154-Speed 365.25 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 111050   Required: 0 hours
Training: 2025-08-31 17:06:33,675-Speed 365.28 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 111100   Required: 0 hours
Training: 2025-08-31 17:06:51,204-Speed 365.11 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 111150   Required: 0 hours
Training: 2025-08-31 17:07:08,739-Speed 364.98 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 111200   Required: 0 hours
Training: 2025-08-31 17:07:26,275-Speed 364.98 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 111250   Required: 0 hours
Training: 2025-08-31 17:07:43,809-Speed 365.00 samples/sec   Loss 0.0010 Epoch: 39   Global Step: 111300   Required: 0 hours
Training: 2025-08-31 17:08:01,339-Speed 365.08 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 111350   Required: 0 hours
Training: 2025-08-31 17:08:18,861-Speed 365.26 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 111400   Required: 0 hours
Training: 2025-08-31 17:08:36,388-Speed 365.15 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 111450   Required: 0 hours
Training: 2025-08-31 17:08:53,912-Speed 365.22 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 111500   Required: 0 hours
Training: 2025-08-31 17:09:11,434-Speed 365.27 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 111550   Required: 0 hours
Training: 2025-08-31 17:09:28,952-Speed 365.35 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 111600   Required: 0 hours
Training: 2025-08-31 17:09:46,468-Speed 365.38 samples/sec   Loss 0.0006 Epoch: 39   Global Step: 111650   Required: 0 hours
Training: 2025-08-31 17:10:03,995-Speed 365.16 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 111700   Required: 0 hours
Training: 2025-08-31 17:10:21,520-Speed 365.18 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 111750   Required: 0 hours
Training: 2025-08-31 17:10:39,046-Speed 365.19 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 111800   Required: 0 hours
Training: 2025-08-31 17:10:56,573-Speed 365.13 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 111850   Required: 0 hours
Training: 2025-08-31 17:11:14,099-Speed 365.19 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 111900   Required: 0 hours
Training: 2025-08-31 17:11:31,625-Speed 365.17 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 111950   Required: 0 hours
Training: 2025-08-31 17:11:49,147-Speed 365.25 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 112000   Required: 0 hours
Training: 2025-08-31 17:12:06,667-Speed 365.30 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 112050   Required: 0 hours
Training: 2025-08-31 17:12:24,190-Speed 365.24 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 112100   Required: 0 hours
Training: 2025-08-31 17:12:41,712-Speed 365.26 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 112150   Required: 0 hours
Training: 2025-08-31 17:12:59,237-Speed 365.20 samples/sec   Loss 0.0013 Epoch: 39   Global Step: 112200   Required: 0 hours
Training: 2025-08-31 17:13:16,760-Speed 365.23 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 112250   Required: 0 hours
Training: 2025-08-31 17:13:34,279-Speed 365.31 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 112300   Required: 0 hours
Training: 2025-08-31 17:13:51,802-Speed 365.25 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 112350   Required: 0 hours
Training: 2025-08-31 17:14:09,320-Speed 365.35 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 112400   Required: 0 hours
Training: 2025-08-31 17:14:26,841-Speed 365.27 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 112450   Required: 0 hours
Training: 2025-08-31 17:15:01,718-[lfw][112480]XNorm: 15.267384
Training: 2025-08-31 17:15:01,718-[lfw][112480]Accuracy-Flip: 0.83783+-0.01773
Training: 2025-08-31 17:15:01,718-[lfw][112480]Accuracy-Highest: 0.84483
Training: 2025-08-31 17:15:30,029-[cfp_fp][112480]XNorm: 12.904244
Training: 2025-08-31 17:15:30,029-[cfp_fp][112480]Accuracy-Flip: 0.66314+-0.01536
Training: 2025-08-31 17:15:30,029-[cfp_fp][112480]Accuracy-Highest: 0.66529
Training: 2025-08-31 17:15:54,394-[agedb_30][112480]XNorm: 14.631985
Training: 2025-08-31 17:15:54,394-[agedb_30][112480]Accuracy-Flip: 0.55500+-0.01588
Training: 2025-08-31 17:15:54,394-[agedb_30][112480]Accuracy-Highest: 0.56500
Training: 2025-08-31 17:16:18,838-[calfw][112480]XNorm: 15.792407
Training: 2025-08-31 17:16:18,838-[calfw][112480]Accuracy-Flip: 0.69217+-0.02182
Training: 2025-08-31 17:16:18,838-[calfw][112480]Accuracy-Highest: 0.69667
Training: 2025-08-31 17:16:43,273-[cplfw][112480]XNorm: 11.809244
Training: 2025-08-31 17:16:43,273-[cplfw][112480]Accuracy-Flip: 0.63750+-0.01430
Training: 2025-08-31 17:16:43,273-[cplfw][112480]Accuracy-Highest: 0.64600
