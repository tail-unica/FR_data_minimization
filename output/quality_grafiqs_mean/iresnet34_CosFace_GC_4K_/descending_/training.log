Training: 2025-08-30 11:44:13,165-rank_id: 0
Training: 2025-08-30 11:44:13,165-Dataset: /data/Synthetic/GAN_Control_class_images/images
Training: 2025-08-30 11:44:13,692-Classes: 4000 synthetic, 0 real - 239945 images - eval: 1874
Training: 2025-08-30 11:44:14,320-Total Step is: 74982
Training: 2025-08-30 11:44:46,136-Reducer buckets have been rebuilt in this iteration.
Training: 2025-08-30 11:44:46,238-Reducer buckets have been rebuilt in this iteration.
Training: 2025-08-30 11:45:20,004-Speed 372.62 samples/sec   Loss 34.2055 Epoch: 0   Global Step: 100   Required: 8 hours
Training: 2025-08-30 11:45:37,245-Speed 371.21 samples/sec   Loss 31.7935 Epoch: 0   Global Step: 150   Required: 8 hours
Training: 2025-08-30 11:45:54,510-Speed 370.70 samples/sec   Loss 30.2741 Epoch: 0   Global Step: 200   Required: 7 hours
Training: 2025-08-30 11:46:11,783-Speed 370.54 samples/sec   Loss 28.7456 Epoch: 0   Global Step: 250   Required: 7 hours
Training: 2025-08-30 11:46:29,067-Speed 370.29 samples/sec   Loss 27.3517 Epoch: 0   Global Step: 300   Required: 7 hours
Training: 2025-08-30 11:46:46,359-Speed 370.10 samples/sec   Loss 26.1470 Epoch: 0   Global Step: 350   Required: 7 hours
Training: 2025-08-30 11:47:03,656-Speed 370.03 samples/sec   Loss 24.9175 Epoch: 0   Global Step: 400   Required: 7 hours
Training: 2025-08-30 11:47:20,954-Speed 369.99 samples/sec   Loss 23.9746 Epoch: 0   Global Step: 450   Required: 7 hours
Training: 2025-08-30 11:47:38,251-Speed 369.99 samples/sec   Loss 22.8681 Epoch: 0   Global Step: 500   Required: 7 hours
Training: 2025-08-30 11:47:55,547-Speed 370.04 samples/sec   Loss 22.0935 Epoch: 0   Global Step: 550   Required: 7 hours
Training: 2025-08-30 11:48:12,842-Speed 370.05 samples/sec   Loss 20.9857 Epoch: 0   Global Step: 600   Required: 7 hours
Training: 2025-08-30 11:48:30,135-Speed 370.09 samples/sec   Loss 20.0771 Epoch: 0   Global Step: 650   Required: 7 hours
Training: 2025-08-30 11:48:47,431-Speed 370.04 samples/sec   Loss 19.4790 Epoch: 0   Global Step: 700   Required: 7 hours
Training: 2025-08-30 11:49:04,727-Speed 370.02 samples/sec   Loss 18.6123 Epoch: 0   Global Step: 750   Required: 7 hours
Training: 2025-08-30 11:49:22,024-Speed 370.02 samples/sec   Loss 17.9197 Epoch: 0   Global Step: 800   Required: 7 hours
Training: 2025-08-30 11:49:39,320-Speed 370.03 samples/sec   Loss 17.2226 Epoch: 0   Global Step: 850   Required: 7 hours
Training: 2025-08-30 11:49:56,613-Speed 370.09 samples/sec   Loss 16.5966 Epoch: 0   Global Step: 900   Required: 7 hours
Training: 2025-08-30 11:50:13,910-Speed 370.03 samples/sec   Loss 16.0275 Epoch: 0   Global Step: 950   Required: 7 hours
Training: 2025-08-30 11:50:31,206-Speed 370.03 samples/sec   Loss 15.4035 Epoch: 0   Global Step: 1000   Required: 7 hours
Training: 2025-08-30 11:50:48,502-Speed 370.03 samples/sec   Loss 14.7155 Epoch: 0   Global Step: 1050   Required: 7 hours
Training: 2025-08-30 11:51:05,801-Speed 369.96 samples/sec   Loss 14.3957 Epoch: 0   Global Step: 1100   Required: 7 hours
Training: 2025-08-30 11:51:23,098-Speed 370.01 samples/sec   Loss 13.8442 Epoch: 0   Global Step: 1150   Required: 7 hours
Training: 2025-08-30 11:51:40,391-Speed 370.10 samples/sec   Loss 13.3587 Epoch: 0   Global Step: 1200   Required: 7 hours
Training: 2025-08-30 11:51:57,678-Speed 370.21 samples/sec   Loss 12.9692 Epoch: 0   Global Step: 1250   Required: 7 hours
Training: 2025-08-30 11:52:14,962-Speed 370.29 samples/sec   Loss 12.4346 Epoch: 0   Global Step: 1300   Required: 7 hours
Training: 2025-08-30 11:52:32,248-Speed 370.26 samples/sec   Loss 12.1589 Epoch: 0   Global Step: 1350   Required: 7 hours
Training: 2025-08-30 11:52:49,531-Speed 370.31 samples/sec   Loss 11.6548 Epoch: 0   Global Step: 1400   Required: 7 hours
Training: 2025-08-30 11:53:06,819-Speed 370.19 samples/sec   Loss 11.4391 Epoch: 0   Global Step: 1450   Required: 7 hours
Training: 2025-08-30 11:53:24,110-Speed 370.14 samples/sec   Loss 11.0320 Epoch: 0   Global Step: 1500   Required: 7 hours
Training: 2025-08-30 11:53:41,395-Speed 370.26 samples/sec   Loss 10.6701 Epoch: 0   Global Step: 1550   Required: 7 hours
Training: 2025-08-30 11:53:58,684-Speed 370.18 samples/sec   Loss 10.4813 Epoch: 0   Global Step: 1600   Required: 7 hours
Training: 2025-08-30 11:54:15,972-Speed 370.21 samples/sec   Loss 10.1379 Epoch: 0   Global Step: 1650   Required: 7 hours
Training: 2025-08-30 11:54:33,256-Speed 370.28 samples/sec   Loss 9.8148 Epoch: 0   Global Step: 1700   Required: 7 hours
Training: 2025-08-30 11:54:50,543-Speed 370.22 samples/sec   Loss 9.4412 Epoch: 0   Global Step: 1750   Required: 7 hours
Training: 2025-08-30 11:55:07,825-Speed 370.32 samples/sec   Loss 9.1744 Epoch: 0   Global Step: 1800   Required: 7 hours
Training: 2025-08-30 11:55:25,109-Speed 370.30 samples/sec   Loss 8.8800 Epoch: 0   Global Step: 1850   Required: 7 hours
Training: 2025-08-30 11:55:57,993-[lfw][1874]XNorm: 22.728986
Training: 2025-08-30 11:55:57,993-[lfw][1874]Accuracy-Flip: 0.76783+-0.01414
Training: 2025-08-30 11:55:57,993-[lfw][1874]Accuracy-Highest: 0.76783
Training: 2025-08-30 11:56:26,296-[cfp_fp][1874]XNorm: 23.376537
Training: 2025-08-30 11:56:26,296-[cfp_fp][1874]Accuracy-Flip: 0.60543+-0.02087
Training: 2025-08-30 11:56:26,296-[cfp_fp][1874]Accuracy-Highest: 0.60543
Training: 2025-08-30 11:56:50,649-[agedb_30][1874]XNorm: 20.094384
Training: 2025-08-30 11:56:50,649-[agedb_30][1874]Accuracy-Flip: 0.49950+-0.00597
Training: 2025-08-30 11:56:50,649-[agedb_30][1874]Accuracy-Highest: 0.49950
Training: 2025-08-30 11:57:15,090-[calfw][1874]XNorm: 22.810944
Training: 2025-08-30 11:57:15,090-[calfw][1874]Accuracy-Flip: 0.61550+-0.01474
Training: 2025-08-30 11:57:15,090-[calfw][1874]Accuracy-Highest: 0.61550
Training: 2025-08-30 11:57:39,521-[cplfw][1874]XNorm: 20.698980
Training: 2025-08-30 11:57:39,521-[cplfw][1874]Accuracy-Flip: 0.60183+-0.01055
Training: 2025-08-30 11:57:39,521-[cplfw][1874]Accuracy-Highest: 0.60183
Training: 2025-08-30 11:57:48,688-Speed 44.57 samples/sec   Loss 8.2767 Epoch: 1   Global Step: 1900   Required: 8 hours
Training: 2025-08-30 11:58:05,965-Speed 370.44 samples/sec   Loss 7.7290 Epoch: 1   Global Step: 1950   Required: 8 hours
Training: 2025-08-30 11:58:23,242-Speed 370.45 samples/sec   Loss 7.5394 Epoch: 1   Global Step: 2000   Required: 8 hours
Training: 2025-08-30 11:58:40,523-Speed 370.34 samples/sec   Loss 7.4438 Epoch: 1   Global Step: 2050   Required: 8 hours
Training: 2025-08-30 11:58:57,806-Speed 370.30 samples/sec   Loss 7.4037 Epoch: 1   Global Step: 2100   Required: 8 hours
Training: 2025-08-30 11:59:15,088-Speed 370.34 samples/sec   Loss 7.3569 Epoch: 1   Global Step: 2150   Required: 8 hours
Training: 2025-08-30 11:59:32,375-Speed 370.22 samples/sec   Loss 6.9983 Epoch: 1   Global Step: 2200   Required: 8 hours
Training: 2025-08-30 11:59:49,661-Speed 370.25 samples/sec   Loss 6.8376 Epoch: 1   Global Step: 2250   Required: 8 hours
Training: 2025-08-30 12:00:06,954-Speed 370.09 samples/sec   Loss 6.8626 Epoch: 1   Global Step: 2300   Required: 8 hours
Training: 2025-08-30 12:00:24,246-Speed 370.11 samples/sec   Loss 6.6278 Epoch: 1   Global Step: 2350   Required: 8 hours
Training: 2025-08-30 12:00:41,541-Speed 370.05 samples/sec   Loss 6.5633 Epoch: 1   Global Step: 2400   Required: 8 hours
Training: 2025-08-30 12:00:58,836-Speed 370.05 samples/sec   Loss 6.3326 Epoch: 1   Global Step: 2450   Required: 8 hours
Training: 2025-08-30 12:01:16,134-Speed 370.00 samples/sec   Loss 6.1647 Epoch: 1   Global Step: 2500   Required: 8 hours
Training: 2025-08-30 12:01:33,432-Speed 369.98 samples/sec   Loss 6.1669 Epoch: 1   Global Step: 2550   Required: 8 hours
Training: 2025-08-30 12:01:50,729-Speed 370.01 samples/sec   Loss 6.0297 Epoch: 1   Global Step: 2600   Required: 8 hours
Training: 2025-08-30 12:02:08,032-Speed 369.88 samples/sec   Loss 5.8831 Epoch: 1   Global Step: 2650   Required: 8 hours
Training: 2025-08-30 12:02:25,331-Speed 369.97 samples/sec   Loss 5.7844 Epoch: 1   Global Step: 2700   Required: 8 hours
Training: 2025-08-30 12:02:42,628-Speed 370.00 samples/sec   Loss 5.6264 Epoch: 1   Global Step: 2750   Required: 8 hours
Training: 2025-08-30 12:02:59,926-Speed 369.98 samples/sec   Loss 5.4509 Epoch: 1   Global Step: 2800   Required: 8 hours
Training: 2025-08-30 12:03:17,223-Speed 370.02 samples/sec   Loss 5.3811 Epoch: 1   Global Step: 2850   Required: 8 hours
Training: 2025-08-30 12:03:34,519-Speed 370.03 samples/sec   Loss 5.2384 Epoch: 1   Global Step: 2900   Required: 8 hours
Training: 2025-08-30 12:03:51,814-Speed 370.06 samples/sec   Loss 5.0818 Epoch: 1   Global Step: 2950   Required: 8 hours
Training: 2025-08-30 12:04:09,104-Speed 370.14 samples/sec   Loss 5.0863 Epoch: 1   Global Step: 3000   Required: 8 hours
Training: 2025-08-30 12:04:26,394-Speed 370.17 samples/sec   Loss 4.9418 Epoch: 1   Global Step: 3050   Required: 8 hours
Training: 2025-08-30 12:04:43,685-Speed 370.14 samples/sec   Loss 4.8964 Epoch: 1   Global Step: 3100   Required: 8 hours
Training: 2025-08-30 12:05:00,971-Speed 370.24 samples/sec   Loss 4.7206 Epoch: 1   Global Step: 3150   Required: 8 hours
Training: 2025-08-30 12:05:18,259-Speed 370.21 samples/sec   Loss 4.5943 Epoch: 1   Global Step: 3200   Required: 8 hours
Training: 2025-08-30 12:05:35,550-Speed 370.13 samples/sec   Loss 4.4853 Epoch: 1   Global Step: 3250   Required: 8 hours
Training: 2025-08-30 12:05:52,836-Speed 370.25 samples/sec   Loss 4.5003 Epoch: 1   Global Step: 3300   Required: 8 hours
Training: 2025-08-30 12:06:10,123-Speed 370.21 samples/sec   Loss 4.4006 Epoch: 1   Global Step: 3350   Required: 8 hours
Training: 2025-08-30 12:06:27,412-Speed 370.19 samples/sec   Loss 4.2494 Epoch: 1   Global Step: 3400   Required: 8 hours
Training: 2025-08-30 12:06:44,697-Speed 370.25 samples/sec   Loss 4.1470 Epoch: 1   Global Step: 3450   Required: 8 hours
Training: 2025-08-30 12:07:01,984-Speed 370.23 samples/sec   Loss 4.0258 Epoch: 1   Global Step: 3500   Required: 8 hours
Training: 2025-08-30 12:07:19,267-Speed 370.30 samples/sec   Loss 4.0638 Epoch: 1   Global Step: 3550   Required: 8 hours
Training: 2025-08-30 12:07:36,554-Speed 370.24 samples/sec   Loss 4.0505 Epoch: 1   Global Step: 3600   Required: 8 hours
Training: 2025-08-30 12:07:53,839-Speed 370.25 samples/sec   Loss 3.8847 Epoch: 1   Global Step: 3650   Required: 8 hours
Training: 2025-08-30 12:08:11,127-Speed 370.22 samples/sec   Loss 3.7882 Epoch: 1   Global Step: 3700   Required: 8 hours
Training: 2025-08-30 12:08:52,078-[lfw][3748]XNorm: 20.738831
Training: 2025-08-30 12:08:52,078-[lfw][3748]Accuracy-Flip: 0.78467+-0.01894
Training: 2025-08-30 12:08:52,078-[lfw][3748]Accuracy-Highest: 0.78467
Training: 2025-08-30 12:09:20,369-[cfp_fp][3748]XNorm: 19.101124
Training: 2025-08-30 12:09:20,369-[cfp_fp][3748]Accuracy-Flip: 0.61986+-0.01761
Training: 2025-08-30 12:09:20,369-[cfp_fp][3748]Accuracy-Highest: 0.61986
Training: 2025-08-30 12:09:44,792-[agedb_30][3748]XNorm: 17.446537
Training: 2025-08-30 12:09:44,792-[agedb_30][3748]Accuracy-Flip: 0.51783+-0.02191
Training: 2025-08-30 12:09:44,792-[agedb_30][3748]Accuracy-Highest: 0.51783
Training: 2025-08-30 12:10:09,203-[calfw][3748]XNorm: 20.730900
Training: 2025-08-30 12:10:09,203-[calfw][3748]Accuracy-Flip: 0.62600+-0.02190
Training: 2025-08-30 12:10:09,203-[calfw][3748]Accuracy-Highest: 0.62600
Training: 2025-08-30 12:10:33,611-[cplfw][3748]XNorm: 18.299623
Training: 2025-08-30 12:10:33,611-[cplfw][3748]Accuracy-Flip: 0.61100+-0.01383
Training: 2025-08-30 12:10:33,611-[cplfw][3748]Accuracy-Highest: 0.61100
Training: 2025-08-30 12:10:34,456-Speed 44.65 samples/sec   Loss 3.8275 Epoch: 2   Global Step: 3750   Required: 8 hours
Training: 2025-08-30 12:10:51,723-Speed 370.66 samples/sec   Loss 3.1017 Epoch: 2   Global Step: 3800   Required: 8 hours
Training: 2025-08-30 12:11:08,994-Speed 370.56 samples/sec   Loss 3.0861 Epoch: 2   Global Step: 3850   Required: 8 hours
Training: 2025-08-30 12:11:26,269-Speed 370.46 samples/sec   Loss 3.0103 Epoch: 2   Global Step: 3900   Required: 8 hours
Training: 2025-08-30 12:11:43,546-Speed 370.45 samples/sec   Loss 2.9938 Epoch: 2   Global Step: 3950   Required: 8 hours
Training: 2025-08-30 12:12:00,826-Speed 370.36 samples/sec   Loss 3.1091 Epoch: 2   Global Step: 4000   Required: 8 hours
Training: 2025-08-30 12:12:18,109-Speed 370.32 samples/sec   Loss 3.0399 Epoch: 2   Global Step: 4050   Required: 8 hours
Training: 2025-08-30 12:12:35,396-Speed 370.22 samples/sec   Loss 3.0487 Epoch: 2   Global Step: 4100   Required: 8 hours
Training: 2025-08-30 12:12:52,680-Speed 370.28 samples/sec   Loss 2.9098 Epoch: 2   Global Step: 4150   Required: 8 hours
Training: 2025-08-30 12:13:09,970-Speed 370.17 samples/sec   Loss 3.0774 Epoch: 2   Global Step: 4200   Required: 8 hours
Training: 2025-08-30 12:13:27,254-Speed 370.29 samples/sec   Loss 2.8943 Epoch: 2   Global Step: 4250   Required: 8 hours
Training: 2025-08-30 12:13:44,532-Speed 370.42 samples/sec   Loss 2.9451 Epoch: 2   Global Step: 4300   Required: 8 hours
Training: 2025-08-30 12:14:01,812-Speed 370.36 samples/sec   Loss 2.9559 Epoch: 2   Global Step: 4350   Required: 8 hours
Training: 2025-08-30 12:14:19,094-Speed 370.33 samples/sec   Loss 2.7790 Epoch: 2   Global Step: 4400   Required: 8 hours
Training: 2025-08-30 12:14:36,378-Speed 370.28 samples/sec   Loss 2.7642 Epoch: 2   Global Step: 4450   Required: 8 hours
Training: 2025-08-30 12:14:53,661-Speed 370.33 samples/sec   Loss 2.6912 Epoch: 2   Global Step: 4500   Required: 8 hours
Training: 2025-08-30 12:15:10,947-Speed 370.23 samples/sec   Loss 2.7063 Epoch: 2   Global Step: 4550   Required: 8 hours
Training: 2025-08-30 12:15:28,230-Speed 370.31 samples/sec   Loss 2.7282 Epoch: 2   Global Step: 4600   Required: 8 hours
Training: 2025-08-30 12:15:45,511-Speed 370.36 samples/sec   Loss 2.6918 Epoch: 2   Global Step: 4650   Required: 8 hours
Training: 2025-08-30 12:16:02,793-Speed 370.32 samples/sec   Loss 2.5023 Epoch: 2   Global Step: 4700   Required: 8 hours
Training: 2025-08-30 12:16:20,074-Speed 370.36 samples/sec   Loss 2.5094 Epoch: 2   Global Step: 4750   Required: 8 hours
Training: 2025-08-30 12:16:37,358-Speed 370.29 samples/sec   Loss 2.5512 Epoch: 2   Global Step: 4800   Required: 8 hours
Training: 2025-08-30 12:16:54,639-Speed 370.34 samples/sec   Loss 2.4954 Epoch: 2   Global Step: 4850   Required: 8 hours
Training: 2025-08-30 12:17:11,924-Speed 370.27 samples/sec   Loss 2.4645 Epoch: 2   Global Step: 4900   Required: 8 hours
Training: 2025-08-30 12:17:29,207-Speed 370.29 samples/sec   Loss 2.4647 Epoch: 2   Global Step: 4950   Required: 8 hours
Training: 2025-08-30 12:17:46,487-Speed 370.38 samples/sec   Loss 2.3464 Epoch: 2   Global Step: 5000   Required: 8 hours
Training: 2025-08-30 12:18:03,767-Speed 370.37 samples/sec   Loss 2.4670 Epoch: 2   Global Step: 5050   Required: 8 hours
Training: 2025-08-30 12:18:21,052-Speed 370.28 samples/sec   Loss 2.4308 Epoch: 2   Global Step: 5100   Required: 8 hours
Training: 2025-08-30 12:18:38,334-Speed 370.33 samples/sec   Loss 2.3140 Epoch: 2   Global Step: 5150   Required: 8 hours
Training: 2025-08-30 12:18:55,614-Speed 370.37 samples/sec   Loss 2.3181 Epoch: 2   Global Step: 5200   Required: 8 hours
Training: 2025-08-30 12:19:12,894-Speed 370.36 samples/sec   Loss 2.3010 Epoch: 2   Global Step: 5250   Required: 8 hours
Training: 2025-08-30 12:19:30,176-Speed 370.33 samples/sec   Loss 2.2167 Epoch: 2   Global Step: 5300   Required: 8 hours
Training: 2025-08-30 12:19:47,461-Speed 370.28 samples/sec   Loss 2.2381 Epoch: 2   Global Step: 5350   Required: 8 hours
Training: 2025-08-30 12:20:04,740-Speed 370.39 samples/sec   Loss 2.1727 Epoch: 2   Global Step: 5400   Required: 8 hours
Training: 2025-08-30 12:20:22,019-Speed 370.39 samples/sec   Loss 2.1740 Epoch: 2   Global Step: 5450   Required: 8 hours
Training: 2025-08-30 12:20:39,302-Speed 370.32 samples/sec   Loss 2.1459 Epoch: 2   Global Step: 5500   Required: 8 hours
Training: 2025-08-30 12:20:56,576-Speed 370.50 samples/sec   Loss 2.1035 Epoch: 2   Global Step: 5550   Required: 8 hours
Training: 2025-08-30 12:21:13,852-Speed 370.45 samples/sec   Loss 2.1079 Epoch: 2   Global Step: 5600   Required: 8 hours
Training: 2025-08-30 12:21:45,774-[lfw][5622]XNorm: 19.946907
Training: 2025-08-30 12:21:45,774-[lfw][5622]Accuracy-Flip: 0.80533+-0.01897
Training: 2025-08-30 12:21:45,774-[lfw][5622]Accuracy-Highest: 0.80533
Training: 2025-08-30 12:22:14,031-[cfp_fp][5622]XNorm: 19.571104
Training: 2025-08-30 12:22:14,031-[cfp_fp][5622]Accuracy-Flip: 0.62729+-0.01396
Training: 2025-08-30 12:22:14,031-[cfp_fp][5622]Accuracy-Highest: 0.62729
Training: 2025-08-30 12:22:38,343-[agedb_30][5622]XNorm: 16.071146
Training: 2025-08-30 12:22:38,343-[agedb_30][5622]Accuracy-Flip: 0.51467+-0.02335
Training: 2025-08-30 12:22:38,343-[agedb_30][5622]Accuracy-Highest: 0.51783
Training: 2025-08-30 12:23:02,747-[calfw][5622]XNorm: 19.819666
Training: 2025-08-30 12:23:02,748-[calfw][5622]Accuracy-Flip: 0.63567+-0.01332
Training: 2025-08-30 12:23:02,748-[calfw][5622]Accuracy-Highest: 0.63567
Training: 2025-08-30 12:23:27,131-[cplfw][5622]XNorm: 17.386549
Training: 2025-08-30 12:23:27,131-[cplfw][5622]Accuracy-Flip: 0.61850+-0.00926
Training: 2025-08-30 12:23:27,131-[cplfw][5622]Accuracy-Highest: 0.61850
Training: 2025-08-30 12:23:36,947-Speed 44.73 samples/sec   Loss 1.8278 Epoch: 3   Global Step: 5650   Required: 8 hours
Training: 2025-08-30 12:23:54,206-Speed 370.82 samples/sec   Loss 1.6290 Epoch: 3   Global Step: 5700   Required: 8 hours
Training: 2025-08-30 12:24:11,472-Speed 370.69 samples/sec   Loss 1.6576 Epoch: 3   Global Step: 5750   Required: 8 hours
Training: 2025-08-30 12:24:28,742-Speed 370.59 samples/sec   Loss 1.7304 Epoch: 3   Global Step: 5800   Required: 8 hours
Training: 2025-08-30 12:24:46,010-Speed 370.63 samples/sec   Loss 1.6680 Epoch: 3   Global Step: 5850   Required: 8 hours
Training: 2025-08-30 12:25:03,281-Speed 370.58 samples/sec   Loss 1.6334 Epoch: 3   Global Step: 5900   Required: 8 hours
Training: 2025-08-30 12:25:20,548-Speed 370.65 samples/sec   Loss 1.6697 Epoch: 3   Global Step: 5950   Required: 8 hours
Training: 2025-08-30 12:25:37,820-Speed 370.54 samples/sec   Loss 1.6881 Epoch: 3   Global Step: 6000   Required: 8 hours
Training: 2025-08-30 12:25:55,095-Speed 370.49 samples/sec   Loss 1.6451 Epoch: 3   Global Step: 6050   Required: 8 hours
Training: 2025-08-30 12:26:12,369-Speed 370.50 samples/sec   Loss 1.7069 Epoch: 3   Global Step: 6100   Required: 8 hours
Training: 2025-08-30 12:26:29,639-Speed 370.59 samples/sec   Loss 1.6812 Epoch: 3   Global Step: 6150   Required: 8 hours
Training: 2025-08-30 12:26:46,912-Speed 370.52 samples/sec   Loss 1.5981 Epoch: 3   Global Step: 6200   Required: 8 hours
Training: 2025-08-30 12:27:04,183-Speed 370.57 samples/sec   Loss 1.6594 Epoch: 3   Global Step: 6250   Required: 8 hours
Training: 2025-08-30 12:27:21,457-Speed 370.49 samples/sec   Loss 1.5331 Epoch: 3   Global Step: 6300   Required: 8 hours
Training: 2025-08-30 12:27:38,732-Speed 370.48 samples/sec   Loss 1.6188 Epoch: 3   Global Step: 6350   Required: 8 hours
Training: 2025-08-30 12:27:56,004-Speed 370.54 samples/sec   Loss 1.6580 Epoch: 3   Global Step: 6400   Required: 8 hours
Training: 2025-08-30 12:28:13,283-Speed 370.41 samples/sec   Loss 1.5746 Epoch: 3   Global Step: 6450   Required: 8 hours
Training: 2025-08-30 12:28:30,560-Speed 370.42 samples/sec   Loss 1.5293 Epoch: 3   Global Step: 6500   Required: 8 hours
Training: 2025-08-30 12:28:47,838-Speed 370.41 samples/sec   Loss 1.5897 Epoch: 3   Global Step: 6550   Required: 8 hours
Training: 2025-08-30 12:29:05,113-Speed 370.48 samples/sec   Loss 1.6569 Epoch: 3   Global Step: 6600   Required: 8 hours
Training: 2025-08-30 12:29:22,393-Speed 370.39 samples/sec   Loss 1.5231 Epoch: 3   Global Step: 6650   Required: 8 hours
Training: 2025-08-30 12:29:39,666-Speed 370.51 samples/sec   Loss 1.5577 Epoch: 3   Global Step: 6700   Required: 8 hours
Training: 2025-08-30 12:29:56,940-Speed 370.51 samples/sec   Loss 1.5059 Epoch: 3   Global Step: 6750   Required: 8 hours
Training: 2025-08-30 12:30:14,215-Speed 370.47 samples/sec   Loss 1.6391 Epoch: 3   Global Step: 6800   Required: 8 hours
Training: 2025-08-30 12:30:31,493-Speed 370.42 samples/sec   Loss 1.5544 Epoch: 3   Global Step: 6850   Required: 8 hours
Training: 2025-08-30 12:30:48,770-Speed 370.42 samples/sec   Loss 1.5427 Epoch: 3   Global Step: 6900   Required: 8 hours
Training: 2025-08-30 12:31:06,042-Speed 370.55 samples/sec   Loss 1.4737 Epoch: 3   Global Step: 6950   Required: 8 hours
Training: 2025-08-30 12:31:23,316-Speed 370.49 samples/sec   Loss 1.4818 Epoch: 3   Global Step: 7000   Required: 8 hours
Training: 2025-08-30 12:31:40,591-Speed 370.49 samples/sec   Loss 1.4575 Epoch: 3   Global Step: 7050   Required: 8 hours
Training: 2025-08-30 12:31:57,865-Speed 370.50 samples/sec   Loss 1.4199 Epoch: 3   Global Step: 7100   Required: 8 hours
Training: 2025-08-30 12:32:15,138-Speed 370.51 samples/sec   Loss 1.4700 Epoch: 3   Global Step: 7150   Required: 8 hours
Training: 2025-08-30 12:32:32,414-Speed 370.48 samples/sec   Loss 1.4121 Epoch: 3   Global Step: 7200   Required: 8 hours
Training: 2025-08-30 12:32:49,690-Speed 370.44 samples/sec   Loss 1.4163 Epoch: 3   Global Step: 7250   Required: 7 hours
Training: 2025-08-30 12:33:06,965-Speed 370.48 samples/sec   Loss 1.4160 Epoch: 3   Global Step: 7300   Required: 7 hours
Training: 2025-08-30 12:33:24,238-Speed 370.54 samples/sec   Loss 1.3875 Epoch: 3   Global Step: 7350   Required: 7 hours
Training: 2025-08-30 12:33:41,515-Speed 370.43 samples/sec   Loss 1.3753 Epoch: 3   Global Step: 7400   Required: 7 hours
Training: 2025-08-30 12:33:58,789-Speed 370.50 samples/sec   Loss 1.3657 Epoch: 3   Global Step: 7450   Required: 7 hours
Training: 2025-08-30 12:34:39,008-[lfw][7496]XNorm: 19.218083
Training: 2025-08-30 12:34:39,008-[lfw][7496]Accuracy-Flip: 0.79067+-0.01670
Training: 2025-08-30 12:34:39,008-[lfw][7496]Accuracy-Highest: 0.80533
Training: 2025-08-30 12:35:07,253-[cfp_fp][7496]XNorm: 17.285962
Training: 2025-08-30 12:35:07,253-[cfp_fp][7496]Accuracy-Flip: 0.62986+-0.02174
Training: 2025-08-30 12:35:07,253-[cfp_fp][7496]Accuracy-Highest: 0.62986
Training: 2025-08-30 12:35:31,555-[agedb_30][7496]XNorm: 16.530662
Training: 2025-08-30 12:35:31,555-[agedb_30][7496]Accuracy-Flip: 0.50850+-0.02546
Training: 2025-08-30 12:35:31,555-[agedb_30][7496]Accuracy-Highest: 0.51783
Training: 2025-08-30 12:35:55,955-[calfw][7496]XNorm: 19.322333
Training: 2025-08-30 12:35:55,955-[calfw][7496]Accuracy-Flip: 0.63767+-0.01193
Training: 2025-08-30 12:35:55,955-[calfw][7496]Accuracy-Highest: 0.63767
Training: 2025-08-30 12:36:20,341-[cplfw][7496]XNorm: 16.557330
Training: 2025-08-30 12:36:20,341-[cplfw][7496]Accuracy-Flip: 0.61700+-0.01673
Training: 2025-08-30 12:36:20,341-[cplfw][7496]Accuracy-Highest: 0.61850
Training: 2025-08-30 12:36:21,879-Speed 44.73 samples/sec   Loss 1.3311 Epoch: 4   Global Step: 7500   Required: 8 hours
Training: 2025-08-30 12:36:39,139-Speed 370.80 samples/sec   Loss 1.1046 Epoch: 4   Global Step: 7550   Required: 8 hours
Training: 2025-08-30 12:36:56,399-Speed 370.81 samples/sec   Loss 1.0987 Epoch: 4   Global Step: 7600   Required: 8 hours
Training: 2025-08-30 12:37:13,663-Speed 370.72 samples/sec   Loss 1.0650 Epoch: 4   Global Step: 7650   Required: 8 hours
Training: 2025-08-30 12:37:30,937-Speed 370.49 samples/sec   Loss 1.1066 Epoch: 4   Global Step: 7700   Required: 8 hours
Training: 2025-08-30 12:37:48,212-Speed 370.48 samples/sec   Loss 1.0715 Epoch: 4   Global Step: 7750   Required: 8 hours
Training: 2025-08-30 12:38:05,485-Speed 370.51 samples/sec   Loss 1.1197 Epoch: 4   Global Step: 7800   Required: 8 hours
Training: 2025-08-30 12:38:22,763-Speed 370.42 samples/sec   Loss 1.0896 Epoch: 4   Global Step: 7850   Required: 8 hours
Training: 2025-08-30 12:38:40,038-Speed 370.49 samples/sec   Loss 1.1238 Epoch: 4   Global Step: 7900   Required: 8 hours
Training: 2025-08-30 12:38:57,316-Speed 370.40 samples/sec   Loss 1.1018 Epoch: 4   Global Step: 7950   Required: 8 hours
Training: 2025-08-30 12:39:14,593-Speed 370.45 samples/sec   Loss 1.1202 Epoch: 4   Global Step: 8000   Required: 8 hours
Training: 2025-08-30 12:39:31,871-Speed 370.40 samples/sec   Loss 1.0898 Epoch: 4   Global Step: 8050   Required: 8 hours
Training: 2025-08-30 12:39:49,150-Speed 370.41 samples/sec   Loss 1.0909 Epoch: 4   Global Step: 8100   Required: 8 hours
Training: 2025-08-30 12:40:06,427-Speed 370.42 samples/sec   Loss 1.1242 Epoch: 4   Global Step: 8150   Required: 8 hours
Training: 2025-08-30 12:40:23,709-Speed 370.34 samples/sec   Loss 1.1585 Epoch: 4   Global Step: 8200   Required: 8 hours
Training: 2025-08-30 12:40:40,980-Speed 370.55 samples/sec   Loss 1.1505 Epoch: 4   Global Step: 8250   Required: 8 hours
Training: 2025-08-30 12:40:58,258-Speed 370.42 samples/sec   Loss 1.1201 Epoch: 4   Global Step: 8300   Required: 8 hours
Training: 2025-08-30 12:41:15,541-Speed 370.32 samples/sec   Loss 1.0870 Epoch: 4   Global Step: 8350   Required: 8 hours
Training: 2025-08-30 12:41:32,829-Speed 370.20 samples/sec   Loss 1.0899 Epoch: 4   Global Step: 8400   Required: 8 hours
Training: 2025-08-30 12:41:50,111-Speed 370.33 samples/sec   Loss 1.0432 Epoch: 4   Global Step: 8450   Required: 7 hours
Training: 2025-08-30 12:42:07,392-Speed 370.35 samples/sec   Loss 1.1406 Epoch: 4   Global Step: 8500   Required: 7 hours
Training: 2025-08-30 12:42:24,677-Speed 370.25 samples/sec   Loss 1.1018 Epoch: 4   Global Step: 8550   Required: 7 hours
Training: 2025-08-30 12:42:41,957-Speed 370.38 samples/sec   Loss 1.1267 Epoch: 4   Global Step: 8600   Required: 7 hours
Training: 2025-08-30 12:42:59,237-Speed 370.36 samples/sec   Loss 1.1024 Epoch: 4   Global Step: 8650   Required: 7 hours
Training: 2025-08-30 12:43:16,519-Speed 370.34 samples/sec   Loss 1.0446 Epoch: 4   Global Step: 8700   Required: 7 hours
Training: 2025-08-30 12:43:33,797-Speed 370.42 samples/sec   Loss 1.0971 Epoch: 4   Global Step: 8750   Required: 7 hours
Training: 2025-08-30 12:43:51,072-Speed 370.47 samples/sec   Loss 1.0931 Epoch: 4   Global Step: 8800   Required: 7 hours
Training: 2025-08-30 12:44:08,348-Speed 370.46 samples/sec   Loss 1.0782 Epoch: 4   Global Step: 8850   Required: 7 hours
Training: 2025-08-30 12:44:25,624-Speed 370.46 samples/sec   Loss 1.0823 Epoch: 4   Global Step: 8900   Required: 7 hours
Training: 2025-08-30 12:44:42,899-Speed 370.49 samples/sec   Loss 1.0988 Epoch: 4   Global Step: 8950   Required: 7 hours
Training: 2025-08-30 12:45:00,173-Speed 370.49 samples/sec   Loss 1.0781 Epoch: 4   Global Step: 9000   Required: 7 hours
Training: 2025-08-30 12:45:17,444-Speed 370.57 samples/sec   Loss 1.0410 Epoch: 4   Global Step: 9050   Required: 7 hours
Training: 2025-08-30 12:45:34,722-Speed 370.43 samples/sec   Loss 0.9881 Epoch: 4   Global Step: 9100   Required: 7 hours
Training: 2025-08-30 12:45:51,999-Speed 370.42 samples/sec   Loss 1.0620 Epoch: 4   Global Step: 9150   Required: 7 hours
Training: 2025-08-30 12:46:09,279-Speed 370.39 samples/sec   Loss 1.1176 Epoch: 4   Global Step: 9200   Required: 7 hours
Training: 2025-08-30 12:46:26,556-Speed 370.42 samples/sec   Loss 1.0654 Epoch: 4   Global Step: 9250   Required: 7 hours
Training: 2025-08-30 12:46:43,836-Speed 370.39 samples/sec   Loss 1.0941 Epoch: 4   Global Step: 9300   Required: 7 hours
Training: 2025-08-30 12:47:01,116-Speed 370.36 samples/sec   Loss 1.0311 Epoch: 4   Global Step: 9350   Required: 7 hours
Training: 2025-08-30 12:47:32,362-[lfw][9370]XNorm: 19.006630
Training: 2025-08-30 12:47:32,362-[lfw][9370]Accuracy-Flip: 0.79600+-0.01216
Training: 2025-08-30 12:47:32,362-[lfw][9370]Accuracy-Highest: 0.80533
Training: 2025-08-30 12:48:00,637-[cfp_fp][9370]XNorm: 17.190393
Training: 2025-08-30 12:48:00,637-[cfp_fp][9370]Accuracy-Flip: 0.63986+-0.01947
Training: 2025-08-30 12:48:00,637-[cfp_fp][9370]Accuracy-Highest: 0.63986
Training: 2025-08-30 12:48:24,959-[agedb_30][9370]XNorm: 16.145928
Training: 2025-08-30 12:48:24,959-[agedb_30][9370]Accuracy-Flip: 0.52967+-0.01748
Training: 2025-08-30 12:48:24,959-[agedb_30][9370]Accuracy-Highest: 0.52967
Training: 2025-08-30 12:48:49,379-[calfw][9370]XNorm: 18.932434
Training: 2025-08-30 12:48:49,379-[calfw][9370]Accuracy-Flip: 0.65483+-0.00982
Training: 2025-08-30 12:48:49,379-[calfw][9370]Accuracy-Highest: 0.65483
Training: 2025-08-30 12:49:13,786-[cplfw][9370]XNorm: 16.330816
Training: 2025-08-30 12:49:13,786-[cplfw][9370]Accuracy-Flip: 0.62467+-0.01701
Training: 2025-08-30 12:49:13,786-[cplfw][9370]Accuracy-Highest: 0.62467
Training: 2025-08-30 12:49:24,325-Speed 44.69 samples/sec   Loss 0.8646 Epoch: 5   Global Step: 9400   Required: 8 hours
Training: 2025-08-30 12:49:41,592-Speed 370.65 samples/sec   Loss 0.7910 Epoch: 5   Global Step: 9450   Required: 8 hours
Training: 2025-08-30 12:49:58,863-Speed 370.56 samples/sec   Loss 0.8128 Epoch: 5   Global Step: 9500   Required: 7 hours
Training: 2025-08-30 12:50:16,139-Speed 370.47 samples/sec   Loss 0.8698 Epoch: 5   Global Step: 9550   Required: 7 hours
Training: 2025-08-30 12:50:33,410-Speed 370.55 samples/sec   Loss 0.8506 Epoch: 5   Global Step: 9600   Required: 7 hours
Training: 2025-08-30 12:50:50,682-Speed 370.56 samples/sec   Loss 0.8275 Epoch: 5   Global Step: 9650   Required: 7 hours
Training: 2025-08-30 12:51:07,961-Speed 370.39 samples/sec   Loss 0.8471 Epoch: 5   Global Step: 9700   Required: 7 hours
Training: 2025-08-30 12:51:25,233-Speed 370.54 samples/sec   Loss 0.8311 Epoch: 5   Global Step: 9750   Required: 7 hours
Training: 2025-08-30 12:51:42,510-Speed 370.45 samples/sec   Loss 0.8571 Epoch: 5   Global Step: 9800   Required: 7 hours
Training: 2025-08-30 12:51:59,789-Speed 370.39 samples/sec   Loss 0.8451 Epoch: 5   Global Step: 9850   Required: 7 hours
Training: 2025-08-30 12:52:17,072-Speed 370.30 samples/sec   Loss 0.8633 Epoch: 5   Global Step: 9900   Required: 7 hours
Training: 2025-08-30 12:52:34,355-Speed 370.30 samples/sec   Loss 0.8774 Epoch: 5   Global Step: 9950   Required: 7 hours
Training: 2025-08-30 12:52:51,635-Speed 370.39 samples/sec   Loss 0.8541 Epoch: 5   Global Step: 10000   Required: 7 hours
Training: 2025-08-30 12:53:08,918-Speed 370.31 samples/sec   Loss 0.8511 Epoch: 5   Global Step: 10050   Required: 7 hours
Training: 2025-08-30 12:53:26,199-Speed 370.34 samples/sec   Loss 0.9151 Epoch: 5   Global Step: 10100   Required: 7 hours
Training: 2025-08-30 12:53:43,479-Speed 370.38 samples/sec   Loss 0.8967 Epoch: 5   Global Step: 10150   Required: 7 hours
Training: 2025-08-30 12:54:00,761-Speed 370.33 samples/sec   Loss 0.8832 Epoch: 5   Global Step: 10200   Required: 7 hours
Training: 2025-08-30 12:54:18,043-Speed 370.33 samples/sec   Loss 0.8655 Epoch: 5   Global Step: 10250   Required: 7 hours
Training: 2025-08-30 12:54:35,324-Speed 370.36 samples/sec   Loss 0.8855 Epoch: 5   Global Step: 10300   Required: 7 hours
Training: 2025-08-30 12:54:52,606-Speed 370.31 samples/sec   Loss 0.8831 Epoch: 5   Global Step: 10350   Required: 7 hours
Training: 2025-08-30 12:55:09,884-Speed 370.42 samples/sec   Loss 0.8997 Epoch: 5   Global Step: 10400   Required: 7 hours
Training: 2025-08-30 12:55:27,168-Speed 370.30 samples/sec   Loss 0.8465 Epoch: 5   Global Step: 10450   Required: 7 hours
Training: 2025-08-30 12:55:44,445-Speed 370.42 samples/sec   Loss 0.8604 Epoch: 5   Global Step: 10500   Required: 7 hours
Training: 2025-08-30 12:56:01,718-Speed 370.52 samples/sec   Loss 0.9194 Epoch: 5   Global Step: 10550   Required: 7 hours
Training: 2025-08-30 12:56:18,998-Speed 370.39 samples/sec   Loss 0.8784 Epoch: 5   Global Step: 10600   Required: 7 hours
Training: 2025-08-30 12:56:36,280-Speed 370.32 samples/sec   Loss 0.8657 Epoch: 5   Global Step: 10650   Required: 7 hours
Training: 2025-08-30 12:56:53,559-Speed 370.40 samples/sec   Loss 0.8838 Epoch: 5   Global Step: 10700   Required: 7 hours
Training: 2025-08-30 12:57:10,836-Speed 370.43 samples/sec   Loss 0.8657 Epoch: 5   Global Step: 10750   Required: 7 hours
Training: 2025-08-30 12:57:28,117-Speed 370.35 samples/sec   Loss 0.8680 Epoch: 5   Global Step: 10800   Required: 7 hours
Training: 2025-08-30 12:57:45,393-Speed 370.46 samples/sec   Loss 0.8909 Epoch: 5   Global Step: 10850   Required: 7 hours
Training: 2025-08-30 12:58:02,668-Speed 370.49 samples/sec   Loss 0.8219 Epoch: 5   Global Step: 10900   Required: 7 hours
Training: 2025-08-30 12:58:19,943-Speed 370.47 samples/sec   Loss 0.8755 Epoch: 5   Global Step: 10950   Required: 7 hours
Training: 2025-08-30 12:58:37,221-Speed 370.41 samples/sec   Loss 0.8838 Epoch: 5   Global Step: 11000   Required: 7 hours
Training: 2025-08-30 12:58:54,494-Speed 370.53 samples/sec   Loss 0.9134 Epoch: 5   Global Step: 11050   Required: 7 hours
Training: 2025-08-30 12:59:11,768-Speed 370.50 samples/sec   Loss 0.8517 Epoch: 5   Global Step: 11100   Required: 7 hours
Training: 2025-08-30 12:59:29,046-Speed 370.42 samples/sec   Loss 0.8423 Epoch: 5   Global Step: 11150   Required: 7 hours
Training: 2025-08-30 12:59:46,321-Speed 370.47 samples/sec   Loss 0.8709 Epoch: 5   Global Step: 11200   Required: 7 hours
Training: 2025-08-30 13:00:25,842-[lfw][11244]XNorm: 18.060739
Training: 2025-08-30 13:00:25,842-[lfw][11244]Accuracy-Flip: 0.81250+-0.01682
Training: 2025-08-30 13:00:25,842-[lfw][11244]Accuracy-Highest: 0.81250
Training: 2025-08-30 13:00:54,106-[cfp_fp][11244]XNorm: 16.778934
Training: 2025-08-30 13:00:54,106-[cfp_fp][11244]Accuracy-Flip: 0.64057+-0.02128
Training: 2025-08-30 13:00:54,106-[cfp_fp][11244]Accuracy-Highest: 0.64057
Training: 2025-08-30 13:01:18,432-[agedb_30][11244]XNorm: 17.218421
Training: 2025-08-30 13:01:18,432-[agedb_30][11244]Accuracy-Flip: 0.53283+-0.01919
Training: 2025-08-30 13:01:18,432-[agedb_30][11244]Accuracy-Highest: 0.53283
Training: 2025-08-30 13:01:42,861-[calfw][11244]XNorm: 18.538920
Training: 2025-08-30 13:01:42,861-[calfw][11244]Accuracy-Flip: 0.64867+-0.01251
Training: 2025-08-30 13:01:42,861-[calfw][11244]Accuracy-Highest: 0.65483
Training: 2025-08-30 13:02:07,274-[cplfw][11244]XNorm: 15.387294
Training: 2025-08-30 13:02:07,274-[cplfw][11244]Accuracy-Flip: 0.62583+-0.01442
Training: 2025-08-30 13:02:07,274-[cplfw][11244]Accuracy-Highest: 0.62583
Training: 2025-08-30 13:02:09,503-Speed 44.70 samples/sec   Loss 0.8904 Epoch: 6   Global Step: 11250   Required: 7 hours
Training: 2025-08-30 13:02:26,772-Speed 370.60 samples/sec   Loss 0.6916 Epoch: 6   Global Step: 11300   Required: 7 hours
Training: 2025-08-30 13:02:44,047-Speed 370.49 samples/sec   Loss 0.6216 Epoch: 6   Global Step: 11350   Required: 7 hours
Training: 2025-08-30 13:03:01,323-Speed 370.45 samples/sec   Loss 0.7002 Epoch: 6   Global Step: 11400   Required: 7 hours
Training: 2025-08-30 13:03:18,603-Speed 370.36 samples/sec   Loss 0.6870 Epoch: 6   Global Step: 11450   Required: 7 hours
Training: 2025-08-30 13:03:35,890-Speed 370.23 samples/sec   Loss 0.7073 Epoch: 6   Global Step: 11500   Required: 7 hours
Training: 2025-08-30 13:03:53,179-Speed 370.18 samples/sec   Loss 0.7017 Epoch: 6   Global Step: 11550   Required: 7 hours
Training: 2025-08-30 13:04:10,471-Speed 370.13 samples/sec   Loss 0.6877 Epoch: 6   Global Step: 11600   Required: 7 hours
Training: 2025-08-30 13:04:27,758-Speed 370.22 samples/sec   Loss 0.7264 Epoch: 6   Global Step: 11650   Required: 7 hours
Training: 2025-08-30 13:04:45,042-Speed 370.27 samples/sec   Loss 0.6927 Epoch: 6   Global Step: 11700   Required: 7 hours
Training: 2025-08-30 13:05:02,328-Speed 370.26 samples/sec   Loss 0.7073 Epoch: 6   Global Step: 11750   Required: 7 hours
Training: 2025-08-30 13:05:19,615-Speed 370.22 samples/sec   Loss 0.6975 Epoch: 6   Global Step: 11800   Required: 7 hours
Training: 2025-08-30 13:05:36,896-Speed 370.36 samples/sec   Loss 0.7231 Epoch: 6   Global Step: 11850   Required: 7 hours
Training: 2025-08-30 13:05:54,180-Speed 370.29 samples/sec   Loss 0.7302 Epoch: 6   Global Step: 11900   Required: 7 hours
Training: 2025-08-30 13:06:11,467-Speed 370.21 samples/sec   Loss 0.7099 Epoch: 6   Global Step: 11950   Required: 7 hours
Training: 2025-08-30 13:06:28,754-Speed 370.24 samples/sec   Loss 0.7402 Epoch: 6   Global Step: 12000   Required: 7 hours
Training: 2025-08-30 13:06:46,041-Speed 370.22 samples/sec   Loss 0.7841 Epoch: 6   Global Step: 12050   Required: 7 hours
Training: 2025-08-30 13:07:03,328-Speed 370.22 samples/sec   Loss 0.7152 Epoch: 6   Global Step: 12100   Required: 7 hours
Training: 2025-08-30 13:07:20,616-Speed 370.21 samples/sec   Loss 0.7858 Epoch: 6   Global Step: 12150   Required: 7 hours
Training: 2025-08-30 13:07:37,898-Speed 370.33 samples/sec   Loss 0.7784 Epoch: 6   Global Step: 12200   Required: 7 hours
Training: 2025-08-30 13:07:55,180-Speed 370.33 samples/sec   Loss 0.7693 Epoch: 6   Global Step: 12250   Required: 7 hours
Training: 2025-08-30 13:08:12,457-Speed 370.42 samples/sec   Loss 0.7370 Epoch: 6   Global Step: 12300   Required: 7 hours
Training: 2025-08-30 13:08:29,735-Speed 370.43 samples/sec   Loss 0.7624 Epoch: 6   Global Step: 12350   Required: 7 hours
Training: 2025-08-30 13:08:47,016-Speed 370.35 samples/sec   Loss 0.7309 Epoch: 6   Global Step: 12400   Required: 7 hours
Training: 2025-08-30 13:09:04,298-Speed 370.33 samples/sec   Loss 0.7166 Epoch: 6   Global Step: 12450   Required: 7 hours
Training: 2025-08-30 13:09:21,582-Speed 370.28 samples/sec   Loss 0.7337 Epoch: 6   Global Step: 12500   Required: 7 hours
Training: 2025-08-30 13:09:38,867-Speed 370.27 samples/sec   Loss 0.7460 Epoch: 6   Global Step: 12550   Required: 7 hours
Training: 2025-08-30 13:09:56,151-Speed 370.28 samples/sec   Loss 0.7554 Epoch: 6   Global Step: 12600   Required: 7 hours
Training: 2025-08-30 13:10:13,432-Speed 370.37 samples/sec   Loss 0.7428 Epoch: 6   Global Step: 12650   Required: 7 hours
Training: 2025-08-30 13:10:30,712-Speed 370.36 samples/sec   Loss 0.7567 Epoch: 6   Global Step: 12700   Required: 7 hours
Training: 2025-08-30 13:10:47,995-Speed 370.32 samples/sec   Loss 0.7281 Epoch: 6   Global Step: 12750   Required: 7 hours
Training: 2025-08-30 13:11:05,277-Speed 370.33 samples/sec   Loss 0.7930 Epoch: 6   Global Step: 12800   Required: 7 hours
Training: 2025-08-30 13:11:22,559-Speed 370.33 samples/sec   Loss 0.7306 Epoch: 6   Global Step: 12850   Required: 7 hours
Training: 2025-08-30 13:11:39,838-Speed 370.38 samples/sec   Loss 0.7665 Epoch: 6   Global Step: 12900   Required: 7 hours
Training: 2025-08-30 13:11:57,116-Speed 370.44 samples/sec   Loss 0.7704 Epoch: 6   Global Step: 12950   Required: 7 hours
Training: 2025-08-30 13:12:14,393-Speed 370.43 samples/sec   Loss 0.7698 Epoch: 6   Global Step: 13000   Required: 7 hours
Training: 2025-08-30 13:12:31,668-Speed 370.48 samples/sec   Loss 0.8042 Epoch: 6   Global Step: 13050   Required: 7 hours
Training: 2025-08-30 13:12:48,947-Speed 370.40 samples/sec   Loss 0.7333 Epoch: 6   Global Step: 13100   Required: 7 hours
Training: 2025-08-30 13:13:19,500-[lfw][13118]XNorm: 18.811472
Training: 2025-08-30 13:13:19,500-[lfw][13118]Accuracy-Flip: 0.80167+-0.00707
Training: 2025-08-30 13:13:19,500-[lfw][13118]Accuracy-Highest: 0.81250
Training: 2025-08-30 13:13:47,750-[cfp_fp][13118]XNorm: 16.967219
Training: 2025-08-30 13:13:47,750-[cfp_fp][13118]Accuracy-Flip: 0.63143+-0.02398
Training: 2025-08-30 13:13:47,750-[cfp_fp][13118]Accuracy-Highest: 0.64057
Training: 2025-08-30 13:14:12,062-[agedb_30][13118]XNorm: 16.020249
Training: 2025-08-30 13:14:12,062-[agedb_30][13118]Accuracy-Flip: 0.54117+-0.01606
Training: 2025-08-30 13:14:12,062-[agedb_30][13118]Accuracy-Highest: 0.54117
Training: 2025-08-30 13:14:36,468-[calfw][13118]XNorm: 19.001890
Training: 2025-08-30 13:14:36,468-[calfw][13118]Accuracy-Flip: 0.64033+-0.01464
Training: 2025-08-30 13:14:36,468-[calfw][13118]Accuracy-Highest: 0.65483
Training: 2025-08-30 13:15:00,868-[cplfw][13118]XNorm: 15.859256
Training: 2025-08-30 13:15:00,868-[cplfw][13118]Accuracy-Flip: 0.62233+-0.01160
Training: 2025-08-30 13:15:00,868-[cplfw][13118]Accuracy-Highest: 0.62583
Training: 2025-08-30 13:15:12,065-Speed 44.72 samples/sec   Loss 0.6319 Epoch: 7   Global Step: 13150   Required: 7 hours
Training: 2025-08-30 13:15:29,329-Speed 370.72 samples/sec   Loss 0.5907 Epoch: 7   Global Step: 13200   Required: 7 hours
Training: 2025-08-30 13:15:46,595-Speed 370.66 samples/sec   Loss 0.5988 Epoch: 7   Global Step: 13250   Required: 7 hours
Training: 2025-08-30 13:16:03,865-Speed 370.59 samples/sec   Loss 0.5998 Epoch: 7   Global Step: 13300   Required: 7 hours
Training: 2025-08-30 13:16:21,140-Speed 370.50 samples/sec   Loss 0.6198 Epoch: 7   Global Step: 13350   Required: 7 hours
Training: 2025-08-30 13:16:38,409-Speed 370.61 samples/sec   Loss 0.6448 Epoch: 7   Global Step: 13400   Required: 7 hours
Training: 2025-08-30 13:16:55,683-Speed 370.49 samples/sec   Loss 0.6550 Epoch: 7   Global Step: 13450   Required: 7 hours
Training: 2025-08-30 13:17:12,960-Speed 370.43 samples/sec   Loss 0.5769 Epoch: 7   Global Step: 13500   Required: 7 hours
Training: 2025-08-30 13:17:30,240-Speed 370.38 samples/sec   Loss 0.6146 Epoch: 7   Global Step: 13550   Required: 7 hours
Training: 2025-08-30 13:17:47,520-Speed 370.37 samples/sec   Loss 0.6203 Epoch: 7   Global Step: 13600   Required: 7 hours
Training: 2025-08-30 13:18:04,799-Speed 370.39 samples/sec   Loss 0.6858 Epoch: 7   Global Step: 13650   Required: 7 hours
Training: 2025-08-30 13:18:22,074-Speed 370.49 samples/sec   Loss 0.6377 Epoch: 7   Global Step: 13700   Required: 7 hours
Training: 2025-08-30 13:18:39,352-Speed 370.40 samples/sec   Loss 0.6325 Epoch: 7   Global Step: 13750   Required: 7 hours
Training: 2025-08-30 13:18:56,636-Speed 370.30 samples/sec   Loss 0.6365 Epoch: 7   Global Step: 13800   Required: 7 hours
Training: 2025-08-30 13:19:13,913-Speed 370.44 samples/sec   Loss 0.6481 Epoch: 7   Global Step: 13850   Required: 7 hours
Training: 2025-08-30 13:19:31,192-Speed 370.38 samples/sec   Loss 0.6585 Epoch: 7   Global Step: 13900   Required: 7 hours
Training: 2025-08-30 13:19:48,473-Speed 370.36 samples/sec   Loss 0.6489 Epoch: 7   Global Step: 13950   Required: 7 hours
Training: 2025-08-30 13:20:05,756-Speed 370.31 samples/sec   Loss 0.6888 Epoch: 7   Global Step: 14000   Required: 7 hours
Training: 2025-08-30 13:20:23,039-Speed 370.31 samples/sec   Loss 0.6618 Epoch: 7   Global Step: 14050   Required: 7 hours
Training: 2025-08-30 13:20:40,316-Speed 370.42 samples/sec   Loss 0.6640 Epoch: 7   Global Step: 14100   Required: 7 hours
Training: 2025-08-30 13:20:57,598-Speed 370.34 samples/sec   Loss 0.7168 Epoch: 7   Global Step: 14150   Required: 7 hours
Training: 2025-08-30 13:21:14,883-Speed 370.26 samples/sec   Loss 0.6646 Epoch: 7   Global Step: 14200   Required: 7 hours
Training: 2025-08-30 13:21:32,164-Speed 370.36 samples/sec   Loss 0.6896 Epoch: 7   Global Step: 14250   Required: 7 hours
Training: 2025-08-30 13:21:49,445-Speed 370.34 samples/sec   Loss 0.6486 Epoch: 7   Global Step: 14300   Required: 7 hours
Training: 2025-08-30 13:22:06,724-Speed 370.40 samples/sec   Loss 0.6894 Epoch: 7   Global Step: 14350   Required: 7 hours
Training: 2025-08-30 13:22:23,998-Speed 370.50 samples/sec   Loss 0.6830 Epoch: 7   Global Step: 14400   Required: 7 hours
Training: 2025-08-30 13:22:41,273-Speed 370.48 samples/sec   Loss 0.6440 Epoch: 7   Global Step: 14450   Required: 7 hours
Training: 2025-08-30 13:22:58,553-Speed 370.37 samples/sec   Loss 0.7001 Epoch: 7   Global Step: 14500   Required: 7 hours
Training: 2025-08-30 13:23:15,831-Speed 370.41 samples/sec   Loss 0.6772 Epoch: 7   Global Step: 14550   Required: 7 hours
Training: 2025-08-30 13:23:33,108-Speed 370.43 samples/sec   Loss 0.7031 Epoch: 7   Global Step: 14600   Required: 7 hours
Training: 2025-08-30 13:23:50,389-Speed 370.36 samples/sec   Loss 0.6916 Epoch: 7   Global Step: 14650   Required: 7 hours
Training: 2025-08-30 13:24:07,673-Speed 370.29 samples/sec   Loss 0.7038 Epoch: 7   Global Step: 14700   Required: 7 hours
Training: 2025-08-30 13:24:24,955-Speed 370.32 samples/sec   Loss 0.6699 Epoch: 7   Global Step: 14750   Required: 7 hours
Training: 2025-08-30 13:24:42,229-Speed 370.50 samples/sec   Loss 0.6890 Epoch: 7   Global Step: 14800   Required: 7 hours
Training: 2025-08-30 13:24:59,503-Speed 370.50 samples/sec   Loss 0.6712 Epoch: 7   Global Step: 14850   Required: 7 hours
Training: 2025-08-30 13:25:16,781-Speed 370.42 samples/sec   Loss 0.6950 Epoch: 7   Global Step: 14900   Required: 7 hours
Training: 2025-08-30 13:25:34,060-Speed 370.40 samples/sec   Loss 0.6822 Epoch: 7   Global Step: 14950   Required: 7 hours
Training: 2025-08-30 13:26:12,901-[lfw][14992]XNorm: 18.104756
Training: 2025-08-30 13:26:12,901-[lfw][14992]Accuracy-Flip: 0.78733+-0.01991
Training: 2025-08-30 13:26:12,901-[lfw][14992]Accuracy-Highest: 0.81250
Training: 2025-08-30 13:26:41,169-[cfp_fp][14992]XNorm: 16.006673
Training: 2025-08-30 13:26:41,169-[cfp_fp][14992]Accuracy-Flip: 0.63043+-0.01684
Training: 2025-08-30 13:26:41,169-[cfp_fp][14992]Accuracy-Highest: 0.64057
Training: 2025-08-30 13:27:05,492-[agedb_30][14992]XNorm: 15.217802
Training: 2025-08-30 13:27:05,492-[agedb_30][14992]Accuracy-Flip: 0.52500+-0.01202
Training: 2025-08-30 13:27:05,492-[agedb_30][14992]Accuracy-Highest: 0.54117
Training: 2025-08-30 13:27:29,901-[calfw][14992]XNorm: 18.187848
Training: 2025-08-30 13:27:29,901-[calfw][14992]Accuracy-Flip: 0.63833+-0.01593
Training: 2025-08-30 13:27:29,901-[calfw][14992]Accuracy-Highest: 0.65483
Training: 2025-08-30 13:27:54,304-[cplfw][14992]XNorm: 15.271096
Training: 2025-08-30 13:27:54,304-[cplfw][14992]Accuracy-Flip: 0.61067+-0.01620
Training: 2025-08-30 13:27:54,304-[cplfw][14992]Accuracy-Highest: 0.62583
Training: 2025-08-30 13:27:57,213-Speed 44.71 samples/sec   Loss 0.6364 Epoch: 8   Global Step: 15000   Required: 7 hours
Training: 2025-08-30 13:28:14,474-Speed 370.78 samples/sec   Loss 0.5289 Epoch: 8   Global Step: 15050   Required: 7 hours
Training: 2025-08-30 13:28:31,743-Speed 370.61 samples/sec   Loss 0.5747 Epoch: 8   Global Step: 15100   Required: 7 hours
Training: 2025-08-30 13:28:49,013-Speed 370.59 samples/sec   Loss 0.5450 Epoch: 8   Global Step: 15150   Required: 7 hours
Training: 2025-08-30 13:29:06,284-Speed 370.57 samples/sec   Loss 0.5612 Epoch: 8   Global Step: 15200   Required: 7 hours
Training: 2025-08-30 13:29:23,565-Speed 370.34 samples/sec   Loss 0.5562 Epoch: 8   Global Step: 15250   Required: 7 hours
Training: 2025-08-30 13:29:40,853-Speed 370.20 samples/sec   Loss 0.5649 Epoch: 8   Global Step: 15300   Required: 7 hours
Training: 2025-08-30 13:29:58,139-Speed 370.25 samples/sec   Loss 0.6019 Epoch: 8   Global Step: 15350   Required: 7 hours
Training: 2025-08-30 13:30:15,426-Speed 370.23 samples/sec   Loss 0.5463 Epoch: 8   Global Step: 15400   Required: 7 hours
Training: 2025-08-30 13:30:32,713-Speed 370.21 samples/sec   Loss 0.5840 Epoch: 8   Global Step: 15450   Required: 7 hours
Training: 2025-08-30 13:30:50,000-Speed 370.24 samples/sec   Loss 0.5896 Epoch: 8   Global Step: 15500   Required: 7 hours
Training: 2025-08-30 13:31:07,288-Speed 370.19 samples/sec   Loss 0.6477 Epoch: 8   Global Step: 15550   Required: 7 hours
Training: 2025-08-30 13:31:24,570-Speed 370.33 samples/sec   Loss 0.5914 Epoch: 8   Global Step: 15600   Required: 7 hours
Training: 2025-08-30 13:31:41,849-Speed 370.39 samples/sec   Loss 0.6143 Epoch: 8   Global Step: 15650   Required: 7 hours
Training: 2025-08-30 13:31:59,133-Speed 370.28 samples/sec   Loss 0.6148 Epoch: 8   Global Step: 15700   Required: 7 hours
Training: 2025-08-30 13:32:16,419-Speed 370.25 samples/sec   Loss 0.5917 Epoch: 8   Global Step: 15750   Required: 7 hours
Training: 2025-08-30 13:32:33,698-Speed 370.39 samples/sec   Loss 0.5806 Epoch: 8   Global Step: 15800   Required: 7 hours
Training: 2025-08-30 13:32:50,984-Speed 370.26 samples/sec   Loss 0.5855 Epoch: 8   Global Step: 15850   Required: 7 hours
Training: 2025-08-30 13:33:08,266-Speed 370.33 samples/sec   Loss 0.6431 Epoch: 8   Global Step: 15900   Required: 7 hours
Training: 2025-08-30 13:33:25,547-Speed 370.35 samples/sec   Loss 0.6041 Epoch: 8   Global Step: 15950   Required: 7 hours
Training: 2025-08-30 13:33:42,832-Speed 370.26 samples/sec   Loss 0.5906 Epoch: 8   Global Step: 16000   Required: 7 hours
Training: 2025-08-30 13:34:00,115-Speed 370.30 samples/sec   Loss 0.6234 Epoch: 8   Global Step: 16050   Required: 7 hours
Training: 2025-08-30 13:34:17,399-Speed 370.30 samples/sec   Loss 0.5683 Epoch: 8   Global Step: 16100   Required: 7 hours
Training: 2025-08-30 13:34:34,676-Speed 370.44 samples/sec   Loss 0.6254 Epoch: 8   Global Step: 16150   Required: 7 hours
Training: 2025-08-30 13:34:51,957-Speed 370.34 samples/sec   Loss 0.6402 Epoch: 8   Global Step: 16200   Required: 7 hours
Training: 2025-08-30 13:35:09,235-Speed 370.42 samples/sec   Loss 0.6068 Epoch: 8   Global Step: 16250   Required: 7 hours
Training: 2025-08-30 13:35:26,512-Speed 370.44 samples/sec   Loss 0.5894 Epoch: 8   Global Step: 16300   Required: 7 hours
Training: 2025-08-30 13:35:43,787-Speed 370.48 samples/sec   Loss 0.6267 Epoch: 8   Global Step: 16350   Required: 7 hours
Training: 2025-08-30 13:36:01,068-Speed 370.37 samples/sec   Loss 0.6452 Epoch: 8   Global Step: 16400   Required: 7 hours
Training: 2025-08-30 13:36:18,346-Speed 370.40 samples/sec   Loss 0.6264 Epoch: 8   Global Step: 16450   Required: 7 hours
Training: 2025-08-30 13:36:35,625-Speed 370.41 samples/sec   Loss 0.6230 Epoch: 8   Global Step: 16500   Required: 7 hours
Training: 2025-08-30 13:36:52,903-Speed 370.41 samples/sec   Loss 0.6161 Epoch: 8   Global Step: 16550   Required: 7 hours
Training: 2025-08-30 13:37:10,184-Speed 370.34 samples/sec   Loss 0.6074 Epoch: 8   Global Step: 16600   Required: 7 hours
Training: 2025-08-30 13:37:27,459-Speed 370.48 samples/sec   Loss 0.6204 Epoch: 8   Global Step: 16650   Required: 7 hours
Training: 2025-08-30 13:37:44,743-Speed 370.29 samples/sec   Loss 0.6733 Epoch: 8   Global Step: 16700   Required: 7 hours
Training: 2025-08-30 13:38:02,034-Speed 370.14 samples/sec   Loss 0.6696 Epoch: 8   Global Step: 16750   Required: 7 hours
Training: 2025-08-30 13:38:19,325-Speed 370.14 samples/sec   Loss 0.6171 Epoch: 8   Global Step: 16800   Required: 7 hours
Training: 2025-08-30 13:38:36,617-Speed 370.11 samples/sec   Loss 0.5783 Epoch: 8   Global Step: 16850   Required: 7 hours
Training: 2025-08-30 13:39:06,491-[lfw][16866]XNorm: 19.478702
Training: 2025-08-30 13:39:06,491-[lfw][16866]Accuracy-Flip: 0.82750+-0.01453
Training: 2025-08-30 13:39:06,491-[lfw][16866]Accuracy-Highest: 0.82750
Training: 2025-08-30 13:39:34,770-[cfp_fp][16866]XNorm: 17.998753
Training: 2025-08-30 13:39:34,770-[cfp_fp][16866]Accuracy-Flip: 0.63286+-0.01733
Training: 2025-08-30 13:39:34,770-[cfp_fp][16866]Accuracy-Highest: 0.64057
Training: 2025-08-30 13:39:59,097-[agedb_30][16866]XNorm: 16.923914
Training: 2025-08-30 13:39:59,097-[agedb_30][16866]Accuracy-Flip: 0.52850+-0.00871
Training: 2025-08-30 13:39:59,098-[agedb_30][16866]Accuracy-Highest: 0.54117
Training: 2025-08-30 13:40:23,515-[calfw][16866]XNorm: 19.457627
Training: 2025-08-30 13:40:23,515-[calfw][16866]Accuracy-Flip: 0.66850+-0.01469
Training: 2025-08-30 13:40:23,515-[calfw][16866]Accuracy-Highest: 0.66850
Training: 2025-08-30 13:40:47,924-[cplfw][16866]XNorm: 16.220474
Training: 2025-08-30 13:40:47,924-[cplfw][16866]Accuracy-Flip: 0.64217+-0.00715
Training: 2025-08-30 13:40:47,925-[cplfw][16866]Accuracy-Highest: 0.64217
Training: 2025-08-30 13:40:59,844-Speed 44.68 samples/sec   Loss 0.5516 Epoch: 9   Global Step: 16900   Required: 7 hours
Training: 2025-08-30 13:41:17,109-Speed 370.69 samples/sec   Loss 0.5137 Epoch: 9   Global Step: 16950   Required: 7 hours
Training: 2025-08-30 13:41:34,385-Speed 370.46 samples/sec   Loss 0.4817 Epoch: 9   Global Step: 17000   Required: 7 hours
Training: 2025-08-30 13:41:51,666-Speed 370.34 samples/sec   Loss 0.5365 Epoch: 9   Global Step: 17050   Required: 7 hours
Training: 2025-08-30 13:42:08,949-Speed 370.31 samples/sec   Loss 0.5173 Epoch: 9   Global Step: 17100   Required: 7 hours
Training: 2025-08-30 13:42:26,231-Speed 370.33 samples/sec   Loss 0.5038 Epoch: 9   Global Step: 17150   Required: 7 hours
Training: 2025-08-30 13:42:43,517-Speed 370.26 samples/sec   Loss 0.5244 Epoch: 9   Global Step: 17200   Required: 7 hours
Training: 2025-08-30 13:43:00,802-Speed 370.26 samples/sec   Loss 0.5690 Epoch: 9   Global Step: 17250   Required: 7 hours
Training: 2025-08-30 13:43:18,087-Speed 370.27 samples/sec   Loss 0.5569 Epoch: 9   Global Step: 17300   Required: 7 hours
Training: 2025-08-30 13:43:35,376-Speed 370.19 samples/sec   Loss 0.5252 Epoch: 9   Global Step: 17350   Required: 7 hours
Training: 2025-08-30 13:43:52,667-Speed 370.14 samples/sec   Loss 0.5613 Epoch: 9   Global Step: 17400   Required: 7 hours
Training: 2025-08-30 13:44:09,956-Speed 370.16 samples/sec   Loss 0.5668 Epoch: 9   Global Step: 17450   Required: 7 hours
Training: 2025-08-30 13:44:27,242-Speed 370.26 samples/sec   Loss 0.5695 Epoch: 9   Global Step: 17500   Required: 7 hours
Training: 2025-08-30 13:44:44,525-Speed 370.30 samples/sec   Loss 0.5350 Epoch: 9   Global Step: 17550   Required: 7 hours
Training: 2025-08-30 13:45:01,815-Speed 370.16 samples/sec   Loss 0.5241 Epoch: 9   Global Step: 17600   Required: 7 hours
Training: 2025-08-30 13:45:19,105-Speed 370.15 samples/sec   Loss 0.5532 Epoch: 9   Global Step: 17650   Required: 7 hours
Training: 2025-08-30 13:45:36,393-Speed 370.20 samples/sec   Loss 0.5439 Epoch: 9   Global Step: 17700   Required: 7 hours
Training: 2025-08-30 13:45:53,679-Speed 370.26 samples/sec   Loss 0.5915 Epoch: 9   Global Step: 17750   Required: 7 hours
Training: 2025-08-30 13:46:10,959-Speed 370.35 samples/sec   Loss 0.5600 Epoch: 9   Global Step: 17800   Required: 7 hours
Training: 2025-08-30 13:46:28,246-Speed 370.24 samples/sec   Loss 0.5428 Epoch: 9   Global Step: 17850   Required: 6 hours
Training: 2025-08-30 13:46:45,531-Speed 370.26 samples/sec   Loss 0.5618 Epoch: 9   Global Step: 17900   Required: 6 hours
Training: 2025-08-30 13:47:02,814-Speed 370.31 samples/sec   Loss 0.5759 Epoch: 9   Global Step: 17950   Required: 6 hours
Training: 2025-08-30 13:47:20,094-Speed 370.38 samples/sec   Loss 0.5653 Epoch: 9   Global Step: 18000   Required: 6 hours
Training: 2025-08-30 13:47:37,378-Speed 370.29 samples/sec   Loss 0.5566 Epoch: 9   Global Step: 18050   Required: 6 hours
Training: 2025-08-30 13:47:54,659-Speed 370.35 samples/sec   Loss 0.5754 Epoch: 9   Global Step: 18100   Required: 6 hours
Training: 2025-08-30 13:48:11,943-Speed 370.28 samples/sec   Loss 0.5789 Epoch: 9   Global Step: 18150   Required: 6 hours
Training: 2025-08-30 13:48:29,224-Speed 370.35 samples/sec   Loss 0.5656 Epoch: 9   Global Step: 18200   Required: 6 hours
Training: 2025-08-30 13:48:46,501-Speed 370.44 samples/sec   Loss 0.5518 Epoch: 9   Global Step: 18250   Required: 6 hours
Training: 2025-08-30 13:49:03,781-Speed 370.38 samples/sec   Loss 0.5709 Epoch: 9   Global Step: 18300   Required: 6 hours
Training: 2025-08-30 13:49:21,064-Speed 370.31 samples/sec   Loss 0.5586 Epoch: 9   Global Step: 18350   Required: 6 hours
Training: 2025-08-30 13:49:38,347-Speed 370.31 samples/sec   Loss 0.5760 Epoch: 9   Global Step: 18400   Required: 6 hours
Training: 2025-08-30 13:49:55,627-Speed 370.38 samples/sec   Loss 0.6081 Epoch: 9   Global Step: 18450   Required: 6 hours
Training: 2025-08-30 13:50:12,907-Speed 370.37 samples/sec   Loss 0.6180 Epoch: 9   Global Step: 18500   Required: 6 hours
Training: 2025-08-30 13:50:30,184-Speed 370.45 samples/sec   Loss 0.5772 Epoch: 9   Global Step: 18550   Required: 6 hours
Training: 2025-08-30 13:50:47,464-Speed 370.37 samples/sec   Loss 0.6067 Epoch: 9   Global Step: 18600   Required: 6 hours
Training: 2025-08-30 13:51:04,740-Speed 370.46 samples/sec   Loss 0.5775 Epoch: 9   Global Step: 18650   Required: 6 hours
Training: 2025-08-30 13:51:22,019-Speed 370.39 samples/sec   Loss 0.5469 Epoch: 9   Global Step: 18700   Required: 6 hours
Training: 2025-08-30 13:52:00,182-[lfw][18740]XNorm: 16.567792
Training: 2025-08-30 13:52:00,182-[lfw][18740]Accuracy-Flip: 0.81250+-0.01450
Training: 2025-08-30 13:52:00,182-[lfw][18740]Accuracy-Highest: 0.82750
Training: 2025-08-30 13:52:28,451-[cfp_fp][18740]XNorm: 13.708431
Training: 2025-08-30 13:52:28,451-[cfp_fp][18740]Accuracy-Flip: 0.65243+-0.01922
Training: 2025-08-30 13:52:28,451-[cfp_fp][18740]Accuracy-Highest: 0.65243
Training: 2025-08-30 13:52:52,772-[agedb_30][18740]XNorm: 13.884134
Training: 2025-08-30 13:52:52,772-[agedb_30][18740]Accuracy-Flip: 0.51133+-0.01100
Training: 2025-08-30 13:52:52,772-[agedb_30][18740]Accuracy-Highest: 0.54117
Training: 2025-08-30 13:53:17,180-[calfw][18740]XNorm: 16.600504
Training: 2025-08-30 13:53:17,180-[calfw][18740]Accuracy-Flip: 0.65200+-0.01534
Training: 2025-08-30 13:53:17,180-[calfw][18740]Accuracy-Highest: 0.66850
Training: 2025-08-30 13:53:41,582-[cplfw][18740]XNorm: 13.501245
Training: 2025-08-30 13:53:41,583-[cplfw][18740]Accuracy-Flip: 0.62517+-0.00959
Training: 2025-08-30 13:53:41,583-[cplfw][18740]Accuracy-Highest: 0.64217
Training: 2025-08-30 13:53:45,215-Speed 44.69 samples/sec   Loss 0.5850 Epoch: 10   Global Step: 18750   Required: 6 hours
Training: 2025-08-30 13:54:02,486-Speed 370.56 samples/sec   Loss 0.4608 Epoch: 10   Global Step: 18800   Required: 6 hours
Training: 2025-08-30 13:54:19,766-Speed 370.37 samples/sec   Loss 0.4701 Epoch: 10   Global Step: 18850   Required: 6 hours
Training: 2025-08-30 13:54:37,043-Speed 370.44 samples/sec   Loss 0.4782 Epoch: 10   Global Step: 18900   Required: 6 hours
Training: 2025-08-30 13:54:54,321-Speed 370.43 samples/sec   Loss 0.4676 Epoch: 10   Global Step: 18950   Required: 6 hours
Training: 2025-08-30 13:55:11,603-Speed 370.32 samples/sec   Loss 0.4751 Epoch: 10   Global Step: 19000   Required: 6 hours
Training: 2025-08-30 13:55:28,884-Speed 370.35 samples/sec   Loss 0.5240 Epoch: 10   Global Step: 19050   Required: 6 hours
Training: 2025-08-30 13:55:46,170-Speed 370.26 samples/sec   Loss 0.5037 Epoch: 10   Global Step: 19100   Required: 6 hours
Training: 2025-08-30 13:56:03,457-Speed 370.22 samples/sec   Loss 0.5442 Epoch: 10   Global Step: 19150   Required: 6 hours
Training: 2025-08-30 13:56:20,746-Speed 370.17 samples/sec   Loss 0.5337 Epoch: 10   Global Step: 19200   Required: 6 hours
Training: 2025-08-30 13:56:38,034-Speed 370.20 samples/sec   Loss 0.4710 Epoch: 10   Global Step: 19250   Required: 6 hours
Training: 2025-08-30 13:56:55,321-Speed 370.23 samples/sec   Loss 0.4973 Epoch: 10   Global Step: 19300   Required: 6 hours
Training: 2025-08-30 13:57:12,615-Speed 370.08 samples/sec   Loss 0.5314 Epoch: 10   Global Step: 19350   Required: 6 hours
Training: 2025-08-30 13:57:29,908-Speed 370.09 samples/sec   Loss 0.4863 Epoch: 10   Global Step: 19400   Required: 6 hours
Training: 2025-08-30 13:57:47,197-Speed 370.18 samples/sec   Loss 0.5209 Epoch: 10   Global Step: 19450   Required: 6 hours
Training: 2025-08-30 13:58:04,488-Speed 370.14 samples/sec   Loss 0.5138 Epoch: 10   Global Step: 19500   Required: 6 hours
Training: 2025-08-30 13:58:21,775-Speed 370.22 samples/sec   Loss 0.5204 Epoch: 10   Global Step: 19550   Required: 6 hours
Training: 2025-08-30 13:58:39,059-Speed 370.29 samples/sec   Loss 0.4849 Epoch: 10   Global Step: 19600   Required: 6 hours
Training: 2025-08-30 13:58:56,341-Speed 370.32 samples/sec   Loss 0.5556 Epoch: 10   Global Step: 19650   Required: 6 hours
Training: 2025-08-30 13:59:13,620-Speed 370.41 samples/sec   Loss 0.5321 Epoch: 10   Global Step: 19700   Required: 6 hours
Training: 2025-08-30 13:59:30,901-Speed 370.35 samples/sec   Loss 0.5530 Epoch: 10   Global Step: 19750   Required: 6 hours
Training: 2025-08-30 13:59:48,182-Speed 370.36 samples/sec   Loss 0.5353 Epoch: 10   Global Step: 19800   Required: 6 hours
Training: 2025-08-30 14:00:05,461-Speed 370.38 samples/sec   Loss 0.5375 Epoch: 10   Global Step: 19850   Required: 6 hours
Training: 2025-08-30 14:00:22,738-Speed 370.44 samples/sec   Loss 0.5581 Epoch: 10   Global Step: 19900   Required: 6 hours
Training: 2025-08-30 14:00:40,019-Speed 370.35 samples/sec   Loss 0.5414 Epoch: 10   Global Step: 19950   Required: 6 hours
Training: 2025-08-30 14:00:57,303-Speed 370.30 samples/sec   Loss 0.5268 Epoch: 10   Global Step: 20000   Required: 6 hours
Training: 2025-08-30 14:01:14,584-Speed 370.34 samples/sec   Loss 0.5479 Epoch: 10   Global Step: 20050   Required: 6 hours
Training: 2025-08-30 14:01:31,866-Speed 370.34 samples/sec   Loss 0.5516 Epoch: 10   Global Step: 20100   Required: 6 hours
Training: 2025-08-30 14:01:49,151-Speed 370.25 samples/sec   Loss 0.5619 Epoch: 10   Global Step: 20150   Required: 6 hours
Training: 2025-08-30 14:02:06,439-Speed 370.20 samples/sec   Loss 0.5285 Epoch: 10   Global Step: 20200   Required: 6 hours
Training: 2025-08-30 14:02:23,722-Speed 370.31 samples/sec   Loss 0.5729 Epoch: 10   Global Step: 20250   Required: 6 hours
Training: 2025-08-30 14:02:41,002-Speed 370.36 samples/sec   Loss 0.5351 Epoch: 10   Global Step: 20300   Required: 6 hours
Training: 2025-08-30 14:02:58,280-Speed 370.43 samples/sec   Loss 0.5564 Epoch: 10   Global Step: 20350   Required: 6 hours
Training: 2025-08-30 14:03:15,558-Speed 370.41 samples/sec   Loss 0.5407 Epoch: 10   Global Step: 20400   Required: 6 hours
Training: 2025-08-30 14:03:32,837-Speed 370.40 samples/sec   Loss 0.5421 Epoch: 10   Global Step: 20450   Required: 6 hours
Training: 2025-08-30 14:03:50,115-Speed 370.41 samples/sec   Loss 0.5284 Epoch: 10   Global Step: 20500   Required: 6 hours
Training: 2025-08-30 14:04:07,391-Speed 370.46 samples/sec   Loss 0.5648 Epoch: 10   Global Step: 20550   Required: 6 hours
Training: 2025-08-30 14:04:24,664-Speed 370.51 samples/sec   Loss 0.5357 Epoch: 10   Global Step: 20600   Required: 6 hours
Training: 2025-08-30 14:04:53,832-[lfw][20614]XNorm: 17.628561
Training: 2025-08-30 14:04:53,832-[lfw][20614]Accuracy-Flip: 0.80717+-0.01962
Training: 2025-08-30 14:04:53,832-[lfw][20614]Accuracy-Highest: 0.82750
Training: 2025-08-30 14:05:22,081-[cfp_fp][20614]XNorm: 15.986771
Training: 2025-08-30 14:05:22,081-[cfp_fp][20614]Accuracy-Flip: 0.63771+-0.02129
Training: 2025-08-30 14:05:22,081-[cfp_fp][20614]Accuracy-Highest: 0.65243
Training: 2025-08-30 14:05:46,407-[agedb_30][20614]XNorm: 16.465479
Training: 2025-08-30 14:05:46,408-[agedb_30][20614]Accuracy-Flip: 0.52450+-0.01869
Training: 2025-08-30 14:05:46,408-[agedb_30][20614]Accuracy-Highest: 0.54117
Training: 2025-08-30 14:06:10,828-[calfw][20614]XNorm: 18.192463
Training: 2025-08-30 14:06:10,829-[calfw][20614]Accuracy-Flip: 0.65250+-0.02089
Training: 2025-08-30 14:06:10,829-[calfw][20614]Accuracy-Highest: 0.66850
Training: 2025-08-30 14:06:35,232-[cplfw][20614]XNorm: 14.713803
Training: 2025-08-30 14:06:35,232-[cplfw][20614]Accuracy-Flip: 0.62050+-0.01682
Training: 2025-08-30 14:06:35,232-[cplfw][20614]Accuracy-Highest: 0.64217
Training: 2025-08-30 14:06:47,852-Speed 44.70 samples/sec   Loss 0.4519 Epoch: 11   Global Step: 20650   Required: 6 hours
Training: 2025-08-30 14:07:05,118-Speed 370.67 samples/sec   Loss 0.4490 Epoch: 11   Global Step: 20700   Required: 6 hours
Training: 2025-08-30 14:07:22,389-Speed 370.57 samples/sec   Loss 0.4727 Epoch: 11   Global Step: 20750   Required: 6 hours
Training: 2025-08-30 14:07:39,667-Speed 370.43 samples/sec   Loss 0.4552 Epoch: 11   Global Step: 20800   Required: 6 hours
Training: 2025-08-30 14:07:56,944-Speed 370.44 samples/sec   Loss 0.4804 Epoch: 11   Global Step: 20850   Required: 6 hours
Training: 2025-08-30 14:08:14,222-Speed 370.42 samples/sec   Loss 0.4893 Epoch: 11   Global Step: 20900   Required: 6 hours
Training: 2025-08-30 14:08:31,504-Speed 370.33 samples/sec   Loss 0.4540 Epoch: 11   Global Step: 20950   Required: 6 hours
Training: 2025-08-30 14:08:48,788-Speed 370.29 samples/sec   Loss 0.4918 Epoch: 11   Global Step: 21000   Required: 6 hours
Training: 2025-08-30 14:09:06,070-Speed 370.34 samples/sec   Loss 0.4623 Epoch: 11   Global Step: 21050   Required: 6 hours
Training: 2025-08-30 14:09:23,353-Speed 370.31 samples/sec   Loss 0.4825 Epoch: 11   Global Step: 21100   Required: 6 hours
Training: 2025-08-30 14:09:40,631-Speed 370.42 samples/sec   Loss 0.4766 Epoch: 11   Global Step: 21150   Required: 6 hours
Training: 2025-08-30 14:09:57,909-Speed 370.41 samples/sec   Loss 0.4739 Epoch: 11   Global Step: 21200   Required: 6 hours
Training: 2025-08-30 14:10:15,184-Speed 370.47 samples/sec   Loss 0.5079 Epoch: 11   Global Step: 21250   Required: 6 hours
Training: 2025-08-30 14:10:32,464-Speed 370.37 samples/sec   Loss 0.5006 Epoch: 11   Global Step: 21300   Required: 6 hours
Training: 2025-08-30 14:10:49,745-Speed 370.37 samples/sec   Loss 0.4847 Epoch: 11   Global Step: 21350   Required: 6 hours
Training: 2025-08-30 14:11:07,024-Speed 370.39 samples/sec   Loss 0.5521 Epoch: 11   Global Step: 21400   Required: 6 hours
Training: 2025-08-30 14:11:24,300-Speed 370.46 samples/sec   Loss 0.4710 Epoch: 11   Global Step: 21450   Required: 6 hours
Training: 2025-08-30 14:11:41,575-Speed 370.49 samples/sec   Loss 0.5188 Epoch: 11   Global Step: 21500   Required: 6 hours
Training: 2025-08-30 14:11:58,851-Speed 370.45 samples/sec   Loss 0.4761 Epoch: 11   Global Step: 21550   Required: 6 hours
Training: 2025-08-30 14:12:16,131-Speed 370.38 samples/sec   Loss 0.5294 Epoch: 11   Global Step: 21600   Required: 6 hours
Training: 2025-08-30 14:12:33,412-Speed 370.34 samples/sec   Loss 0.5146 Epoch: 11   Global Step: 21650   Required: 6 hours
Training: 2025-08-30 14:12:50,695-Speed 370.31 samples/sec   Loss 0.4797 Epoch: 11   Global Step: 21700   Required: 6 hours
Training: 2025-08-30 14:13:07,977-Speed 370.34 samples/sec   Loss 0.5498 Epoch: 11   Global Step: 21750   Required: 6 hours
Training: 2025-08-30 14:13:25,254-Speed 370.44 samples/sec   Loss 0.5362 Epoch: 11   Global Step: 21800   Required: 6 hours
Training: 2025-08-30 14:13:42,526-Speed 370.53 samples/sec   Loss 0.5404 Epoch: 11   Global Step: 21850   Required: 6 hours
Training: 2025-08-30 14:13:59,795-Speed 370.62 samples/sec   Loss 0.4864 Epoch: 11   Global Step: 21900   Required: 6 hours
Training: 2025-08-30 14:14:17,065-Speed 370.57 samples/sec   Loss 0.5301 Epoch: 11   Global Step: 21950   Required: 6 hours
Training: 2025-08-30 14:14:34,338-Speed 370.53 samples/sec   Loss 0.4992 Epoch: 11   Global Step: 22000   Required: 6 hours
Training: 2025-08-30 14:14:51,612-Speed 370.50 samples/sec   Loss 0.5134 Epoch: 11   Global Step: 22050   Required: 6 hours
Training: 2025-08-30 14:15:08,891-Speed 370.38 samples/sec   Loss 0.4752 Epoch: 11   Global Step: 22100   Required: 6 hours
Training: 2025-08-30 14:15:26,168-Speed 370.45 samples/sec   Loss 0.5179 Epoch: 11   Global Step: 22150   Required: 6 hours
Training: 2025-08-30 14:15:43,439-Speed 370.56 samples/sec   Loss 0.5296 Epoch: 11   Global Step: 22200   Required: 6 hours
Training: 2025-08-30 14:16:00,716-Speed 370.44 samples/sec   Loss 0.4980 Epoch: 11   Global Step: 22250   Required: 6 hours
Training: 2025-08-30 14:16:17,993-Speed 370.45 samples/sec   Loss 0.5206 Epoch: 11   Global Step: 22300   Required: 6 hours
Training: 2025-08-30 14:16:35,272-Speed 370.40 samples/sec   Loss 0.4947 Epoch: 11   Global Step: 22350   Required: 6 hours
Training: 2025-08-30 14:16:52,553-Speed 370.34 samples/sec   Loss 0.5671 Epoch: 11   Global Step: 22400   Required: 6 hours
Training: 2025-08-30 14:17:09,827-Speed 370.49 samples/sec   Loss 0.5300 Epoch: 11   Global Step: 22450   Required: 6 hours
Training: 2025-08-30 14:17:47,291-[lfw][22488]XNorm: 19.088909
Training: 2025-08-30 14:17:47,291-[lfw][22488]Accuracy-Flip: 0.80717+-0.02190
Training: 2025-08-30 14:17:47,291-[lfw][22488]Accuracy-Highest: 0.82750
Training: 2025-08-30 14:18:15,551-[cfp_fp][22488]XNorm: 16.844488
Training: 2025-08-30 14:18:15,551-[cfp_fp][22488]Accuracy-Flip: 0.63871+-0.01989
Training: 2025-08-30 14:18:15,551-[cfp_fp][22488]Accuracy-Highest: 0.65243
Training: 2025-08-30 14:18:39,871-[agedb_30][22488]XNorm: 17.207214
Training: 2025-08-30 14:18:39,872-[agedb_30][22488]Accuracy-Flip: 0.53733+-0.02042
Training: 2025-08-30 14:18:39,872-[agedb_30][22488]Accuracy-Highest: 0.54117
Training: 2025-08-30 14:19:04,273-[calfw][22488]XNorm: 19.377311
Training: 2025-08-30 14:19:04,273-[calfw][22488]Accuracy-Flip: 0.65283+-0.01648
Training: 2025-08-30 14:19:04,273-[calfw][22488]Accuracy-Highest: 0.66850
Training: 2025-08-30 14:19:28,659-[cplfw][22488]XNorm: 15.871554
Training: 2025-08-30 14:19:28,659-[cplfw][22488]Accuracy-Flip: 0.62000+-0.01509
Training: 2025-08-30 14:19:28,659-[cplfw][22488]Accuracy-Highest: 0.64217
Training: 2025-08-30 14:19:33,001-Speed 44.70 samples/sec   Loss 0.5146 Epoch: 12   Global Step: 22500   Required: 6 hours
Training: 2025-08-30 14:19:50,256-Speed 370.92 samples/sec   Loss 0.4411 Epoch: 12   Global Step: 22550   Required: 6 hours
Training: 2025-08-30 14:20:07,518-Speed 370.75 samples/sec   Loss 0.4498 Epoch: 12   Global Step: 22600   Required: 6 hours
Training: 2025-08-30 14:20:24,788-Speed 370.60 samples/sec   Loss 0.4246 Epoch: 12   Global Step: 22650   Required: 6 hours
Training: 2025-08-30 14:20:42,063-Speed 370.48 samples/sec   Loss 0.4304 Epoch: 12   Global Step: 22700   Required: 6 hours
Training: 2025-08-30 14:20:59,342-Speed 370.40 samples/sec   Loss 0.4236 Epoch: 12   Global Step: 22750   Required: 6 hours
Training: 2025-08-30 14:21:16,623-Speed 370.34 samples/sec   Loss 0.4331 Epoch: 12   Global Step: 22800   Required: 6 hours
Training: 2025-08-30 14:21:33,910-Speed 370.23 samples/sec   Loss 0.4289 Epoch: 12   Global Step: 22850   Required: 6 hours
Training: 2025-08-30 14:21:51,195-Speed 370.25 samples/sec   Loss 0.4501 Epoch: 12   Global Step: 22900   Required: 6 hours
Training: 2025-08-30 14:22:08,477-Speed 370.34 samples/sec   Loss 0.4516 Epoch: 12   Global Step: 22950   Required: 6 hours
Training: 2025-08-30 14:22:25,758-Speed 370.36 samples/sec   Loss 0.4932 Epoch: 12   Global Step: 23000   Required: 6 hours
Training: 2025-08-30 14:22:43,047-Speed 370.18 samples/sec   Loss 0.4261 Epoch: 12   Global Step: 23050   Required: 6 hours
Training: 2025-08-30 14:23:00,333-Speed 370.24 samples/sec   Loss 0.4748 Epoch: 12   Global Step: 23100   Required: 6 hours
Training: 2025-08-30 14:23:17,619-Speed 370.24 samples/sec   Loss 0.4751 Epoch: 12   Global Step: 23150   Required: 6 hours
Training: 2025-08-30 14:23:34,910-Speed 370.14 samples/sec   Loss 0.4567 Epoch: 12   Global Step: 23200   Required: 6 hours
Training: 2025-08-30 14:23:52,199-Speed 370.18 samples/sec   Loss 0.4836 Epoch: 12   Global Step: 23250   Required: 6 hours
Training: 2025-08-30 14:24:09,484-Speed 370.26 samples/sec   Loss 0.5097 Epoch: 12   Global Step: 23300   Required: 6 hours
Training: 2025-08-30 14:24:26,773-Speed 370.19 samples/sec   Loss 0.5058 Epoch: 12   Global Step: 23350   Required: 6 hours
Training: 2025-08-30 14:24:44,059-Speed 370.24 samples/sec   Loss 0.4953 Epoch: 12   Global Step: 23400   Required: 6 hours
Training: 2025-08-30 14:25:01,345-Speed 370.23 samples/sec   Loss 0.5299 Epoch: 12   Global Step: 23450   Required: 6 hours
Training: 2025-08-30 14:25:18,632-Speed 370.24 samples/sec   Loss 0.4951 Epoch: 12   Global Step: 23500   Required: 6 hours
Training: 2025-08-30 14:25:35,921-Speed 370.18 samples/sec   Loss 0.4692 Epoch: 12   Global Step: 23550   Required: 6 hours
Training: 2025-08-30 14:25:53,209-Speed 370.20 samples/sec   Loss 0.4891 Epoch: 12   Global Step: 23600   Required: 6 hours
Training: 2025-08-30 14:26:10,495-Speed 370.23 samples/sec   Loss 0.4633 Epoch: 12   Global Step: 23650   Required: 6 hours
Training: 2025-08-30 14:26:27,786-Speed 370.15 samples/sec   Loss 0.4719 Epoch: 12   Global Step: 23700   Required: 6 hours
Training: 2025-08-30 14:26:45,075-Speed 370.17 samples/sec   Loss 0.4515 Epoch: 12   Global Step: 23750   Required: 6 hours
Training: 2025-08-30 14:27:02,364-Speed 370.18 samples/sec   Loss 0.4892 Epoch: 12   Global Step: 23800   Required: 6 hours
Training: 2025-08-30 14:27:19,653-Speed 370.17 samples/sec   Loss 0.4764 Epoch: 12   Global Step: 23850   Required: 6 hours
Training: 2025-08-30 14:27:36,946-Speed 370.10 samples/sec   Loss 0.4741 Epoch: 12   Global Step: 23900   Required: 6 hours
Training: 2025-08-30 14:27:54,236-Speed 370.16 samples/sec   Loss 0.4529 Epoch: 12   Global Step: 23950   Required: 6 hours
Training: 2025-08-30 14:28:11,523-Speed 370.23 samples/sec   Loss 0.4867 Epoch: 12   Global Step: 24000   Required: 6 hours
Training: 2025-08-30 14:28:28,809-Speed 370.23 samples/sec   Loss 0.4624 Epoch: 12   Global Step: 24050   Required: 6 hours
Training: 2025-08-30 14:28:46,093-Speed 370.30 samples/sec   Loss 0.5126 Epoch: 12   Global Step: 24100   Required: 6 hours
Training: 2025-08-30 14:29:03,372-Speed 370.38 samples/sec   Loss 0.4955 Epoch: 12   Global Step: 24150   Required: 6 hours
Training: 2025-08-30 14:29:20,656-Speed 370.30 samples/sec   Loss 0.4943 Epoch: 12   Global Step: 24200   Required: 6 hours
Training: 2025-08-30 14:29:37,938-Speed 370.32 samples/sec   Loss 0.5160 Epoch: 12   Global Step: 24250   Required: 6 hours
Training: 2025-08-30 14:29:55,224-Speed 370.25 samples/sec   Loss 0.4741 Epoch: 12   Global Step: 24300   Required: 6 hours
Training: 2025-08-30 14:30:12,510-Speed 370.24 samples/sec   Loss 0.4787 Epoch: 12   Global Step: 24350   Required: 6 hours
Training: 2025-08-30 14:30:41,060-[lfw][24362]XNorm: 18.273599
Training: 2025-08-30 14:30:41,060-[lfw][24362]Accuracy-Flip: 0.78667+-0.02100
Training: 2025-08-30 14:30:41,060-[lfw][24362]Accuracy-Highest: 0.82750
Training: 2025-08-30 14:31:09,418-[cfp_fp][24362]XNorm: 15.841278
Training: 2025-08-30 14:31:09,418-[cfp_fp][24362]Accuracy-Flip: 0.65071+-0.01693
Training: 2025-08-30 14:31:09,418-[cfp_fp][24362]Accuracy-Highest: 0.65243
Training: 2025-08-30 14:31:33,794-[agedb_30][24362]XNorm: 16.006605
Training: 2025-08-30 14:31:33,794-[agedb_30][24362]Accuracy-Flip: 0.52450+-0.01765
Training: 2025-08-30 14:31:33,794-[agedb_30][24362]Accuracy-Highest: 0.54117
Training: 2025-08-30 14:31:58,254-[calfw][24362]XNorm: 18.179610
Training: 2025-08-30 14:31:58,255-[calfw][24362]Accuracy-Flip: 0.64550+-0.01276
Training: 2025-08-30 14:31:58,255-[calfw][24362]Accuracy-Highest: 0.66850
Training: 2025-08-30 14:32:22,699-[cplfw][24362]XNorm: 14.993681
Training: 2025-08-30 14:32:22,699-[cplfw][24362]Accuracy-Flip: 0.62050+-0.01393
Training: 2025-08-30 14:32:22,699-[cplfw][24362]Accuracy-Highest: 0.64217
Training: 2025-08-30 14:32:35,974-Speed 44.61 samples/sec   Loss 0.4129 Epoch: 13   Global Step: 24400   Required: 6 hours
Training: 2025-08-30 14:32:53,242-Speed 370.62 samples/sec   Loss 0.4078 Epoch: 13   Global Step: 24450   Required: 6 hours
Training: 2025-08-30 14:33:10,510-Speed 370.63 samples/sec   Loss 0.4008 Epoch: 13   Global Step: 24500   Required: 6 hours
Training: 2025-08-30 14:33:27,786-Speed 370.46 samples/sec   Loss 0.4034 Epoch: 13   Global Step: 24550   Required: 6 hours
Training: 2025-08-30 14:33:45,066-Speed 370.38 samples/sec   Loss 0.4250 Epoch: 13   Global Step: 24600   Required: 6 hours
Training: 2025-08-30 14:34:02,347-Speed 370.34 samples/sec   Loss 0.4560 Epoch: 13   Global Step: 24650   Required: 6 hours
Training: 2025-08-30 14:34:19,633-Speed 370.25 samples/sec   Loss 0.4208 Epoch: 13   Global Step: 24700   Required: 6 hours
Training: 2025-08-30 14:34:36,925-Speed 370.11 samples/sec   Loss 0.4487 Epoch: 13   Global Step: 24750   Required: 6 hours
Training: 2025-08-30 14:34:54,216-Speed 370.14 samples/sec   Loss 0.4425 Epoch: 13   Global Step: 24800   Required: 6 hours
Training: 2025-08-30 14:35:11,506-Speed 370.15 samples/sec   Loss 0.4247 Epoch: 13   Global Step: 24850   Required: 6 hours
Training: 2025-08-30 14:35:28,796-Speed 370.17 samples/sec   Loss 0.4400 Epoch: 13   Global Step: 24900   Required: 6 hours
Training: 2025-08-30 14:35:46,086-Speed 370.16 samples/sec   Loss 0.4683 Epoch: 13   Global Step: 24950   Required: 6 hours
Training: 2025-08-30 14:36:03,376-Speed 370.16 samples/sec   Loss 0.4650 Epoch: 13   Global Step: 25000   Required: 6 hours
Training: 2025-08-30 14:36:20,664-Speed 370.20 samples/sec   Loss 0.4438 Epoch: 13   Global Step: 25050   Required: 6 hours
Training: 2025-08-30 14:36:37,948-Speed 370.27 samples/sec   Loss 0.4474 Epoch: 13   Global Step: 25100   Required: 6 hours
Training: 2025-08-30 14:36:55,243-Speed 370.07 samples/sec   Loss 0.4461 Epoch: 13   Global Step: 25150   Required: 6 hours
Training: 2025-08-30 14:37:12,537-Speed 370.07 samples/sec   Loss 0.4190 Epoch: 13   Global Step: 25200   Required: 6 hours
Training: 2025-08-30 14:37:29,830-Speed 370.08 samples/sec   Loss 0.4352 Epoch: 13   Global Step: 25250   Required: 6 hours
Training: 2025-08-30 14:37:47,119-Speed 370.18 samples/sec   Loss 0.4210 Epoch: 13   Global Step: 25300   Required: 6 hours
Training: 2025-08-30 14:38:04,404-Speed 370.27 samples/sec   Loss 0.4685 Epoch: 13   Global Step: 25350   Required: 6 hours
Training: 2025-08-30 14:38:21,694-Speed 370.17 samples/sec   Loss 0.4382 Epoch: 13   Global Step: 25400   Required: 6 hours
Training: 2025-08-30 14:38:38,981-Speed 370.21 samples/sec   Loss 0.4532 Epoch: 13   Global Step: 25450   Required: 6 hours
Training: 2025-08-30 14:38:56,267-Speed 370.26 samples/sec   Loss 0.4685 Epoch: 13   Global Step: 25500   Required: 6 hours
Training: 2025-08-30 14:39:13,553-Speed 370.23 samples/sec   Loss 0.4509 Epoch: 13   Global Step: 25550   Required: 6 hours
Training: 2025-08-30 14:39:30,839-Speed 370.25 samples/sec   Loss 0.4827 Epoch: 13   Global Step: 25600   Required: 6 hours
Training: 2025-08-30 14:39:48,122-Speed 370.31 samples/sec   Loss 0.4595 Epoch: 13   Global Step: 25650   Required: 6 hours
Training: 2025-08-30 14:40:05,405-Speed 370.30 samples/sec   Loss 0.4956 Epoch: 13   Global Step: 25700   Required: 6 hours
Training: 2025-08-30 14:40:22,691-Speed 370.25 samples/sec   Loss 0.4521 Epoch: 13   Global Step: 25750   Required: 6 hours
Training: 2025-08-30 14:40:39,979-Speed 370.19 samples/sec   Loss 0.4397 Epoch: 13   Global Step: 25800   Required: 6 hours
Training: 2025-08-30 14:40:57,266-Speed 370.23 samples/sec   Loss 0.4836 Epoch: 13   Global Step: 25850   Required: 6 hours
Training: 2025-08-30 14:41:14,552-Speed 370.23 samples/sec   Loss 0.4720 Epoch: 13   Global Step: 25900   Required: 6 hours
Training: 2025-08-30 14:41:31,839-Speed 370.24 samples/sec   Loss 0.4688 Epoch: 13   Global Step: 25950   Required: 6 hours
Training: 2025-08-30 14:41:49,125-Speed 370.24 samples/sec   Loss 0.4683 Epoch: 13   Global Step: 26000   Required: 6 hours
Training: 2025-08-30 14:42:06,408-Speed 370.29 samples/sec   Loss 0.4942 Epoch: 13   Global Step: 26050   Required: 6 hours
Training: 2025-08-30 14:42:23,691-Speed 370.31 samples/sec   Loss 0.4881 Epoch: 13   Global Step: 26100   Required: 6 hours
Training: 2025-08-30 14:42:40,969-Speed 370.42 samples/sec   Loss 0.5072 Epoch: 13   Global Step: 26150   Required: 6 hours
Training: 2025-08-30 14:42:58,249-Speed 370.36 samples/sec   Loss 0.4867 Epoch: 13   Global Step: 26200   Required: 6 hours
Training: 2025-08-30 14:43:35,035-[lfw][26236]XNorm: 15.732598
Training: 2025-08-30 14:43:35,035-[lfw][26236]Accuracy-Flip: 0.80867+-0.02172
Training: 2025-08-30 14:43:35,035-[lfw][26236]Accuracy-Highest: 0.82750
Training: 2025-08-30 14:44:03,311-[cfp_fp][26236]XNorm: 15.582651
Training: 2025-08-30 14:44:03,311-[cfp_fp][26236]Accuracy-Flip: 0.62714+-0.02123
Training: 2025-08-30 14:44:03,311-[cfp_fp][26236]Accuracy-Highest: 0.65243
Training: 2025-08-30 14:44:27,650-[agedb_30][26236]XNorm: 13.748669
Training: 2025-08-30 14:44:27,650-[agedb_30][26236]Accuracy-Flip: 0.53783+-0.01293
Training: 2025-08-30 14:44:27,650-[agedb_30][26236]Accuracy-Highest: 0.54117
Training: 2025-08-30 14:44:52,065-[calfw][26236]XNorm: 16.342135
Training: 2025-08-30 14:44:52,065-[calfw][26236]Accuracy-Flip: 0.63467+-0.01273
Training: 2025-08-30 14:44:52,065-[calfw][26236]Accuracy-Highest: 0.66850
Training: 2025-08-30 14:45:16,478-[cplfw][26236]XNorm: 13.076142
Training: 2025-08-30 14:45:16,478-[cplfw][26236]Accuracy-Flip: 0.62200+-0.01813
Training: 2025-08-30 14:45:16,478-[cplfw][26236]Accuracy-Highest: 0.64217
Training: 2025-08-30 14:45:21,488-Speed 44.68 samples/sec   Loss 0.4717 Epoch: 14   Global Step: 26250   Required: 6 hours
Training: 2025-08-30 14:45:38,758-Speed 370.60 samples/sec   Loss 0.3782 Epoch: 14   Global Step: 26300   Required: 6 hours
Training: 2025-08-30 14:45:56,031-Speed 370.52 samples/sec   Loss 0.4036 Epoch: 14   Global Step: 26350   Required: 6 hours
Training: 2025-08-30 14:46:13,305-Speed 370.51 samples/sec   Loss 0.3955 Epoch: 14   Global Step: 26400   Required: 6 hours
Training: 2025-08-30 14:46:30,585-Speed 370.37 samples/sec   Loss 0.4007 Epoch: 14   Global Step: 26450   Required: 6 hours
Training: 2025-08-30 14:46:47,863-Speed 370.40 samples/sec   Loss 0.3683 Epoch: 14   Global Step: 26500   Required: 6 hours
Training: 2025-08-30 14:47:05,147-Speed 370.30 samples/sec   Loss 0.4071 Epoch: 14   Global Step: 26550   Required: 6 hours
Training: 2025-08-30 14:47:22,432-Speed 370.25 samples/sec   Loss 0.4086 Epoch: 14   Global Step: 26600   Required: 6 hours
Training: 2025-08-30 14:47:39,717-Speed 370.28 samples/sec   Loss 0.3730 Epoch: 14   Global Step: 26650   Required: 6 hours
Training: 2025-08-30 14:47:57,007-Speed 370.16 samples/sec   Loss 0.4309 Epoch: 14   Global Step: 26700   Required: 6 hours
Training: 2025-08-30 14:48:14,297-Speed 370.15 samples/sec   Loss 0.4426 Epoch: 14   Global Step: 26750   Required: 6 hours
Training: 2025-08-30 14:48:31,585-Speed 370.19 samples/sec   Loss 0.4394 Epoch: 14   Global Step: 26800   Required: 6 hours
Training: 2025-08-30 14:48:48,878-Speed 370.10 samples/sec   Loss 0.4153 Epoch: 14   Global Step: 26850   Required: 6 hours
Training: 2025-08-30 14:49:06,166-Speed 370.20 samples/sec   Loss 0.4325 Epoch: 14   Global Step: 26900   Required: 5 hours
Training: 2025-08-30 14:49:23,456-Speed 370.16 samples/sec   Loss 0.4124 Epoch: 14   Global Step: 26950   Required: 5 hours
Training: 2025-08-30 14:49:40,749-Speed 370.09 samples/sec   Loss 0.4072 Epoch: 14   Global Step: 27000   Required: 5 hours
Training: 2025-08-30 14:49:58,040-Speed 370.14 samples/sec   Loss 0.4262 Epoch: 14   Global Step: 27050   Required: 5 hours
Training: 2025-08-30 14:50:15,333-Speed 370.11 samples/sec   Loss 0.4531 Epoch: 14   Global Step: 27100   Required: 5 hours
Training: 2025-08-30 14:50:32,623-Speed 370.15 samples/sec   Loss 0.4601 Epoch: 14   Global Step: 27150   Required: 5 hours
Training: 2025-08-30 14:50:49,912-Speed 370.19 samples/sec   Loss 0.4135 Epoch: 14   Global Step: 27200   Required: 5 hours
Training: 2025-08-30 14:51:07,198-Speed 370.23 samples/sec   Loss 0.4305 Epoch: 14   Global Step: 27250   Required: 5 hours
Training: 2025-08-30 14:51:24,487-Speed 370.18 samples/sec   Loss 0.4349 Epoch: 14   Global Step: 27300   Required: 5 hours
Training: 2025-08-30 14:51:41,779-Speed 370.13 samples/sec   Loss 0.4476 Epoch: 14   Global Step: 27350   Required: 5 hours
Training: 2025-08-30 14:51:59,072-Speed 370.08 samples/sec   Loss 0.4326 Epoch: 14   Global Step: 27400   Required: 5 hours
Training: 2025-08-30 14:52:16,361-Speed 370.19 samples/sec   Loss 0.4475 Epoch: 14   Global Step: 27450   Required: 5 hours
Training: 2025-08-30 14:52:33,646-Speed 370.27 samples/sec   Loss 0.4342 Epoch: 14   Global Step: 27500   Required: 5 hours
Training: 2025-08-30 14:52:50,936-Speed 370.14 samples/sec   Loss 0.4179 Epoch: 14   Global Step: 27550   Required: 5 hours
Training: 2025-08-30 14:53:08,229-Speed 370.09 samples/sec   Loss 0.4516 Epoch: 14   Global Step: 27600   Required: 5 hours
Training: 2025-08-30 14:53:25,515-Speed 370.25 samples/sec   Loss 0.4424 Epoch: 14   Global Step: 27650   Required: 5 hours
Training: 2025-08-30 14:53:42,801-Speed 370.25 samples/sec   Loss 0.4494 Epoch: 14   Global Step: 27700   Required: 5 hours
Training: 2025-08-30 14:54:00,086-Speed 370.27 samples/sec   Loss 0.4272 Epoch: 14   Global Step: 27750   Required: 5 hours
Training: 2025-08-30 14:54:17,369-Speed 370.30 samples/sec   Loss 0.4502 Epoch: 14   Global Step: 27800   Required: 5 hours
Training: 2025-08-30 14:54:34,655-Speed 370.25 samples/sec   Loss 0.4186 Epoch: 14   Global Step: 27850   Required: 5 hours
Training: 2025-08-30 14:54:51,941-Speed 370.25 samples/sec   Loss 0.4596 Epoch: 14   Global Step: 27900   Required: 5 hours
Training: 2025-08-30 14:55:09,225-Speed 370.28 samples/sec   Loss 0.4850 Epoch: 14   Global Step: 27950   Required: 5 hours
Training: 2025-08-30 14:55:26,511-Speed 370.24 samples/sec   Loss 0.4582 Epoch: 14   Global Step: 28000   Required: 5 hours
Training: 2025-08-30 14:55:43,792-Speed 370.34 samples/sec   Loss 0.4761 Epoch: 14   Global Step: 28050   Required: 5 hours
Training: 2025-08-30 14:56:01,071-Speed 370.40 samples/sec   Loss 0.4192 Epoch: 14   Global Step: 28100   Required: 5 hours
Training: 2025-08-30 14:56:28,869-[lfw][28110]XNorm: 16.271023
Training: 2025-08-30 14:56:28,869-[lfw][28110]Accuracy-Flip: 0.79733+-0.01257
Training: 2025-08-30 14:56:28,869-[lfw][28110]Accuracy-Highest: 0.82750
Training: 2025-08-30 14:56:57,156-[cfp_fp][28110]XNorm: 15.656595
Training: 2025-08-30 14:56:57,156-[cfp_fp][28110]Accuracy-Flip: 0.61800+-0.01694
Training: 2025-08-30 14:56:57,156-[cfp_fp][28110]Accuracy-Highest: 0.65243
Training: 2025-08-30 14:57:21,489-[agedb_30][28110]XNorm: 14.930620
Training: 2025-08-30 14:57:21,489-[agedb_30][28110]Accuracy-Flip: 0.52450+-0.01093
Training: 2025-08-30 14:57:21,489-[agedb_30][28110]Accuracy-Highest: 0.54117
Training: 2025-08-30 14:57:45,915-[calfw][28110]XNorm: 16.686418
Training: 2025-08-30 14:57:45,915-[calfw][28110]Accuracy-Flip: 0.64400+-0.01652
Training: 2025-08-30 14:57:45,915-[calfw][28110]Accuracy-Highest: 0.66850
Training: 2025-08-30 14:58:10,327-[cplfw][28110]XNorm: 13.249587
Training: 2025-08-30 14:58:10,327-[cplfw][28110]Accuracy-Flip: 0.61400+-0.01700
Training: 2025-08-30 14:58:10,327-[cplfw][28110]Accuracy-Highest: 0.64217
Training: 2025-08-30 14:58:24,343-Speed 44.67 samples/sec   Loss 0.4101 Epoch: 15   Global Step: 28150   Required: 5 hours
Training: 2025-08-30 14:58:41,616-Speed 370.51 samples/sec   Loss 0.3649 Epoch: 15   Global Step: 28200   Required: 5 hours
Training: 2025-08-30 14:58:58,891-Speed 370.49 samples/sec   Loss 0.3825 Epoch: 15   Global Step: 28250   Required: 5 hours
Training: 2025-08-30 14:59:16,170-Speed 370.39 samples/sec   Loss 0.4015 Epoch: 15   Global Step: 28300   Required: 5 hours
Training: 2025-08-30 14:59:33,450-Speed 370.37 samples/sec   Loss 0.3586 Epoch: 15   Global Step: 28350   Required: 5 hours
Training: 2025-08-30 14:59:50,733-Speed 370.30 samples/sec   Loss 0.3796 Epoch: 15   Global Step: 28400   Required: 5 hours
Training: 2025-08-30 15:00:08,014-Speed 370.36 samples/sec   Loss 0.4083 Epoch: 15   Global Step: 28450   Required: 5 hours
Training: 2025-08-30 15:00:25,293-Speed 370.39 samples/sec   Loss 0.3635 Epoch: 15   Global Step: 28500   Required: 5 hours
Training: 2025-08-30 15:00:42,575-Speed 370.34 samples/sec   Loss 0.4176 Epoch: 15   Global Step: 28550   Required: 5 hours
Training: 2025-08-30 15:00:59,861-Speed 370.23 samples/sec   Loss 0.3997 Epoch: 15   Global Step: 28600   Required: 5 hours
Training: 2025-08-30 15:01:17,144-Speed 370.31 samples/sec   Loss 0.3811 Epoch: 15   Global Step: 28650   Required: 5 hours
Training: 2025-08-30 15:01:34,428-Speed 370.28 samples/sec   Loss 0.3853 Epoch: 15   Global Step: 28700   Required: 5 hours
Training: 2025-08-30 15:01:51,715-Speed 370.23 samples/sec   Loss 0.3982 Epoch: 15   Global Step: 28750   Required: 5 hours
Training: 2025-08-30 15:02:09,000-Speed 370.27 samples/sec   Loss 0.4313 Epoch: 15   Global Step: 28800   Required: 5 hours
Training: 2025-08-30 15:02:26,282-Speed 370.32 samples/sec   Loss 0.4216 Epoch: 15   Global Step: 28850   Required: 5 hours
Training: 2025-08-30 15:02:43,564-Speed 370.34 samples/sec   Loss 0.3961 Epoch: 15   Global Step: 28900   Required: 5 hours
Training: 2025-08-30 15:03:00,843-Speed 370.40 samples/sec   Loss 0.4267 Epoch: 15   Global Step: 28950   Required: 5 hours
Training: 2025-08-30 15:03:18,121-Speed 370.42 samples/sec   Loss 0.4270 Epoch: 15   Global Step: 29000   Required: 5 hours
Training: 2025-08-30 15:03:35,396-Speed 370.47 samples/sec   Loss 0.4250 Epoch: 15   Global Step: 29050   Required: 5 hours
Training: 2025-08-30 15:03:52,672-Speed 370.45 samples/sec   Loss 0.4085 Epoch: 15   Global Step: 29100   Required: 5 hours
Training: 2025-08-30 15:04:09,949-Speed 370.45 samples/sec   Loss 0.3830 Epoch: 15   Global Step: 29150   Required: 5 hours
Training: 2025-08-30 15:04:27,224-Speed 370.48 samples/sec   Loss 0.4084 Epoch: 15   Global Step: 29200   Required: 5 hours
Training: 2025-08-30 15:04:44,497-Speed 370.52 samples/sec   Loss 0.4221 Epoch: 15   Global Step: 29250   Required: 5 hours
Training: 2025-08-30 15:05:01,769-Speed 370.53 samples/sec   Loss 0.4493 Epoch: 15   Global Step: 29300   Required: 5 hours
Training: 2025-08-30 15:05:19,045-Speed 370.48 samples/sec   Loss 0.4411 Epoch: 15   Global Step: 29350   Required: 5 hours
Training: 2025-08-30 15:05:36,328-Speed 370.30 samples/sec   Loss 0.4036 Epoch: 15   Global Step: 29400   Required: 5 hours
Training: 2025-08-30 15:05:53,606-Speed 370.41 samples/sec   Loss 0.4414 Epoch: 15   Global Step: 29450   Required: 5 hours
Training: 2025-08-30 15:06:10,882-Speed 370.46 samples/sec   Loss 0.4046 Epoch: 15   Global Step: 29500   Required: 5 hours
Training: 2025-08-30 15:06:28,158-Speed 370.46 samples/sec   Loss 0.4397 Epoch: 15   Global Step: 29550   Required: 5 hours
Training: 2025-08-30 15:06:45,436-Speed 370.43 samples/sec   Loss 0.4360 Epoch: 15   Global Step: 29600   Required: 5 hours
Training: 2025-08-30 15:07:02,713-Speed 370.44 samples/sec   Loss 0.4065 Epoch: 15   Global Step: 29650   Required: 5 hours
Training: 2025-08-30 15:07:19,986-Speed 370.52 samples/sec   Loss 0.4205 Epoch: 15   Global Step: 29700   Required: 5 hours
Training: 2025-08-30 15:07:37,262-Speed 370.46 samples/sec   Loss 0.4371 Epoch: 15   Global Step: 29750   Required: 5 hours
Training: 2025-08-30 15:07:54,542-Speed 370.38 samples/sec   Loss 0.4430 Epoch: 15   Global Step: 29800   Required: 5 hours
Training: 2025-08-30 15:08:11,823-Speed 370.35 samples/sec   Loss 0.4609 Epoch: 15   Global Step: 29850   Required: 5 hours
Training: 2025-08-30 15:08:29,100-Speed 370.43 samples/sec   Loss 0.4433 Epoch: 15   Global Step: 29900   Required: 5 hours
Training: 2025-08-30 15:08:46,378-Speed 370.42 samples/sec   Loss 0.4092 Epoch: 15   Global Step: 29950   Required: 5 hours
Training: 2025-08-30 15:09:22,467-[lfw][29984]XNorm: 15.148112
Training: 2025-08-30 15:09:22,467-[lfw][29984]Accuracy-Flip: 0.79517+-0.01539
Training: 2025-08-30 15:09:22,467-[lfw][29984]Accuracy-Highest: 0.82750
Training: 2025-08-30 15:09:50,802-[cfp_fp][29984]XNorm: 13.501801
Training: 2025-08-30 15:09:50,802-[cfp_fp][29984]Accuracy-Flip: 0.64757+-0.01650
Training: 2025-08-30 15:09:50,802-[cfp_fp][29984]Accuracy-Highest: 0.65243
Training: 2025-08-30 15:10:15,168-[agedb_30][29984]XNorm: 15.691623
Training: 2025-08-30 15:10:15,168-[agedb_30][29984]Accuracy-Flip: 0.52233+-0.01832
Training: 2025-08-30 15:10:15,168-[agedb_30][29984]Accuracy-Highest: 0.54117
Training: 2025-08-30 15:10:39,592-[calfw][29984]XNorm: 15.850768
Training: 2025-08-30 15:10:39,592-[calfw][29984]Accuracy-Flip: 0.64483+-0.01503
Training: 2025-08-30 15:10:39,592-[calfw][29984]Accuracy-Highest: 0.66850
Training: 2025-08-30 15:11:03,999-[cplfw][29984]XNorm: 12.369701
Training: 2025-08-30 15:11:03,999-[cplfw][29984]Accuracy-Flip: 0.61417+-0.01808
Training: 2025-08-30 15:11:03,999-[cplfw][29984]Accuracy-Highest: 0.64217
Training: 2025-08-30 15:11:09,706-Speed 44.65 samples/sec   Loss 0.4091 Epoch: 16   Global Step: 30000   Required: 5 hours
Training: 2025-08-30 15:11:26,969-Speed 370.75 samples/sec   Loss 0.3705 Epoch: 16   Global Step: 30050   Required: 5 hours
Training: 2025-08-30 15:11:44,231-Speed 370.74 samples/sec   Loss 0.3692 Epoch: 16   Global Step: 30100   Required: 5 hours
Training: 2025-08-30 15:12:01,501-Speed 370.60 samples/sec   Loss 0.3639 Epoch: 16   Global Step: 30150   Required: 5 hours
Training: 2025-08-30 15:12:18,775-Speed 370.50 samples/sec   Loss 0.3685 Epoch: 16   Global Step: 30200   Required: 5 hours
Training: 2025-08-30 15:12:36,052-Speed 370.42 samples/sec   Loss 0.3608 Epoch: 16   Global Step: 30250   Required: 5 hours
Training: 2025-08-30 15:12:53,332-Speed 370.38 samples/sec   Loss 0.3709 Epoch: 16   Global Step: 30300   Required: 5 hours
Training: 2025-08-30 15:13:10,608-Speed 370.45 samples/sec   Loss 0.3791 Epoch: 16   Global Step: 30350   Required: 5 hours
Training: 2025-08-30 15:13:27,895-Speed 370.23 samples/sec   Loss 0.3709 Epoch: 16   Global Step: 30400   Required: 5 hours
Training: 2025-08-30 15:13:45,180-Speed 370.27 samples/sec   Loss 0.3864 Epoch: 16   Global Step: 30450   Required: 5 hours
Training: 2025-08-30 15:14:02,469-Speed 370.19 samples/sec   Loss 0.3987 Epoch: 16   Global Step: 30500   Required: 5 hours
Training: 2025-08-30 15:14:19,753-Speed 370.29 samples/sec   Loss 0.3776 Epoch: 16   Global Step: 30550   Required: 5 hours
Training: 2025-08-30 15:14:37,032-Speed 370.38 samples/sec   Loss 0.3802 Epoch: 16   Global Step: 30600   Required: 5 hours
Training: 2025-08-30 15:14:54,320-Speed 370.21 samples/sec   Loss 0.4059 Epoch: 16   Global Step: 30650   Required: 5 hours
Training: 2025-08-30 15:15:11,607-Speed 370.22 samples/sec   Loss 0.4003 Epoch: 16   Global Step: 30700   Required: 5 hours
Training: 2025-08-30 15:15:28,891-Speed 370.29 samples/sec   Loss 0.3890 Epoch: 16   Global Step: 30750   Required: 5 hours
Training: 2025-08-30 15:15:46,173-Speed 370.33 samples/sec   Loss 0.3943 Epoch: 16   Global Step: 30800   Required: 5 hours
Training: 2025-08-30 15:16:03,454-Speed 370.35 samples/sec   Loss 0.3776 Epoch: 16   Global Step: 30850   Required: 5 hours
Training: 2025-08-30 15:16:20,735-Speed 370.35 samples/sec   Loss 0.4273 Epoch: 16   Global Step: 30900   Required: 5 hours
Training: 2025-08-30 15:16:38,024-Speed 370.20 samples/sec   Loss 0.4162 Epoch: 16   Global Step: 30950   Required: 5 hours
Training: 2025-08-30 15:16:55,311-Speed 370.20 samples/sec   Loss 0.3849 Epoch: 16   Global Step: 31000   Required: 5 hours
Training: 2025-08-30 15:17:12,595-Speed 370.30 samples/sec   Loss 0.4156 Epoch: 16   Global Step: 31050   Required: 5 hours
Training: 2025-08-30 15:17:29,878-Speed 370.32 samples/sec   Loss 0.3801 Epoch: 16   Global Step: 31100   Required: 5 hours
Training: 2025-08-30 15:17:47,158-Speed 370.37 samples/sec   Loss 0.4280 Epoch: 16   Global Step: 31150   Required: 5 hours
Training: 2025-08-30 15:18:04,441-Speed 370.31 samples/sec   Loss 0.4351 Epoch: 16   Global Step: 31200   Required: 5 hours
Training: 2025-08-30 15:18:21,723-Speed 370.33 samples/sec   Loss 0.3989 Epoch: 16   Global Step: 31250   Required: 5 hours
Training: 2025-08-30 15:18:39,009-Speed 370.24 samples/sec   Loss 0.4134 Epoch: 16   Global Step: 31300   Required: 5 hours
Training: 2025-08-30 15:18:56,301-Speed 370.12 samples/sec   Loss 0.4171 Epoch: 16   Global Step: 31350   Required: 5 hours
Training: 2025-08-30 15:19:13,582-Speed 370.34 samples/sec   Loss 0.3995 Epoch: 16   Global Step: 31400   Required: 5 hours
Training: 2025-08-30 15:19:30,871-Speed 370.19 samples/sec   Loss 0.4184 Epoch: 16   Global Step: 31450   Required: 5 hours
Training: 2025-08-30 15:19:48,164-Speed 370.08 samples/sec   Loss 0.4342 Epoch: 16   Global Step: 31500   Required: 5 hours
Training: 2025-08-30 15:20:05,457-Speed 370.11 samples/sec   Loss 0.3891 Epoch: 16   Global Step: 31550   Required: 5 hours
Training: 2025-08-30 15:20:22,746-Speed 370.17 samples/sec   Loss 0.3933 Epoch: 16   Global Step: 31600   Required: 5 hours
Training: 2025-08-30 15:20:40,037-Speed 370.14 samples/sec   Loss 0.4280 Epoch: 16   Global Step: 31650   Required: 5 hours
Training: 2025-08-30 15:20:57,326-Speed 370.18 samples/sec   Loss 0.4568 Epoch: 16   Global Step: 31700   Required: 5 hours
Training: 2025-08-30 15:21:14,612-Speed 370.25 samples/sec   Loss 0.4205 Epoch: 16   Global Step: 31750   Required: 5 hours
Training: 2025-08-30 15:21:31,901-Speed 370.17 samples/sec   Loss 0.3970 Epoch: 16   Global Step: 31800   Required: 5 hours
Training: 2025-08-30 15:21:49,192-Speed 370.16 samples/sec   Loss 0.4400 Epoch: 16   Global Step: 31850   Required: 5 hours
Training: 2025-08-30 15:22:16,304-[lfw][31858]XNorm: 17.376695
Training: 2025-08-30 15:22:16,304-[lfw][31858]Accuracy-Flip: 0.80000+-0.01348
Training: 2025-08-30 15:22:16,304-[lfw][31858]Accuracy-Highest: 0.82750
Training: 2025-08-30 15:22:44,691-[cfp_fp][31858]XNorm: 15.025386
Training: 2025-08-30 15:22:44,692-[cfp_fp][31858]Accuracy-Flip: 0.63957+-0.01787
Training: 2025-08-30 15:22:44,692-[cfp_fp][31858]Accuracy-Highest: 0.65243
Training: 2025-08-30 15:23:09,031-[agedb_30][31858]XNorm: 14.335876
Training: 2025-08-30 15:23:09,031-[agedb_30][31858]Accuracy-Flip: 0.52517+-0.01473
Training: 2025-08-30 15:23:09,031-[agedb_30][31858]Accuracy-Highest: 0.54117
Training: 2025-08-30 15:23:33,465-[calfw][31858]XNorm: 17.232663
Training: 2025-08-30 15:23:33,466-[calfw][31858]Accuracy-Flip: 0.65917+-0.01387
Training: 2025-08-30 15:23:33,466-[calfw][31858]Accuracy-Highest: 0.66850
Training: 2025-08-30 15:23:57,877-[cplfw][31858]XNorm: 13.851635
Training: 2025-08-30 15:23:57,877-[cplfw][31858]Accuracy-Flip: 0.61133+-0.00942
Training: 2025-08-30 15:23:57,877-[cplfw][31858]Accuracy-Highest: 0.64217
Training: 2025-08-30 15:24:12,558-Speed 44.64 samples/sec   Loss 0.3172 Epoch: 17   Global Step: 31900   Required: 5 hours
Training: 2025-08-30 15:24:29,826-Speed 370.63 samples/sec   Loss 0.3502 Epoch: 17   Global Step: 31950   Required: 5 hours
Training: 2025-08-30 15:24:47,101-Speed 370.48 samples/sec   Loss 0.3298 Epoch: 17   Global Step: 32000   Required: 5 hours
Training: 2025-08-30 15:25:04,383-Speed 370.34 samples/sec   Loss 0.3309 Epoch: 17   Global Step: 32050   Required: 5 hours
Training: 2025-08-30 15:25:21,664-Speed 370.34 samples/sec   Loss 0.3702 Epoch: 17   Global Step: 32100   Required: 5 hours
Training: 2025-08-30 15:25:38,948-Speed 370.29 samples/sec   Loss 0.3456 Epoch: 17   Global Step: 32150   Required: 5 hours
Training: 2025-08-30 15:25:56,231-Speed 370.31 samples/sec   Loss 0.3751 Epoch: 17   Global Step: 32200   Required: 5 hours
Training: 2025-08-30 15:26:13,512-Speed 370.36 samples/sec   Loss 0.3806 Epoch: 17   Global Step: 32250   Required: 5 hours
Training: 2025-08-30 15:26:30,795-Speed 370.31 samples/sec   Loss 0.3623 Epoch: 17   Global Step: 32300   Required: 5 hours
Training: 2025-08-30 15:26:48,077-Speed 370.33 samples/sec   Loss 0.3780 Epoch: 17   Global Step: 32350   Required: 5 hours
Training: 2025-08-30 15:27:05,360-Speed 370.29 samples/sec   Loss 0.3880 Epoch: 17   Global Step: 32400   Required: 5 hours
Training: 2025-08-30 15:27:22,643-Speed 370.32 samples/sec   Loss 0.3767 Epoch: 17   Global Step: 32450   Required: 5 hours
Training: 2025-08-30 15:27:39,930-Speed 370.22 samples/sec   Loss 0.3701 Epoch: 17   Global Step: 32500   Required: 5 hours
Training: 2025-08-30 15:27:57,217-Speed 370.22 samples/sec   Loss 0.3975 Epoch: 17   Global Step: 32550   Required: 5 hours
Training: 2025-08-30 15:28:14,502-Speed 370.26 samples/sec   Loss 0.3842 Epoch: 17   Global Step: 32600   Required: 5 hours
Training: 2025-08-30 15:28:31,793-Speed 370.13 samples/sec   Loss 0.3725 Epoch: 17   Global Step: 32650   Required: 5 hours
Training: 2025-08-30 15:28:49,081-Speed 370.21 samples/sec   Loss 0.4020 Epoch: 17   Global Step: 32700   Required: 5 hours
Training: 2025-08-30 15:29:06,369-Speed 370.21 samples/sec   Loss 0.4059 Epoch: 17   Global Step: 32750   Required: 5 hours
Training: 2025-08-30 15:29:23,658-Speed 370.19 samples/sec   Loss 0.4014 Epoch: 17   Global Step: 32800   Required: 5 hours
Training: 2025-08-30 15:29:40,941-Speed 370.29 samples/sec   Loss 0.4224 Epoch: 17   Global Step: 32850   Required: 5 hours
Training: 2025-08-30 15:29:58,219-Speed 370.42 samples/sec   Loss 0.3914 Epoch: 17   Global Step: 32900   Required: 5 hours
Training: 2025-08-30 15:30:15,498-Speed 370.40 samples/sec   Loss 0.4147 Epoch: 17   Global Step: 32950   Required: 5 hours
Training: 2025-08-30 15:30:32,778-Speed 370.37 samples/sec   Loss 0.4089 Epoch: 17   Global Step: 33000   Required: 5 hours
Training: 2025-08-30 15:30:50,062-Speed 370.28 samples/sec   Loss 0.3794 Epoch: 17   Global Step: 33050   Required: 5 hours
Training: 2025-08-30 15:31:07,350-Speed 370.19 samples/sec   Loss 0.4014 Epoch: 17   Global Step: 33100   Required: 5 hours
Training: 2025-08-30 15:31:24,633-Speed 370.31 samples/sec   Loss 0.4010 Epoch: 17   Global Step: 33150   Required: 5 hours
Training: 2025-08-30 15:31:41,913-Speed 370.37 samples/sec   Loss 0.4029 Epoch: 17   Global Step: 33200   Required: 5 hours
Training: 2025-08-30 15:31:59,197-Speed 370.29 samples/sec   Loss 0.3971 Epoch: 17   Global Step: 33250   Required: 5 hours
Training: 2025-08-30 15:32:16,483-Speed 370.25 samples/sec   Loss 0.4135 Epoch: 17   Global Step: 33300   Required: 5 hours
Training: 2025-08-30 15:32:33,770-Speed 370.23 samples/sec   Loss 0.3891 Epoch: 17   Global Step: 33350   Required: 5 hours
Training: 2025-08-30 15:32:51,055-Speed 370.27 samples/sec   Loss 0.4079 Epoch: 17   Global Step: 33400   Required: 5 hours
Training: 2025-08-30 15:33:08,343-Speed 370.20 samples/sec   Loss 0.4006 Epoch: 17   Global Step: 33450   Required: 5 hours
Training: 2025-08-30 15:33:25,627-Speed 370.29 samples/sec   Loss 0.4009 Epoch: 17   Global Step: 33500   Required: 5 hours
Training: 2025-08-30 15:33:42,916-Speed 370.17 samples/sec   Loss 0.4490 Epoch: 17   Global Step: 33550   Required: 5 hours
Training: 2025-08-30 15:34:00,198-Speed 370.33 samples/sec   Loss 0.4060 Epoch: 17   Global Step: 33600   Required: 5 hours
Training: 2025-08-30 15:34:17,479-Speed 370.36 samples/sec   Loss 0.3957 Epoch: 17   Global Step: 33650   Required: 5 hours
Training: 2025-08-30 15:34:34,756-Speed 370.43 samples/sec   Loss 0.4198 Epoch: 17   Global Step: 33700   Required: 5 hours
Training: 2025-08-30 15:35:10,139-[lfw][33732]XNorm: 16.941435
Training: 2025-08-30 15:35:10,139-[lfw][33732]Accuracy-Flip: 0.79700+-0.02016
Training: 2025-08-30 15:35:10,139-[lfw][33732]Accuracy-Highest: 0.82750
Training: 2025-08-30 15:35:38,434-[cfp_fp][33732]XNorm: 15.506138
Training: 2025-08-30 15:35:38,434-[cfp_fp][33732]Accuracy-Flip: 0.65900+-0.01845
Training: 2025-08-30 15:35:38,434-[cfp_fp][33732]Accuracy-Highest: 0.65900
Training: 2025-08-30 15:36:02,755-[agedb_30][33732]XNorm: 15.421145
Training: 2025-08-30 15:36:02,755-[agedb_30][33732]Accuracy-Flip: 0.52667+-0.01769
Training: 2025-08-30 15:36:02,755-[agedb_30][33732]Accuracy-Highest: 0.54117
Training: 2025-08-30 15:36:27,169-[calfw][33732]XNorm: 17.539437
Training: 2025-08-30 15:36:27,169-[calfw][33732]Accuracy-Flip: 0.64833+-0.01402
Training: 2025-08-30 15:36:27,169-[calfw][33732]Accuracy-Highest: 0.66850
Training: 2025-08-30 15:36:51,573-[cplfw][33732]XNorm: 14.185391
Training: 2025-08-30 15:36:51,573-[cplfw][33732]Accuracy-Flip: 0.60933+-0.01234
Training: 2025-08-30 15:36:51,573-[cplfw][33732]Accuracy-Highest: 0.64217
Training: 2025-08-30 15:36:57,932-Speed 44.70 samples/sec   Loss 0.3921 Epoch: 18   Global Step: 33750   Required: 5 hours
Training: 2025-08-30 15:37:15,198-Speed 370.68 samples/sec   Loss 0.3600 Epoch: 18   Global Step: 33800   Required: 5 hours
Training: 2025-08-30 15:37:32,466-Speed 370.64 samples/sec   Loss 0.3430 Epoch: 18   Global Step: 33850   Required: 5 hours
Training: 2025-08-30 15:37:49,739-Speed 370.52 samples/sec   Loss 0.3471 Epoch: 18   Global Step: 33900   Required: 5 hours
Training: 2025-08-30 15:38:07,014-Speed 370.49 samples/sec   Loss 0.3009 Epoch: 18   Global Step: 33950   Required: 5 hours
Training: 2025-08-30 15:38:24,291-Speed 370.43 samples/sec   Loss 0.3310 Epoch: 18   Global Step: 34000   Required: 5 hours
Training: 2025-08-30 15:38:41,575-Speed 370.29 samples/sec   Loss 0.3671 Epoch: 18   Global Step: 34050   Required: 5 hours
Training: 2025-08-30 15:38:58,863-Speed 370.19 samples/sec   Loss 0.3587 Epoch: 18   Global Step: 34100   Required: 5 hours
Training: 2025-08-30 15:39:16,154-Speed 370.14 samples/sec   Loss 0.3342 Epoch: 18   Global Step: 34150   Required: 5 hours
Training: 2025-08-30 15:39:33,445-Speed 370.13 samples/sec   Loss 0.3747 Epoch: 18   Global Step: 34200   Required: 5 hours
Training: 2025-08-30 15:39:50,737-Speed 370.11 samples/sec   Loss 0.3685 Epoch: 18   Global Step: 34250   Required: 5 hours
Training: 2025-08-30 15:40:08,034-Speed 370.02 samples/sec   Loss 0.3769 Epoch: 18   Global Step: 34300   Required: 5 hours
Training: 2025-08-30 15:40:25,329-Speed 370.04 samples/sec   Loss 0.3642 Epoch: 18   Global Step: 34350   Required: 5 hours
Training: 2025-08-30 15:40:42,626-Speed 370.02 samples/sec   Loss 0.3579 Epoch: 18   Global Step: 34400   Required: 5 hours
Training: 2025-08-30 15:40:59,922-Speed 370.03 samples/sec   Loss 0.3792 Epoch: 18   Global Step: 34450   Required: 5 hours
Training: 2025-08-30 15:41:17,220-Speed 369.98 samples/sec   Loss 0.3717 Epoch: 18   Global Step: 34500   Required: 5 hours
Training: 2025-08-30 15:41:34,524-Speed 369.87 samples/sec   Loss 0.3919 Epoch: 18   Global Step: 34550   Required: 5 hours
Training: 2025-08-30 15:41:51,822-Speed 369.98 samples/sec   Loss 0.3667 Epoch: 18   Global Step: 34600   Required: 5 hours
Training: 2025-08-30 15:42:09,127-Speed 369.85 samples/sec   Loss 0.3886 Epoch: 18   Global Step: 34650   Required: 5 hours
Training: 2025-08-30 15:42:26,430-Speed 369.87 samples/sec   Loss 0.3872 Epoch: 18   Global Step: 34700   Required: 5 hours
Training: 2025-08-30 15:42:43,732-Speed 369.90 samples/sec   Loss 0.3574 Epoch: 18   Global Step: 34750   Required: 5 hours
Training: 2025-08-30 15:43:01,034-Speed 369.90 samples/sec   Loss 0.3725 Epoch: 18   Global Step: 34800   Required: 5 hours
Training: 2025-08-30 15:43:18,337-Speed 369.88 samples/sec   Loss 0.4228 Epoch: 18   Global Step: 34850   Required: 5 hours
Training: 2025-08-30 15:43:35,638-Speed 369.92 samples/sec   Loss 0.3886 Epoch: 18   Global Step: 34900   Required: 5 hours
Training: 2025-08-30 15:43:52,934-Speed 370.03 samples/sec   Loss 0.3948 Epoch: 18   Global Step: 34950   Required: 5 hours
Training: 2025-08-30 15:44:10,232-Speed 369.98 samples/sec   Loss 0.3680 Epoch: 18   Global Step: 35000   Required: 5 hours
Training: 2025-08-30 15:44:27,529-Speed 370.01 samples/sec   Loss 0.3939 Epoch: 18   Global Step: 35050   Required: 5 hours
Training: 2025-08-30 15:44:44,826-Speed 370.02 samples/sec   Loss 0.4125 Epoch: 18   Global Step: 35100   Required: 5 hours
Training: 2025-08-30 15:45:02,121-Speed 370.05 samples/sec   Loss 0.4248 Epoch: 18   Global Step: 35150   Required: 5 hours
Training: 2025-08-30 15:45:19,415-Speed 370.08 samples/sec   Loss 0.3921 Epoch: 18   Global Step: 35200   Required: 5 hours
Training: 2025-08-30 15:45:36,716-Speed 369.93 samples/sec   Loss 0.4216 Epoch: 18   Global Step: 35250   Required: 5 hours
Training: 2025-08-30 15:45:54,009-Speed 370.09 samples/sec   Loss 0.3957 Epoch: 18   Global Step: 35300   Required: 5 hours
Training: 2025-08-30 15:46:11,301-Speed 370.13 samples/sec   Loss 0.4181 Epoch: 18   Global Step: 35350   Required: 5 hours
Training: 2025-08-30 15:46:28,592-Speed 370.14 samples/sec   Loss 0.4034 Epoch: 18   Global Step: 35400   Required: 5 hours
Training: 2025-08-30 15:46:45,885-Speed 370.09 samples/sec   Loss 0.4291 Epoch: 18   Global Step: 35450   Required: 4 hours
Training: 2025-08-30 15:47:03,171-Speed 370.24 samples/sec   Loss 0.3979 Epoch: 18   Global Step: 35500   Required: 4 hours
Training: 2025-08-30 15:47:20,460-Speed 370.19 samples/sec   Loss 0.4492 Epoch: 18   Global Step: 35550   Required: 4 hours
Training: 2025-08-30 15:47:37,749-Speed 370.18 samples/sec   Loss 0.4066 Epoch: 18   Global Step: 35600   Required: 4 hours
Training: 2025-08-30 15:48:04,174-[lfw][35606]XNorm: 16.180029
Training: 2025-08-30 15:48:04,174-[lfw][35606]Accuracy-Flip: 0.81533+-0.02194
Training: 2025-08-30 15:48:04,174-[lfw][35606]Accuracy-Highest: 0.82750
Training: 2025-08-30 15:48:32,599-[cfp_fp][35606]XNorm: 13.742861
Training: 2025-08-30 15:48:32,599-[cfp_fp][35606]Accuracy-Flip: 0.65543+-0.01833
Training: 2025-08-30 15:48:32,599-[cfp_fp][35606]Accuracy-Highest: 0.65900
Training: 2025-08-30 15:48:56,920-[agedb_30][35606]XNorm: 15.149850
Training: 2025-08-30 15:48:56,920-[agedb_30][35606]Accuracy-Flip: 0.52500+-0.01794
Training: 2025-08-30 15:48:56,920-[agedb_30][35606]Accuracy-Highest: 0.54117
Training: 2025-08-30 15:49:21,340-[calfw][35606]XNorm: 16.563235
Training: 2025-08-30 15:49:21,341-[calfw][35606]Accuracy-Flip: 0.67050+-0.01333
Training: 2025-08-30 15:49:21,341-[calfw][35606]Accuracy-Highest: 0.67050
Training: 2025-08-30 15:49:45,751-[cplfw][35606]XNorm: 13.147069
Training: 2025-08-30 15:49:45,751-[cplfw][35606]Accuracy-Flip: 0.61650+-0.01107
Training: 2025-08-30 15:49:45,751-[cplfw][35606]Accuracy-Highest: 0.64217
Training: 2025-08-30 15:50:01,129-Speed 44.64 samples/sec   Loss 0.3145 Epoch: 19   Global Step: 35650   Required: 5 hours
Training: 2025-08-30 15:50:18,400-Speed 370.56 samples/sec   Loss 0.3412 Epoch: 19   Global Step: 35700   Required: 5 hours
Training: 2025-08-30 15:50:35,676-Speed 370.46 samples/sec   Loss 0.3173 Epoch: 19   Global Step: 35750   Required: 4 hours
Training: 2025-08-30 15:50:52,956-Speed 370.38 samples/sec   Loss 0.3355 Epoch: 19   Global Step: 35800   Required: 4 hours
Training: 2025-08-30 15:51:10,245-Speed 370.17 samples/sec   Loss 0.3333 Epoch: 19   Global Step: 35850   Required: 4 hours
Training: 2025-08-30 15:51:27,533-Speed 370.21 samples/sec   Loss 0.3415 Epoch: 19   Global Step: 35900   Required: 4 hours
Training: 2025-08-30 15:51:44,819-Speed 370.23 samples/sec   Loss 0.3472 Epoch: 19   Global Step: 35950   Required: 4 hours
Training: 2025-08-30 15:52:02,110-Speed 370.15 samples/sec   Loss 0.3415 Epoch: 19   Global Step: 36000   Required: 4 hours
Training: 2025-08-30 15:52:19,397-Speed 370.21 samples/sec   Loss 0.3337 Epoch: 19   Global Step: 36050   Required: 4 hours
Training: 2025-08-30 15:52:36,682-Speed 370.27 samples/sec   Loss 0.3345 Epoch: 19   Global Step: 36100   Required: 4 hours
Training: 2025-08-30 15:52:53,973-Speed 370.15 samples/sec   Loss 0.3705 Epoch: 19   Global Step: 36150   Required: 4 hours
Training: 2025-08-30 15:53:11,260-Speed 370.21 samples/sec   Loss 0.3948 Epoch: 19   Global Step: 36200   Required: 4 hours
Training: 2025-08-30 15:53:28,547-Speed 370.22 samples/sec   Loss 0.3585 Epoch: 19   Global Step: 36250   Required: 4 hours
Training: 2025-08-30 15:53:45,836-Speed 370.19 samples/sec   Loss 0.3577 Epoch: 19   Global Step: 36300   Required: 4 hours
Training: 2025-08-30 15:54:03,124-Speed 370.21 samples/sec   Loss 0.3625 Epoch: 19   Global Step: 36350   Required: 4 hours
Training: 2025-08-30 15:54:20,419-Speed 370.04 samples/sec   Loss 0.3694 Epoch: 19   Global Step: 36400   Required: 4 hours
Training: 2025-08-30 15:54:37,710-Speed 370.13 samples/sec   Loss 0.3596 Epoch: 19   Global Step: 36450   Required: 4 hours
Training: 2025-08-30 15:54:54,995-Speed 370.28 samples/sec   Loss 0.3674 Epoch: 19   Global Step: 36500   Required: 4 hours
Training: 2025-08-30 15:55:12,281-Speed 370.23 samples/sec   Loss 0.3674 Epoch: 19   Global Step: 36550   Required: 4 hours
Training: 2025-08-30 15:55:29,570-Speed 370.19 samples/sec   Loss 0.3547 Epoch: 19   Global Step: 36600   Required: 4 hours
Training: 2025-08-30 15:55:46,860-Speed 370.15 samples/sec   Loss 0.3542 Epoch: 19   Global Step: 36650   Required: 4 hours
Training: 2025-08-30 15:56:04,151-Speed 370.15 samples/sec   Loss 0.3664 Epoch: 19   Global Step: 36700   Required: 4 hours
Training: 2025-08-30 15:56:21,441-Speed 370.16 samples/sec   Loss 0.3631 Epoch: 19   Global Step: 36750   Required: 4 hours
Training: 2025-08-30 15:56:38,727-Speed 370.23 samples/sec   Loss 0.3819 Epoch: 19   Global Step: 36800   Required: 4 hours
Training: 2025-08-30 15:56:56,016-Speed 370.18 samples/sec   Loss 0.3841 Epoch: 19   Global Step: 36850   Required: 4 hours
Training: 2025-08-30 15:57:13,302-Speed 370.26 samples/sec   Loss 0.3453 Epoch: 19   Global Step: 36900   Required: 4 hours
Training: 2025-08-30 15:57:30,589-Speed 370.22 samples/sec   Loss 0.3669 Epoch: 19   Global Step: 36950   Required: 4 hours
Training: 2025-08-30 15:57:47,877-Speed 370.19 samples/sec   Loss 0.3950 Epoch: 19   Global Step: 37000   Required: 4 hours
Training: 2025-08-30 15:58:05,166-Speed 370.17 samples/sec   Loss 0.4004 Epoch: 19   Global Step: 37050   Required: 4 hours
Training: 2025-08-30 15:58:22,456-Speed 370.17 samples/sec   Loss 0.3712 Epoch: 19   Global Step: 37100   Required: 4 hours
Training: 2025-08-30 15:58:39,749-Speed 370.10 samples/sec   Loss 0.3715 Epoch: 19   Global Step: 37150   Required: 4 hours
Training: 2025-08-30 15:58:57,041-Speed 370.11 samples/sec   Loss 0.3925 Epoch: 19   Global Step: 37200   Required: 4 hours
Training: 2025-08-30 15:59:14,328-Speed 370.22 samples/sec   Loss 0.3731 Epoch: 19   Global Step: 37250   Required: 4 hours
Training: 2025-08-30 15:59:31,615-Speed 370.24 samples/sec   Loss 0.4230 Epoch: 19   Global Step: 37300   Required: 4 hours
Training: 2025-08-30 15:59:48,894-Speed 370.38 samples/sec   Loss 0.3797 Epoch: 19   Global Step: 37350   Required: 4 hours
Training: 2025-08-30 16:00:06,178-Speed 370.30 samples/sec   Loss 0.3754 Epoch: 19   Global Step: 37400   Required: 4 hours
Training: 2025-08-30 16:00:23,462-Speed 370.28 samples/sec   Loss 0.4023 Epoch: 19   Global Step: 37450   Required: 4 hours
Training: 2025-08-30 16:00:58,181-[lfw][37480]XNorm: 14.682995
Training: 2025-08-30 16:00:58,181-[lfw][37480]Accuracy-Flip: 0.82433+-0.01977
Training: 2025-08-30 16:00:58,181-[lfw][37480]Accuracy-Highest: 0.82750
Training: 2025-08-30 16:01:26,459-[cfp_fp][37480]XNorm: 13.323295
Training: 2025-08-30 16:01:26,459-[cfp_fp][37480]Accuracy-Flip: 0.64857+-0.01734
Training: 2025-08-30 16:01:26,459-[cfp_fp][37480]Accuracy-Highest: 0.65900
Training: 2025-08-30 16:01:50,790-[agedb_30][37480]XNorm: 14.098301
Training: 2025-08-30 16:01:50,790-[agedb_30][37480]Accuracy-Flip: 0.53317+-0.01475
Training: 2025-08-30 16:01:50,790-[agedb_30][37480]Accuracy-Highest: 0.54117
Training: 2025-08-30 16:02:15,213-[calfw][37480]XNorm: 15.296143
Training: 2025-08-30 16:02:15,214-[calfw][37480]Accuracy-Flip: 0.66650+-0.01074
Training: 2025-08-30 16:02:15,214-[calfw][37480]Accuracy-Highest: 0.67050
Training: 2025-08-30 16:02:39,627-[cplfw][37480]XNorm: 12.077754
Training: 2025-08-30 16:02:39,627-[cplfw][37480]Accuracy-Flip: 0.62933+-0.01705
Training: 2025-08-30 16:02:39,627-[cplfw][37480]Accuracy-Highest: 0.64217
Training: 2025-08-30 16:02:46,692-Speed 44.68 samples/sec   Loss 0.3945 Epoch: 20   Global Step: 37500   Required: 4 hours
Training: 2025-08-30 16:03:03,960-Speed 370.62 samples/sec   Loss 0.3189 Epoch: 20   Global Step: 37550   Required: 4 hours
Training: 2025-08-30 16:03:21,229-Speed 370.61 samples/sec   Loss 0.3310 Epoch: 20   Global Step: 37600   Required: 4 hours
Training: 2025-08-30 16:03:38,502-Speed 370.52 samples/sec   Loss 0.3508 Epoch: 20   Global Step: 37650   Required: 4 hours
Training: 2025-08-30 16:03:55,782-Speed 370.38 samples/sec   Loss 0.3394 Epoch: 20   Global Step: 37700   Required: 4 hours
Training: 2025-08-30 16:04:13,060-Speed 370.40 samples/sec   Loss 0.3347 Epoch: 20   Global Step: 37750   Required: 4 hours
Training: 2025-08-30 16:04:30,343-Speed 370.32 samples/sec   Loss 0.3449 Epoch: 20   Global Step: 37800   Required: 4 hours
Training: 2025-08-30 16:04:47,626-Speed 370.31 samples/sec   Loss 0.3501 Epoch: 20   Global Step: 37850   Required: 4 hours
Training: 2025-08-30 16:05:04,911-Speed 370.25 samples/sec   Loss 0.3659 Epoch: 20   Global Step: 37900   Required: 4 hours
Training: 2025-08-30 16:05:22,197-Speed 370.25 samples/sec   Loss 0.3484 Epoch: 20   Global Step: 37950   Required: 4 hours
Training: 2025-08-30 16:05:39,482-Speed 370.27 samples/sec   Loss 0.3424 Epoch: 20   Global Step: 38000   Required: 4 hours
Training: 2025-08-30 16:05:56,766-Speed 370.28 samples/sec   Loss 0.3363 Epoch: 20   Global Step: 38050   Required: 4 hours
Training: 2025-08-30 16:06:14,053-Speed 370.22 samples/sec   Loss 0.3503 Epoch: 20   Global Step: 38100   Required: 4 hours
Training: 2025-08-30 16:06:31,340-Speed 370.22 samples/sec   Loss 0.3384 Epoch: 20   Global Step: 38150   Required: 4 hours
Training: 2025-08-30 16:06:48,618-Speed 370.40 samples/sec   Loss 0.3518 Epoch: 20   Global Step: 38200   Required: 4 hours
Training: 2025-08-30 16:07:05,898-Speed 370.38 samples/sec   Loss 0.3585 Epoch: 20   Global Step: 38250   Required: 4 hours
Training: 2025-08-30 16:07:23,178-Speed 370.39 samples/sec   Loss 0.3521 Epoch: 20   Global Step: 38300   Required: 4 hours
Training: 2025-08-30 16:07:40,457-Speed 370.37 samples/sec   Loss 0.3781 Epoch: 20   Global Step: 38350   Required: 4 hours
Training: 2025-08-30 16:07:57,738-Speed 370.36 samples/sec   Loss 0.3535 Epoch: 20   Global Step: 38400   Required: 4 hours
Training: 2025-08-30 16:08:15,018-Speed 370.37 samples/sec   Loss 0.3614 Epoch: 20   Global Step: 38450   Required: 4 hours
Training: 2025-08-30 16:08:32,298-Speed 370.38 samples/sec   Loss 0.3571 Epoch: 20   Global Step: 38500   Required: 4 hours
Training: 2025-08-30 16:08:49,575-Speed 370.44 samples/sec   Loss 0.3442 Epoch: 20   Global Step: 38550   Required: 4 hours
Training: 2025-08-30 16:09:06,854-Speed 370.40 samples/sec   Loss 0.3692 Epoch: 20   Global Step: 38600   Required: 4 hours
Training: 2025-08-30 16:09:24,133-Speed 370.39 samples/sec   Loss 0.3733 Epoch: 20   Global Step: 38650   Required: 4 hours
Training: 2025-08-30 16:09:41,413-Speed 370.38 samples/sec   Loss 0.3852 Epoch: 20   Global Step: 38700   Required: 4 hours
Training: 2025-08-30 16:09:58,696-Speed 370.31 samples/sec   Loss 0.3697 Epoch: 20   Global Step: 38750   Required: 4 hours
Training: 2025-08-30 16:10:15,980-Speed 370.29 samples/sec   Loss 0.3806 Epoch: 20   Global Step: 38800   Required: 4 hours
Training: 2025-08-30 16:10:33,267-Speed 370.22 samples/sec   Loss 0.3902 Epoch: 20   Global Step: 38850   Required: 4 hours
Training: 2025-08-30 16:10:50,554-Speed 370.23 samples/sec   Loss 0.3589 Epoch: 20   Global Step: 38900   Required: 4 hours
Training: 2025-08-30 16:11:07,832-Speed 370.40 samples/sec   Loss 0.3793 Epoch: 20   Global Step: 38950   Required: 4 hours
Training: 2025-08-30 16:11:25,118-Speed 370.24 samples/sec   Loss 0.3490 Epoch: 20   Global Step: 39000   Required: 4 hours
Training: 2025-08-30 16:11:42,400-Speed 370.34 samples/sec   Loss 0.3529 Epoch: 20   Global Step: 39050   Required: 4 hours
Training: 2025-08-30 16:11:59,685-Speed 370.27 samples/sec   Loss 0.4249 Epoch: 20   Global Step: 39100   Required: 4 hours
Training: 2025-08-30 16:12:16,968-Speed 370.31 samples/sec   Loss 0.3923 Epoch: 20   Global Step: 39150   Required: 4 hours
Training: 2025-08-30 16:12:34,256-Speed 370.21 samples/sec   Loss 0.3721 Epoch: 20   Global Step: 39200   Required: 4 hours
Training: 2025-08-30 16:12:51,546-Speed 370.15 samples/sec   Loss 0.3597 Epoch: 20   Global Step: 39250   Required: 4 hours
Training: 2025-08-30 16:13:08,833-Speed 370.23 samples/sec   Loss 0.3575 Epoch: 20   Global Step: 39300   Required: 4 hours
Training: 2025-08-30 16:13:26,120-Speed 370.23 samples/sec   Loss 0.3819 Epoch: 20   Global Step: 39350   Required: 4 hours
Training: 2025-08-30 16:13:51,846-[lfw][39354]XNorm: 15.786562
Training: 2025-08-30 16:13:51,846-[lfw][39354]Accuracy-Flip: 0.79450+-0.01317
Training: 2025-08-30 16:13:51,846-[lfw][39354]Accuracy-Highest: 0.82750
Training: 2025-08-30 16:14:20,234-[cfp_fp][39354]XNorm: 13.660776
Training: 2025-08-30 16:14:20,234-[cfp_fp][39354]Accuracy-Flip: 0.63714+-0.02555
Training: 2025-08-30 16:14:20,234-[cfp_fp][39354]Accuracy-Highest: 0.65900
Training: 2025-08-30 16:14:44,572-[agedb_30][39354]XNorm: 14.120774
Training: 2025-08-30 16:14:44,572-[agedb_30][39354]Accuracy-Flip: 0.52583+-0.01814
Training: 2025-08-30 16:14:44,572-[agedb_30][39354]Accuracy-Highest: 0.54117
Training: 2025-08-30 16:15:08,998-[calfw][39354]XNorm: 16.061998
Training: 2025-08-30 16:15:08,998-[calfw][39354]Accuracy-Flip: 0.65533+-0.02221
Training: 2025-08-30 16:15:08,998-[calfw][39354]Accuracy-Highest: 0.67050
Training: 2025-08-30 16:15:33,412-[cplfw][39354]XNorm: 12.925087
Training: 2025-08-30 16:15:33,412-[cplfw][39354]Accuracy-Flip: 0.62017+-0.02040
Training: 2025-08-30 16:15:33,412-[cplfw][39354]Accuracy-Highest: 0.64217
Training: 2025-08-30 16:15:49,467-Speed 44.65 samples/sec   Loss 0.2160 Epoch: 21   Global Step: 39400   Required: 4 hours
Training: 2025-08-30 16:16:06,742-Speed 370.49 samples/sec   Loss 0.1084 Epoch: 21   Global Step: 39450   Required: 4 hours
Training: 2025-08-30 16:16:24,013-Speed 370.57 samples/sec   Loss 0.0882 Epoch: 21   Global Step: 39500   Required: 4 hours
Training: 2025-08-30 16:16:41,291-Speed 370.42 samples/sec   Loss 0.0689 Epoch: 21   Global Step: 39550   Required: 4 hours
Training: 2025-08-30 16:16:58,572-Speed 370.33 samples/sec   Loss 0.0520 Epoch: 21   Global Step: 39600   Required: 4 hours
Training: 2025-08-30 16:17:15,858-Speed 370.26 samples/sec   Loss 0.0526 Epoch: 21   Global Step: 39650   Required: 4 hours
Training: 2025-08-30 16:17:33,143-Speed 370.26 samples/sec   Loss 0.0457 Epoch: 21   Global Step: 39700   Required: 4 hours
Training: 2025-08-30 16:17:50,430-Speed 370.22 samples/sec   Loss 0.0429 Epoch: 21   Global Step: 39750   Required: 4 hours
Training: 2025-08-30 16:18:07,717-Speed 370.21 samples/sec   Loss 0.0326 Epoch: 21   Global Step: 39800   Required: 4 hours
Training: 2025-08-30 16:18:25,007-Speed 370.16 samples/sec   Loss 0.0381 Epoch: 21   Global Step: 39850   Required: 4 hours
Training: 2025-08-30 16:18:42,299-Speed 370.12 samples/sec   Loss 0.0320 Epoch: 21   Global Step: 39900   Required: 4 hours
Training: 2025-08-30 16:18:59,586-Speed 370.22 samples/sec   Loss 0.0371 Epoch: 21   Global Step: 39950   Required: 4 hours
Training: 2025-08-30 16:19:16,869-Speed 370.31 samples/sec   Loss 0.0369 Epoch: 21   Global Step: 40000   Required: 4 hours
Training: 2025-08-30 16:19:34,151-Speed 370.33 samples/sec   Loss 0.0288 Epoch: 21   Global Step: 40050   Required: 4 hours
Training: 2025-08-30 16:19:51,432-Speed 370.36 samples/sec   Loss 0.0383 Epoch: 21   Global Step: 40100   Required: 4 hours
Training: 2025-08-30 16:20:08,717-Speed 370.26 samples/sec   Loss 0.0330 Epoch: 21   Global Step: 40150   Required: 4 hours
Training: 2025-08-30 16:20:26,004-Speed 370.23 samples/sec   Loss 0.0258 Epoch: 21   Global Step: 40200   Required: 4 hours
Training: 2025-08-30 16:20:43,293-Speed 370.18 samples/sec   Loss 0.0213 Epoch: 21   Global Step: 40250   Required: 4 hours
Training: 2025-08-30 16:21:00,587-Speed 370.06 samples/sec   Loss 0.0245 Epoch: 21   Global Step: 40300   Required: 4 hours
Training: 2025-08-30 16:21:17,879-Speed 370.12 samples/sec   Loss 0.0200 Epoch: 21   Global Step: 40350   Required: 4 hours
Training: 2025-08-30 16:21:35,170-Speed 370.14 samples/sec   Loss 0.0214 Epoch: 21   Global Step: 40400   Required: 4 hours
Training: 2025-08-30 16:21:52,462-Speed 370.12 samples/sec   Loss 0.0186 Epoch: 21   Global Step: 40450   Required: 4 hours
Training: 2025-08-30 16:22:09,756-Speed 370.06 samples/sec   Loss 0.0244 Epoch: 21   Global Step: 40500   Required: 4 hours
Training: 2025-08-30 16:22:27,052-Speed 370.04 samples/sec   Loss 0.0244 Epoch: 21   Global Step: 40550   Required: 4 hours
Training: 2025-08-30 16:22:44,341-Speed 370.18 samples/sec   Loss 0.0237 Epoch: 21   Global Step: 40600   Required: 4 hours
Training: 2025-08-30 16:23:01,630-Speed 370.18 samples/sec   Loss 0.0215 Epoch: 21   Global Step: 40650   Required: 4 hours
Training: 2025-08-30 16:23:18,918-Speed 370.20 samples/sec   Loss 0.0187 Epoch: 21   Global Step: 40700   Required: 4 hours
Training: 2025-08-30 16:23:36,204-Speed 370.24 samples/sec   Loss 0.0154 Epoch: 21   Global Step: 40750   Required: 4 hours
Training: 2025-08-30 16:23:53,484-Speed 370.37 samples/sec   Loss 0.0202 Epoch: 21   Global Step: 40800   Required: 4 hours
Training: 2025-08-30 16:24:10,770-Speed 370.24 samples/sec   Loss 0.0195 Epoch: 21   Global Step: 40850   Required: 4 hours
Training: 2025-08-30 16:24:28,060-Speed 370.16 samples/sec   Loss 0.0137 Epoch: 21   Global Step: 40900   Required: 4 hours
Training: 2025-08-30 16:24:45,346-Speed 370.25 samples/sec   Loss 0.0210 Epoch: 21   Global Step: 40950   Required: 4 hours
Training: 2025-08-30 16:25:02,633-Speed 370.23 samples/sec   Loss 0.0123 Epoch: 21   Global Step: 41000   Required: 4 hours
Training: 2025-08-30 16:25:19,921-Speed 370.18 samples/sec   Loss 0.0188 Epoch: 21   Global Step: 41050   Required: 4 hours
Training: 2025-08-30 16:25:37,209-Speed 370.22 samples/sec   Loss 0.0189 Epoch: 21   Global Step: 41100   Required: 4 hours
Training: 2025-08-30 16:25:54,491-Speed 370.33 samples/sec   Loss 0.0208 Epoch: 21   Global Step: 41150   Required: 4 hours
Training: 2025-08-30 16:26:11,772-Speed 370.33 samples/sec   Loss 0.0196 Epoch: 21   Global Step: 41200   Required: 4 hours
Training: 2025-08-30 16:26:45,790-[lfw][41228]XNorm: 15.271746
Training: 2025-08-30 16:26:45,790-[lfw][41228]Accuracy-Flip: 0.83233+-0.02146
Training: 2025-08-30 16:26:45,790-[lfw][41228]Accuracy-Highest: 0.83233
Training: 2025-08-30 16:27:14,055-[cfp_fp][41228]XNorm: 13.065026
Training: 2025-08-30 16:27:14,055-[cfp_fp][41228]Accuracy-Flip: 0.65871+-0.02009
Training: 2025-08-30 16:27:14,055-[cfp_fp][41228]Accuracy-Highest: 0.65900
Training: 2025-08-30 16:27:38,380-[agedb_30][41228]XNorm: 13.343373
Training: 2025-08-30 16:27:38,381-[agedb_30][41228]Accuracy-Flip: 0.53017+-0.01630
Training: 2025-08-30 16:27:38,381-[agedb_30][41228]Accuracy-Highest: 0.54117
Training: 2025-08-30 16:28:02,796-[calfw][41228]XNorm: 15.533731
Training: 2025-08-30 16:28:02,796-[calfw][41228]Accuracy-Flip: 0.67700+-0.01621
Training: 2025-08-30 16:28:02,796-[calfw][41228]Accuracy-Highest: 0.67700
Training: 2025-08-30 16:28:27,196-[cplfw][41228]XNorm: 11.988466
Training: 2025-08-30 16:28:27,196-[cplfw][41228]Accuracy-Flip: 0.63800+-0.01451
Training: 2025-08-30 16:28:27,196-[cplfw][41228]Accuracy-Highest: 0.64217
Training: 2025-08-30 16:28:34,984-Speed 44.69 samples/sec   Loss 0.0146 Epoch: 22   Global Step: 41250   Required: 4 hours
Training: 2025-08-30 16:28:52,255-Speed 370.55 samples/sec   Loss 0.0064 Epoch: 22   Global Step: 41300   Required: 4 hours
Training: 2025-08-30 16:29:09,528-Speed 370.53 samples/sec   Loss 0.0078 Epoch: 22   Global Step: 41350   Required: 4 hours
Training: 2025-08-30 16:29:26,814-Speed 370.25 samples/sec   Loss 0.0075 Epoch: 22   Global Step: 41400   Required: 4 hours
Training: 2025-08-30 16:29:44,098-Speed 370.28 samples/sec   Loss 0.0057 Epoch: 22   Global Step: 41450   Required: 4 hours
Training: 2025-08-30 16:30:01,385-Speed 370.23 samples/sec   Loss 0.0067 Epoch: 22   Global Step: 41500   Required: 4 hours
Training: 2025-08-30 16:30:18,676-Speed 370.13 samples/sec   Loss 0.0072 Epoch: 22   Global Step: 41550   Required: 4 hours
Training: 2025-08-30 16:30:35,965-Speed 370.18 samples/sec   Loss 0.0090 Epoch: 22   Global Step: 41600   Required: 4 hours
Training: 2025-08-30 16:30:53,255-Speed 370.17 samples/sec   Loss 0.0064 Epoch: 22   Global Step: 41650   Required: 4 hours
Training: 2025-08-30 16:31:10,545-Speed 370.15 samples/sec   Loss 0.0084 Epoch: 22   Global Step: 41700   Required: 4 hours
Training: 2025-08-30 16:31:27,831-Speed 370.24 samples/sec   Loss 0.0078 Epoch: 22   Global Step: 41750   Required: 4 hours
Training: 2025-08-30 16:31:45,121-Speed 370.16 samples/sec   Loss 0.0098 Epoch: 22   Global Step: 41800   Required: 4 hours
Training: 2025-08-30 16:32:02,408-Speed 370.23 samples/sec   Loss 0.0051 Epoch: 22   Global Step: 41850   Required: 4 hours
Training: 2025-08-30 16:32:19,693-Speed 370.26 samples/sec   Loss 0.0080 Epoch: 22   Global Step: 41900   Required: 4 hours
Training: 2025-08-30 16:32:36,980-Speed 370.23 samples/sec   Loss 0.0073 Epoch: 22   Global Step: 41950   Required: 4 hours
Training: 2025-08-30 16:32:54,262-Speed 370.33 samples/sec   Loss 0.0067 Epoch: 22   Global Step: 42000   Required: 4 hours
Training: 2025-08-30 16:33:11,545-Speed 370.32 samples/sec   Loss 0.0068 Epoch: 22   Global Step: 42050   Required: 4 hours
Training: 2025-08-30 16:33:28,829-Speed 370.28 samples/sec   Loss 0.0099 Epoch: 22   Global Step: 42100   Required: 4 hours
Training: 2025-08-30 16:33:46,111-Speed 370.33 samples/sec   Loss 0.0053 Epoch: 22   Global Step: 42150   Required: 4 hours
Training: 2025-08-30 16:34:03,398-Speed 370.21 samples/sec   Loss 0.0070 Epoch: 22   Global Step: 42200   Required: 4 hours
Training: 2025-08-30 16:34:20,688-Speed 370.17 samples/sec   Loss 0.0064 Epoch: 22   Global Step: 42250   Required: 4 hours
Training: 2025-08-30 16:34:37,978-Speed 370.17 samples/sec   Loss 0.0080 Epoch: 22   Global Step: 42300   Required: 4 hours
Training: 2025-08-30 16:34:55,264-Speed 370.25 samples/sec   Loss 0.0070 Epoch: 22   Global Step: 42350   Required: 4 hours
Training: 2025-08-30 16:35:12,555-Speed 370.12 samples/sec   Loss 0.0078 Epoch: 22   Global Step: 42400   Required: 4 hours
Training: 2025-08-30 16:35:29,844-Speed 370.19 samples/sec   Loss 0.0056 Epoch: 22   Global Step: 42450   Required: 4 hours
Training: 2025-08-30 16:35:47,130-Speed 370.24 samples/sec   Loss 0.0069 Epoch: 22   Global Step: 42500   Required: 4 hours
Training: 2025-08-30 16:36:04,421-Speed 370.15 samples/sec   Loss 0.0053 Epoch: 22   Global Step: 42550   Required: 4 hours
Training: 2025-08-30 16:36:21,708-Speed 370.22 samples/sec   Loss 0.0052 Epoch: 22   Global Step: 42600   Required: 4 hours
Training: 2025-08-30 16:36:38,996-Speed 370.21 samples/sec   Loss 0.0057 Epoch: 22   Global Step: 42650   Required: 4 hours
Training: 2025-08-30 16:36:56,281-Speed 370.25 samples/sec   Loss 0.0052 Epoch: 22   Global Step: 42700   Required: 4 hours
Training: 2025-08-30 16:37:13,569-Speed 370.21 samples/sec   Loss 0.0075 Epoch: 22   Global Step: 42750   Required: 4 hours
Training: 2025-08-30 16:37:30,856-Speed 370.22 samples/sec   Loss 0.0047 Epoch: 22   Global Step: 42800   Required: 4 hours
Training: 2025-08-30 16:37:48,142-Speed 370.24 samples/sec   Loss 0.0051 Epoch: 22   Global Step: 42850   Required: 4 hours
Training: 2025-08-30 16:38:05,431-Speed 370.18 samples/sec   Loss 0.0062 Epoch: 22   Global Step: 42900   Required: 4 hours
Training: 2025-08-30 16:38:22,725-Speed 370.08 samples/sec   Loss 0.0045 Epoch: 22   Global Step: 42950   Required: 4 hours
Training: 2025-08-30 16:38:40,016-Speed 370.14 samples/sec   Loss 0.0072 Epoch: 22   Global Step: 43000   Required: 4 hours
Training: 2025-08-30 16:38:57,306-Speed 370.17 samples/sec   Loss 0.0075 Epoch: 22   Global Step: 43050   Required: 4 hours
Training: 2025-08-30 16:39:14,591-Speed 370.26 samples/sec   Loss 0.0074 Epoch: 22   Global Step: 43100   Required: 4 hours
Training: 2025-08-30 16:39:39,622-[lfw][43102]XNorm: 15.231853
Training: 2025-08-30 16:39:39,622-[lfw][43102]Accuracy-Flip: 0.83300+-0.01850
Training: 2025-08-30 16:39:39,622-[lfw][43102]Accuracy-Highest: 0.83300
Training: 2025-08-30 16:40:07,889-[cfp_fp][43102]XNorm: 13.172185
Training: 2025-08-30 16:40:07,889-[cfp_fp][43102]Accuracy-Flip: 0.65314+-0.02153
Training: 2025-08-30 16:40:07,889-[cfp_fp][43102]Accuracy-Highest: 0.65900
Training: 2025-08-30 16:40:32,209-[agedb_30][43102]XNorm: 13.309144
Training: 2025-08-30 16:40:32,209-[agedb_30][43102]Accuracy-Flip: 0.53467+-0.01706
Training: 2025-08-30 16:40:32,209-[agedb_30][43102]Accuracy-Highest: 0.54117
Training: 2025-08-30 16:40:56,626-[calfw][43102]XNorm: 15.512218
Training: 2025-08-30 16:40:56,626-[calfw][43102]Accuracy-Flip: 0.68583+-0.02073
Training: 2025-08-30 16:40:56,626-[calfw][43102]Accuracy-Highest: 0.68583
Training: 2025-08-30 16:41:21,023-[cplfw][43102]XNorm: 11.934912
Training: 2025-08-30 16:41:21,023-[cplfw][43102]Accuracy-Flip: 0.63850+-0.01212
Training: 2025-08-30 16:41:21,023-[cplfw][43102]Accuracy-Highest: 0.64217
Training: 2025-08-30 16:41:37,777-Speed 44.70 samples/sec   Loss 0.0049 Epoch: 23   Global Step: 43150   Required: 4 hours
Training: 2025-08-30 16:41:55,042-Speed 370.69 samples/sec   Loss 0.0034 Epoch: 23   Global Step: 43200   Required: 4 hours
Training: 2025-08-30 16:42:12,317-Speed 370.47 samples/sec   Loss 0.0044 Epoch: 23   Global Step: 43250   Required: 4 hours
Training: 2025-08-30 16:42:29,600-Speed 370.32 samples/sec   Loss 0.0032 Epoch: 23   Global Step: 43300   Required: 4 hours
Training: 2025-08-30 16:42:46,886-Speed 370.24 samples/sec   Loss 0.0056 Epoch: 23   Global Step: 43350   Required: 4 hours
Training: 2025-08-30 16:43:04,170-Speed 370.27 samples/sec   Loss 0.0064 Epoch: 23   Global Step: 43400   Required: 4 hours
Training: 2025-08-30 16:43:21,454-Speed 370.30 samples/sec   Loss 0.0044 Epoch: 23   Global Step: 43450   Required: 4 hours
Training: 2025-08-30 16:43:38,749-Speed 370.06 samples/sec   Loss 0.0038 Epoch: 23   Global Step: 43500   Required: 4 hours
Training: 2025-08-30 16:43:56,040-Speed 370.12 samples/sec   Loss 0.0040 Epoch: 23   Global Step: 43550   Required: 4 hours
Training: 2025-08-30 16:44:13,337-Speed 370.02 samples/sec   Loss 0.0034 Epoch: 23   Global Step: 43600   Required: 4 hours
Training: 2025-08-30 16:44:30,633-Speed 370.02 samples/sec   Loss 0.0056 Epoch: 23   Global Step: 43650   Required: 4 hours
Training: 2025-08-30 16:44:47,921-Speed 370.21 samples/sec   Loss 0.0071 Epoch: 23   Global Step: 43700   Required: 4 hours
Training: 2025-08-30 16:45:05,210-Speed 370.17 samples/sec   Loss 0.0049 Epoch: 23   Global Step: 43750   Required: 4 hours
Training: 2025-08-30 16:45:22,494-Speed 370.28 samples/sec   Loss 0.0034 Epoch: 23   Global Step: 43800   Required: 4 hours
Training: 2025-08-30 16:45:39,781-Speed 370.22 samples/sec   Loss 0.0035 Epoch: 23   Global Step: 43850   Required: 4 hours
Training: 2025-08-30 16:45:57,072-Speed 370.14 samples/sec   Loss 0.0044 Epoch: 23   Global Step: 43900   Required: 4 hours
Training: 2025-08-30 16:46:14,361-Speed 370.18 samples/sec   Loss 0.0038 Epoch: 23   Global Step: 43950   Required: 4 hours
Training: 2025-08-30 16:46:31,652-Speed 370.13 samples/sec   Loss 0.0024 Epoch: 23   Global Step: 44000   Required: 4 hours
Training: 2025-08-30 16:46:48,939-Speed 370.23 samples/sec   Loss 0.0038 Epoch: 23   Global Step: 44050   Required: 4 hours
Training: 2025-08-30 16:47:06,230-Speed 370.14 samples/sec   Loss 0.0036 Epoch: 23   Global Step: 44100   Required: 4 hours
Training: 2025-08-30 16:47:23,512-Speed 370.33 samples/sec   Loss 0.0052 Epoch: 23   Global Step: 44150   Required: 4 hours
Training: 2025-08-30 16:47:40,797-Speed 370.28 samples/sec   Loss 0.0047 Epoch: 23   Global Step: 44200   Required: 4 hours
Training: 2025-08-30 16:47:58,084-Speed 370.22 samples/sec   Loss 0.0038 Epoch: 23   Global Step: 44250   Required: 4 hours
Training: 2025-08-30 16:48:15,371-Speed 370.21 samples/sec   Loss 0.0033 Epoch: 23   Global Step: 44300   Required: 4 hours
Training: 2025-08-30 16:48:32,655-Speed 370.30 samples/sec   Loss 0.0028 Epoch: 23   Global Step: 44350   Required: 3 hours
Training: 2025-08-30 16:48:49,940-Speed 370.25 samples/sec   Loss 0.0033 Epoch: 23   Global Step: 44400   Required: 3 hours
Training: 2025-08-30 16:49:07,227-Speed 370.23 samples/sec   Loss 0.0037 Epoch: 23   Global Step: 44450   Required: 3 hours
Training: 2025-08-30 16:49:24,512-Speed 370.28 samples/sec   Loss 0.0035 Epoch: 23   Global Step: 44500   Required: 3 hours
Training: 2025-08-30 16:49:41,800-Speed 370.20 samples/sec   Loss 0.0029 Epoch: 23   Global Step: 44550   Required: 3 hours
Training: 2025-08-30 16:49:59,090-Speed 370.15 samples/sec   Loss 0.0037 Epoch: 23   Global Step: 44600   Required: 3 hours
Training: 2025-08-30 16:50:16,370-Speed 370.38 samples/sec   Loss 0.0046 Epoch: 23   Global Step: 44650   Required: 3 hours
Training: 2025-08-30 16:50:33,651-Speed 370.35 samples/sec   Loss 0.0044 Epoch: 23   Global Step: 44700   Required: 3 hours
Training: 2025-08-30 16:50:50,930-Speed 370.39 samples/sec   Loss 0.0044 Epoch: 23   Global Step: 44750   Required: 3 hours
Training: 2025-08-30 16:51:08,210-Speed 370.39 samples/sec   Loss 0.0029 Epoch: 23   Global Step: 44800   Required: 3 hours
Training: 2025-08-30 16:51:25,494-Speed 370.28 samples/sec   Loss 0.0039 Epoch: 23   Global Step: 44850   Required: 3 hours
Training: 2025-08-30 16:51:42,776-Speed 370.33 samples/sec   Loss 0.0052 Epoch: 23   Global Step: 44900   Required: 3 hours
Training: 2025-08-30 16:52:00,061-Speed 370.26 samples/sec   Loss 0.0038 Epoch: 23   Global Step: 44950   Required: 3 hours
Training: 2025-08-30 16:52:33,392-[lfw][44976]XNorm: 15.280275
Training: 2025-08-30 16:52:33,392-[lfw][44976]Accuracy-Flip: 0.83633+-0.01941
Training: 2025-08-30 16:52:33,392-[lfw][44976]Accuracy-Highest: 0.83633
Training: 2025-08-30 16:53:01,725-[cfp_fp][44976]XNorm: 13.204324
Training: 2025-08-30 16:53:01,726-[cfp_fp][44976]Accuracy-Flip: 0.64914+-0.02173
Training: 2025-08-30 16:53:01,726-[cfp_fp][44976]Accuracy-Highest: 0.65900
Training: 2025-08-30 16:53:26,042-[agedb_30][44976]XNorm: 13.232609
Training: 2025-08-30 16:53:26,042-[agedb_30][44976]Accuracy-Flip: 0.55033+-0.02257
Training: 2025-08-30 16:53:26,042-[agedb_30][44976]Accuracy-Highest: 0.55033
Training: 2025-08-30 16:53:50,454-[calfw][44976]XNorm: 15.510090
Training: 2025-08-30 16:53:50,454-[calfw][44976]Accuracy-Flip: 0.68067+-0.01826
Training: 2025-08-30 16:53:50,454-[calfw][44976]Accuracy-Highest: 0.68583
Training: 2025-08-30 16:54:14,849-[cplfw][44976]XNorm: 11.954363
Training: 2025-08-30 16:54:14,849-[cplfw][44976]Accuracy-Flip: 0.63700+-0.01693
Training: 2025-08-30 16:54:14,849-[cplfw][44976]Accuracy-Highest: 0.64217
Training: 2025-08-30 16:54:23,324-Speed 44.67 samples/sec   Loss 0.0024 Epoch: 24   Global Step: 45000   Required: 3 hours
Training: 2025-08-30 16:54:40,597-Speed 370.53 samples/sec   Loss 0.0032 Epoch: 24   Global Step: 45050   Required: 3 hours
Training: 2025-08-30 16:54:57,873-Speed 370.45 samples/sec   Loss 0.0029 Epoch: 24   Global Step: 45100   Required: 3 hours
Training: 2025-08-30 16:55:15,153-Speed 370.37 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 45150   Required: 3 hours
Training: 2025-08-30 16:55:32,433-Speed 370.36 samples/sec   Loss 0.0025 Epoch: 24   Global Step: 45200   Required: 3 hours
Training: 2025-08-30 16:55:49,719-Speed 370.24 samples/sec   Loss 0.0021 Epoch: 24   Global Step: 45250   Required: 3 hours
Training: 2025-08-30 16:56:07,003-Speed 370.28 samples/sec   Loss 0.0026 Epoch: 24   Global Step: 45300   Required: 3 hours
Training: 2025-08-30 16:56:24,291-Speed 370.22 samples/sec   Loss 0.0021 Epoch: 24   Global Step: 45350   Required: 3 hours
Training: 2025-08-30 16:56:41,582-Speed 370.13 samples/sec   Loss 0.0037 Epoch: 24   Global Step: 45400   Required: 3 hours
Training: 2025-08-30 16:56:58,870-Speed 370.21 samples/sec   Loss 0.0020 Epoch: 24   Global Step: 45450   Required: 3 hours
Training: 2025-08-30 16:57:16,153-Speed 370.31 samples/sec   Loss 0.0025 Epoch: 24   Global Step: 45500   Required: 3 hours
Training: 2025-08-30 16:57:33,435-Speed 370.32 samples/sec   Loss 0.0028 Epoch: 24   Global Step: 45550   Required: 3 hours
Training: 2025-08-30 16:57:50,718-Speed 370.31 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 45600   Required: 3 hours
Training: 2025-08-30 16:58:08,006-Speed 370.21 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 45650   Required: 3 hours
Training: 2025-08-30 16:58:25,294-Speed 370.19 samples/sec   Loss 0.0022 Epoch: 24   Global Step: 45700   Required: 3 hours
Training: 2025-08-30 16:58:42,585-Speed 370.15 samples/sec   Loss 0.0016 Epoch: 24   Global Step: 45750   Required: 3 hours
Training: 2025-08-30 16:58:59,866-Speed 370.35 samples/sec   Loss 0.0033 Epoch: 24   Global Step: 45800   Required: 3 hours
Training: 2025-08-30 16:59:17,150-Speed 370.29 samples/sec   Loss 0.0024 Epoch: 24   Global Step: 45850   Required: 3 hours
Training: 2025-08-30 16:59:34,437-Speed 370.21 samples/sec   Loss 0.0035 Epoch: 24   Global Step: 45900   Required: 3 hours
Training: 2025-08-30 16:59:51,726-Speed 370.19 samples/sec   Loss 0.0030 Epoch: 24   Global Step: 45950   Required: 3 hours
Training: 2025-08-30 17:00:09,012-Speed 370.23 samples/sec   Loss 0.0025 Epoch: 24   Global Step: 46000   Required: 3 hours
Training: 2025-08-30 17:00:26,303-Speed 370.15 samples/sec   Loss 0.0019 Epoch: 24   Global Step: 46050   Required: 3 hours
Training: 2025-08-30 17:00:43,591-Speed 370.20 samples/sec   Loss 0.0028 Epoch: 24   Global Step: 46100   Required: 3 hours
Training: 2025-08-30 17:01:00,882-Speed 370.13 samples/sec   Loss 0.0029 Epoch: 24   Global Step: 46150   Required: 3 hours
Training: 2025-08-30 17:01:18,175-Speed 370.09 samples/sec   Loss 0.0033 Epoch: 24   Global Step: 46200   Required: 3 hours
Training: 2025-08-30 17:01:35,464-Speed 370.17 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 46250   Required: 3 hours
Training: 2025-08-30 17:01:52,747-Speed 370.31 samples/sec   Loss 0.0028 Epoch: 24   Global Step: 46300   Required: 3 hours
Training: 2025-08-30 17:02:10,030-Speed 370.32 samples/sec   Loss 0.0021 Epoch: 24   Global Step: 46350   Required: 3 hours
Training: 2025-08-30 17:02:27,316-Speed 370.24 samples/sec   Loss 0.0029 Epoch: 24   Global Step: 46400   Required: 3 hours
Training: 2025-08-30 17:02:44,599-Speed 370.31 samples/sec   Loss 0.0030 Epoch: 24   Global Step: 46450   Required: 3 hours
Training: 2025-08-30 17:03:01,884-Speed 370.27 samples/sec   Loss 0.0020 Epoch: 24   Global Step: 46500   Required: 3 hours
Training: 2025-08-30 17:03:19,168-Speed 370.27 samples/sec   Loss 0.0023 Epoch: 24   Global Step: 46550   Required: 3 hours
Training: 2025-08-30 17:03:36,458-Speed 370.18 samples/sec   Loss 0.0017 Epoch: 24   Global Step: 46600   Required: 3 hours
Training: 2025-08-30 17:03:53,747-Speed 370.17 samples/sec   Loss 0.0025 Epoch: 24   Global Step: 46650   Required: 3 hours
Training: 2025-08-30 17:04:11,033-Speed 370.24 samples/sec   Loss 0.0022 Epoch: 24   Global Step: 46700   Required: 3 hours
Training: 2025-08-30 17:04:28,318-Speed 370.26 samples/sec   Loss 0.0024 Epoch: 24   Global Step: 46750   Required: 3 hours
Training: 2025-08-30 17:04:45,601-Speed 370.31 samples/sec   Loss 0.0024 Epoch: 24   Global Step: 46800   Required: 3 hours
Training: 2025-08-30 17:05:02,886-Speed 370.27 samples/sec   Loss 0.0025 Epoch: 24   Global Step: 46850   Required: 3 hours
Training: 2025-08-30 17:05:27,234-[lfw][46850]XNorm: 15.213462
Training: 2025-08-30 17:05:27,234-[lfw][46850]Accuracy-Flip: 0.83050+-0.01969
Training: 2025-08-30 17:05:27,234-[lfw][46850]Accuracy-Highest: 0.83633
Training: 2025-08-30 17:05:55,529-[cfp_fp][46850]XNorm: 13.175832
Training: 2025-08-30 17:05:55,529-[cfp_fp][46850]Accuracy-Flip: 0.65000+-0.02161
Training: 2025-08-30 17:05:55,529-[cfp_fp][46850]Accuracy-Highest: 0.65900
Training: 2025-08-30 17:06:19,859-[agedb_30][46850]XNorm: 13.260671
Training: 2025-08-30 17:06:19,859-[agedb_30][46850]Accuracy-Flip: 0.53417+-0.01703
Training: 2025-08-30 17:06:19,859-[agedb_30][46850]Accuracy-Highest: 0.55033
Training: 2025-08-30 17:06:44,281-[calfw][46850]XNorm: 15.468290
Training: 2025-08-30 17:06:44,281-[calfw][46850]Accuracy-Flip: 0.68300+-0.01976
Training: 2025-08-30 17:06:44,281-[calfw][46850]Accuracy-Highest: 0.68583
Training: 2025-08-30 17:07:08,684-[cplfw][46850]XNorm: 11.913701
Training: 2025-08-30 17:07:08,684-[cplfw][46850]Accuracy-Flip: 0.63867+-0.01560
Training: 2025-08-30 17:07:08,684-[cplfw][46850]Accuracy-Highest: 0.64217
Training: 2025-08-30 17:07:26,131-Speed 44.68 samples/sec   Loss 0.0021 Epoch: 25   Global Step: 46900   Required: 3 hours
Training: 2025-08-30 17:07:43,401-Speed 370.57 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 46950   Required: 3 hours
Training: 2025-08-30 17:08:00,678-Speed 370.45 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 47000   Required: 3 hours
Training: 2025-08-30 17:08:17,956-Speed 370.40 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 47050   Required: 3 hours
Training: 2025-08-30 17:08:35,240-Speed 370.30 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 47100   Required: 3 hours
Training: 2025-08-30 17:08:52,522-Speed 370.32 samples/sec   Loss 0.0030 Epoch: 25   Global Step: 47150   Required: 3 hours
Training: 2025-08-30 17:09:09,805-Speed 370.32 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 47200   Required: 3 hours
Training: 2025-08-30 17:09:27,090-Speed 370.27 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 47250   Required: 3 hours
Training: 2025-08-30 17:09:44,372-Speed 370.32 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 47300   Required: 3 hours
Training: 2025-08-30 17:10:01,661-Speed 370.17 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 47350   Required: 3 hours
Training: 2025-08-30 17:10:18,950-Speed 370.20 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 47400   Required: 3 hours
Training: 2025-08-30 17:10:36,236-Speed 370.23 samples/sec   Loss 0.0018 Epoch: 25   Global Step: 47450   Required: 3 hours
Training: 2025-08-30 17:10:53,522-Speed 370.25 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 47500   Required: 3 hours
Training: 2025-08-30 17:11:10,808-Speed 370.24 samples/sec   Loss 0.0020 Epoch: 25   Global Step: 47550   Required: 3 hours
Training: 2025-08-30 17:11:28,091-Speed 370.31 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 47600   Required: 3 hours
Training: 2025-08-30 17:11:45,378-Speed 370.23 samples/sec   Loss 0.0027 Epoch: 25   Global Step: 47650   Required: 3 hours
Training: 2025-08-30 17:12:02,662-Speed 370.27 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 47700   Required: 3 hours
Training: 2025-08-30 17:12:19,946-Speed 370.29 samples/sec   Loss 0.0027 Epoch: 25   Global Step: 47750   Required: 3 hours
Training: 2025-08-30 17:12:37,229-Speed 370.30 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 47800   Required: 3 hours
Training: 2025-08-30 17:12:54,517-Speed 370.21 samples/sec   Loss 0.0025 Epoch: 25   Global Step: 47850   Required: 3 hours
Training: 2025-08-30 17:13:11,802-Speed 370.26 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 47900   Required: 3 hours
Training: 2025-08-30 17:13:29,090-Speed 370.20 samples/sec   Loss 0.0021 Epoch: 25   Global Step: 47950   Required: 3 hours
Training: 2025-08-30 17:13:46,379-Speed 370.18 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 48000   Required: 3 hours
Training: 2025-08-30 17:14:03,668-Speed 370.17 samples/sec   Loss 0.0014 Epoch: 25   Global Step: 48050   Required: 3 hours
Training: 2025-08-30 17:14:20,955-Speed 370.23 samples/sec   Loss 0.0022 Epoch: 25   Global Step: 48100   Required: 3 hours
Training: 2025-08-30 17:14:38,238-Speed 370.30 samples/sec   Loss 0.0015 Epoch: 25   Global Step: 48150   Required: 3 hours
Training: 2025-08-30 17:14:55,526-Speed 370.21 samples/sec   Loss 0.0016 Epoch: 25   Global Step: 48200   Required: 3 hours
Training: 2025-08-30 17:15:12,813-Speed 370.22 samples/sec   Loss 0.0014 Epoch: 25   Global Step: 48250   Required: 3 hours
Training: 2025-08-30 17:15:30,102-Speed 370.18 samples/sec   Loss 0.0020 Epoch: 25   Global Step: 48300   Required: 3 hours
Training: 2025-08-30 17:15:47,395-Speed 370.10 samples/sec   Loss 0.0022 Epoch: 25   Global Step: 48350   Required: 3 hours
Training: 2025-08-30 17:16:04,688-Speed 370.10 samples/sec   Loss 0.0017 Epoch: 25   Global Step: 48400   Required: 3 hours
Training: 2025-08-30 17:16:21,972-Speed 370.27 samples/sec   Loss 0.0021 Epoch: 25   Global Step: 48450   Required: 3 hours
Training: 2025-08-30 17:16:39,258-Speed 370.26 samples/sec   Loss 0.0015 Epoch: 25   Global Step: 48500   Required: 3 hours
Training: 2025-08-30 17:16:56,544-Speed 370.25 samples/sec   Loss 0.0013 Epoch: 25   Global Step: 48550   Required: 3 hours
Training: 2025-08-30 17:17:13,830-Speed 370.23 samples/sec   Loss 0.0020 Epoch: 25   Global Step: 48600   Required: 3 hours
Training: 2025-08-30 17:17:31,118-Speed 370.21 samples/sec   Loss 0.0014 Epoch: 25   Global Step: 48650   Required: 3 hours
Training: 2025-08-30 17:17:48,403-Speed 370.26 samples/sec   Loss 0.0019 Epoch: 25   Global Step: 48700   Required: 3 hours
Training: 2025-08-30 17:18:21,038-[lfw][48724]XNorm: 15.285233
Training: 2025-08-30 17:18:21,038-[lfw][48724]Accuracy-Flip: 0.82750+-0.01800
Training: 2025-08-30 17:18:21,038-[lfw][48724]Accuracy-Highest: 0.83633
Training: 2025-08-30 17:18:49,324-[cfp_fp][48724]XNorm: 13.241309
Training: 2025-08-30 17:18:49,325-[cfp_fp][48724]Accuracy-Flip: 0.64900+-0.01711
Training: 2025-08-30 17:18:49,325-[cfp_fp][48724]Accuracy-Highest: 0.65900
Training: 2025-08-30 17:19:13,659-[agedb_30][48724]XNorm: 13.342840
Training: 2025-08-30 17:19:13,659-[agedb_30][48724]Accuracy-Flip: 0.53933+-0.01621
Training: 2025-08-30 17:19:13,659-[agedb_30][48724]Accuracy-Highest: 0.55033
Training: 2025-08-30 17:19:38,075-[calfw][48724]XNorm: 15.522474
Training: 2025-08-30 17:19:38,075-[calfw][48724]Accuracy-Flip: 0.68150+-0.01924
Training: 2025-08-30 17:19:38,076-[calfw][48724]Accuracy-Highest: 0.68583
Training: 2025-08-30 17:20:02,482-[cplfw][48724]XNorm: 12.010393
Training: 2025-08-30 17:20:02,482-[cplfw][48724]Accuracy-Flip: 0.64117+-0.01261
Training: 2025-08-30 17:20:02,482-[cplfw][48724]Accuracy-Highest: 0.64217
Training: 2025-08-30 17:20:11,630-Speed 44.68 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 48750   Required: 3 hours
Training: 2025-08-30 17:20:28,903-Speed 370.53 samples/sec   Loss 0.0021 Epoch: 26   Global Step: 48800   Required: 3 hours
Training: 2025-08-30 17:20:46,179-Speed 370.45 samples/sec   Loss 0.0015 Epoch: 26   Global Step: 48850   Required: 3 hours
Training: 2025-08-30 17:21:03,459-Speed 370.38 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 48900   Required: 3 hours
Training: 2025-08-30 17:21:20,747-Speed 370.21 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 48950   Required: 3 hours
Training: 2025-08-30 17:21:38,031-Speed 370.29 samples/sec   Loss 0.0024 Epoch: 26   Global Step: 49000   Required: 3 hours
Training: 2025-08-30 17:21:55,317-Speed 370.24 samples/sec   Loss 0.0017 Epoch: 26   Global Step: 49050   Required: 3 hours
Training: 2025-08-30 17:22:12,606-Speed 370.17 samples/sec   Loss 0.0019 Epoch: 26   Global Step: 49100   Required: 3 hours
Training: 2025-08-30 17:22:29,900-Speed 370.08 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 49150   Required: 3 hours
Training: 2025-08-30 17:22:47,188-Speed 370.21 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 49200   Required: 3 hours
Training: 2025-08-30 17:23:04,481-Speed 370.09 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 49250   Required: 3 hours
Training: 2025-08-30 17:23:21,770-Speed 370.18 samples/sec   Loss 0.0015 Epoch: 26   Global Step: 49300   Required: 3 hours
Training: 2025-08-30 17:23:39,056-Speed 370.24 samples/sec   Loss 0.0015 Epoch: 26   Global Step: 49350   Required: 3 hours
Training: 2025-08-30 17:23:56,342-Speed 370.25 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 49400   Required: 3 hours
Training: 2025-08-30 17:24:13,634-Speed 370.12 samples/sec   Loss 0.0023 Epoch: 26   Global Step: 49450   Required: 3 hours
Training: 2025-08-30 17:24:30,921-Speed 370.22 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 49500   Required: 3 hours
Training: 2025-08-30 17:24:48,205-Speed 370.29 samples/sec   Loss 0.0015 Epoch: 26   Global Step: 49550   Required: 3 hours
Training: 2025-08-30 17:25:05,490-Speed 370.27 samples/sec   Loss 0.0016 Epoch: 26   Global Step: 49600   Required: 3 hours
Training: 2025-08-30 17:25:22,778-Speed 370.20 samples/sec   Loss 0.0015 Epoch: 26   Global Step: 49650   Required: 3 hours
Training: 2025-08-30 17:25:40,065-Speed 370.22 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 49700   Required: 3 hours
Training: 2025-08-30 17:25:57,351-Speed 370.24 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 49750   Required: 3 hours
Training: 2025-08-30 17:26:14,636-Speed 370.27 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 49800   Required: 3 hours
Training: 2025-08-30 17:26:31,920-Speed 370.29 samples/sec   Loss 0.0018 Epoch: 26   Global Step: 49850   Required: 3 hours
Training: 2025-08-30 17:26:49,206-Speed 370.24 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 49900   Required: 3 hours
Training: 2025-08-30 17:27:06,493-Speed 370.24 samples/sec   Loss 0.0013 Epoch: 26   Global Step: 49950   Required: 3 hours
Training: 2025-08-30 17:27:23,780-Speed 370.21 samples/sec   Loss 0.0015 Epoch: 26   Global Step: 50000   Required: 3 hours
Training: 2025-08-30 17:27:41,065-Speed 370.27 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 50050   Required: 3 hours
Training: 2025-08-30 17:27:58,351-Speed 370.25 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 50100   Required: 3 hours
Training: 2025-08-30 17:28:15,631-Speed 370.35 samples/sec   Loss 0.0017 Epoch: 26   Global Step: 50150   Required: 3 hours
Training: 2025-08-30 17:28:32,914-Speed 370.32 samples/sec   Loss 0.0017 Epoch: 26   Global Step: 50200   Required: 3 hours
Training: 2025-08-30 17:28:50,201-Speed 370.22 samples/sec   Loss 0.0017 Epoch: 26   Global Step: 50250   Required: 3 hours
Training: 2025-08-30 17:29:07,487-Speed 370.24 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 50300   Required: 3 hours
Training: 2025-08-30 17:29:24,766-Speed 370.39 samples/sec   Loss 0.0016 Epoch: 26   Global Step: 50350   Required: 3 hours
Training: 2025-08-30 17:29:42,047-Speed 370.36 samples/sec   Loss 0.0031 Epoch: 26   Global Step: 50400   Required: 3 hours
Training: 2025-08-30 17:29:59,324-Speed 370.44 samples/sec   Loss 0.0014 Epoch: 26   Global Step: 50450   Required: 3 hours
Training: 2025-08-30 17:30:16,609-Speed 370.25 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 50500   Required: 3 hours
Training: 2025-08-30 17:30:33,888-Speed 370.40 samples/sec   Loss 0.0012 Epoch: 26   Global Step: 50550   Required: 3 hours
Training: 2025-08-30 17:31:14,822-[lfw][50598]XNorm: 15.158418
Training: 2025-08-30 17:31:14,822-[lfw][50598]Accuracy-Flip: 0.83300+-0.01833
Training: 2025-08-30 17:31:14,822-[lfw][50598]Accuracy-Highest: 0.83633
Training: 2025-08-30 17:31:43,088-[cfp_fp][50598]XNorm: 13.156292
Training: 2025-08-30 17:31:43,089-[cfp_fp][50598]Accuracy-Flip: 0.65414+-0.01946
Training: 2025-08-30 17:31:43,089-[cfp_fp][50598]Accuracy-Highest: 0.65900
Training: 2025-08-30 17:32:07,416-[agedb_30][50598]XNorm: 13.278951
Training: 2025-08-30 17:32:07,416-[agedb_30][50598]Accuracy-Flip: 0.53917+-0.01567
Training: 2025-08-30 17:32:07,416-[agedb_30][50598]Accuracy-Highest: 0.55033
Training: 2025-08-30 17:32:31,833-[calfw][50598]XNorm: 15.445232
Training: 2025-08-30 17:32:31,834-[calfw][50598]Accuracy-Flip: 0.68333+-0.01758
Training: 2025-08-30 17:32:31,834-[calfw][50598]Accuracy-Highest: 0.68583
Training: 2025-08-30 17:32:56,242-[cplfw][50598]XNorm: 11.910733
Training: 2025-08-30 17:32:56,242-[cplfw][50598]Accuracy-Flip: 0.64083+-0.01401
Training: 2025-08-30 17:32:56,242-[cplfw][50598]Accuracy-Highest: 0.64217
Training: 2025-08-30 17:32:57,121-Speed 44.68 samples/sec   Loss 0.0013 Epoch: 27   Global Step: 50600   Required: 3 hours
Training: 2025-08-30 17:33:14,383-Speed 370.75 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 50650   Required: 3 hours
Training: 2025-08-30 17:33:31,652-Speed 370.62 samples/sec   Loss 0.0015 Epoch: 27   Global Step: 50700   Required: 3 hours
Training: 2025-08-30 17:33:48,926-Speed 370.50 samples/sec   Loss 0.0017 Epoch: 27   Global Step: 50750   Required: 3 hours
Training: 2025-08-30 17:34:06,209-Speed 370.32 samples/sec   Loss 0.0014 Epoch: 27   Global Step: 50800   Required: 3 hours
Training: 2025-08-30 17:34:23,497-Speed 370.20 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 50850   Required: 3 hours
Training: 2025-08-30 17:34:40,786-Speed 370.17 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 50900   Required: 3 hours
Training: 2025-08-30 17:34:58,074-Speed 370.20 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 50950   Required: 3 hours
Training: 2025-08-30 17:35:15,368-Speed 370.08 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 51000   Required: 3 hours
Training: 2025-08-30 17:35:32,658-Speed 370.16 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 51050   Required: 3 hours
Training: 2025-08-30 17:35:49,943-Speed 370.25 samples/sec   Loss 0.0013 Epoch: 27   Global Step: 51100   Required: 3 hours
Training: 2025-08-30 17:36:07,233-Speed 370.18 samples/sec   Loss 0.0015 Epoch: 27   Global Step: 51150   Required: 3 hours
Training: 2025-08-30 17:36:24,515-Speed 370.32 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 51200   Required: 3 hours
Training: 2025-08-30 17:36:41,798-Speed 370.31 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 51250   Required: 3 hours
Training: 2025-08-30 17:36:59,078-Speed 370.37 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 51300   Required: 3 hours
Training: 2025-08-30 17:37:16,361-Speed 370.30 samples/sec   Loss 0.0014 Epoch: 27   Global Step: 51350   Required: 3 hours
Training: 2025-08-30 17:37:33,649-Speed 370.20 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 51400   Required: 3 hours
Training: 2025-08-30 17:37:50,935-Speed 370.25 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 51450   Required: 3 hours
Training: 2025-08-30 17:38:08,223-Speed 370.21 samples/sec   Loss 0.0013 Epoch: 27   Global Step: 51500   Required: 3 hours
Training: 2025-08-30 17:38:25,501-Speed 370.40 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 51550   Required: 3 hours
Training: 2025-08-30 17:38:42,785-Speed 370.29 samples/sec   Loss 0.0014 Epoch: 27   Global Step: 51600   Required: 3 hours
Training: 2025-08-30 17:39:00,067-Speed 370.32 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 51650   Required: 3 hours
Training: 2025-08-30 17:39:17,357-Speed 370.17 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 51700   Required: 3 hours
Training: 2025-08-30 17:39:34,643-Speed 370.24 samples/sec   Loss 0.0016 Epoch: 27   Global Step: 51750   Required: 3 hours
Training: 2025-08-30 17:39:51,928-Speed 370.27 samples/sec   Loss 0.0019 Epoch: 27   Global Step: 51800   Required: 3 hours
Training: 2025-08-30 17:40:09,213-Speed 370.27 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 51850   Required: 3 hours
Training: 2025-08-30 17:40:26,497-Speed 370.29 samples/sec   Loss 0.0016 Epoch: 27   Global Step: 51900   Required: 3 hours
Training: 2025-08-30 17:40:43,779-Speed 370.32 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 51950   Required: 3 hours
Training: 2025-08-30 17:41:01,067-Speed 370.20 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 52000   Required: 3 hours
Training: 2025-08-30 17:41:18,352-Speed 370.28 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 52050   Required: 3 hours
Training: 2025-08-30 17:41:35,634-Speed 370.32 samples/sec   Loss 0.0014 Epoch: 27   Global Step: 52100   Required: 3 hours
Training: 2025-08-30 17:41:52,913-Speed 370.40 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 52150   Required: 3 hours
Training: 2025-08-30 17:42:10,194-Speed 370.34 samples/sec   Loss 0.0013 Epoch: 27   Global Step: 52200   Required: 3 hours
Training: 2025-08-30 17:42:27,479-Speed 370.28 samples/sec   Loss 0.0010 Epoch: 27   Global Step: 52250   Required: 3 hours
Training: 2025-08-30 17:42:44,761-Speed 370.32 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 52300   Required: 3 hours
Training: 2025-08-30 17:43:02,043-Speed 370.32 samples/sec   Loss 0.0013 Epoch: 27   Global Step: 52350   Required: 3 hours
Training: 2025-08-30 17:43:19,324-Speed 370.35 samples/sec   Loss 0.0011 Epoch: 27   Global Step: 52400   Required: 3 hours
Training: 2025-08-30 17:43:36,611-Speed 370.24 samples/sec   Loss 0.0012 Epoch: 27   Global Step: 52450   Required: 3 hours
Training: 2025-08-30 17:44:08,561-[lfw][52472]XNorm: 15.240129
Training: 2025-08-30 17:44:08,561-[lfw][52472]Accuracy-Flip: 0.82333+-0.01721
Training: 2025-08-30 17:44:08,561-[lfw][52472]Accuracy-Highest: 0.83633
Training: 2025-08-30 17:44:36,895-[cfp_fp][52472]XNorm: 13.339318
Training: 2025-08-30 17:44:36,895-[cfp_fp][52472]Accuracy-Flip: 0.64900+-0.01774
Training: 2025-08-30 17:44:36,895-[cfp_fp][52472]Accuracy-Highest: 0.65900
Training: 2025-08-30 17:45:01,236-[agedb_30][52472]XNorm: 13.474306
Training: 2025-08-30 17:45:01,237-[agedb_30][52472]Accuracy-Flip: 0.54383+-0.01675
Training: 2025-08-30 17:45:01,237-[agedb_30][52472]Accuracy-Highest: 0.55033
Training: 2025-08-30 17:45:25,651-[calfw][52472]XNorm: 15.545300
Training: 2025-08-30 17:45:25,651-[calfw][52472]Accuracy-Flip: 0.68033+-0.01915
Training: 2025-08-30 17:45:25,651-[calfw][52472]Accuracy-Highest: 0.68583
Training: 2025-08-30 17:45:50,057-[cplfw][52472]XNorm: 11.988705
Training: 2025-08-30 17:45:50,057-[cplfw][52472]Accuracy-Flip: 0.63367+-0.01449
Training: 2025-08-30 17:45:50,057-[cplfw][52472]Accuracy-Highest: 0.64217
Training: 2025-08-30 17:45:59,917-Speed 44.66 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 52500   Required: 3 hours
Training: 2025-08-30 17:46:17,187-Speed 370.57 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 52550   Required: 3 hours
Training: 2025-08-30 17:46:34,465-Speed 370.42 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 52600   Required: 3 hours
Training: 2025-08-30 17:46:51,747-Speed 370.33 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 52650   Required: 3 hours
Training: 2025-08-30 17:47:09,032-Speed 370.25 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 52700   Required: 3 hours
Training: 2025-08-30 17:47:26,321-Speed 370.18 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 52750   Required: 3 hours
Training: 2025-08-30 17:47:43,612-Speed 370.14 samples/sec   Loss 0.0014 Epoch: 28   Global Step: 52800   Required: 3 hours
Training: 2025-08-30 17:48:00,901-Speed 370.18 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 52850   Required: 3 hours
Training: 2025-08-30 17:48:18,188-Speed 370.22 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 52900   Required: 3 hours
Training: 2025-08-30 17:48:35,479-Speed 370.14 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 52950   Required: 3 hours
Training: 2025-08-30 17:48:52,767-Speed 370.20 samples/sec   Loss 0.0027 Epoch: 28   Global Step: 53000   Required: 3 hours
Training: 2025-08-30 17:49:10,051-Speed 370.29 samples/sec   Loss 0.0008 Epoch: 28   Global Step: 53050   Required: 3 hours
Training: 2025-08-30 17:49:27,344-Speed 370.09 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 53100   Required: 3 hours
Training: 2025-08-30 17:49:44,636-Speed 370.11 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 53150   Required: 2 hours
Training: 2025-08-30 17:50:01,927-Speed 370.14 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 53200   Required: 2 hours
Training: 2025-08-30 17:50:19,216-Speed 370.18 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 53250   Required: 2 hours
Training: 2025-08-30 17:50:36,510-Speed 370.06 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 53300   Required: 2 hours
Training: 2025-08-30 17:50:53,799-Speed 370.20 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 53350   Required: 2 hours
Training: 2025-08-30 17:51:11,089-Speed 370.14 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 53400   Required: 2 hours
Training: 2025-08-30 17:51:28,382-Speed 370.11 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 53450   Required: 2 hours
Training: 2025-08-30 17:51:45,674-Speed 370.12 samples/sec   Loss 0.0013 Epoch: 28   Global Step: 53500   Required: 2 hours
Training: 2025-08-30 17:52:02,968-Speed 370.08 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 53550   Required: 2 hours
Training: 2025-08-30 17:52:20,259-Speed 370.13 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 53600   Required: 2 hours
Training: 2025-08-30 17:52:37,549-Speed 370.17 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 53650   Required: 2 hours
Training: 2025-08-30 17:52:54,839-Speed 370.14 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 53700   Required: 2 hours
Training: 2025-08-30 17:53:12,129-Speed 370.15 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 53750   Required: 2 hours
Training: 2025-08-30 17:53:29,421-Speed 370.12 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 53800   Required: 2 hours
Training: 2025-08-30 17:53:46,711-Speed 370.17 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 53850   Required: 2 hours
Training: 2025-08-30 17:54:03,998-Speed 370.22 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 53900   Required: 2 hours
Training: 2025-08-30 17:54:21,283-Speed 370.27 samples/sec   Loss 0.0014 Epoch: 28   Global Step: 53950   Required: 2 hours
Training: 2025-08-30 17:54:38,568-Speed 370.27 samples/sec   Loss 0.0011 Epoch: 28   Global Step: 54000   Required: 2 hours
Training: 2025-08-30 17:54:55,855-Speed 370.22 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 54050   Required: 2 hours
Training: 2025-08-30 17:55:13,145-Speed 370.16 samples/sec   Loss 0.0012 Epoch: 28   Global Step: 54100   Required: 2 hours
Training: 2025-08-30 17:55:30,441-Speed 370.03 samples/sec   Loss 0.0010 Epoch: 28   Global Step: 54150   Required: 2 hours
Training: 2025-08-30 17:55:47,733-Speed 370.11 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 54200   Required: 2 hours
Training: 2025-08-30 17:56:05,023-Speed 370.18 samples/sec   Loss 0.0013 Epoch: 28   Global Step: 54250   Required: 2 hours
Training: 2025-08-30 17:56:22,319-Speed 370.03 samples/sec   Loss 0.0009 Epoch: 28   Global Step: 54300   Required: 2 hours
Training: 2025-08-30 17:57:02,588-[lfw][54346]XNorm: 15.227063
Training: 2025-08-30 17:57:02,588-[lfw][54346]Accuracy-Flip: 0.82617+-0.01668
Training: 2025-08-30 17:57:02,588-[lfw][54346]Accuracy-Highest: 0.83633
Training: 2025-08-30 17:57:30,935-[cfp_fp][54346]XNorm: 13.313953
Training: 2025-08-30 17:57:30,935-[cfp_fp][54346]Accuracy-Flip: 0.64686+-0.01676
Training: 2025-08-30 17:57:30,935-[cfp_fp][54346]Accuracy-Highest: 0.65900
Training: 2025-08-30 17:57:55,260-[agedb_30][54346]XNorm: 13.403584
Training: 2025-08-30 17:57:55,260-[agedb_30][54346]Accuracy-Flip: 0.53800+-0.01560
Training: 2025-08-30 17:57:55,261-[agedb_30][54346]Accuracy-Highest: 0.55033
Training: 2025-08-30 17:58:19,672-[calfw][54346]XNorm: 15.497478
Training: 2025-08-30 17:58:19,672-[calfw][54346]Accuracy-Flip: 0.67417+-0.01896
Training: 2025-08-30 17:58:19,672-[calfw][54346]Accuracy-Highest: 0.68583
Training: 2025-08-30 17:58:44,077-[cplfw][54346]XNorm: 11.941053
Training: 2025-08-30 17:58:44,077-[cplfw][54346]Accuracy-Flip: 0.64083+-0.01567
Training: 2025-08-30 17:58:44,077-[cplfw][54346]Accuracy-Highest: 0.64217
Training: 2025-08-30 17:58:45,604-Speed 44.67 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 54350   Required: 2 hours
Training: 2025-08-30 17:59:02,876-Speed 370.55 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 54400   Required: 2 hours
Training: 2025-08-30 17:59:20,158-Speed 370.32 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 54450   Required: 2 hours
Training: 2025-08-30 17:59:37,443-Speed 370.27 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 54500   Required: 2 hours
Training: 2025-08-30 17:59:54,723-Speed 370.37 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 54550   Required: 2 hours
Training: 2025-08-30 18:00:12,009-Speed 370.25 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 54600   Required: 2 hours
Training: 2025-08-30 18:00:29,295-Speed 370.24 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 54650   Required: 2 hours
Training: 2025-08-30 18:00:46,584-Speed 370.18 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 54700   Required: 2 hours
Training: 2025-08-30 18:01:03,873-Speed 370.18 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 54750   Required: 2 hours
Training: 2025-08-30 18:01:21,162-Speed 370.17 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 54800   Required: 2 hours
Training: 2025-08-30 18:01:38,453-Speed 370.14 samples/sec   Loss 0.0007 Epoch: 29   Global Step: 54850   Required: 2 hours
Training: 2025-08-30 18:01:55,745-Speed 370.13 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 54900   Required: 2 hours
Training: 2025-08-30 18:02:13,034-Speed 370.17 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 54950   Required: 2 hours
Training: 2025-08-30 18:02:30,330-Speed 370.02 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 55000   Required: 2 hours
Training: 2025-08-30 18:02:47,627-Speed 370.03 samples/sec   Loss 0.0011 Epoch: 29   Global Step: 55050   Required: 2 hours
Training: 2025-08-30 18:03:04,918-Speed 370.12 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 55100   Required: 2 hours
Training: 2025-08-30 18:03:22,207-Speed 370.18 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 55150   Required: 2 hours
Training: 2025-08-30 18:03:39,503-Speed 370.05 samples/sec   Loss 0.0011 Epoch: 29   Global Step: 55200   Required: 2 hours
Training: 2025-08-30 18:03:56,796-Speed 370.08 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 55250   Required: 2 hours
Training: 2025-08-30 18:04:14,087-Speed 370.14 samples/sec   Loss 0.0013 Epoch: 29   Global Step: 55300   Required: 2 hours
Training: 2025-08-30 18:04:31,375-Speed 370.19 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 55350   Required: 2 hours
Training: 2025-08-30 18:04:48,662-Speed 370.22 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 55400   Required: 2 hours
Training: 2025-08-30 18:05:05,949-Speed 370.22 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 55450   Required: 2 hours
Training: 2025-08-30 18:05:23,241-Speed 370.13 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 55500   Required: 2 hours
Training: 2025-08-30 18:05:40,532-Speed 370.13 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 55550   Required: 2 hours
Training: 2025-08-30 18:05:57,821-Speed 370.17 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 55600   Required: 2 hours
Training: 2025-08-30 18:06:15,112-Speed 370.15 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 55650   Required: 2 hours
Training: 2025-08-30 18:06:32,396-Speed 370.27 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 55700   Required: 2 hours
Training: 2025-08-30 18:06:49,685-Speed 370.19 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 55750   Required: 2 hours
Training: 2025-08-30 18:07:06,973-Speed 370.20 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 55800   Required: 2 hours
Training: 2025-08-30 18:07:24,261-Speed 370.20 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 55850   Required: 2 hours
Training: 2025-08-30 18:07:41,553-Speed 370.13 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 55900   Required: 2 hours
Training: 2025-08-30 18:07:58,840-Speed 370.20 samples/sec   Loss 0.0010 Epoch: 29   Global Step: 55950   Required: 2 hours
Training: 2025-08-30 18:08:16,130-Speed 370.16 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 56000   Required: 2 hours
Training: 2025-08-30 18:08:33,419-Speed 370.19 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 56050   Required: 2 hours
Training: 2025-08-30 18:08:50,705-Speed 370.24 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 56100   Required: 2 hours
Training: 2025-08-30 18:09:07,987-Speed 370.34 samples/sec   Loss 0.0009 Epoch: 29   Global Step: 56150   Required: 2 hours
Training: 2025-08-30 18:09:25,272-Speed 370.25 samples/sec   Loss 0.0008 Epoch: 29   Global Step: 56200   Required: 2 hours
Training: 2025-08-30 18:09:56,536-[lfw][56220]XNorm: 15.203537
Training: 2025-08-30 18:09:56,536-[lfw][56220]Accuracy-Flip: 0.82700+-0.01626
Training: 2025-08-30 18:09:56,536-[lfw][56220]Accuracy-Highest: 0.83633
Training: 2025-08-30 18:10:24,803-[cfp_fp][56220]XNorm: 13.251993
Training: 2025-08-30 18:10:24,803-[cfp_fp][56220]Accuracy-Flip: 0.65114+-0.01729
Training: 2025-08-30 18:10:24,803-[cfp_fp][56220]Accuracy-Highest: 0.65900
Training: 2025-08-30 18:10:49,144-[agedb_30][56220]XNorm: 13.406979
Training: 2025-08-30 18:10:49,144-[agedb_30][56220]Accuracy-Flip: 0.53783+-0.01718
Training: 2025-08-30 18:10:49,144-[agedb_30][56220]Accuracy-Highest: 0.55033
Training: 2025-08-30 18:11:13,565-[calfw][56220]XNorm: 15.488501
Training: 2025-08-30 18:11:13,565-[calfw][56220]Accuracy-Flip: 0.67950+-0.01889
Training: 2025-08-30 18:11:13,565-[calfw][56220]Accuracy-Highest: 0.68583
Training: 2025-08-30 18:11:37,959-[cplfw][56220]XNorm: 11.919713
Training: 2025-08-30 18:11:37,959-[cplfw][56220]Accuracy-Flip: 0.64183+-0.01320
Training: 2025-08-30 18:11:37,959-[cplfw][56220]Accuracy-Highest: 0.64217
Training: 2025-08-30 18:11:48,513-Speed 44.68 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 56250   Required: 2 hours
Training: 2025-08-30 18:12:05,782-Speed 370.62 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 56300   Required: 2 hours
Training: 2025-08-30 18:12:23,056-Speed 370.51 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 56350   Required: 2 hours
Training: 2025-08-30 18:12:40,333-Speed 370.43 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 56400   Required: 2 hours
Training: 2025-08-30 18:12:57,613-Speed 370.36 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 56450   Required: 2 hours
Training: 2025-08-30 18:13:14,899-Speed 370.24 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 56500   Required: 2 hours
Training: 2025-08-30 18:13:32,186-Speed 370.24 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 56550   Required: 2 hours
Training: 2025-08-30 18:13:49,472-Speed 370.23 samples/sec   Loss 0.0012 Epoch: 30   Global Step: 56600   Required: 2 hours
Training: 2025-08-30 18:14:06,760-Speed 370.21 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 56650   Required: 2 hours
Training: 2025-08-30 18:14:24,056-Speed 370.03 samples/sec   Loss 0.0014 Epoch: 30   Global Step: 56700   Required: 2 hours
Training: 2025-08-30 18:14:41,350-Speed 370.08 samples/sec   Loss 0.0014 Epoch: 30   Global Step: 56750   Required: 2 hours
Training: 2025-08-30 18:14:58,640-Speed 370.14 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 56800   Required: 2 hours
Training: 2025-08-30 18:15:15,930-Speed 370.17 samples/sec   Loss 0.0012 Epoch: 30   Global Step: 56850   Required: 2 hours
Training: 2025-08-30 18:15:33,224-Speed 370.06 samples/sec   Loss 0.0011 Epoch: 30   Global Step: 56900   Required: 2 hours
Training: 2025-08-30 18:15:50,517-Speed 370.10 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 56950   Required: 2 hours
Training: 2025-08-30 18:16:07,814-Speed 370.02 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 57000   Required: 2 hours
Training: 2025-08-30 18:16:25,114-Speed 369.94 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 57050   Required: 2 hours
Training: 2025-08-30 18:16:42,412-Speed 369.98 samples/sec   Loss 0.0012 Epoch: 30   Global Step: 57100   Required: 2 hours
Training: 2025-08-30 18:16:59,706-Speed 370.08 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 57150   Required: 2 hours
Training: 2025-08-30 18:17:16,993-Speed 370.21 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 57200   Required: 2 hours
Training: 2025-08-30 18:17:34,282-Speed 370.18 samples/sec   Loss 0.0007 Epoch: 30   Global Step: 57250   Required: 2 hours
Training: 2025-08-30 18:17:51,569-Speed 370.23 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 57300   Required: 2 hours
Training: 2025-08-30 18:18:08,861-Speed 370.11 samples/sec   Loss 0.0011 Epoch: 30   Global Step: 57350   Required: 2 hours
Training: 2025-08-30 18:18:26,156-Speed 370.05 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 57400   Required: 2 hours
Training: 2025-08-30 18:18:43,446-Speed 370.16 samples/sec   Loss 0.0011 Epoch: 30   Global Step: 57450   Required: 2 hours
Training: 2025-08-30 18:19:00,734-Speed 370.21 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 57500   Required: 2 hours
Training: 2025-08-30 18:19:18,026-Speed 370.12 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 57550   Required: 2 hours
Training: 2025-08-30 18:19:35,318-Speed 370.11 samples/sec   Loss 0.0012 Epoch: 30   Global Step: 57600   Required: 2 hours
Training: 2025-08-30 18:19:52,608-Speed 370.16 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 57650   Required: 2 hours
Training: 2025-08-30 18:20:09,900-Speed 370.12 samples/sec   Loss 0.0008 Epoch: 30   Global Step: 57700   Required: 2 hours
Training: 2025-08-30 18:20:27,194-Speed 370.07 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 57750   Required: 2 hours
Training: 2025-08-30 18:20:44,482-Speed 370.19 samples/sec   Loss 0.0010 Epoch: 30   Global Step: 57800   Required: 2 hours
Training: 2025-08-30 18:21:01,769-Speed 370.22 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 57850   Required: 2 hours
Training: 2025-08-30 18:21:19,059-Speed 370.16 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 57900   Required: 2 hours
Training: 2025-08-30 18:21:36,349-Speed 370.17 samples/sec   Loss 0.0013 Epoch: 30   Global Step: 57950   Required: 2 hours
Training: 2025-08-30 18:21:53,638-Speed 370.18 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 58000   Required: 2 hours
Training: 2025-08-30 18:22:10,932-Speed 370.07 samples/sec   Loss 0.0009 Epoch: 30   Global Step: 58050   Required: 2 hours
Training: 2025-08-30 18:22:50,489-[lfw][58094]XNorm: 15.212425
Training: 2025-08-30 18:22:50,489-[lfw][58094]Accuracy-Flip: 0.82617+-0.01555
Training: 2025-08-30 18:22:50,489-[lfw][58094]Accuracy-Highest: 0.83633
Training: 2025-08-30 18:23:18,801-[cfp_fp][58094]XNorm: 13.280858
Training: 2025-08-30 18:23:18,801-[cfp_fp][58094]Accuracy-Flip: 0.64829+-0.01722
Training: 2025-08-30 18:23:18,801-[cfp_fp][58094]Accuracy-Highest: 0.65900
Training: 2025-08-30 18:23:43,131-[agedb_30][58094]XNorm: 13.452419
Training: 2025-08-30 18:23:43,131-[agedb_30][58094]Accuracy-Flip: 0.54083+-0.01387
Training: 2025-08-30 18:23:43,131-[agedb_30][58094]Accuracy-Highest: 0.55033
Training: 2025-08-30 18:24:07,541-[calfw][58094]XNorm: 15.510960
Training: 2025-08-30 18:24:07,541-[calfw][58094]Accuracy-Flip: 0.67850+-0.02025
Training: 2025-08-30 18:24:07,541-[calfw][58094]Accuracy-Highest: 0.68583
Training: 2025-08-30 18:24:31,957-[cplfw][58094]XNorm: 11.930952
Training: 2025-08-30 18:24:31,957-[cplfw][58094]Accuracy-Flip: 0.63933+-0.00995
Training: 2025-08-30 18:24:31,957-[cplfw][58094]Accuracy-Highest: 0.64217
Training: 2025-08-30 18:24:34,214-Speed 44.67 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 58100   Required: 2 hours
Training: 2025-08-30 18:24:51,488-Speed 370.51 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 58150   Required: 2 hours
Training: 2025-08-30 18:25:08,766-Speed 370.40 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 58200   Required: 2 hours
Training: 2025-08-30 18:25:26,049-Speed 370.32 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 58250   Required: 2 hours
Training: 2025-08-30 18:25:43,338-Speed 370.19 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 58300   Required: 2 hours
Training: 2025-08-30 18:26:00,630-Speed 370.10 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 58350   Required: 2 hours
Training: 2025-08-30 18:26:17,926-Speed 370.04 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 58400   Required: 2 hours
Training: 2025-08-30 18:26:35,223-Speed 369.99 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 58450   Required: 2 hours
Training: 2025-08-30 18:26:52,522-Speed 369.97 samples/sec   Loss 0.0012 Epoch: 31   Global Step: 58500   Required: 2 hours
Training: 2025-08-30 18:27:09,818-Speed 370.03 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 58550   Required: 2 hours
Training: 2025-08-30 18:27:27,119-Speed 369.93 samples/sec   Loss 0.0011 Epoch: 31   Global Step: 58600   Required: 2 hours
Training: 2025-08-30 18:27:44,420-Speed 369.92 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 58650   Required: 2 hours
Training: 2025-08-30 18:28:01,716-Speed 370.02 samples/sec   Loss 0.0011 Epoch: 31   Global Step: 58700   Required: 2 hours
Training: 2025-08-30 18:28:19,019-Speed 369.90 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 58750   Required: 2 hours
Training: 2025-08-30 18:28:36,320-Speed 369.91 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 58800   Required: 2 hours
Training: 2025-08-30 18:28:53,622-Speed 369.90 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 58850   Required: 2 hours
Training: 2025-08-30 18:29:10,924-Speed 369.91 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 58900   Required: 2 hours
Training: 2025-08-30 18:29:28,230-Speed 369.82 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 58950   Required: 2 hours
Training: 2025-08-30 18:29:45,536-Speed 369.81 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 59000   Required: 2 hours
Training: 2025-08-30 18:30:02,840-Speed 369.87 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 59050   Required: 2 hours
Training: 2025-08-30 18:30:20,140-Speed 369.93 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 59100   Required: 2 hours
Training: 2025-08-30 18:30:37,440-Speed 369.94 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 59150   Required: 2 hours
Training: 2025-08-30 18:30:54,745-Speed 369.85 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 59200   Required: 2 hours
Training: 2025-08-30 18:31:12,050-Speed 369.84 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 59250   Required: 2 hours
Training: 2025-08-30 18:31:29,351-Speed 369.91 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 59300   Required: 2 hours
Training: 2025-08-30 18:31:46,654-Speed 369.89 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 59350   Required: 2 hours
Training: 2025-08-30 18:32:03,956-Speed 369.90 samples/sec   Loss 0.0011 Epoch: 31   Global Step: 59400   Required: 2 hours
Training: 2025-08-30 18:32:21,254-Speed 369.97 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 59450   Required: 2 hours
Training: 2025-08-30 18:32:38,556-Speed 369.91 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 59500   Required: 2 hours
Training: 2025-08-30 18:32:55,855-Speed 369.96 samples/sec   Loss 0.0011 Epoch: 31   Global Step: 59550   Required: 2 hours
Training: 2025-08-30 18:33:13,156-Speed 369.94 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 59600   Required: 2 hours
Training: 2025-08-30 18:33:30,459-Speed 369.87 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 59650   Required: 2 hours
Training: 2025-08-30 18:33:47,764-Speed 369.83 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 59700   Required: 2 hours
Training: 2025-08-30 18:34:05,071-Speed 369.81 samples/sec   Loss 0.0007 Epoch: 31   Global Step: 59750   Required: 2 hours
Training: 2025-08-30 18:34:22,375-Speed 369.85 samples/sec   Loss 0.0008 Epoch: 31   Global Step: 59800   Required: 2 hours
Training: 2025-08-30 18:34:39,680-Speed 369.84 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 59850   Required: 2 hours
Training: 2025-08-30 18:34:56,980-Speed 369.94 samples/sec   Loss 0.0010 Epoch: 31   Global Step: 59900   Required: 2 hours
Training: 2025-08-30 18:35:14,283-Speed 369.87 samples/sec   Loss 0.0009 Epoch: 31   Global Step: 59950   Required: 2 hours
Training: 2025-08-30 18:35:44,880-[lfw][59968]XNorm: 15.234596
Training: 2025-08-30 18:35:44,880-[lfw][59968]Accuracy-Flip: 0.82917+-0.01715
Training: 2025-08-30 18:35:44,880-[lfw][59968]Accuracy-Highest: 0.83633
Training: 2025-08-30 18:36:13,253-[cfp_fp][59968]XNorm: 13.252944
Training: 2025-08-30 18:36:13,253-[cfp_fp][59968]Accuracy-Flip: 0.64829+-0.01865
Training: 2025-08-30 18:36:13,253-[cfp_fp][59968]Accuracy-Highest: 0.65900
Training: 2025-08-30 18:36:37,605-[agedb_30][59968]XNorm: 13.484649
Training: 2025-08-30 18:36:37,605-[agedb_30][59968]Accuracy-Flip: 0.53767+-0.01615
Training: 2025-08-30 18:36:37,605-[agedb_30][59968]Accuracy-Highest: 0.55033
Training: 2025-08-30 18:37:02,042-[calfw][59968]XNorm: 15.532553
Training: 2025-08-30 18:37:02,043-[calfw][59968]Accuracy-Flip: 0.68150+-0.02039
Training: 2025-08-30 18:37:02,043-[calfw][59968]Accuracy-Highest: 0.68583
Training: 2025-08-30 18:37:26,465-[cplfw][59968]XNorm: 11.965329
Training: 2025-08-30 18:37:26,465-[cplfw][59968]Accuracy-Flip: 0.64400+-0.01218
Training: 2025-08-30 18:37:26,465-[cplfw][59968]Accuracy-Highest: 0.64400
Training: 2025-08-30 18:37:37,712-Speed 44.62 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 60000   Required: 2 hours
Training: 2025-08-30 18:37:54,996-Speed 370.28 samples/sec   Loss 0.0011 Epoch: 32   Global Step: 60050   Required: 2 hours
Training: 2025-08-30 18:38:12,288-Speed 370.12 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 60100   Required: 2 hours
Training: 2025-08-30 18:38:29,581-Speed 370.09 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 60150   Required: 2 hours
Training: 2025-08-30 18:38:46,877-Speed 370.02 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 60200   Required: 2 hours
Training: 2025-08-30 18:39:04,176-Speed 369.97 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 60250   Required: 2 hours
Training: 2025-08-30 18:39:21,472-Speed 370.03 samples/sec   Loss 0.0010 Epoch: 32   Global Step: 60300   Required: 2 hours
Training: 2025-08-30 18:39:38,771-Speed 369.96 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 60350   Required: 2 hours
Training: 2025-08-30 18:39:56,071-Speed 369.95 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 60400   Required: 2 hours
Training: 2025-08-30 18:40:13,368-Speed 370.00 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 60450   Required: 2 hours
Training: 2025-08-30 18:40:30,664-Speed 370.02 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 60500   Required: 2 hours
Training: 2025-08-30 18:40:47,957-Speed 370.09 samples/sec   Loss 0.0011 Epoch: 32   Global Step: 60550   Required: 2 hours
Training: 2025-08-30 18:41:05,254-Speed 370.01 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 60600   Required: 2 hours
Training: 2025-08-30 18:41:22,554-Speed 369.95 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 60650   Required: 2 hours
Training: 2025-08-30 18:41:39,854-Speed 369.95 samples/sec   Loss 0.0010 Epoch: 32   Global Step: 60700   Required: 2 hours
Training: 2025-08-30 18:41:57,150-Speed 370.02 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 60750   Required: 2 hours
Training: 2025-08-30 18:42:14,447-Speed 370.01 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 60800   Required: 2 hours
Training: 2025-08-30 18:42:31,743-Speed 370.03 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 60850   Required: 2 hours
Training: 2025-08-30 18:42:49,039-Speed 370.04 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 60900   Required: 2 hours
Training: 2025-08-30 18:43:06,334-Speed 370.04 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 60950   Required: 2 hours
Training: 2025-08-30 18:43:23,627-Speed 370.08 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 61000   Required: 2 hours
Training: 2025-08-30 18:43:40,925-Speed 370.01 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 61050   Required: 2 hours
Training: 2025-08-30 18:43:58,217-Speed 370.11 samples/sec   Loss 0.0010 Epoch: 32   Global Step: 61100   Required: 2 hours
Training: 2025-08-30 18:44:15,511-Speed 370.06 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 61150   Required: 2 hours
Training: 2025-08-30 18:44:32,802-Speed 370.15 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 61200   Required: 2 hours
Training: 2025-08-30 18:44:50,091-Speed 370.17 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 61250   Required: 2 hours
Training: 2025-08-30 18:45:07,388-Speed 370.02 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 61300   Required: 2 hours
Training: 2025-08-30 18:45:24,685-Speed 370.00 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 61350   Required: 2 hours
Training: 2025-08-30 18:45:41,974-Speed 370.19 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 61400   Required: 2 hours
Training: 2025-08-30 18:45:59,265-Speed 370.13 samples/sec   Loss 0.0007 Epoch: 32   Global Step: 61450   Required: 2 hours
Training: 2025-08-30 18:46:16,553-Speed 370.22 samples/sec   Loss 0.0010 Epoch: 32   Global Step: 61500   Required: 2 hours
Training: 2025-08-30 18:46:33,842-Speed 370.17 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 61550   Required: 2 hours
Training: 2025-08-30 18:46:51,137-Speed 370.05 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 61600   Required: 2 hours
Training: 2025-08-30 18:47:08,429-Speed 370.13 samples/sec   Loss 0.0010 Epoch: 32   Global Step: 61650   Required: 2 hours
Training: 2025-08-30 18:47:25,718-Speed 370.18 samples/sec   Loss 0.0009 Epoch: 32   Global Step: 61700   Required: 2 hours
Training: 2025-08-30 18:47:43,006-Speed 370.20 samples/sec   Loss 0.0011 Epoch: 32   Global Step: 61750   Required: 2 hours
Training: 2025-08-30 18:48:00,291-Speed 370.26 samples/sec   Loss 0.0008 Epoch: 32   Global Step: 61800   Required: 2 hours
Training: 2025-08-30 18:48:39,162-[lfw][61842]XNorm: 15.253573
Training: 2025-08-30 18:48:39,162-[lfw][61842]Accuracy-Flip: 0.82467+-0.01598
Training: 2025-08-30 18:48:39,163-[lfw][61842]Accuracy-Highest: 0.83633
Training: 2025-08-30 18:49:07,563-[cfp_fp][61842]XNorm: 13.248835
Training: 2025-08-30 18:49:07,563-[cfp_fp][61842]Accuracy-Flip: 0.65814+-0.01843
Training: 2025-08-30 18:49:07,563-[cfp_fp][61842]Accuracy-Highest: 0.65900
Training: 2025-08-30 18:49:31,896-[agedb_30][61842]XNorm: 13.448505
Training: 2025-08-30 18:49:31,896-[agedb_30][61842]Accuracy-Flip: 0.54117+-0.01402
Training: 2025-08-30 18:49:31,896-[agedb_30][61842]Accuracy-Highest: 0.55033
Training: 2025-08-30 18:49:56,316-[calfw][61842]XNorm: 15.518110
Training: 2025-08-30 18:49:56,316-[calfw][61842]Accuracy-Flip: 0.67950+-0.01856
Training: 2025-08-30 18:49:56,316-[calfw][61842]Accuracy-Highest: 0.68583
Training: 2025-08-30 18:50:20,722-[cplfw][61842]XNorm: 11.977079
Training: 2025-08-30 18:50:20,722-[cplfw][61842]Accuracy-Flip: 0.64367+-0.01306
Training: 2025-08-30 18:50:20,722-[cplfw][61842]Accuracy-Highest: 0.64400
Training: 2025-08-30 18:50:23,686-Speed 44.63 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 61850   Required: 2 hours
Training: 2025-08-30 18:50:40,959-Speed 370.52 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 61900   Required: 2 hours
Training: 2025-08-30 18:50:58,233-Speed 370.49 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 61950   Required: 1 hours
Training: 2025-08-30 18:51:15,513-Speed 370.37 samples/sec   Loss 0.0010 Epoch: 33   Global Step: 62000   Required: 1 hours
Training: 2025-08-30 18:51:32,800-Speed 370.23 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 62050   Required: 1 hours
Training: 2025-08-30 18:51:50,094-Speed 370.08 samples/sec   Loss 0.0011 Epoch: 33   Global Step: 62100   Required: 1 hours
Training: 2025-08-30 18:52:07,384-Speed 370.14 samples/sec   Loss 0.0010 Epoch: 33   Global Step: 62150   Required: 1 hours
Training: 2025-08-30 18:52:24,681-Speed 370.03 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 62200   Required: 1 hours
Training: 2025-08-30 18:52:41,977-Speed 370.01 samples/sec   Loss 0.0010 Epoch: 33   Global Step: 62250   Required: 1 hours
Training: 2025-08-30 18:52:59,275-Speed 369.99 samples/sec   Loss 0.0011 Epoch: 33   Global Step: 62300   Required: 1 hours
Training: 2025-08-30 18:53:16,573-Speed 369.99 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 62350   Required: 1 hours
Training: 2025-08-30 18:53:33,867-Speed 370.07 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 62400   Required: 1 hours
Training: 2025-08-30 18:53:51,163-Speed 370.04 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 62450   Required: 1 hours
Training: 2025-08-30 18:54:08,464-Speed 369.93 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 62500   Required: 1 hours
Training: 2025-08-30 18:54:25,761-Speed 369.99 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 62550   Required: 1 hours
Training: 2025-08-30 18:54:43,056-Speed 370.07 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 62600   Required: 1 hours
Training: 2025-08-30 18:55:00,347-Speed 370.14 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 62650   Required: 1 hours
Training: 2025-08-30 18:55:17,639-Speed 370.11 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 62700   Required: 1 hours
Training: 2025-08-30 18:55:34,930-Speed 370.13 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 62750   Required: 1 hours
Training: 2025-08-30 18:55:52,223-Speed 370.10 samples/sec   Loss 0.0010 Epoch: 33   Global Step: 62800   Required: 1 hours
Training: 2025-08-30 18:56:09,509-Speed 370.24 samples/sec   Loss 0.0007 Epoch: 33   Global Step: 62850   Required: 1 hours
Training: 2025-08-30 18:56:26,797-Speed 370.21 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 62900   Required: 1 hours
Training: 2025-08-30 18:56:44,082-Speed 370.26 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 62950   Required: 1 hours
Training: 2025-08-30 18:57:01,367-Speed 370.28 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 63000   Required: 1 hours
Training: 2025-08-30 18:57:18,657-Speed 370.15 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 63050   Required: 1 hours
Training: 2025-08-30 18:57:35,939-Speed 370.33 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 63100   Required: 1 hours
Training: 2025-08-30 18:57:53,224-Speed 370.25 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 63150   Required: 1 hours
Training: 2025-08-30 18:58:10,510-Speed 370.26 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 63200   Required: 1 hours
Training: 2025-08-30 18:58:27,797-Speed 370.22 samples/sec   Loss 0.0010 Epoch: 33   Global Step: 63250   Required: 1 hours
Training: 2025-08-30 18:58:45,080-Speed 370.30 samples/sec   Loss 0.0008 Epoch: 33   Global Step: 63300   Required: 1 hours
Training: 2025-08-30 18:59:02,364-Speed 370.29 samples/sec   Loss 0.0011 Epoch: 33   Global Step: 63350   Required: 1 hours
Training: 2025-08-30 18:59:19,648-Speed 370.29 samples/sec   Loss 0.0011 Epoch: 33   Global Step: 63400   Required: 1 hours
Training: 2025-08-30 18:59:36,938-Speed 370.16 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 63450   Required: 1 hours
Training: 2025-08-30 18:59:54,225-Speed 370.22 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 63500   Required: 1 hours
Training: 2025-08-30 19:00:11,513-Speed 370.21 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 63550   Required: 1 hours
Training: 2025-08-30 19:00:28,797-Speed 370.29 samples/sec   Loss 0.0010 Epoch: 33   Global Step: 63600   Required: 1 hours
Training: 2025-08-30 19:00:46,082-Speed 370.26 samples/sec   Loss 0.0009 Epoch: 33   Global Step: 63650   Required: 1 hours
Training: 2025-08-30 19:01:03,374-Speed 370.13 samples/sec   Loss 0.0011 Epoch: 33   Global Step: 63700   Required: 1 hours
Training: 2025-08-30 19:01:33,247-[lfw][63716]XNorm: 15.245557
Training: 2025-08-30 19:01:33,247-[lfw][63716]Accuracy-Flip: 0.82683+-0.01624
Training: 2025-08-30 19:01:33,247-[lfw][63716]Accuracy-Highest: 0.83633
Training: 2025-08-30 19:02:01,525-[cfp_fp][63716]XNorm: 13.289096
Training: 2025-08-30 19:02:01,525-[cfp_fp][63716]Accuracy-Flip: 0.64971+-0.01703
Training: 2025-08-30 19:02:01,525-[cfp_fp][63716]Accuracy-Highest: 0.65900
Training: 2025-08-30 19:02:25,856-[agedb_30][63716]XNorm: 13.442047
Training: 2025-08-30 19:02:25,856-[agedb_30][63716]Accuracy-Flip: 0.54067+-0.01513
Training: 2025-08-30 19:02:25,856-[agedb_30][63716]Accuracy-Highest: 0.55033
Training: 2025-08-30 19:02:50,269-[calfw][63716]XNorm: 15.529319
Training: 2025-08-30 19:02:50,269-[calfw][63716]Accuracy-Flip: 0.68183+-0.02055
Training: 2025-08-30 19:02:50,269-[calfw][63716]Accuracy-Highest: 0.68583
Training: 2025-08-30 19:03:14,671-[cplfw][63716]XNorm: 11.953788
Training: 2025-08-30 19:03:14,671-[cplfw][63716]Accuracy-Flip: 0.64150+-0.01180
Training: 2025-08-30 19:03:14,671-[cplfw][63716]Accuracy-Highest: 0.64400
Training: 2025-08-30 19:03:26,617-Speed 44.68 samples/sec   Loss 0.0011 Epoch: 34   Global Step: 63750   Required: 1 hours
Training: 2025-08-30 19:03:43,894-Speed 370.44 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 63800   Required: 1 hours
Training: 2025-08-30 19:04:01,174-Speed 370.36 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 63850   Required: 1 hours
Training: 2025-08-30 19:04:18,461-Speed 370.23 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 63900   Required: 1 hours
Training: 2025-08-30 19:04:35,755-Speed 370.08 samples/sec   Loss 0.0010 Epoch: 34   Global Step: 63950   Required: 1 hours
Training: 2025-08-30 19:04:53,047-Speed 370.11 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 64000   Required: 1 hours
Training: 2025-08-30 19:05:10,334-Speed 370.21 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 64050   Required: 1 hours
Training: 2025-08-30 19:05:27,624-Speed 370.17 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 64100   Required: 1 hours
Training: 2025-08-30 19:05:44,914-Speed 370.15 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 64150   Required: 1 hours
Training: 2025-08-30 19:06:02,209-Speed 370.05 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 64200   Required: 1 hours
Training: 2025-08-30 19:06:19,508-Speed 369.97 samples/sec   Loss 0.0011 Epoch: 34   Global Step: 64250   Required: 1 hours
Training: 2025-08-30 19:06:36,803-Speed 370.06 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 64300   Required: 1 hours
Training: 2025-08-30 19:06:54,096-Speed 370.09 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 64350   Required: 1 hours
Training: 2025-08-30 19:07:11,396-Speed 369.95 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 64400   Required: 1 hours
Training: 2025-08-30 19:07:28,697-Speed 369.92 samples/sec   Loss 0.0010 Epoch: 34   Global Step: 64450   Required: 1 hours
Training: 2025-08-30 19:07:45,992-Speed 370.05 samples/sec   Loss 0.0010 Epoch: 34   Global Step: 64500   Required: 1 hours
Training: 2025-08-30 19:08:03,286-Speed 370.07 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 64550   Required: 1 hours
Training: 2025-08-30 19:08:20,584-Speed 370.00 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 64600   Required: 1 hours
Training: 2025-08-30 19:08:37,881-Speed 370.01 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 64650   Required: 1 hours
Training: 2025-08-30 19:08:55,174-Speed 370.09 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 64700   Required: 1 hours
Training: 2025-08-30 19:09:12,472-Speed 369.98 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 64750   Required: 1 hours
Training: 2025-08-30 19:09:29,771-Speed 369.97 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 64800   Required: 1 hours
Training: 2025-08-30 19:09:47,066-Speed 370.05 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 64850   Required: 1 hours
Training: 2025-08-30 19:10:04,360-Speed 370.06 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 64900   Required: 1 hours
Training: 2025-08-30 19:10:21,656-Speed 370.04 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 64950   Required: 1 hours
Training: 2025-08-30 19:10:38,954-Speed 369.99 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 65000   Required: 1 hours
Training: 2025-08-30 19:10:56,253-Speed 369.96 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 65050   Required: 1 hours
Training: 2025-08-30 19:11:13,552-Speed 369.98 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 65100   Required: 1 hours
Training: 2025-08-30 19:11:30,854-Speed 369.88 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 65150   Required: 1 hours
Training: 2025-08-30 19:11:48,153-Speed 369.97 samples/sec   Loss 0.0007 Epoch: 34   Global Step: 65200   Required: 1 hours
Training: 2025-08-30 19:12:05,454-Speed 369.93 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 65250   Required: 1 hours
Training: 2025-08-30 19:12:22,753-Speed 369.97 samples/sec   Loss 0.0008 Epoch: 34   Global Step: 65300   Required: 1 hours
Training: 2025-08-30 19:12:40,050-Speed 370.00 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 65350   Required: 1 hours
Training: 2025-08-30 19:12:57,348-Speed 370.00 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 65400   Required: 1 hours
Training: 2025-08-30 19:13:14,640-Speed 370.10 samples/sec   Loss 0.0010 Epoch: 34   Global Step: 65450   Required: 1 hours
Training: 2025-08-30 19:13:31,936-Speed 370.04 samples/sec   Loss 0.0009 Epoch: 34   Global Step: 65500   Required: 1 hours
Training: 2025-08-30 19:13:49,229-Speed 370.08 samples/sec   Loss 0.0011 Epoch: 34   Global Step: 65550   Required: 1 hours
Training: 2025-08-30 19:14:27,428-[lfw][65590]XNorm: 15.187787
Training: 2025-08-30 19:14:27,428-[lfw][65590]Accuracy-Flip: 0.82483+-0.01438
Training: 2025-08-30 19:14:27,428-[lfw][65590]Accuracy-Highest: 0.83633
Training: 2025-08-30 19:14:55,788-[cfp_fp][65590]XNorm: 13.241869
Training: 2025-08-30 19:14:55,788-[cfp_fp][65590]Accuracy-Flip: 0.65129+-0.01899
Training: 2025-08-30 19:14:55,788-[cfp_fp][65590]Accuracy-Highest: 0.65900
Training: 2025-08-30 19:15:20,131-[agedb_30][65590]XNorm: 13.412499
Training: 2025-08-30 19:15:20,132-[agedb_30][65590]Accuracy-Flip: 0.53800+-0.01380
Training: 2025-08-30 19:15:20,132-[agedb_30][65590]Accuracy-Highest: 0.55033
Training: 2025-08-30 19:15:44,564-[calfw][65590]XNorm: 15.483602
Training: 2025-08-30 19:15:44,564-[calfw][65590]Accuracy-Flip: 0.68450+-0.02015
Training: 2025-08-30 19:15:44,564-[calfw][65590]Accuracy-Highest: 0.68583
Training: 2025-08-30 19:16:08,982-[cplfw][65590]XNorm: 11.925119
Training: 2025-08-30 19:16:08,982-[cplfw][65590]Accuracy-Flip: 0.64350+-0.01248
Training: 2025-08-30 19:16:08,982-[cplfw][65590]Accuracy-Highest: 0.64400
Training: 2025-08-30 19:16:12,593-Speed 44.64 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 65600   Required: 1 hours
Training: 2025-08-30 19:16:29,867-Speed 370.50 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 65650   Required: 1 hours
Training: 2025-08-30 19:16:47,151-Speed 370.28 samples/sec   Loss 0.0010 Epoch: 35   Global Step: 65700   Required: 1 hours
Training: 2025-08-30 19:17:04,444-Speed 370.10 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 65750   Required: 1 hours
Training: 2025-08-30 19:17:21,734-Speed 370.15 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 65800   Required: 1 hours
Training: 2025-08-30 19:17:39,026-Speed 370.12 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 65850   Required: 1 hours
Training: 2025-08-30 19:17:56,317-Speed 370.15 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 65900   Required: 1 hours
Training: 2025-08-30 19:18:13,605-Speed 370.19 samples/sec   Loss 0.0010 Epoch: 35   Global Step: 65950   Required: 1 hours
Training: 2025-08-30 19:18:30,896-Speed 370.15 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 66000   Required: 1 hours
Training: 2025-08-30 19:18:48,188-Speed 370.10 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 66050   Required: 1 hours
Training: 2025-08-30 19:19:05,480-Speed 370.12 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 66100   Required: 1 hours
Training: 2025-08-30 19:19:22,770-Speed 370.17 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 66150   Required: 1 hours
Training: 2025-08-30 19:19:40,064-Speed 370.07 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 66200   Required: 1 hours
Training: 2025-08-30 19:19:57,356-Speed 370.12 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 66250   Required: 1 hours
Training: 2025-08-30 19:20:14,639-Speed 370.30 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 66300   Required: 1 hours
Training: 2025-08-30 19:20:31,925-Speed 370.26 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 66350   Required: 1 hours
Training: 2025-08-30 19:20:49,211-Speed 370.24 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 66400   Required: 1 hours
Training: 2025-08-30 19:21:06,500-Speed 370.18 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 66450   Required: 1 hours
Training: 2025-08-30 19:21:23,788-Speed 370.20 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 66500   Required: 1 hours
Training: 2025-08-30 19:21:41,077-Speed 370.18 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 66550   Required: 1 hours
Training: 2025-08-30 19:21:58,364-Speed 370.23 samples/sec   Loss 0.0010 Epoch: 35   Global Step: 66600   Required: 1 hours
Training: 2025-08-30 19:22:15,650-Speed 370.25 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 66650   Required: 1 hours
Training: 2025-08-30 19:22:32,935-Speed 370.26 samples/sec   Loss 0.0006 Epoch: 35   Global Step: 66700   Required: 1 hours
Training: 2025-08-30 19:22:50,221-Speed 370.25 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 66750   Required: 1 hours
Training: 2025-08-30 19:23:07,508-Speed 370.22 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 66800   Required: 1 hours
Training: 2025-08-30 19:23:24,796-Speed 370.21 samples/sec   Loss 0.0010 Epoch: 35   Global Step: 66850   Required: 1 hours
Training: 2025-08-30 19:23:42,087-Speed 370.13 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 66900   Required: 1 hours
Training: 2025-08-30 19:23:59,378-Speed 370.13 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 66950   Required: 1 hours
Training: 2025-08-30 19:24:16,662-Speed 370.28 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 67000   Required: 1 hours
Training: 2025-08-30 19:24:33,950-Speed 370.20 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 67050   Required: 1 hours
Training: 2025-08-30 19:24:51,233-Speed 370.32 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 67100   Required: 1 hours
Training: 2025-08-30 19:25:08,521-Speed 370.21 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 67150   Required: 1 hours
Training: 2025-08-30 19:25:25,810-Speed 370.17 samples/sec   Loss 0.0008 Epoch: 35   Global Step: 67200   Required: 1 hours
Training: 2025-08-30 19:25:43,098-Speed 370.20 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 67250   Required: 1 hours
Training: 2025-08-30 19:26:00,381-Speed 370.32 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 67300   Required: 1 hours
Training: 2025-08-30 19:26:17,665-Speed 370.29 samples/sec   Loss 0.0009 Epoch: 35   Global Step: 67350   Required: 1 hours
Training: 2025-08-30 19:26:34,951-Speed 370.23 samples/sec   Loss 0.0010 Epoch: 35   Global Step: 67400   Required: 1 hours
Training: 2025-08-30 19:26:52,234-Speed 370.31 samples/sec   Loss 0.0007 Epoch: 35   Global Step: 67450   Required: 1 hours
Training: 2025-08-30 19:27:21,410-[lfw][67464]XNorm: 15.233590
Training: 2025-08-30 19:27:21,410-[lfw][67464]Accuracy-Flip: 0.82683+-0.01769
Training: 2025-08-30 19:27:21,410-[lfw][67464]Accuracy-Highest: 0.83633
Training: 2025-08-30 19:27:49,744-[cfp_fp][67464]XNorm: 13.228387
Training: 2025-08-30 19:27:49,744-[cfp_fp][67464]Accuracy-Flip: 0.65529+-0.01935
Training: 2025-08-30 19:27:49,744-[cfp_fp][67464]Accuracy-Highest: 0.65900
Training: 2025-08-30 19:28:14,067-[agedb_30][67464]XNorm: 13.434914
Training: 2025-08-30 19:28:14,067-[agedb_30][67464]Accuracy-Flip: 0.53717+-0.01729
Training: 2025-08-30 19:28:14,067-[agedb_30][67464]Accuracy-Highest: 0.55033
Training: 2025-08-30 19:28:38,468-[calfw][67464]XNorm: 15.536375
Training: 2025-08-30 19:28:38,468-[calfw][67464]Accuracy-Flip: 0.67733+-0.02043
Training: 2025-08-30 19:28:38,468-[calfw][67464]Accuracy-Highest: 0.68583
Training: 2025-08-30 19:29:02,854-[cplfw][67464]XNorm: 11.947025
Training: 2025-08-30 19:29:02,854-[cplfw][67464]Accuracy-Flip: 0.64083+-0.01081
Training: 2025-08-30 19:29:02,854-[cplfw][67464]Accuracy-Highest: 0.64400
Training: 2025-08-30 19:29:15,441-Speed 44.69 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 67500   Required: 1 hours
Training: 2025-08-30 19:29:32,704-Speed 370.72 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 67550   Required: 1 hours
Training: 2025-08-30 19:29:49,973-Speed 370.61 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 67600   Required: 1 hours
Training: 2025-08-30 19:30:07,248-Speed 370.48 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 67650   Required: 1 hours
Training: 2025-08-30 19:30:24,529-Speed 370.37 samples/sec   Loss 0.0010 Epoch: 36   Global Step: 67700   Required: 1 hours
Training: 2025-08-30 19:30:41,813-Speed 370.27 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 67750   Required: 1 hours
Training: 2025-08-30 19:30:59,102-Speed 370.18 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 67800   Required: 1 hours
Training: 2025-08-30 19:31:16,387-Speed 370.27 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 67850   Required: 1 hours
Training: 2025-08-30 19:31:33,675-Speed 370.20 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 67900   Required: 1 hours
Training: 2025-08-30 19:31:50,958-Speed 370.30 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 67950   Required: 1 hours
Training: 2025-08-30 19:32:08,245-Speed 370.22 samples/sec   Loss 0.0010 Epoch: 36   Global Step: 68000   Required: 1 hours
Training: 2025-08-30 19:32:25,530-Speed 370.28 samples/sec   Loss 0.0010 Epoch: 36   Global Step: 68050   Required: 1 hours
Training: 2025-08-30 19:32:42,813-Speed 370.29 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 68100   Required: 1 hours
Training: 2025-08-30 19:33:00,101-Speed 370.20 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 68150   Required: 1 hours
Training: 2025-08-30 19:33:17,392-Speed 370.16 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 68200   Required: 1 hours
Training: 2025-08-30 19:33:34,687-Speed 370.05 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 68250   Required: 1 hours
Training: 2025-08-30 19:33:51,975-Speed 370.21 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 68300   Required: 1 hours
Training: 2025-08-30 19:34:09,264-Speed 370.18 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 68350   Required: 1 hours
Training: 2025-08-30 19:34:26,553-Speed 370.17 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 68400   Required: 1 hours
Training: 2025-08-30 19:34:43,842-Speed 370.20 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 68450   Required: 1 hours
Training: 2025-08-30 19:35:01,125-Speed 370.31 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 68500   Required: 1 hours
Training: 2025-08-30 19:35:18,413-Speed 370.19 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 68550   Required: 1 hours
Training: 2025-08-30 19:35:35,701-Speed 370.21 samples/sec   Loss 0.0010 Epoch: 36   Global Step: 68600   Required: 1 hours
Training: 2025-08-30 19:35:52,981-Speed 370.37 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 68650   Required: 1 hours
Training: 2025-08-30 19:36:10,265-Speed 370.27 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 68700   Required: 1 hours
Training: 2025-08-30 19:36:27,546-Speed 370.36 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 68750   Required: 1 hours
Training: 2025-08-30 19:36:44,830-Speed 370.30 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 68800   Required: 1 hours
Training: 2025-08-30 19:37:02,115-Speed 370.26 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 68850   Required: 1 hours
Training: 2025-08-30 19:37:19,398-Speed 370.32 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 68900   Required: 1 hours
Training: 2025-08-30 19:37:36,684-Speed 370.22 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 68950   Required: 1 hours
Training: 2025-08-30 19:37:53,967-Speed 370.32 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 69000   Required: 1 hours
Training: 2025-08-30 19:38:11,248-Speed 370.36 samples/sec   Loss 0.0007 Epoch: 36   Global Step: 69050   Required: 1 hours
Training: 2025-08-30 19:38:28,526-Speed 370.40 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 69100   Required: 1 hours
Training: 2025-08-30 19:38:45,810-Speed 370.29 samples/sec   Loss 0.0008 Epoch: 36   Global Step: 69150   Required: 1 hours
Training: 2025-08-30 19:39:03,094-Speed 370.30 samples/sec   Loss 0.0009 Epoch: 36   Global Step: 69200   Required: 1 hours
Training: 2025-08-30 19:39:20,375-Speed 370.35 samples/sec   Loss 0.0010 Epoch: 36   Global Step: 69250   Required: 1 hours
Training: 2025-08-30 19:39:37,662-Speed 370.22 samples/sec   Loss 0.0006 Epoch: 36   Global Step: 69300   Required: 1 hours
Training: 2025-08-30 19:40:15,134-[lfw][69338]XNorm: 15.211540
Training: 2025-08-30 19:40:15,134-[lfw][69338]Accuracy-Flip: 0.82983+-0.01707
Training: 2025-08-30 19:40:15,134-[lfw][69338]Accuracy-Highest: 0.83633
Training: 2025-08-30 19:40:43,484-[cfp_fp][69338]XNorm: 13.212115
Training: 2025-08-30 19:40:43,484-[cfp_fp][69338]Accuracy-Flip: 0.65314+-0.01668
Training: 2025-08-30 19:40:43,484-[cfp_fp][69338]Accuracy-Highest: 0.65900
Training: 2025-08-30 19:41:07,809-[agedb_30][69338]XNorm: 13.381694
Training: 2025-08-30 19:41:07,810-[agedb_30][69338]Accuracy-Flip: 0.54133+-0.01366
Training: 2025-08-30 19:41:07,810-[agedb_30][69338]Accuracy-Highest: 0.55033
Training: 2025-08-30 19:41:32,218-[calfw][69338]XNorm: 15.461711
Training: 2025-08-30 19:41:32,218-[calfw][69338]Accuracy-Flip: 0.68067+-0.02015
Training: 2025-08-30 19:41:32,218-[calfw][69338]Accuracy-Highest: 0.68583
Training: 2025-08-30 19:41:56,595-[cplfw][69338]XNorm: 11.936779
Training: 2025-08-30 19:41:56,595-[cplfw][69338]Accuracy-Flip: 0.63917+-0.01279
Training: 2025-08-30 19:41:56,595-[cplfw][69338]Accuracy-Highest: 0.64400
Training: 2025-08-30 19:42:00,921-Speed 44.67 samples/sec   Loss 0.0011 Epoch: 37   Global Step: 69350   Required: 1 hours
Training: 2025-08-30 19:42:18,189-Speed 370.62 samples/sec   Loss 0.0011 Epoch: 37   Global Step: 69400   Required: 1 hours
Training: 2025-08-30 19:42:35,461-Speed 370.54 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 69450   Required: 1 hours
Training: 2025-08-30 19:42:52,733-Speed 370.55 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 69500   Required: 1 hours
Training: 2025-08-30 19:43:10,013-Speed 370.39 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 69550   Required: 1 hours
Training: 2025-08-30 19:43:27,293-Speed 370.37 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 69600   Required: 1 hours
Training: 2025-08-30 19:43:44,574-Speed 370.35 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 69650   Required: 1 hours
Training: 2025-08-30 19:44:01,851-Speed 370.44 samples/sec   Loss 0.0012 Epoch: 37   Global Step: 69700   Required: 1 hours
Training: 2025-08-30 19:44:19,122-Speed 370.57 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 69750   Required: 1 hours
Training: 2025-08-30 19:44:36,398-Speed 370.45 samples/sec   Loss 0.0010 Epoch: 37   Global Step: 69800   Required: 1 hours
Training: 2025-08-30 19:44:53,675-Speed 370.45 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 69850   Required: 1 hours
Training: 2025-08-30 19:45:10,957-Speed 370.33 samples/sec   Loss 0.0011 Epoch: 37   Global Step: 69900   Required: 1 hours
Training: 2025-08-30 19:45:28,240-Speed 370.29 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 69950   Required: 1 hours
Training: 2025-08-30 19:45:45,524-Speed 370.31 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 70000   Required: 1 hours
Training: 2025-08-30 19:46:02,806-Speed 370.33 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 70050   Required: 1 hours
Training: 2025-08-30 19:46:20,094-Speed 370.20 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 70100   Required: 1 hours
Training: 2025-08-30 19:46:37,376-Speed 370.32 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 70150   Required: 1 hours
Training: 2025-08-30 19:46:54,656-Speed 370.38 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 70200   Required: 1 hours
Training: 2025-08-30 19:47:11,937-Speed 370.34 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 70250   Required: 1 hours
Training: 2025-08-30 19:47:29,218-Speed 370.35 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 70300   Required: 1 hours
Training: 2025-08-30 19:47:46,497-Speed 370.39 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 70350   Required: 1 hours
Training: 2025-08-30 19:48:03,774-Speed 370.45 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 70400   Required: 1 hours
Training: 2025-08-30 19:48:21,056-Speed 370.33 samples/sec   Loss 0.0010 Epoch: 37   Global Step: 70450   Required: 1 hours
Training: 2025-08-30 19:48:38,335-Speed 370.39 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 70500   Required: 1 hours
Training: 2025-08-30 19:48:55,617-Speed 370.32 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 70550   Required: 1 hours
Training: 2025-08-30 19:49:12,899-Speed 370.33 samples/sec   Loss 0.0007 Epoch: 37   Global Step: 70600   Required: 1 hours
Training: 2025-08-30 19:49:30,182-Speed 370.31 samples/sec   Loss 0.0012 Epoch: 37   Global Step: 70650   Required: 0 hours
Training: 2025-08-30 19:49:47,461-Speed 370.40 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 70700   Required: 0 hours
Training: 2025-08-30 19:50:04,742-Speed 370.35 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 70750   Required: 0 hours
Training: 2025-08-30 19:50:22,020-Speed 370.40 samples/sec   Loss 0.0009 Epoch: 37   Global Step: 70800   Required: 0 hours
Training: 2025-08-30 19:50:39,303-Speed 370.31 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 70850   Required: 0 hours
Training: 2025-08-30 19:50:56,585-Speed 370.34 samples/sec   Loss 0.0010 Epoch: 37   Global Step: 70900   Required: 0 hours
Training: 2025-08-30 19:51:13,871-Speed 370.25 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 70950   Required: 0 hours
Training: 2025-08-30 19:51:31,154-Speed 370.30 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 71000   Required: 0 hours
Training: 2025-08-30 19:51:48,441-Speed 370.23 samples/sec   Loss 0.0010 Epoch: 37   Global Step: 71050   Required: 0 hours
Training: 2025-08-30 19:52:05,726-Speed 370.26 samples/sec   Loss 0.0010 Epoch: 37   Global Step: 71100   Required: 0 hours
Training: 2025-08-30 19:52:23,005-Speed 370.39 samples/sec   Loss 0.0011 Epoch: 37   Global Step: 71150   Required: 0 hours
Training: 2025-08-30 19:52:40,287-Speed 370.34 samples/sec   Loss 0.0008 Epoch: 37   Global Step: 71200   Required: 0 hours
Training: 2025-08-30 19:53:08,762-[lfw][71212]XNorm: 15.212348
Training: 2025-08-30 19:53:08,763-[lfw][71212]Accuracy-Flip: 0.82567+-0.01601
Training: 2025-08-30 19:53:08,763-[lfw][71212]Accuracy-Highest: 0.83633
Training: 2025-08-30 19:53:37,085-[cfp_fp][71212]XNorm: 13.253683
Training: 2025-08-30 19:53:37,085-[cfp_fp][71212]Accuracy-Flip: 0.64729+-0.01633
Training: 2025-08-30 19:53:37,085-[cfp_fp][71212]Accuracy-Highest: 0.65900
Training: 2025-08-30 19:54:01,414-[agedb_30][71212]XNorm: 13.506966
Training: 2025-08-30 19:54:01,415-[agedb_30][71212]Accuracy-Flip: 0.54417+-0.01495
Training: 2025-08-30 19:54:01,415-[agedb_30][71212]Accuracy-Highest: 0.55033
Training: 2025-08-30 19:54:25,820-[calfw][71212]XNorm: 15.505701
Training: 2025-08-30 19:54:25,820-[calfw][71212]Accuracy-Flip: 0.67883+-0.01833
Training: 2025-08-30 19:54:25,820-[calfw][71212]Accuracy-Highest: 0.68583
Training: 2025-08-30 19:54:50,206-[cplfw][71212]XNorm: 11.941795
Training: 2025-08-30 19:54:50,206-[cplfw][71212]Accuracy-Flip: 0.64417+-0.01296
Training: 2025-08-30 19:54:50,206-[cplfw][71212]Accuracy-Highest: 0.64417
Training: 2025-08-30 19:55:03,484-Speed 44.69 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 71250   Required: 0 hours
Training: 2025-08-30 19:55:20,758-Speed 370.48 samples/sec   Loss 0.0010 Epoch: 38   Global Step: 71300   Required: 0 hours
Training: 2025-08-30 19:55:38,032-Speed 370.51 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 71350   Required: 0 hours
Training: 2025-08-30 19:55:55,310-Speed 370.40 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 71400   Required: 0 hours
Training: 2025-08-30 19:56:12,591-Speed 370.37 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 71450   Required: 0 hours
Training: 2025-08-30 19:56:29,878-Speed 370.21 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 71500   Required: 0 hours
Training: 2025-08-30 19:56:47,159-Speed 370.36 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 71550   Required: 0 hours
Training: 2025-08-30 19:57:04,441-Speed 370.33 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 71600   Required: 0 hours
Training: 2025-08-30 19:57:21,723-Speed 370.32 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 71650   Required: 0 hours
Training: 2025-08-30 19:57:39,002-Speed 370.40 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 71700   Required: 0 hours
Training: 2025-08-30 19:57:56,284-Speed 370.34 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 71750   Required: 0 hours
Training: 2025-08-30 19:58:13,567-Speed 370.30 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 71800   Required: 0 hours
Training: 2025-08-30 19:58:30,849-Speed 370.35 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 71850   Required: 0 hours
Training: 2025-08-30 19:58:48,129-Speed 370.37 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 71900   Required: 0 hours
Training: 2025-08-30 19:59:05,416-Speed 370.21 samples/sec   Loss 0.0010 Epoch: 38   Global Step: 71950   Required: 0 hours
Training: 2025-08-30 19:59:22,704-Speed 370.20 samples/sec   Loss 0.0010 Epoch: 38   Global Step: 72000   Required: 0 hours
Training: 2025-08-30 19:59:39,990-Speed 370.25 samples/sec   Loss 0.0012 Epoch: 38   Global Step: 72050   Required: 0 hours
Training: 2025-08-30 19:59:57,277-Speed 370.22 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 72100   Required: 0 hours
Training: 2025-08-30 20:00:14,567-Speed 370.16 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 72150   Required: 0 hours
Training: 2025-08-30 20:00:31,850-Speed 370.31 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 72200   Required: 0 hours
Training: 2025-08-30 20:00:49,139-Speed 370.17 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 72250   Required: 0 hours
Training: 2025-08-30 20:01:06,428-Speed 370.18 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 72300   Required: 0 hours
Training: 2025-08-30 20:01:23,713-Speed 370.27 samples/sec   Loss 0.0010 Epoch: 38   Global Step: 72350   Required: 0 hours
Training: 2025-08-30 20:01:40,996-Speed 370.30 samples/sec   Loss 0.0010 Epoch: 38   Global Step: 72400   Required: 0 hours
Training: 2025-08-30 20:01:58,278-Speed 370.33 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 72450   Required: 0 hours
Training: 2025-08-30 20:02:15,561-Speed 370.31 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 72500   Required: 0 hours
Training: 2025-08-30 20:02:32,842-Speed 370.36 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 72550   Required: 0 hours
Training: 2025-08-30 20:02:50,125-Speed 370.30 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 72600   Required: 0 hours
Training: 2025-08-30 20:03:07,413-Speed 370.21 samples/sec   Loss 0.0010 Epoch: 38   Global Step: 72650   Required: 0 hours
Training: 2025-08-30 20:03:24,699-Speed 370.23 samples/sec   Loss 0.0007 Epoch: 38   Global Step: 72700   Required: 0 hours
Training: 2025-08-30 20:03:41,984-Speed 370.29 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 72750   Required: 0 hours
Training: 2025-08-30 20:03:59,268-Speed 370.28 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 72800   Required: 0 hours
Training: 2025-08-30 20:04:16,552-Speed 370.29 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 72850   Required: 0 hours
Training: 2025-08-30 20:04:33,834-Speed 370.32 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 72900   Required: 0 hours
Training: 2025-08-30 20:04:51,116-Speed 370.35 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 72950   Required: 0 hours
Training: 2025-08-30 20:05:08,395-Speed 370.38 samples/sec   Loss 0.0008 Epoch: 38   Global Step: 73000   Required: 0 hours
Training: 2025-08-30 20:05:25,681-Speed 370.26 samples/sec   Loss 0.0009 Epoch: 38   Global Step: 73050   Required: 0 hours
Training: 2025-08-30 20:06:02,463-[lfw][73086]XNorm: 15.286658
Training: 2025-08-30 20:06:02,463-[lfw][73086]Accuracy-Flip: 0.82667+-0.01794
Training: 2025-08-30 20:06:02,463-[lfw][73086]Accuracy-Highest: 0.83633
Training: 2025-08-30 20:06:30,768-[cfp_fp][73086]XNorm: 13.302148
Training: 2025-08-30 20:06:30,768-[cfp_fp][73086]Accuracy-Flip: 0.65757+-0.02174
Training: 2025-08-30 20:06:30,768-[cfp_fp][73086]Accuracy-Highest: 0.65900
Training: 2025-08-30 20:06:55,092-[agedb_30][73086]XNorm: 13.542186
Training: 2025-08-30 20:06:55,092-[agedb_30][73086]Accuracy-Flip: 0.54500+-0.01406
Training: 2025-08-30 20:06:55,092-[agedb_30][73086]Accuracy-Highest: 0.55033
Training: 2025-08-30 20:07:19,497-[calfw][73086]XNorm: 15.574485
Training: 2025-08-30 20:07:19,497-[calfw][73086]Accuracy-Flip: 0.68250+-0.01968
Training: 2025-08-30 20:07:19,497-[calfw][73086]Accuracy-Highest: 0.68583
Training: 2025-08-30 20:07:43,887-[cplfw][73086]XNorm: 11.988748
Training: 2025-08-30 20:07:43,887-[cplfw][73086]Accuracy-Flip: 0.63900+-0.01259
Training: 2025-08-30 20:07:43,887-[cplfw][73086]Accuracy-Highest: 0.64417
Training: 2025-08-30 20:07:48,899-Speed 44.69 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 73100   Required: 0 hours
Training: 2025-08-30 20:08:06,161-Speed 370.76 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 73150   Required: 0 hours
Training: 2025-08-30 20:08:23,433-Speed 370.55 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 73200   Required: 0 hours
Training: 2025-08-30 20:08:40,714-Speed 370.36 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 73250   Required: 0 hours
Training: 2025-08-30 20:08:57,992-Speed 370.40 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 73300   Required: 0 hours
Training: 2025-08-30 20:09:15,277-Speed 370.27 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 73350   Required: 0 hours
Training: 2025-08-30 20:09:32,562-Speed 370.27 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 73400   Required: 0 hours
Training: 2025-08-30 20:09:49,844-Speed 370.33 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 73450   Required: 0 hours
Training: 2025-08-30 20:10:07,123-Speed 370.40 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 73500   Required: 0 hours
Training: 2025-08-30 20:10:24,403-Speed 370.38 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 73550   Required: 0 hours
Training: 2025-08-30 20:10:41,681-Speed 370.41 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 73600   Required: 0 hours
Training: 2025-08-30 20:10:58,960-Speed 370.39 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 73650   Required: 0 hours
Training: 2025-08-30 20:11:16,241-Speed 370.35 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 73700   Required: 0 hours
Training: 2025-08-30 20:11:33,530-Speed 370.20 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 73750   Required: 0 hours
Training: 2025-08-30 20:11:50,816-Speed 370.24 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 73800   Required: 0 hours
Training: 2025-08-30 20:12:08,106-Speed 370.15 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 73850   Required: 0 hours
Training: 2025-08-30 20:12:25,396-Speed 370.16 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 73900   Required: 0 hours
Training: 2025-08-30 20:12:42,681-Speed 370.26 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 73950   Required: 0 hours
Training: 2025-08-30 20:12:59,967-Speed 370.26 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 74000   Required: 0 hours
Training: 2025-08-30 20:13:17,250-Speed 370.31 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 74050   Required: 0 hours
Training: 2025-08-30 20:13:34,534-Speed 370.27 samples/sec   Loss 0.0011 Epoch: 39   Global Step: 74100   Required: 0 hours
Training: 2025-08-30 20:13:51,819-Speed 370.28 samples/sec   Loss 0.0011 Epoch: 39   Global Step: 74150   Required: 0 hours
Training: 2025-08-30 20:14:09,100-Speed 370.34 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 74200   Required: 0 hours
Training: 2025-08-30 20:14:26,379-Speed 370.39 samples/sec   Loss 0.0010 Epoch: 39   Global Step: 74250   Required: 0 hours
Training: 2025-08-30 20:14:43,666-Speed 370.24 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 74300   Required: 0 hours
Training: 2025-08-30 20:15:00,944-Speed 370.41 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 74350   Required: 0 hours
Training: 2025-08-30 20:15:18,225-Speed 370.36 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 74400   Required: 0 hours
Training: 2025-08-30 20:15:35,502-Speed 370.43 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 74450   Required: 0 hours
Training: 2025-08-30 20:15:52,777-Speed 370.47 samples/sec   Loss 0.0010 Epoch: 39   Global Step: 74500   Required: 0 hours
Training: 2025-08-30 20:16:10,055-Speed 370.42 samples/sec   Loss 0.0010 Epoch: 39   Global Step: 74550   Required: 0 hours
Training: 2025-08-30 20:16:27,328-Speed 370.52 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 74600   Required: 0 hours
Training: 2025-08-30 20:16:44,613-Speed 370.26 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 74650   Required: 0 hours
Training: 2025-08-30 20:17:01,899-Speed 370.24 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 74700   Required: 0 hours
Training: 2025-08-30 20:17:19,179-Speed 370.38 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 74750   Required: 0 hours
Training: 2025-08-30 20:17:36,462-Speed 370.31 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 74800   Required: 0 hours
Training: 2025-08-30 20:17:53,746-Speed 370.27 samples/sec   Loss 0.0007 Epoch: 39   Global Step: 74850   Required: 0 hours
Training: 2025-08-30 20:18:11,023-Speed 370.44 samples/sec   Loss 0.0008 Epoch: 39   Global Step: 74900   Required: 0 hours
Training: 2025-08-30 20:18:28,304-Speed 370.35 samples/sec   Loss 0.0009 Epoch: 39   Global Step: 74950   Required: 0 hours
Training: 2025-08-30 20:18:56,091-[lfw][74960]XNorm: 15.285157
Training: 2025-08-30 20:18:56,091-[lfw][74960]Accuracy-Flip: 0.82917+-0.01623
Training: 2025-08-30 20:18:56,092-[lfw][74960]Accuracy-Highest: 0.83633
Training: 2025-08-30 20:19:24,409-[cfp_fp][74960]XNorm: 13.335275
Training: 2025-08-30 20:19:24,409-[cfp_fp][74960]Accuracy-Flip: 0.65457+-0.02003
Training: 2025-08-30 20:19:24,409-[cfp_fp][74960]Accuracy-Highest: 0.65900
Training: 2025-08-30 20:19:48,727-[agedb_30][74960]XNorm: 13.548508
Training: 2025-08-30 20:19:48,727-[agedb_30][74960]Accuracy-Flip: 0.54150+-0.01606
Training: 2025-08-30 20:19:48,727-[agedb_30][74960]Accuracy-Highest: 0.55033
Training: 2025-08-30 20:20:13,127-[calfw][74960]XNorm: 15.569521
Training: 2025-08-30 20:20:13,127-[calfw][74960]Accuracy-Flip: 0.68367+-0.01885
Training: 2025-08-30 20:20:13,127-[calfw][74960]Accuracy-Highest: 0.68583
Training: 2025-08-30 20:20:37,524-[cplfw][74960]XNorm: 12.016170
Training: 2025-08-30 20:20:37,525-[cplfw][74960]Accuracy-Flip: 0.64217+-0.01169
Training: 2025-08-30 20:20:37,525-[cplfw][74960]Accuracy-Highest: 0.64417
