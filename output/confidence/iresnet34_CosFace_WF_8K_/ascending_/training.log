Training: 2025-05-30 07:59:14,829-rank_id: 0
Training: 2025-05-30 07:59:14,829-Dataset: /data/Authentic/casia_training
Training: 2025-05-30 07:59:15,176-Classes: 0 synthetic, 8000 real - 260929 images - eval: 2038
Training: 2025-05-30 07:59:16,122-Total Step is: 81540
Training: 2025-05-30 07:59:48,224-Reducer buckets have been rebuilt in this iteration.
Training: 2025-05-30 07:59:48,324-Reducer buckets have been rebuilt in this iteration.
Training: 2025-05-30 08:00:22,053-Speed 372.84 samples/sec   Loss 36.2940 Epoch: 0   Global Step: 100   Required: 9 hours
Training: 2025-05-30 08:00:39,275-Speed 371.61 samples/sec   Loss 35.8126 Epoch: 0   Global Step: 150   Required: 8 hours
Training: 2025-05-30 08:00:56,527-Speed 370.99 samples/sec   Loss 35.1679 Epoch: 0   Global Step: 200   Required: 8 hours
Training: 2025-05-30 08:01:13,788-Speed 370.77 samples/sec   Loss 34.7763 Epoch: 0   Global Step: 250   Required: 8 hours
Training: 2025-05-30 08:01:31,060-Speed 370.55 samples/sec   Loss 34.2758 Epoch: 0   Global Step: 300   Required: 8 hours
Training: 2025-05-30 08:01:48,335-Speed 370.49 samples/sec   Loss 33.8725 Epoch: 0   Global Step: 350   Required: 8 hours
Training: 2025-05-30 08:02:05,615-Speed 370.36 samples/sec   Loss 33.4884 Epoch: 0   Global Step: 400   Required: 8 hours
Training: 2025-05-30 08:02:22,903-Speed 370.22 samples/sec   Loss 33.0006 Epoch: 0   Global Step: 450   Required: 8 hours
Training: 2025-05-30 08:02:40,187-Speed 370.28 samples/sec   Loss 32.6477 Epoch: 0   Global Step: 500   Required: 8 hours
Training: 2025-05-30 08:02:57,477-Speed 370.17 samples/sec   Loss 32.3002 Epoch: 0   Global Step: 550   Required: 8 hours
Training: 2025-05-30 08:03:14,764-Speed 370.22 samples/sec   Loss 31.9069 Epoch: 0   Global Step: 600   Required: 8 hours
Training: 2025-05-30 08:03:32,056-Speed 370.12 samples/sec   Loss 31.5514 Epoch: 0   Global Step: 650   Required: 8 hours
Training: 2025-05-30 08:03:49,344-Speed 370.19 samples/sec   Loss 31.4347 Epoch: 0   Global Step: 700   Required: 8 hours
Training: 2025-05-30 08:04:06,632-Speed 370.20 samples/sec   Loss 30.9674 Epoch: 0   Global Step: 750   Required: 8 hours
Training: 2025-05-30 08:04:23,920-Speed 370.20 samples/sec   Loss 30.7493 Epoch: 0   Global Step: 800   Required: 8 hours
Training: 2025-05-30 08:04:41,204-Speed 370.29 samples/sec   Loss 30.4316 Epoch: 0   Global Step: 850   Required: 8 hours
Training: 2025-05-30 08:04:58,486-Speed 370.34 samples/sec   Loss 30.0903 Epoch: 0   Global Step: 900   Required: 8 hours
Training: 2025-05-30 08:05:15,767-Speed 370.34 samples/sec   Loss 29.8846 Epoch: 0   Global Step: 950   Required: 8 hours
Training: 2025-05-30 08:05:33,051-Speed 370.29 samples/sec   Loss 29.7206 Epoch: 0   Global Step: 1000   Required: 8 hours
Training: 2025-05-30 08:05:50,333-Speed 370.33 samples/sec   Loss 29.4265 Epoch: 0   Global Step: 1050   Required: 8 hours
Training: 2025-05-30 08:06:07,616-Speed 370.31 samples/sec   Loss 29.1248 Epoch: 0   Global Step: 1100   Required: 8 hours
Training: 2025-05-30 08:06:24,894-Speed 370.42 samples/sec   Loss 28.9485 Epoch: 0   Global Step: 1150   Required: 8 hours
Training: 2025-05-30 08:06:42,172-Speed 370.41 samples/sec   Loss 28.7285 Epoch: 0   Global Step: 1200   Required: 8 hours
Training: 2025-05-30 08:06:59,452-Speed 370.38 samples/sec   Loss 28.3735 Epoch: 0   Global Step: 1250   Required: 8 hours
Training: 2025-05-30 08:07:16,728-Speed 370.44 samples/sec   Loss 28.1129 Epoch: 0   Global Step: 1300   Required: 8 hours
Training: 2025-05-30 08:07:34,006-Speed 370.42 samples/sec   Loss 27.8285 Epoch: 0   Global Step: 1350   Required: 8 hours
Training: 2025-05-30 08:07:51,283-Speed 370.44 samples/sec   Loss 27.7224 Epoch: 0   Global Step: 1400   Required: 8 hours
Training: 2025-05-30 08:08:08,556-Speed 370.51 samples/sec   Loss 27.3471 Epoch: 0   Global Step: 1450   Required: 8 hours
Training: 2025-05-30 08:08:25,835-Speed 370.41 samples/sec   Loss 27.2853 Epoch: 0   Global Step: 1500   Required: 8 hours
Training: 2025-05-30 08:08:43,111-Speed 370.45 samples/sec   Loss 27.0531 Epoch: 0   Global Step: 1550   Required: 8 hours
Training: 2025-05-30 08:09:00,390-Speed 370.39 samples/sec   Loss 26.8326 Epoch: 0   Global Step: 1600   Required: 8 hours
Training: 2025-05-30 08:09:17,670-Speed 370.37 samples/sec   Loss 26.4952 Epoch: 0   Global Step: 1650   Required: 8 hours
Training: 2025-05-30 08:09:34,945-Speed 370.48 samples/sec   Loss 26.3219 Epoch: 0   Global Step: 1700   Required: 8 hours
Training: 2025-05-30 08:09:52,224-Speed 370.39 samples/sec   Loss 26.0327 Epoch: 0   Global Step: 1750   Required: 8 hours
Training: 2025-05-30 08:10:09,505-Speed 370.36 samples/sec   Loss 25.9086 Epoch: 0   Global Step: 1800   Required: 8 hours
Training: 2025-05-30 08:10:26,785-Speed 370.38 samples/sec   Loss 25.6394 Epoch: 0   Global Step: 1850   Required: 8 hours
Training: 2025-05-30 08:10:44,059-Speed 370.49 samples/sec   Loss 25.3079 Epoch: 0   Global Step: 1900   Required: 8 hours
Training: 2025-05-30 08:11:01,337-Speed 370.43 samples/sec   Loss 25.2069 Epoch: 0   Global Step: 1950   Required: 8 hours
Training: 2025-05-30 08:11:18,615-Speed 370.41 samples/sec   Loss 24.8788 Epoch: 0   Global Step: 2000   Required: 8 hours
Training: 2025-05-30 08:11:56,513-[lfw][2038]XNorm: 22.771285
Training: 2025-05-30 08:11:56,513-[lfw][2038]Accuracy-Flip: 0.91133+-0.01352
Training: 2025-05-30 08:11:56,513-[lfw][2038]Accuracy-Highest: 0.91133
Training: 2025-05-30 08:12:24,885-[cfp_fp][2038]XNorm: 21.474728
Training: 2025-05-30 08:12:24,885-[cfp_fp][2038]Accuracy-Flip: 0.68543+-0.01899
Training: 2025-05-30 08:12:24,885-[cfp_fp][2038]Accuracy-Highest: 0.68543
Training: 2025-05-30 08:12:49,200-[agedb_30][2038]XNorm: 18.921194
Training: 2025-05-30 08:12:49,200-[agedb_30][2038]Accuracy-Flip: 0.67750+-0.01355
Training: 2025-05-30 08:12:49,200-[agedb_30][2038]Accuracy-Highest: 0.67750
Training: 2025-05-30 08:13:13,607-[calfw][2038]XNorm: 22.248864
Training: 2025-05-30 08:13:13,607-[calfw][2038]Accuracy-Flip: 0.77200+-0.01593
Training: 2025-05-30 08:13:13,607-[calfw][2038]Accuracy-Highest: 0.77200
Training: 2025-05-30 08:13:38,007-[cplfw][2038]XNorm: 22.113045
Training: 2025-05-30 08:13:38,008-[cplfw][2038]Accuracy-Flip: 0.62617+-0.01293
Training: 2025-05-30 08:13:38,008-[cplfw][2038]Accuracy-Highest: 0.62617
Training: 2025-05-30 08:13:42,339-Speed 44.53 samples/sec   Loss 24.3656 Epoch: 1   Global Step: 2050   Required: 9 hours
Training: 2025-05-30 08:13:59,602-Speed 370.74 samples/sec   Loss 22.5637 Epoch: 1   Global Step: 2100   Required: 9 hours
Training: 2025-05-30 08:14:16,871-Speed 370.62 samples/sec   Loss 22.4824 Epoch: 1   Global Step: 2150   Required: 9 hours
Training: 2025-05-30 08:14:34,141-Speed 370.58 samples/sec   Loss 22.5187 Epoch: 1   Global Step: 2200   Required: 9 hours
Training: 2025-05-30 08:14:51,414-Speed 370.52 samples/sec   Loss 22.1964 Epoch: 1   Global Step: 2250   Required: 9 hours
Training: 2025-05-30 08:15:08,690-Speed 370.45 samples/sec   Loss 22.1009 Epoch: 1   Global Step: 2300   Required: 9 hours
Training: 2025-05-30 08:15:25,967-Speed 370.43 samples/sec   Loss 22.1324 Epoch: 1   Global Step: 2350   Required: 9 hours
Training: 2025-05-30 08:15:43,243-Speed 370.47 samples/sec   Loss 21.9886 Epoch: 1   Global Step: 2400   Required: 9 hours
Training: 2025-05-30 08:16:00,521-Speed 370.42 samples/sec   Loss 22.1227 Epoch: 1   Global Step: 2450   Required: 9 hours
Training: 2025-05-30 08:16:17,793-Speed 370.53 samples/sec   Loss 21.9127 Epoch: 1   Global Step: 2500   Required: 9 hours
Training: 2025-05-30 08:16:35,069-Speed 370.45 samples/sec   Loss 21.8545 Epoch: 1   Global Step: 2550   Required: 9 hours
Training: 2025-05-30 08:16:52,346-Speed 370.45 samples/sec   Loss 21.9132 Epoch: 1   Global Step: 2600   Required: 9 hours
Training: 2025-05-30 08:17:09,621-Speed 370.49 samples/sec   Loss 21.6048 Epoch: 1   Global Step: 2650   Required: 9 hours
Training: 2025-05-30 08:17:26,897-Speed 370.46 samples/sec   Loss 21.4629 Epoch: 1   Global Step: 2700   Required: 9 hours
Training: 2025-05-30 08:17:44,171-Speed 370.50 samples/sec   Loss 21.5097 Epoch: 1   Global Step: 2750   Required: 9 hours
Training: 2025-05-30 08:18:01,447-Speed 370.46 samples/sec   Loss 21.5316 Epoch: 1   Global Step: 2800   Required: 9 hours
Training: 2025-05-30 08:18:18,720-Speed 370.51 samples/sec   Loss 21.2705 Epoch: 1   Global Step: 2850   Required: 9 hours
Training: 2025-05-30 08:18:35,995-Speed 370.49 samples/sec   Loss 21.1717 Epoch: 1   Global Step: 2900   Required: 9 hours
Training: 2025-05-30 08:18:53,273-Speed 370.42 samples/sec   Loss 21.0729 Epoch: 1   Global Step: 2950   Required: 9 hours
Training: 2025-05-30 08:19:10,550-Speed 370.43 samples/sec   Loss 20.9074 Epoch: 1   Global Step: 3000   Required: 8 hours
Training: 2025-05-30 08:19:27,825-Speed 370.47 samples/sec   Loss 20.9849 Epoch: 1   Global Step: 3050   Required: 8 hours
Training: 2025-05-30 08:19:45,102-Speed 370.44 samples/sec   Loss 20.6617 Epoch: 1   Global Step: 3100   Required: 8 hours
Training: 2025-05-30 08:20:02,378-Speed 370.46 samples/sec   Loss 20.7424 Epoch: 1   Global Step: 3150   Required: 8 hours
Training: 2025-05-30 08:20:19,654-Speed 370.46 samples/sec   Loss 20.6727 Epoch: 1   Global Step: 3200   Required: 8 hours
Training: 2025-05-30 08:20:36,929-Speed 370.48 samples/sec   Loss 20.4833 Epoch: 1   Global Step: 3250   Required: 8 hours
Training: 2025-05-30 08:20:54,202-Speed 370.53 samples/sec   Loss 20.4509 Epoch: 1   Global Step: 3300   Required: 8 hours
Training: 2025-05-30 08:21:11,477-Speed 370.48 samples/sec   Loss 20.2207 Epoch: 1   Global Step: 3350   Required: 8 hours
Training: 2025-05-30 08:21:28,753-Speed 370.46 samples/sec   Loss 20.2922 Epoch: 1   Global Step: 3400   Required: 8 hours
Training: 2025-05-30 08:21:46,029-Speed 370.47 samples/sec   Loss 20.0391 Epoch: 1   Global Step: 3450   Required: 8 hours
Training: 2025-05-30 08:22:03,306-Speed 370.43 samples/sec   Loss 20.1065 Epoch: 1   Global Step: 3500   Required: 8 hours
Training: 2025-05-30 08:22:20,583-Speed 370.45 samples/sec   Loss 19.9290 Epoch: 1   Global Step: 3550   Required: 8 hours
Training: 2025-05-30 08:22:37,867-Speed 370.29 samples/sec   Loss 19.8808 Epoch: 1   Global Step: 3600   Required: 8 hours
Training: 2025-05-30 08:22:55,146-Speed 370.39 samples/sec   Loss 19.7729 Epoch: 1   Global Step: 3650   Required: 8 hours
Training: 2025-05-30 08:23:12,424-Speed 370.40 samples/sec   Loss 19.4900 Epoch: 1   Global Step: 3700   Required: 8 hours
Training: 2025-05-30 08:23:29,708-Speed 370.31 samples/sec   Loss 19.3163 Epoch: 1   Global Step: 3750   Required: 8 hours
Training: 2025-05-30 08:23:46,984-Speed 370.45 samples/sec   Loss 19.5976 Epoch: 1   Global Step: 3800   Required: 8 hours
Training: 2025-05-30 08:24:04,264-Speed 370.37 samples/sec   Loss 19.5968 Epoch: 1   Global Step: 3850   Required: 8 hours
Training: 2025-05-30 08:24:21,540-Speed 370.46 samples/sec   Loss 19.2966 Epoch: 1   Global Step: 3900   Required: 8 hours
Training: 2025-05-30 08:24:38,815-Speed 370.48 samples/sec   Loss 19.0381 Epoch: 1   Global Step: 3950   Required: 8 hours
Training: 2025-05-30 08:24:56,089-Speed 370.49 samples/sec   Loss 19.2071 Epoch: 1   Global Step: 4000   Required: 8 hours
Training: 2025-05-30 08:25:13,362-Speed 370.53 samples/sec   Loss 19.1061 Epoch: 1   Global Step: 4050   Required: 8 hours
Training: 2025-05-30 08:25:46,719-[lfw][4076]XNorm: 23.650036
Training: 2025-05-30 08:25:46,719-[lfw][4076]Accuracy-Flip: 0.94733+-0.00932
Training: 2025-05-30 08:25:46,719-[lfw][4076]Accuracy-Highest: 0.94733
Training: 2025-05-30 08:26:15,107-[cfp_fp][4076]XNorm: 20.758328
Training: 2025-05-30 08:26:15,107-[cfp_fp][4076]Accuracy-Flip: 0.75243+-0.01265
Training: 2025-05-30 08:26:15,107-[cfp_fp][4076]Accuracy-Highest: 0.75243
Training: 2025-05-30 08:26:39,412-[agedb_30][4076]XNorm: 20.029622
Training: 2025-05-30 08:26:39,412-[agedb_30][4076]Accuracy-Flip: 0.79800+-0.02361
Training: 2025-05-30 08:26:39,412-[agedb_30][4076]Accuracy-Highest: 0.79800
Training: 2025-05-30 08:27:03,802-[calfw][4076]XNorm: 23.120821
Training: 2025-05-30 08:27:03,802-[calfw][4076]Accuracy-Flip: 0.84150+-0.01405
Training: 2025-05-30 08:27:03,802-[calfw][4076]Accuracy-Highest: 0.84150
Training: 2025-05-30 08:27:28,180-[cplfw][4076]XNorm: 21.774766
Training: 2025-05-30 08:27:28,180-[cplfw][4076]Accuracy-Flip: 0.68383+-0.02846
Training: 2025-05-30 08:27:28,180-[cplfw][4076]Accuracy-Highest: 0.68383
Training: 2025-05-30 08:27:36,639-Speed 44.67 samples/sec   Loss 17.7999 Epoch: 2   Global Step: 4100   Required: 9 hours
Training: 2025-05-30 08:27:53,889-Speed 371.02 samples/sec   Loss 16.4583 Epoch: 2   Global Step: 4150   Required: 9 hours
Training: 2025-05-30 08:28:11,147-Speed 370.85 samples/sec   Loss 16.5656 Epoch: 2   Global Step: 4200   Required: 9 hours
Training: 2025-05-30 08:28:28,412-Speed 370.69 samples/sec   Loss 16.5606 Epoch: 2   Global Step: 4250   Required: 9 hours
Training: 2025-05-30 08:28:45,679-Speed 370.64 samples/sec   Loss 16.5338 Epoch: 2   Global Step: 4300   Required: 9 hours
Training: 2025-05-30 08:29:02,955-Speed 370.46 samples/sec   Loss 16.2840 Epoch: 2   Global Step: 4350   Required: 9 hours
Training: 2025-05-30 08:29:20,230-Speed 370.47 samples/sec   Loss 16.6448 Epoch: 2   Global Step: 4400   Required: 9 hours
Training: 2025-05-30 08:29:37,505-Speed 370.49 samples/sec   Loss 16.5726 Epoch: 2   Global Step: 4450   Required: 9 hours
Training: 2025-05-30 08:29:54,776-Speed 370.56 samples/sec   Loss 16.6781 Epoch: 2   Global Step: 4500   Required: 9 hours
Training: 2025-05-30 08:30:12,054-Speed 370.42 samples/sec   Loss 16.6218 Epoch: 2   Global Step: 4550   Required: 9 hours
Training: 2025-05-30 08:30:29,330-Speed 370.44 samples/sec   Loss 16.5960 Epoch: 2   Global Step: 4600   Required: 9 hours
Training: 2025-05-30 08:30:46,604-Speed 370.51 samples/sec   Loss 16.6283 Epoch: 2   Global Step: 4650   Required: 9 hours
Training: 2025-05-30 08:31:03,880-Speed 370.45 samples/sec   Loss 16.6652 Epoch: 2   Global Step: 4700   Required: 9 hours
Training: 2025-05-30 08:31:21,153-Speed 370.53 samples/sec   Loss 16.3916 Epoch: 2   Global Step: 4750   Required: 9 hours
Training: 2025-05-30 08:31:38,421-Speed 370.64 samples/sec   Loss 16.7047 Epoch: 2   Global Step: 4800   Required: 9 hours
Training: 2025-05-30 08:31:55,697-Speed 370.45 samples/sec   Loss 16.7515 Epoch: 2   Global Step: 4850   Required: 8 hours
Training: 2025-05-30 08:32:12,971-Speed 370.49 samples/sec   Loss 16.5544 Epoch: 2   Global Step: 4900   Required: 8 hours
Training: 2025-05-30 08:32:30,251-Speed 370.38 samples/sec   Loss 16.9713 Epoch: 2   Global Step: 4950   Required: 8 hours
Training: 2025-05-30 08:32:47,524-Speed 370.52 samples/sec   Loss 16.6707 Epoch: 2   Global Step: 5000   Required: 8 hours
Training: 2025-05-30 08:33:04,804-Speed 370.38 samples/sec   Loss 16.6734 Epoch: 2   Global Step: 5050   Required: 8 hours
Training: 2025-05-30 08:33:22,076-Speed 370.54 samples/sec   Loss 16.4030 Epoch: 2   Global Step: 5100   Required: 8 hours
Training: 2025-05-30 08:33:39,344-Speed 370.65 samples/sec   Loss 16.8639 Epoch: 2   Global Step: 5150   Required: 8 hours
Training: 2025-05-30 08:33:56,612-Speed 370.62 samples/sec   Loss 16.5894 Epoch: 2   Global Step: 5200   Required: 8 hours
Training: 2025-05-30 08:34:13,876-Speed 370.71 samples/sec   Loss 16.3977 Epoch: 2   Global Step: 5250   Required: 8 hours
Training: 2025-05-30 08:34:31,144-Speed 370.65 samples/sec   Loss 16.5231 Epoch: 2   Global Step: 5300   Required: 8 hours
Training: 2025-05-30 08:34:48,411-Speed 370.64 samples/sec   Loss 16.4965 Epoch: 2   Global Step: 5350   Required: 8 hours
Training: 2025-05-30 08:35:05,678-Speed 370.66 samples/sec   Loss 16.4666 Epoch: 2   Global Step: 5400   Required: 8 hours
Training: 2025-05-30 08:35:22,948-Speed 370.59 samples/sec   Loss 16.4118 Epoch: 2   Global Step: 5450   Required: 8 hours
Training: 2025-05-30 08:35:40,220-Speed 370.55 samples/sec   Loss 16.2963 Epoch: 2   Global Step: 5500   Required: 8 hours
Training: 2025-05-30 08:35:57,488-Speed 370.62 samples/sec   Loss 16.5635 Epoch: 2   Global Step: 5550   Required: 8 hours
Training: 2025-05-30 08:36:14,755-Speed 370.67 samples/sec   Loss 16.3470 Epoch: 2   Global Step: 5600   Required: 8 hours
Training: 2025-05-30 08:36:32,020-Speed 370.70 samples/sec   Loss 16.1622 Epoch: 2   Global Step: 5650   Required: 8 hours
Training: 2025-05-30 08:36:49,288-Speed 370.62 samples/sec   Loss 16.4620 Epoch: 2   Global Step: 5700   Required: 8 hours
Training: 2025-05-30 08:37:06,560-Speed 370.55 samples/sec   Loss 15.9907 Epoch: 2   Global Step: 5750   Required: 8 hours
Training: 2025-05-30 08:37:23,834-Speed 370.50 samples/sec   Loss 16.1727 Epoch: 2   Global Step: 5800   Required: 8 hours
Training: 2025-05-30 08:37:41,105-Speed 370.56 samples/sec   Loss 16.1646 Epoch: 2   Global Step: 5850   Required: 8 hours
Training: 2025-05-30 08:37:58,378-Speed 370.54 samples/sec   Loss 16.0321 Epoch: 2   Global Step: 5900   Required: 8 hours
Training: 2025-05-30 08:38:15,652-Speed 370.50 samples/sec   Loss 16.2357 Epoch: 2   Global Step: 5950   Required: 8 hours
Training: 2025-05-30 08:38:32,918-Speed 370.66 samples/sec   Loss 16.0578 Epoch: 2   Global Step: 6000   Required: 8 hours
Training: 2025-05-30 08:38:50,192-Speed 370.50 samples/sec   Loss 16.0702 Epoch: 2   Global Step: 6050   Required: 8 hours
Training: 2025-05-30 08:39:07,459-Speed 370.66 samples/sec   Loss 16.2383 Epoch: 2   Global Step: 6100   Required: 8 hours
Training: 2025-05-30 08:39:36,596-[lfw][6114]XNorm: 23.260336
Training: 2025-05-30 08:39:36,596-[lfw][6114]Accuracy-Flip: 0.96467+-0.00884
Training: 2025-05-30 08:39:36,596-[lfw][6114]Accuracy-Highest: 0.96467
Training: 2025-05-30 08:40:05,116-[cfp_fp][6114]XNorm: 20.267551
Training: 2025-05-30 08:40:05,117-[cfp_fp][6114]Accuracy-Flip: 0.78357+-0.01825
Training: 2025-05-30 08:40:05,117-[cfp_fp][6114]Accuracy-Highest: 0.78357
Training: 2025-05-30 08:40:29,412-[agedb_30][6114]XNorm: 20.896810
Training: 2025-05-30 08:40:29,412-[agedb_30][6114]Accuracy-Flip: 0.82917+-0.02310
Training: 2025-05-30 08:40:29,412-[agedb_30][6114]Accuracy-Highest: 0.82917
Training: 2025-05-30 08:40:53,788-[calfw][6114]XNorm: 22.913287
Training: 2025-05-30 08:40:53,789-[calfw][6114]Accuracy-Flip: 0.87567+-0.01422
Training: 2025-05-30 08:40:53,789-[calfw][6114]Accuracy-Highest: 0.87567
Training: 2025-05-30 08:41:18,152-[cplfw][6114]XNorm: 20.493445
Training: 2025-05-30 08:41:18,152-[cplfw][6114]Accuracy-Flip: 0.72417+-0.02813
Training: 2025-05-30 08:41:18,152-[cplfw][6114]Accuracy-Highest: 0.72417
Training: 2025-05-30 08:41:30,739-Speed 44.67 samples/sec   Loss 14.0898 Epoch: 3   Global Step: 6150   Required: 9 hours
Training: 2025-05-30 08:41:47,997-Speed 370.84 samples/sec   Loss 13.4790 Epoch: 3   Global Step: 6200   Required: 9 hours
Training: 2025-05-30 08:42:05,260-Speed 370.74 samples/sec   Loss 13.7522 Epoch: 3   Global Step: 6250   Required: 9 hours
Training: 2025-05-30 08:42:22,528-Speed 370.63 samples/sec   Loss 13.8079 Epoch: 3   Global Step: 6300   Required: 8 hours
Training: 2025-05-30 08:42:39,796-Speed 370.62 samples/sec   Loss 13.7356 Epoch: 3   Global Step: 6350   Required: 8 hours
Training: 2025-05-30 08:42:57,062-Speed 370.68 samples/sec   Loss 13.7305 Epoch: 3   Global Step: 6400   Required: 8 hours
Training: 2025-05-30 08:43:14,329-Speed 370.65 samples/sec   Loss 13.8896 Epoch: 3   Global Step: 6450   Required: 8 hours
Training: 2025-05-30 08:43:31,593-Speed 370.72 samples/sec   Loss 14.1407 Epoch: 3   Global Step: 6500   Required: 8 hours
Training: 2025-05-30 08:43:48,863-Speed 370.58 samples/sec   Loss 14.0825 Epoch: 3   Global Step: 6550   Required: 8 hours
Training: 2025-05-30 08:44:06,130-Speed 370.65 samples/sec   Loss 14.1560 Epoch: 3   Global Step: 6600   Required: 8 hours
Training: 2025-05-30 08:44:23,396-Speed 370.69 samples/sec   Loss 14.1511 Epoch: 3   Global Step: 6650   Required: 8 hours
Training: 2025-05-30 08:44:40,662-Speed 370.66 samples/sec   Loss 14.0895 Epoch: 3   Global Step: 6700   Required: 8 hours
Training: 2025-05-30 08:44:57,929-Speed 370.65 samples/sec   Loss 14.3164 Epoch: 3   Global Step: 6750   Required: 8 hours
Training: 2025-05-30 08:45:15,198-Speed 370.61 samples/sec   Loss 14.3530 Epoch: 3   Global Step: 6800   Required: 8 hours
Training: 2025-05-30 08:45:32,465-Speed 370.65 samples/sec   Loss 14.0816 Epoch: 3   Global Step: 6850   Required: 8 hours
Training: 2025-05-30 08:45:49,734-Speed 370.61 samples/sec   Loss 14.4773 Epoch: 3   Global Step: 6900   Required: 8 hours
Training: 2025-05-30 08:46:07,003-Speed 370.61 samples/sec   Loss 14.4138 Epoch: 3   Global Step: 6950   Required: 8 hours
Training: 2025-05-30 08:46:24,274-Speed 370.58 samples/sec   Loss 14.0801 Epoch: 3   Global Step: 7000   Required: 8 hours
Training: 2025-05-30 08:46:41,539-Speed 370.68 samples/sec   Loss 14.5921 Epoch: 3   Global Step: 7050   Required: 8 hours
Training: 2025-05-30 08:46:58,809-Speed 370.60 samples/sec   Loss 14.5064 Epoch: 3   Global Step: 7100   Required: 8 hours
Training: 2025-05-30 08:47:16,079-Speed 370.57 samples/sec   Loss 14.1874 Epoch: 3   Global Step: 7150   Required: 8 hours
Training: 2025-05-30 08:47:33,350-Speed 370.58 samples/sec   Loss 14.2736 Epoch: 3   Global Step: 7200   Required: 8 hours
Training: 2025-05-30 08:47:50,627-Speed 370.44 samples/sec   Loss 14.3886 Epoch: 3   Global Step: 7250   Required: 8 hours
Training: 2025-05-30 08:48:07,901-Speed 370.51 samples/sec   Loss 14.3635 Epoch: 3   Global Step: 7300   Required: 8 hours
Training: 2025-05-30 08:48:25,173-Speed 370.52 samples/sec   Loss 14.2496 Epoch: 3   Global Step: 7350   Required: 8 hours
Training: 2025-05-30 08:48:42,446-Speed 370.52 samples/sec   Loss 14.3087 Epoch: 3   Global Step: 7400   Required: 8 hours
Training: 2025-05-30 08:48:59,718-Speed 370.56 samples/sec   Loss 14.4386 Epoch: 3   Global Step: 7450   Required: 8 hours
Training: 2025-05-30 08:49:16,988-Speed 370.59 samples/sec   Loss 14.4106 Epoch: 3   Global Step: 7500   Required: 8 hours
Training: 2025-05-30 08:49:34,259-Speed 370.57 samples/sec   Loss 14.3549 Epoch: 3   Global Step: 7550   Required: 8 hours
Training: 2025-05-30 08:49:51,533-Speed 370.50 samples/sec   Loss 14.4999 Epoch: 3   Global Step: 7600   Required: 8 hours
Training: 2025-05-30 08:50:08,806-Speed 370.52 samples/sec   Loss 14.3833 Epoch: 3   Global Step: 7650   Required: 8 hours
Training: 2025-05-30 08:50:26,076-Speed 370.58 samples/sec   Loss 14.4333 Epoch: 3   Global Step: 7700   Required: 8 hours
Training: 2025-05-30 08:50:43,344-Speed 370.63 samples/sec   Loss 14.4288 Epoch: 3   Global Step: 7750   Required: 8 hours
Training: 2025-05-30 08:51:00,613-Speed 370.62 samples/sec   Loss 14.4523 Epoch: 3   Global Step: 7800   Required: 8 hours
Training: 2025-05-30 08:51:17,882-Speed 370.61 samples/sec   Loss 14.3475 Epoch: 3   Global Step: 7850   Required: 8 hours
Training: 2025-05-30 08:51:35,151-Speed 370.60 samples/sec   Loss 14.1985 Epoch: 3   Global Step: 7900   Required: 8 hours
Training: 2025-05-30 08:51:52,425-Speed 370.52 samples/sec   Loss 14.4604 Epoch: 3   Global Step: 7950   Required: 8 hours
Training: 2025-05-30 08:52:09,695-Speed 370.57 samples/sec   Loss 14.0776 Epoch: 3   Global Step: 8000   Required: 8 hours
Training: 2025-05-30 08:52:26,964-Speed 370.61 samples/sec   Loss 14.2770 Epoch: 3   Global Step: 8050   Required: 8 hours
Training: 2025-05-30 08:52:44,239-Speed 370.49 samples/sec   Loss 14.6618 Epoch: 3   Global Step: 8100   Required: 8 hours
Training: 2025-05-30 08:53:01,511-Speed 370.54 samples/sec   Loss 14.1668 Epoch: 3   Global Step: 8150   Required: 8 hours
Training: 2025-05-30 08:53:26,511-[lfw][8152]XNorm: 24.904301
Training: 2025-05-30 08:53:26,511-[lfw][8152]Accuracy-Flip: 0.97400+-0.00708
Training: 2025-05-30 08:53:26,511-[lfw][8152]Accuracy-Highest: 0.97400
Training: 2025-05-30 08:53:54,951-[cfp_fp][8152]XNorm: 21.576578
Training: 2025-05-30 08:53:54,951-[cfp_fp][8152]Accuracy-Flip: 0.81729+-0.01590
Training: 2025-05-30 08:53:54,951-[cfp_fp][8152]Accuracy-Highest: 0.81729
Training: 2025-05-30 08:54:19,241-[agedb_30][8152]XNorm: 22.502401
Training: 2025-05-30 08:54:19,242-[agedb_30][8152]Accuracy-Flip: 0.85200+-0.01943
Training: 2025-05-30 08:54:19,242-[agedb_30][8152]Accuracy-Highest: 0.85200
Training: 2025-05-30 08:54:43,613-[calfw][8152]XNorm: 24.581445
Training: 2025-05-30 08:54:43,613-[calfw][8152]Accuracy-Flip: 0.88067+-0.01350
Training: 2025-05-30 08:54:43,614-[calfw][8152]Accuracy-Highest: 0.88067
Training: 2025-05-30 08:55:07,975-[cplfw][8152]XNorm: 21.656106
Training: 2025-05-30 08:55:07,975-[cplfw][8152]Accuracy-Flip: 0.76283+-0.02415
Training: 2025-05-30 08:55:07,975-[cplfw][8152]Accuracy-Highest: 0.76283
Training: 2025-05-30 08:55:24,700-Speed 44.70 samples/sec   Loss 11.7594 Epoch: 4   Global Step: 8200   Required: 8 hours
Training: 2025-05-30 08:55:41,961-Speed 370.78 samples/sec   Loss 11.9862 Epoch: 4   Global Step: 8250   Required: 8 hours
Training: 2025-05-30 08:55:59,221-Speed 370.80 samples/sec   Loss 12.0469 Epoch: 4   Global Step: 8300   Required: 8 hours
Training: 2025-05-30 08:56:16,482-Speed 370.78 samples/sec   Loss 12.1050 Epoch: 4   Global Step: 8350   Required: 8 hours
Training: 2025-05-30 08:56:33,750-Speed 370.63 samples/sec   Loss 12.2275 Epoch: 4   Global Step: 8400   Required: 8 hours
Training: 2025-05-30 08:56:51,021-Speed 370.56 samples/sec   Loss 12.4479 Epoch: 4   Global Step: 8450   Required: 8 hours
Training: 2025-05-30 08:57:08,292-Speed 370.57 samples/sec   Loss 12.2713 Epoch: 4   Global Step: 8500   Required: 8 hours
Training: 2025-05-30 08:57:25,571-Speed 370.39 samples/sec   Loss 12.6454 Epoch: 4   Global Step: 8550   Required: 8 hours
Training: 2025-05-30 08:57:42,849-Speed 370.41 samples/sec   Loss 12.5015 Epoch: 4   Global Step: 8600   Required: 8 hours
Training: 2025-05-30 08:58:00,126-Speed 370.45 samples/sec   Loss 12.6962 Epoch: 4   Global Step: 8650   Required: 8 hours
Training: 2025-05-30 08:58:17,401-Speed 370.47 samples/sec   Loss 12.5838 Epoch: 4   Global Step: 8700   Required: 8 hours
Training: 2025-05-30 08:58:34,677-Speed 370.46 samples/sec   Loss 12.6095 Epoch: 4   Global Step: 8750   Required: 8 hours
Training: 2025-05-30 08:58:51,950-Speed 370.52 samples/sec   Loss 12.4713 Epoch: 4   Global Step: 8800   Required: 8 hours
Training: 2025-05-30 08:59:09,228-Speed 370.41 samples/sec   Loss 12.7589 Epoch: 4   Global Step: 8850   Required: 8 hours
Training: 2025-05-30 08:59:26,505-Speed 370.44 samples/sec   Loss 12.8909 Epoch: 4   Global Step: 8900   Required: 8 hours
Training: 2025-05-30 08:59:43,777-Speed 370.55 samples/sec   Loss 12.9649 Epoch: 4   Global Step: 8950   Required: 8 hours
Training: 2025-05-30 09:00:01,050-Speed 370.52 samples/sec   Loss 13.0859 Epoch: 4   Global Step: 9000   Required: 8 hours
Training: 2025-05-30 09:00:18,328-Speed 370.42 samples/sec   Loss 13.2029 Epoch: 4   Global Step: 9050   Required: 8 hours
Training: 2025-05-30 09:00:35,607-Speed 370.39 samples/sec   Loss 13.0329 Epoch: 4   Global Step: 9100   Required: 8 hours
Training: 2025-05-30 09:00:52,879-Speed 370.53 samples/sec   Loss 12.8747 Epoch: 4   Global Step: 9150   Required: 8 hours
Training: 2025-05-30 09:01:10,153-Speed 370.52 samples/sec   Loss 13.0664 Epoch: 4   Global Step: 9200   Required: 8 hours
Training: 2025-05-30 09:01:27,428-Speed 370.48 samples/sec   Loss 13.2708 Epoch: 4   Global Step: 9250   Required: 8 hours
Training: 2025-05-30 09:01:44,698-Speed 370.58 samples/sec   Loss 13.1441 Epoch: 4   Global Step: 9300   Required: 8 hours
Training: 2025-05-30 09:02:01,966-Speed 370.63 samples/sec   Loss 12.9597 Epoch: 4   Global Step: 9350   Required: 8 hours
Training: 2025-05-30 09:02:19,236-Speed 370.58 samples/sec   Loss 13.0033 Epoch: 4   Global Step: 9400   Required: 8 hours
Training: 2025-05-30 09:02:36,504-Speed 370.63 samples/sec   Loss 13.2990 Epoch: 4   Global Step: 9450   Required: 8 hours
Training: 2025-05-30 09:02:53,776-Speed 370.54 samples/sec   Loss 13.0828 Epoch: 4   Global Step: 9500   Required: 8 hours
Training: 2025-05-30 09:03:11,044-Speed 370.64 samples/sec   Loss 13.2664 Epoch: 4   Global Step: 9550   Required: 8 hours
Training: 2025-05-30 09:03:28,308-Speed 370.70 samples/sec   Loss 12.9416 Epoch: 4   Global Step: 9600   Required: 8 hours
Training: 2025-05-30 09:03:45,575-Speed 370.67 samples/sec   Loss 13.2801 Epoch: 4   Global Step: 9650   Required: 8 hours
Training: 2025-05-30 09:04:02,841-Speed 370.67 samples/sec   Loss 13.2234 Epoch: 4   Global Step: 9700   Required: 8 hours
Training: 2025-05-30 09:04:20,106-Speed 370.70 samples/sec   Loss 12.8399 Epoch: 4   Global Step: 9750   Required: 8 hours
Training: 2025-05-30 09:04:37,370-Speed 370.70 samples/sec   Loss 13.3084 Epoch: 4   Global Step: 9800   Required: 8 hours
Training: 2025-05-30 09:04:54,633-Speed 370.75 samples/sec   Loss 13.1153 Epoch: 4   Global Step: 9850   Required: 8 hours
Training: 2025-05-30 09:05:11,895-Speed 370.77 samples/sec   Loss 13.2474 Epoch: 4   Global Step: 9900   Required: 8 hours
Training: 2025-05-30 09:05:29,164-Speed 370.60 samples/sec   Loss 13.1130 Epoch: 4   Global Step: 9950   Required: 8 hours
Training: 2025-05-30 09:05:46,432-Speed 370.63 samples/sec   Loss 13.2039 Epoch: 4   Global Step: 10000   Required: 8 hours
Training: 2025-05-30 09:06:03,697-Speed 370.70 samples/sec   Loss 13.0708 Epoch: 4   Global Step: 10050   Required: 8 hours
Training: 2025-05-30 09:06:20,962-Speed 370.69 samples/sec   Loss 12.9015 Epoch: 4   Global Step: 10100   Required: 8 hours
Training: 2025-05-30 09:06:38,228-Speed 370.68 samples/sec   Loss 12.8165 Epoch: 4   Global Step: 10150   Required: 8 hours
Training: 2025-05-30 09:07:16,359-[lfw][10190]XNorm: 23.754690
Training: 2025-05-30 09:07:16,359-[lfw][10190]Accuracy-Flip: 0.97550+-0.00667
Training: 2025-05-30 09:07:16,359-[lfw][10190]Accuracy-Highest: 0.97550
Training: 2025-05-30 09:07:44,852-[cfp_fp][10190]XNorm: 20.204108
Training: 2025-05-30 09:07:44,852-[cfp_fp][10190]Accuracy-Flip: 0.85329+-0.01773
Training: 2025-05-30 09:07:44,852-[cfp_fp][10190]Accuracy-Highest: 0.85329
Training: 2025-05-30 09:08:09,128-[agedb_30][10190]XNorm: 22.872565
Training: 2025-05-30 09:08:09,128-[agedb_30][10190]Accuracy-Flip: 0.87217+-0.01997
Training: 2025-05-30 09:08:09,128-[agedb_30][10190]Accuracy-Highest: 0.87217
Training: 2025-05-30 09:08:33,502-[calfw][10190]XNorm: 23.736390
Training: 2025-05-30 09:08:33,502-[calfw][10190]Accuracy-Flip: 0.89167+-0.01396
Training: 2025-05-30 09:08:33,502-[calfw][10190]Accuracy-Highest: 0.89167
Training: 2025-05-30 09:08:57,941-[cplfw][10190]XNorm: 20.276521
Training: 2025-05-30 09:08:57,941-[cplfw][10190]Accuracy-Flip: 0.77467+-0.02640
Training: 2025-05-30 09:08:57,941-[cplfw][10190]Accuracy-Highest: 0.77467
Training: 2025-05-30 09:09:01,542-Speed 44.66 samples/sec   Loss 12.7649 Epoch: 5   Global Step: 10200   Required: 8 hours
Training: 2025-05-30 09:09:18,791-Speed 371.03 samples/sec   Loss 10.6809 Epoch: 5   Global Step: 10250   Required: 8 hours
Training: 2025-05-30 09:09:36,041-Speed 371.02 samples/sec   Loss 10.7916 Epoch: 5   Global Step: 10300   Required: 8 hours
Training: 2025-05-30 09:09:53,301-Speed 370.80 samples/sec   Loss 11.1615 Epoch: 5   Global Step: 10350   Required: 8 hours
Training: 2025-05-30 09:10:10,559-Speed 370.84 samples/sec   Loss 11.0001 Epoch: 5   Global Step: 10400   Required: 8 hours
Training: 2025-05-30 09:10:27,824-Speed 370.70 samples/sec   Loss 11.0520 Epoch: 5   Global Step: 10450   Required: 8 hours
Training: 2025-05-30 09:10:45,091-Speed 370.65 samples/sec   Loss 11.2342 Epoch: 5   Global Step: 10500   Required: 8 hours
Training: 2025-05-30 09:11:02,364-Speed 370.54 samples/sec   Loss 11.3449 Epoch: 5   Global Step: 10550   Required: 8 hours
Training: 2025-05-30 09:11:19,633-Speed 370.61 samples/sec   Loss 11.6066 Epoch: 5   Global Step: 10600   Required: 8 hours
Training: 2025-05-30 09:11:36,907-Speed 370.50 samples/sec   Loss 11.7640 Epoch: 5   Global Step: 10650   Required: 8 hours
Training: 2025-05-30 09:11:54,178-Speed 370.56 samples/sec   Loss 11.5134 Epoch: 5   Global Step: 10700   Required: 8 hours
Training: 2025-05-30 09:12:11,445-Speed 370.66 samples/sec   Loss 11.7564 Epoch: 5   Global Step: 10750   Required: 8 hours
Training: 2025-05-30 09:12:28,713-Speed 370.62 samples/sec   Loss 11.7191 Epoch: 5   Global Step: 10800   Required: 8 hours
Training: 2025-05-30 09:12:45,988-Speed 370.47 samples/sec   Loss 11.6902 Epoch: 5   Global Step: 10850   Required: 8 hours
Training: 2025-05-30 09:13:03,264-Speed 370.46 samples/sec   Loss 11.5257 Epoch: 5   Global Step: 10900   Required: 8 hours
Training: 2025-05-30 09:13:20,539-Speed 370.49 samples/sec   Loss 11.8740 Epoch: 5   Global Step: 10950   Required: 8 hours
Training: 2025-05-30 09:13:37,813-Speed 370.50 samples/sec   Loss 12.0615 Epoch: 5   Global Step: 11000   Required: 8 hours
Training: 2025-05-30 09:13:55,085-Speed 370.54 samples/sec   Loss 12.0271 Epoch: 5   Global Step: 11050   Required: 8 hours
Training: 2025-05-30 09:14:12,361-Speed 370.46 samples/sec   Loss 11.9579 Epoch: 5   Global Step: 11100   Required: 8 hours
Training: 2025-05-30 09:14:29,640-Speed 370.40 samples/sec   Loss 12.2132 Epoch: 5   Global Step: 11150   Required: 8 hours
Training: 2025-05-30 09:14:46,918-Speed 370.40 samples/sec   Loss 11.9955 Epoch: 5   Global Step: 11200   Required: 8 hours
Training: 2025-05-30 09:15:04,198-Speed 370.38 samples/sec   Loss 12.2182 Epoch: 5   Global Step: 11250   Required: 8 hours
Training: 2025-05-30 09:15:21,472-Speed 370.50 samples/sec   Loss 12.1155 Epoch: 5   Global Step: 11300   Required: 8 hours
Training: 2025-05-30 09:15:38,747-Speed 370.49 samples/sec   Loss 12.0019 Epoch: 5   Global Step: 11350   Required: 8 hours
Training: 2025-05-30 09:15:56,019-Speed 370.53 samples/sec   Loss 12.0903 Epoch: 5   Global Step: 11400   Required: 8 hours
Training: 2025-05-30 09:16:13,297-Speed 370.43 samples/sec   Loss 12.2091 Epoch: 5   Global Step: 11450   Required: 8 hours
Training: 2025-05-30 09:16:30,572-Speed 370.48 samples/sec   Loss 12.1777 Epoch: 5   Global Step: 11500   Required: 8 hours
Training: 2025-05-30 09:16:47,845-Speed 370.52 samples/sec   Loss 12.0614 Epoch: 5   Global Step: 11550   Required: 8 hours
Training: 2025-05-30 09:17:05,121-Speed 370.45 samples/sec   Loss 12.2365 Epoch: 5   Global Step: 11600   Required: 8 hours
Training: 2025-05-30 09:17:22,397-Speed 370.47 samples/sec   Loss 12.2023 Epoch: 5   Global Step: 11650   Required: 8 hours
Training: 2025-05-30 09:17:39,674-Speed 370.42 samples/sec   Loss 12.4698 Epoch: 5   Global Step: 11700   Required: 8 hours
Training: 2025-05-30 09:17:56,950-Speed 370.47 samples/sec   Loss 12.2248 Epoch: 5   Global Step: 11750   Required: 8 hours
Training: 2025-05-30 09:18:14,223-Speed 370.51 samples/sec   Loss 12.4254 Epoch: 5   Global Step: 11800   Required: 8 hours
Training: 2025-05-30 09:18:31,500-Speed 370.44 samples/sec   Loss 12.2192 Epoch: 5   Global Step: 11850   Required: 8 hours
Training: 2025-05-30 09:18:48,773-Speed 370.52 samples/sec   Loss 12.2434 Epoch: 5   Global Step: 11900   Required: 8 hours
Training: 2025-05-30 09:19:06,045-Speed 370.56 samples/sec   Loss 12.3233 Epoch: 5   Global Step: 11950   Required: 8 hours
Training: 2025-05-30 09:19:23,320-Speed 370.47 samples/sec   Loss 12.3737 Epoch: 5   Global Step: 12000   Required: 8 hours
Training: 2025-05-30 09:19:40,592-Speed 370.55 samples/sec   Loss 12.4437 Epoch: 5   Global Step: 12050   Required: 8 hours
Training: 2025-05-30 09:19:57,867-Speed 370.48 samples/sec   Loss 12.2269 Epoch: 5   Global Step: 12100   Required: 8 hours
Training: 2025-05-30 09:20:15,145-Speed 370.42 samples/sec   Loss 12.5389 Epoch: 5   Global Step: 12150   Required: 8 hours
Training: 2025-05-30 09:20:32,417-Speed 370.54 samples/sec   Loss 12.4411 Epoch: 5   Global Step: 12200   Required: 8 hours
Training: 2025-05-30 09:21:06,397-[lfw][12228]XNorm: 24.682860
Training: 2025-05-30 09:21:06,397-[lfw][12228]Accuracy-Flip: 0.97983+-0.00626
Training: 2025-05-30 09:21:06,397-[lfw][12228]Accuracy-Highest: 0.97983
Training: 2025-05-30 09:21:34,766-[cfp_fp][12228]XNorm: 21.025972
Training: 2025-05-30 09:21:34,766-[cfp_fp][12228]Accuracy-Flip: 0.85800+-0.01619
Training: 2025-05-30 09:21:34,766-[cfp_fp][12228]Accuracy-Highest: 0.85800
Training: 2025-05-30 09:21:59,057-[agedb_30][12228]XNorm: 23.334674
Training: 2025-05-30 09:21:59,057-[agedb_30][12228]Accuracy-Flip: 0.86417+-0.01941
Training: 2025-05-30 09:21:59,057-[agedb_30][12228]Accuracy-Highest: 0.87217
Training: 2025-05-30 09:22:23,485-[calfw][12228]XNorm: 24.363103
Training: 2025-05-30 09:22:23,485-[calfw][12228]Accuracy-Flip: 0.89700+-0.01059
Training: 2025-05-30 09:22:23,485-[calfw][12228]Accuracy-Highest: 0.89700
Training: 2025-05-30 09:22:48,171-[cplfw][12228]XNorm: 21.364152
Training: 2025-05-30 09:22:48,171-[cplfw][12228]Accuracy-Flip: 0.79800+-0.02582
Training: 2025-05-30 09:22:48,171-[cplfw][12228]Accuracy-Highest: 0.79800
Training: 2025-05-30 09:22:55,951-Speed 44.59 samples/sec   Loss 11.4010 Epoch: 6   Global Step: 12250   Required: 8 hours
Training: 2025-05-30 09:23:13,200-Speed 371.03 samples/sec   Loss 10.0322 Epoch: 6   Global Step: 12300   Required: 8 hours
Training: 2025-05-30 09:23:30,456-Speed 370.89 samples/sec   Loss 10.3073 Epoch: 6   Global Step: 12350   Required: 8 hours
Training: 2025-05-30 09:23:47,720-Speed 370.73 samples/sec   Loss 10.2766 Epoch: 6   Global Step: 12400   Required: 8 hours
Training: 2025-05-30 09:24:04,985-Speed 370.69 samples/sec   Loss 10.0488 Epoch: 6   Global Step: 12450   Required: 8 hours
Training: 2025-05-30 09:24:22,253-Speed 370.63 samples/sec   Loss 10.5254 Epoch: 6   Global Step: 12500   Required: 8 hours
Training: 2025-05-30 09:24:39,530-Speed 370.43 samples/sec   Loss 10.6538 Epoch: 6   Global Step: 12550   Required: 8 hours
Training: 2025-05-30 09:24:56,802-Speed 370.54 samples/sec   Loss 10.7029 Epoch: 6   Global Step: 12600   Required: 8 hours
Training: 2025-05-30 09:25:14,074-Speed 370.54 samples/sec   Loss 10.9213 Epoch: 6   Global Step: 12650   Required: 8 hours
Training: 2025-05-30 09:25:31,343-Speed 370.60 samples/sec   Loss 10.6936 Epoch: 6   Global Step: 12700   Required: 8 hours
Training: 2025-05-30 09:25:48,617-Speed 370.50 samples/sec   Loss 10.7973 Epoch: 6   Global Step: 12750   Required: 8 hours
Training: 2025-05-30 09:26:05,895-Speed 370.43 samples/sec   Loss 11.1618 Epoch: 6   Global Step: 12800   Required: 8 hours
Training: 2025-05-30 09:26:23,172-Speed 370.44 samples/sec   Loss 11.0487 Epoch: 6   Global Step: 12850   Required: 8 hours
Training: 2025-05-30 09:26:40,447-Speed 370.47 samples/sec   Loss 11.0526 Epoch: 6   Global Step: 12900   Required: 8 hours
Training: 2025-05-30 09:26:57,723-Speed 370.46 samples/sec   Loss 11.1045 Epoch: 6   Global Step: 12950   Required: 8 hours
Training: 2025-05-30 09:27:15,000-Speed 370.43 samples/sec   Loss 11.3708 Epoch: 6   Global Step: 13000   Required: 8 hours
Training: 2025-05-30 09:27:32,277-Speed 370.43 samples/sec   Loss 11.2490 Epoch: 6   Global Step: 13050   Required: 8 hours
Training: 2025-05-30 09:27:49,555-Speed 370.42 samples/sec   Loss 11.1758 Epoch: 6   Global Step: 13100   Required: 8 hours
Training: 2025-05-30 09:28:06,835-Speed 370.38 samples/sec   Loss 11.4614 Epoch: 6   Global Step: 13150   Required: 8 hours
Training: 2025-05-30 09:28:24,114-Speed 370.40 samples/sec   Loss 11.2129 Epoch: 6   Global Step: 13200   Required: 8 hours
Training: 2025-05-30 09:28:41,391-Speed 370.45 samples/sec   Loss 11.4795 Epoch: 6   Global Step: 13250   Required: 8 hours
Training: 2025-05-30 09:28:58,661-Speed 370.57 samples/sec   Loss 11.3840 Epoch: 6   Global Step: 13300   Required: 8 hours
Training: 2025-05-30 09:29:15,938-Speed 370.44 samples/sec   Loss 11.5082 Epoch: 6   Global Step: 13350   Required: 8 hours
Training: 2025-05-30 09:29:33,213-Speed 370.47 samples/sec   Loss 11.3064 Epoch: 6   Global Step: 13400   Required: 8 hours
Training: 2025-05-30 09:29:50,491-Speed 370.43 samples/sec   Loss 11.6351 Epoch: 6   Global Step: 13450   Required: 8 hours
Training: 2025-05-30 09:30:07,768-Speed 370.43 samples/sec   Loss 11.7039 Epoch: 6   Global Step: 13500   Required: 8 hours
Training: 2025-05-30 09:30:25,046-Speed 370.43 samples/sec   Loss 11.5520 Epoch: 6   Global Step: 13550   Required: 8 hours
Training: 2025-05-30 09:30:42,321-Speed 370.48 samples/sec   Loss 11.7223 Epoch: 6   Global Step: 13600   Required: 8 hours
Training: 2025-05-30 09:30:59,596-Speed 370.47 samples/sec   Loss 11.7389 Epoch: 6   Global Step: 13650   Required: 8 hours
Training: 2025-05-30 09:31:16,870-Speed 370.51 samples/sec   Loss 11.8151 Epoch: 6   Global Step: 13700   Required: 8 hours
Training: 2025-05-30 09:31:34,147-Speed 370.42 samples/sec   Loss 11.5947 Epoch: 6   Global Step: 13750   Required: 8 hours
Training: 2025-05-30 09:31:51,427-Speed 370.38 samples/sec   Loss 11.7648 Epoch: 6   Global Step: 13800   Required: 8 hours
Training: 2025-05-30 09:32:08,706-Speed 370.40 samples/sec   Loss 11.5969 Epoch: 6   Global Step: 13850   Required: 8 hours
Training: 2025-05-30 09:32:25,980-Speed 370.49 samples/sec   Loss 11.6241 Epoch: 6   Global Step: 13900   Required: 8 hours
Training: 2025-05-30 09:32:43,256-Speed 370.46 samples/sec   Loss 11.7512 Epoch: 6   Global Step: 13950   Required: 8 hours
Training: 2025-05-30 09:33:00,529-Speed 370.52 samples/sec   Loss 11.7869 Epoch: 6   Global Step: 14000   Required: 7 hours
Training: 2025-05-30 09:33:17,805-Speed 370.46 samples/sec   Loss 11.4803 Epoch: 6   Global Step: 14050   Required: 7 hours
Training: 2025-05-30 09:33:35,081-Speed 370.47 samples/sec   Loss 11.6261 Epoch: 6   Global Step: 14100   Required: 7 hours
Training: 2025-05-30 09:33:52,354-Speed 370.52 samples/sec   Loss 11.6133 Epoch: 6   Global Step: 14150   Required: 7 hours
Training: 2025-05-30 09:34:09,628-Speed 370.49 samples/sec   Loss 11.5286 Epoch: 6   Global Step: 14200   Required: 7 hours
Training: 2025-05-30 09:34:26,906-Speed 370.41 samples/sec   Loss 11.7845 Epoch: 6   Global Step: 14250   Required: 7 hours
Training: 2025-05-30 09:34:57,085-[lfw][14266]XNorm: 24.555140
Training: 2025-05-30 09:34:57,085-[lfw][14266]Accuracy-Flip: 0.98333+-0.00667
Training: 2025-05-30 09:34:57,085-[lfw][14266]Accuracy-Highest: 0.98333
Training: 2025-05-30 09:35:25,528-[cfp_fp][14266]XNorm: 21.092537
Training: 2025-05-30 09:35:25,528-[cfp_fp][14266]Accuracy-Flip: 0.86643+-0.02080
Training: 2025-05-30 09:35:25,528-[cfp_fp][14266]Accuracy-Highest: 0.86643
Training: 2025-05-30 09:35:49,864-[agedb_30][14266]XNorm: 23.044668
Training: 2025-05-30 09:35:49,864-[agedb_30][14266]Accuracy-Flip: 0.88517+-0.01873
Training: 2025-05-30 09:35:49,864-[agedb_30][14266]Accuracy-Highest: 0.88517
Training: 2025-05-30 09:36:14,312-[calfw][14266]XNorm: 24.250465
Training: 2025-05-30 09:36:14,312-[calfw][14266]Accuracy-Flip: 0.90950+-0.01385
Training: 2025-05-30 09:36:14,312-[calfw][14266]Accuracy-Highest: 0.90950
Training: 2025-05-30 09:36:38,854-[cplfw][14266]XNorm: 21.780071
Training: 2025-05-30 09:36:38,854-[cplfw][14266]Accuracy-Flip: 0.80417+-0.02404
Training: 2025-05-30 09:36:38,854-[cplfw][14266]Accuracy-Highest: 0.80417
Training: 2025-05-30 09:36:50,746-Speed 44.49 samples/sec   Loss 10.1625 Epoch: 7   Global Step: 14300   Required: 8 hours
Training: 2025-05-30 09:37:08,011-Speed 370.71 samples/sec   Loss 9.4488 Epoch: 7   Global Step: 14350   Required: 8 hours
Training: 2025-05-30 09:37:25,280-Speed 370.61 samples/sec   Loss 9.5492 Epoch: 7   Global Step: 14400   Required: 8 hours
Training: 2025-05-30 09:37:42,543-Speed 370.72 samples/sec   Loss 9.9422 Epoch: 7   Global Step: 14450   Required: 8 hours
Training: 2025-05-30 09:37:59,814-Speed 370.57 samples/sec   Loss 10.0734 Epoch: 7   Global Step: 14500   Required: 8 hours
Training: 2025-05-30 09:38:17,090-Speed 370.46 samples/sec   Loss 10.1443 Epoch: 7   Global Step: 14550   Required: 8 hours
Training: 2025-05-30 09:38:34,369-Speed 370.40 samples/sec   Loss 10.2154 Epoch: 7   Global Step: 14600   Required: 8 hours
Training: 2025-05-30 09:38:51,653-Speed 370.28 samples/sec   Loss 10.1995 Epoch: 7   Global Step: 14650   Required: 8 hours
Training: 2025-05-30 09:39:08,938-Speed 370.27 samples/sec   Loss 10.1276 Epoch: 7   Global Step: 14700   Required: 8 hours
Training: 2025-05-30 09:39:26,220-Speed 370.34 samples/sec   Loss 10.5056 Epoch: 7   Global Step: 14750   Required: 8 hours
Training: 2025-05-30 09:39:43,502-Speed 370.33 samples/sec   Loss 10.4532 Epoch: 7   Global Step: 14800   Required: 8 hours
Training: 2025-05-30 09:40:00,787-Speed 370.26 samples/sec   Loss 10.3342 Epoch: 7   Global Step: 14850   Required: 8 hours
Training: 2025-05-30 09:40:18,069-Speed 370.33 samples/sec   Loss 10.4736 Epoch: 7   Global Step: 14900   Required: 7 hours
Training: 2025-05-30 09:40:35,347-Speed 370.40 samples/sec   Loss 10.6412 Epoch: 7   Global Step: 14950   Required: 7 hours
Training: 2025-05-30 09:40:52,630-Speed 370.31 samples/sec   Loss 10.7167 Epoch: 7   Global Step: 15000   Required: 7 hours
Training: 2025-05-30 09:41:09,910-Speed 370.38 samples/sec   Loss 10.5451 Epoch: 7   Global Step: 15050   Required: 7 hours
Training: 2025-05-30 09:41:27,191-Speed 370.36 samples/sec   Loss 10.8244 Epoch: 7   Global Step: 15100   Required: 7 hours
Training: 2025-05-30 09:41:44,473-Speed 370.34 samples/sec   Loss 10.6751 Epoch: 7   Global Step: 15150   Required: 7 hours
Training: 2025-05-30 09:42:01,754-Speed 370.35 samples/sec   Loss 10.7583 Epoch: 7   Global Step: 15200   Required: 7 hours
Training: 2025-05-30 09:42:19,035-Speed 370.34 samples/sec   Loss 10.9333 Epoch: 7   Global Step: 15250   Required: 7 hours
Training: 2025-05-30 09:42:36,314-Speed 370.40 samples/sec   Loss 11.0553 Epoch: 7   Global Step: 15300   Required: 7 hours
Training: 2025-05-30 09:42:53,597-Speed 370.30 samples/sec   Loss 10.7823 Epoch: 7   Global Step: 15350   Required: 7 hours
Training: 2025-05-30 09:43:10,879-Speed 370.35 samples/sec   Loss 10.8006 Epoch: 7   Global Step: 15400   Required: 7 hours
Training: 2025-05-30 09:43:28,163-Speed 370.27 samples/sec   Loss 11.2518 Epoch: 7   Global Step: 15450   Required: 7 hours
Training: 2025-05-30 09:43:45,447-Speed 370.28 samples/sec   Loss 11.2219 Epoch: 7   Global Step: 15500   Required: 7 hours
Training: 2025-05-30 09:44:02,731-Speed 370.30 samples/sec   Loss 11.0530 Epoch: 7   Global Step: 15550   Required: 7 hours
Training: 2025-05-30 09:44:20,013-Speed 370.31 samples/sec   Loss 10.8654 Epoch: 7   Global Step: 15600   Required: 7 hours
Training: 2025-05-30 09:44:37,300-Speed 370.24 samples/sec   Loss 11.1474 Epoch: 7   Global Step: 15650   Required: 7 hours
Training: 2025-05-30 09:44:54,583-Speed 370.30 samples/sec   Loss 11.0834 Epoch: 7   Global Step: 15700   Required: 7 hours
Training: 2025-05-30 09:45:11,865-Speed 370.33 samples/sec   Loss 11.1935 Epoch: 7   Global Step: 15750   Required: 7 hours
Training: 2025-05-30 09:45:29,148-Speed 370.30 samples/sec   Loss 11.1556 Epoch: 7   Global Step: 15800   Required: 7 hours
Training: 2025-05-30 09:45:46,435-Speed 370.22 samples/sec   Loss 11.0000 Epoch: 7   Global Step: 15850   Required: 7 hours
Training: 2025-05-30 09:46:03,724-Speed 370.18 samples/sec   Loss 11.2493 Epoch: 7   Global Step: 15900   Required: 7 hours
Training: 2025-05-30 09:46:21,008-Speed 370.28 samples/sec   Loss 11.0822 Epoch: 7   Global Step: 15950   Required: 7 hours
Training: 2025-05-30 09:46:38,291-Speed 370.31 samples/sec   Loss 11.2715 Epoch: 7   Global Step: 16000   Required: 7 hours
Training: 2025-05-30 09:46:55,574-Speed 370.32 samples/sec   Loss 11.1397 Epoch: 7   Global Step: 16050   Required: 7 hours
Training: 2025-05-30 09:47:12,856-Speed 370.32 samples/sec   Loss 11.0759 Epoch: 7   Global Step: 16100   Required: 7 hours
Training: 2025-05-30 09:47:30,134-Speed 370.41 samples/sec   Loss 11.5133 Epoch: 7   Global Step: 16150   Required: 7 hours
Training: 2025-05-30 09:47:47,414-Speed 370.38 samples/sec   Loss 11.4018 Epoch: 7   Global Step: 16200   Required: 7 hours
Training: 2025-05-30 09:48:04,695-Speed 370.35 samples/sec   Loss 11.1657 Epoch: 7   Global Step: 16250   Required: 7 hours
Training: 2025-05-30 09:48:21,973-Speed 370.41 samples/sec   Loss 11.2180 Epoch: 7   Global Step: 16300   Required: 7 hours
Training: 2025-05-30 09:48:47,720-[lfw][16304]XNorm: 24.419615
Training: 2025-05-30 09:48:47,720-[lfw][16304]Accuracy-Flip: 0.98533+-0.00414
Training: 2025-05-30 09:48:47,720-[lfw][16304]Accuracy-Highest: 0.98533
Training: 2025-05-30 09:49:16,166-[cfp_fp][16304]XNorm: 20.917286
Training: 2025-05-30 09:49:16,166-[cfp_fp][16304]Accuracy-Flip: 0.87300+-0.01572
Training: 2025-05-30 09:49:16,166-[cfp_fp][16304]Accuracy-Highest: 0.87300
Training: 2025-05-30 09:49:40,497-[agedb_30][16304]XNorm: 23.053705
Training: 2025-05-30 09:49:40,497-[agedb_30][16304]Accuracy-Flip: 0.88733+-0.01728
Training: 2025-05-30 09:49:40,497-[agedb_30][16304]Accuracy-Highest: 0.88733
Training: 2025-05-30 09:50:04,993-[calfw][16304]XNorm: 24.148376
Training: 2025-05-30 09:50:04,993-[calfw][16304]Accuracy-Flip: 0.90700+-0.01475
Training: 2025-05-30 09:50:04,993-[calfw][16304]Accuracy-Highest: 0.90950
Training: 2025-05-30 09:50:29,475-[cplfw][16304]XNorm: 21.136265
Training: 2025-05-30 09:50:29,475-[cplfw][16304]Accuracy-Flip: 0.82000+-0.02330
Training: 2025-05-30 09:50:29,475-[cplfw][16304]Accuracy-Highest: 0.82000
Training: 2025-05-30 09:50:45,515-Speed 44.59 samples/sec   Loss 9.1988 Epoch: 8   Global Step: 16350   Required: 7 hours
Training: 2025-05-30 09:51:02,780-Speed 370.69 samples/sec   Loss 9.1593 Epoch: 8   Global Step: 16400   Required: 7 hours
Training: 2025-05-30 09:51:20,051-Speed 370.58 samples/sec   Loss 9.3173 Epoch: 8   Global Step: 16450   Required: 7 hours
Training: 2025-05-30 09:51:37,325-Speed 370.50 samples/sec   Loss 9.4509 Epoch: 8   Global Step: 16500   Required: 7 hours
Training: 2025-05-30 09:51:54,607-Speed 370.34 samples/sec   Loss 9.5264 Epoch: 8   Global Step: 16550   Required: 7 hours
Training: 2025-05-30 09:52:11,885-Speed 370.41 samples/sec   Loss 9.5277 Epoch: 8   Global Step: 16600   Required: 7 hours
Training: 2025-05-30 09:52:29,167-Speed 370.32 samples/sec   Loss 9.8039 Epoch: 8   Global Step: 16650   Required: 7 hours
Training: 2025-05-30 09:52:46,450-Speed 370.30 samples/sec   Loss 9.7376 Epoch: 8   Global Step: 16700   Required: 7 hours
Training: 2025-05-30 09:53:03,730-Speed 370.37 samples/sec   Loss 9.7945 Epoch: 8   Global Step: 16750   Required: 7 hours
Training: 2025-05-30 09:53:21,017-Speed 370.24 samples/sec   Loss 9.8154 Epoch: 8   Global Step: 16800   Required: 7 hours
Training: 2025-05-30 09:53:38,300-Speed 370.31 samples/sec   Loss 9.8590 Epoch: 8   Global Step: 16850   Required: 7 hours
Training: 2025-05-30 09:53:55,583-Speed 370.30 samples/sec   Loss 10.2412 Epoch: 8   Global Step: 16900   Required: 7 hours
Training: 2025-05-30 09:54:12,864-Speed 370.36 samples/sec   Loss 10.0620 Epoch: 8   Global Step: 16950   Required: 7 hours
Training: 2025-05-30 09:54:30,146-Speed 370.33 samples/sec   Loss 10.0172 Epoch: 8   Global Step: 17000   Required: 7 hours
Training: 2025-05-30 09:54:47,428-Speed 370.32 samples/sec   Loss 10.2660 Epoch: 8   Global Step: 17050   Required: 7 hours
Training: 2025-05-30 09:55:04,710-Speed 370.33 samples/sec   Loss 10.4256 Epoch: 8   Global Step: 17100   Required: 7 hours
Training: 2025-05-30 09:55:21,995-Speed 370.27 samples/sec   Loss 10.3185 Epoch: 8   Global Step: 17150   Required: 7 hours
Training: 2025-05-30 09:55:39,279-Speed 370.28 samples/sec   Loss 10.6885 Epoch: 8   Global Step: 17200   Required: 7 hours
Training: 2025-05-30 09:55:56,568-Speed 370.18 samples/sec   Loss 10.2819 Epoch: 8   Global Step: 17250   Required: 7 hours
Training: 2025-05-30 09:56:13,854-Speed 370.24 samples/sec   Loss 10.3099 Epoch: 8   Global Step: 17300   Required: 7 hours
Training: 2025-05-30 09:56:31,140-Speed 370.24 samples/sec   Loss 10.6270 Epoch: 8   Global Step: 17350   Required: 7 hours
Training: 2025-05-30 09:56:48,428-Speed 370.21 samples/sec   Loss 10.5549 Epoch: 8   Global Step: 17400   Required: 7 hours
Training: 2025-05-30 09:57:05,711-Speed 370.31 samples/sec   Loss 10.6700 Epoch: 8   Global Step: 17450   Required: 7 hours
Training: 2025-05-30 09:57:22,993-Speed 370.33 samples/sec   Loss 10.6516 Epoch: 8   Global Step: 17500   Required: 7 hours
Training: 2025-05-30 09:57:40,281-Speed 370.19 samples/sec   Loss 10.4153 Epoch: 8   Global Step: 17550   Required: 7 hours
Training: 2025-05-30 09:57:57,573-Speed 370.13 samples/sec   Loss 10.7318 Epoch: 8   Global Step: 17600   Required: 7 hours
Training: 2025-05-30 09:58:14,863-Speed 370.16 samples/sec   Loss 10.7143 Epoch: 8   Global Step: 17650   Required: 7 hours
Training: 2025-05-30 09:58:32,153-Speed 370.16 samples/sec   Loss 10.9042 Epoch: 8   Global Step: 17700   Required: 7 hours
Training: 2025-05-30 09:58:49,439-Speed 370.23 samples/sec   Loss 10.9441 Epoch: 8   Global Step: 17750   Required: 7 hours
Training: 2025-05-30 09:59:06,725-Speed 370.25 samples/sec   Loss 10.6960 Epoch: 8   Global Step: 17800   Required: 7 hours
Training: 2025-05-30 09:59:24,007-Speed 370.33 samples/sec   Loss 10.7352 Epoch: 8   Global Step: 17850   Required: 7 hours
Training: 2025-05-30 09:59:41,285-Speed 370.40 samples/sec   Loss 10.7348 Epoch: 8   Global Step: 17900   Required: 7 hours
Training: 2025-05-30 09:59:58,565-Speed 370.39 samples/sec   Loss 10.6213 Epoch: 8   Global Step: 17950   Required: 7 hours
Training: 2025-05-30 10:00:15,849-Speed 370.28 samples/sec   Loss 10.7600 Epoch: 8   Global Step: 18000   Required: 7 hours
Training: 2025-05-30 10:00:33,136-Speed 370.23 samples/sec   Loss 10.6825 Epoch: 8   Global Step: 18050   Required: 7 hours
Training: 2025-05-30 10:00:50,419-Speed 370.30 samples/sec   Loss 10.9932 Epoch: 8   Global Step: 18100   Required: 7 hours
Training: 2025-05-30 10:01:07,703-Speed 370.30 samples/sec   Loss 10.8678 Epoch: 8   Global Step: 18150   Required: 7 hours
Training: 2025-05-30 10:01:24,978-Speed 370.48 samples/sec   Loss 10.8321 Epoch: 8   Global Step: 18200   Required: 7 hours
Training: 2025-05-30 10:01:42,258-Speed 370.36 samples/sec   Loss 10.8947 Epoch: 8   Global Step: 18250   Required: 7 hours
Training: 2025-05-30 10:01:59,538-Speed 370.38 samples/sec   Loss 10.8858 Epoch: 8   Global Step: 18300   Required: 7 hours
Training: 2025-05-30 10:02:38,488-[lfw][18342]XNorm: 24.370971
Training: 2025-05-30 10:02:38,488-[lfw][18342]Accuracy-Flip: 0.98617+-0.00597
Training: 2025-05-30 10:02:38,488-[lfw][18342]Accuracy-Highest: 0.98617
Training: 2025-05-30 10:03:06,741-[cfp_fp][18342]XNorm: 21.242862
Training: 2025-05-30 10:03:06,741-[cfp_fp][18342]Accuracy-Flip: 0.88386+-0.01848
Training: 2025-05-30 10:03:06,741-[cfp_fp][18342]Accuracy-Highest: 0.88386
Training: 2025-05-30 10:03:31,062-[agedb_30][18342]XNorm: 23.098082
Training: 2025-05-30 10:03:31,062-[agedb_30][18342]Accuracy-Flip: 0.90167+-0.01604
Training: 2025-05-30 10:03:31,062-[agedb_30][18342]Accuracy-Highest: 0.90167
Training: 2025-05-30 10:03:55,465-[calfw][18342]XNorm: 24.142648
Training: 2025-05-30 10:03:55,465-[calfw][18342]Accuracy-Flip: 0.90600+-0.00827
Training: 2025-05-30 10:03:55,465-[calfw][18342]Accuracy-Highest: 0.90950
Training: 2025-05-30 10:04:19,900-[cplfw][18342]XNorm: 21.495402
Training: 2025-05-30 10:04:19,900-[cplfw][18342]Accuracy-Flip: 0.82467+-0.02306
Training: 2025-05-30 10:04:19,900-[cplfw][18342]Accuracy-Highest: 0.82467
Training: 2025-05-30 10:04:22,819-Speed 44.67 samples/sec   Loss 10.4707 Epoch: 9   Global Step: 18350   Required: 7 hours
Training: 2025-05-30 10:04:40,089-Speed 370.60 samples/sec   Loss 8.6264 Epoch: 9   Global Step: 18400   Required: 7 hours
Training: 2025-05-30 10:04:57,359-Speed 370.58 samples/sec   Loss 8.8136 Epoch: 9   Global Step: 18450   Required: 7 hours
Training: 2025-05-30 10:05:14,637-Speed 370.43 samples/sec   Loss 9.0294 Epoch: 9   Global Step: 18500   Required: 7 hours
Training: 2025-05-30 10:05:31,913-Speed 370.44 samples/sec   Loss 8.9270 Epoch: 9   Global Step: 18550   Required: 7 hours
Training: 2025-05-30 10:05:49,193-Speed 370.39 samples/sec   Loss 9.1567 Epoch: 9   Global Step: 18600   Required: 7 hours
Training: 2025-05-30 10:06:06,470-Speed 370.42 samples/sec   Loss 9.2374 Epoch: 9   Global Step: 18650   Required: 7 hours
Training: 2025-05-30 10:06:23,752-Speed 370.34 samples/sec   Loss 9.5307 Epoch: 9   Global Step: 18700   Required: 7 hours
Training: 2025-05-30 10:06:41,035-Speed 370.31 samples/sec   Loss 9.2382 Epoch: 9   Global Step: 18750   Required: 7 hours
Training: 2025-05-30 10:06:58,318-Speed 370.30 samples/sec   Loss 9.6537 Epoch: 9   Global Step: 18800   Required: 7 hours
Training: 2025-05-30 10:07:15,606-Speed 370.21 samples/sec   Loss 9.6022 Epoch: 9   Global Step: 18850   Required: 7 hours
Training: 2025-05-30 10:07:32,892-Speed 370.25 samples/sec   Loss 9.7902 Epoch: 9   Global Step: 18900   Required: 7 hours
Training: 2025-05-30 10:07:50,176-Speed 370.30 samples/sec   Loss 9.7528 Epoch: 9   Global Step: 18950   Required: 7 hours
Training: 2025-05-30 10:08:07,465-Speed 370.16 samples/sec   Loss 9.9729 Epoch: 9   Global Step: 19000   Required: 7 hours
Training: 2025-05-30 10:08:24,752-Speed 370.24 samples/sec   Loss 9.9594 Epoch: 9   Global Step: 19050   Required: 7 hours
Training: 2025-05-30 10:08:42,040-Speed 370.19 samples/sec   Loss 10.0878 Epoch: 9   Global Step: 19100   Required: 7 hours
Training: 2025-05-30 10:08:59,325-Speed 370.27 samples/sec   Loss 10.0082 Epoch: 9   Global Step: 19150   Required: 7 hours
Training: 2025-05-30 10:09:16,609-Speed 370.28 samples/sec   Loss 9.9351 Epoch: 9   Global Step: 19200   Required: 7 hours
Training: 2025-05-30 10:09:33,892-Speed 370.31 samples/sec   Loss 10.0744 Epoch: 9   Global Step: 19250   Required: 7 hours
Training: 2025-05-30 10:09:51,175-Speed 370.31 samples/sec   Loss 10.1705 Epoch: 9   Global Step: 19300   Required: 7 hours
Training: 2025-05-30 10:10:08,461-Speed 370.24 samples/sec   Loss 9.8333 Epoch: 9   Global Step: 19350   Required: 7 hours
Training: 2025-05-30 10:10:25,747-Speed 370.24 samples/sec   Loss 10.0853 Epoch: 9   Global Step: 19400   Required: 7 hours
Training: 2025-05-30 10:10:43,029-Speed 370.34 samples/sec   Loss 10.1966 Epoch: 9   Global Step: 19450   Required: 7 hours
Training: 2025-05-30 10:11:00,312-Speed 370.30 samples/sec   Loss 10.3910 Epoch: 9   Global Step: 19500   Required: 7 hours
Training: 2025-05-30 10:11:17,596-Speed 370.29 samples/sec   Loss 10.2010 Epoch: 9   Global Step: 19550   Required: 7 hours
Training: 2025-05-30 10:11:34,878-Speed 370.32 samples/sec   Loss 10.2939 Epoch: 9   Global Step: 19600   Required: 7 hours
Training: 2025-05-30 10:11:52,161-Speed 370.32 samples/sec   Loss 10.2316 Epoch: 9   Global Step: 19650   Required: 7 hours
Training: 2025-05-30 10:12:09,440-Speed 370.38 samples/sec   Loss 10.3882 Epoch: 9   Global Step: 19700   Required: 7 hours
Training: 2025-05-30 10:12:26,722-Speed 370.33 samples/sec   Loss 10.4992 Epoch: 9   Global Step: 19750   Required: 7 hours
Training: 2025-05-30 10:12:44,005-Speed 370.31 samples/sec   Loss 10.3597 Epoch: 9   Global Step: 19800   Required: 7 hours
Training: 2025-05-30 10:13:01,288-Speed 370.30 samples/sec   Loss 10.4293 Epoch: 9   Global Step: 19850   Required: 7 hours
Training: 2025-05-30 10:13:18,576-Speed 370.21 samples/sec   Loss 10.7011 Epoch: 9   Global Step: 19900   Required: 7 hours
Training: 2025-05-30 10:13:35,860-Speed 370.29 samples/sec   Loss 10.5335 Epoch: 9   Global Step: 19950   Required: 7 hours
Training: 2025-05-30 10:13:53,145-Speed 370.26 samples/sec   Loss 10.4390 Epoch: 9   Global Step: 20000   Required: 7 hours
Training: 2025-05-30 10:14:10,432-Speed 370.22 samples/sec   Loss 10.4739 Epoch: 9   Global Step: 20050   Required: 7 hours
Training: 2025-05-30 10:14:27,720-Speed 370.21 samples/sec   Loss 10.6486 Epoch: 9   Global Step: 20100   Required: 7 hours
Training: 2025-05-30 10:14:45,003-Speed 370.30 samples/sec   Loss 10.6313 Epoch: 9   Global Step: 20150   Required: 7 hours
Training: 2025-05-30 10:15:02,286-Speed 370.32 samples/sec   Loss 10.6781 Epoch: 9   Global Step: 20200   Required: 7 hours
Training: 2025-05-30 10:15:19,567-Speed 370.34 samples/sec   Loss 10.6909 Epoch: 9   Global Step: 20250   Required: 7 hours
Training: 2025-05-30 10:15:36,847-Speed 370.39 samples/sec   Loss 10.8249 Epoch: 9   Global Step: 20300   Required: 7 hours
Training: 2025-05-30 10:15:54,130-Speed 370.31 samples/sec   Loss 10.5573 Epoch: 9   Global Step: 20350   Required: 7 hours
Training: 2025-05-30 10:16:28,836-[lfw][20380]XNorm: 22.808629
Training: 2025-05-30 10:16:28,836-[lfw][20380]Accuracy-Flip: 0.98917+-0.00549
Training: 2025-05-30 10:16:28,836-[lfw][20380]Accuracy-Highest: 0.98917
Training: 2025-05-30 10:16:57,094-[cfp_fp][20380]XNorm: 19.776773
Training: 2025-05-30 10:16:57,094-[cfp_fp][20380]Accuracy-Flip: 0.89529+-0.01805
Training: 2025-05-30 10:16:57,094-[cfp_fp][20380]Accuracy-Highest: 0.89529
Training: 2025-05-30 10:17:21,424-[agedb_30][20380]XNorm: 22.064205
Training: 2025-05-30 10:17:21,424-[agedb_30][20380]Accuracy-Flip: 0.89583+-0.01853
Training: 2025-05-30 10:17:21,424-[agedb_30][20380]Accuracy-Highest: 0.90167
Training: 2025-05-30 10:17:45,829-[calfw][20380]XNorm: 22.663755
Training: 2025-05-30 10:17:45,829-[calfw][20380]Accuracy-Flip: 0.91367+-0.01412
Training: 2025-05-30 10:17:45,829-[calfw][20380]Accuracy-Highest: 0.91367
Training: 2025-05-30 10:18:10,254-[cplfw][20380]XNorm: 20.039811
Training: 2025-05-30 10:18:10,254-[cplfw][20380]Accuracy-Flip: 0.83767+-0.01951
Training: 2025-05-30 10:18:10,254-[cplfw][20380]Accuracy-Highest: 0.83767
Training: 2025-05-30 10:18:17,309-Speed 44.70 samples/sec   Loss 9.9966 Epoch: 10   Global Step: 20400   Required: 7 hours
Training: 2025-05-30 10:18:34,574-Speed 370.71 samples/sec   Loss 8.4465 Epoch: 10   Global Step: 20450   Required: 7 hours
Training: 2025-05-30 10:18:51,843-Speed 370.61 samples/sec   Loss 8.4697 Epoch: 10   Global Step: 20500   Required: 7 hours
Training: 2025-05-30 10:19:09,116-Speed 370.51 samples/sec   Loss 9.0861 Epoch: 10   Global Step: 20550   Required: 7 hours
Training: 2025-05-30 10:19:26,392-Speed 370.47 samples/sec   Loss 8.9026 Epoch: 10   Global Step: 20600   Required: 7 hours
Training: 2025-05-30 10:19:43,669-Speed 370.42 samples/sec   Loss 8.8135 Epoch: 10   Global Step: 20650   Required: 7 hours
Training: 2025-05-30 10:20:00,950-Speed 370.36 samples/sec   Loss 9.2252 Epoch: 10   Global Step: 20700   Required: 7 hours
Training: 2025-05-30 10:20:18,229-Speed 370.39 samples/sec   Loss 9.1957 Epoch: 10   Global Step: 20750   Required: 7 hours
Training: 2025-05-30 10:20:35,507-Speed 370.42 samples/sec   Loss 9.3934 Epoch: 10   Global Step: 20800   Required: 7 hours
Training: 2025-05-30 10:20:52,787-Speed 370.36 samples/sec   Loss 9.4433 Epoch: 10   Global Step: 20850   Required: 7 hours
Training: 2025-05-30 10:21:10,066-Speed 370.39 samples/sec   Loss 9.6955 Epoch: 10   Global Step: 20900   Required: 7 hours
Training: 2025-05-30 10:21:27,347-Speed 370.36 samples/sec   Loss 9.4116 Epoch: 10   Global Step: 20950   Required: 7 hours
Training: 2025-05-30 10:21:44,631-Speed 370.27 samples/sec   Loss 9.5282 Epoch: 10   Global Step: 21000   Required: 7 hours
Training: 2025-05-30 10:22:01,915-Speed 370.29 samples/sec   Loss 9.7705 Epoch: 10   Global Step: 21050   Required: 7 hours
Training: 2025-05-30 10:22:19,196-Speed 370.36 samples/sec   Loss 9.6850 Epoch: 10   Global Step: 21100   Required: 7 hours
Training: 2025-05-30 10:22:36,481-Speed 370.27 samples/sec   Loss 9.6464 Epoch: 10   Global Step: 21150   Required: 7 hours
Training: 2025-05-30 10:22:53,759-Speed 370.41 samples/sec   Loss 9.5616 Epoch: 10   Global Step: 21200   Required: 7 hours
Training: 2025-05-30 10:23:11,043-Speed 370.28 samples/sec   Loss 9.8653 Epoch: 10   Global Step: 21250   Required: 7 hours
Training: 2025-05-30 10:23:28,323-Speed 370.37 samples/sec   Loss 9.8005 Epoch: 10   Global Step: 21300   Required: 7 hours
Training: 2025-05-30 10:23:45,606-Speed 370.32 samples/sec   Loss 9.5067 Epoch: 10   Global Step: 21350   Required: 7 hours
Training: 2025-05-30 10:24:02,886-Speed 370.37 samples/sec   Loss 9.7602 Epoch: 10   Global Step: 21400   Required: 7 hours
Training: 2025-05-30 10:24:20,162-Speed 370.44 samples/sec   Loss 10.0736 Epoch: 10   Global Step: 21450   Required: 7 hours
Training: 2025-05-30 10:24:37,435-Speed 370.52 samples/sec   Loss 9.9617 Epoch: 10   Global Step: 21500   Required: 7 hours
Training: 2025-05-30 10:24:54,712-Speed 370.45 samples/sec   Loss 10.0586 Epoch: 10   Global Step: 21550   Required: 7 hours
Training: 2025-05-30 10:25:11,990-Speed 370.41 samples/sec   Loss 10.1910 Epoch: 10   Global Step: 21600   Required: 7 hours
Training: 2025-05-30 10:25:29,274-Speed 370.28 samples/sec   Loss 9.9363 Epoch: 10   Global Step: 21650   Required: 7 hours
Training: 2025-05-30 10:25:46,550-Speed 370.45 samples/sec   Loss 9.9428 Epoch: 10   Global Step: 21700   Required: 7 hours
Training: 2025-05-30 10:26:03,828-Speed 370.42 samples/sec   Loss 10.0442 Epoch: 10   Global Step: 21750   Required: 7 hours
Training: 2025-05-30 10:26:21,104-Speed 370.46 samples/sec   Loss 10.0396 Epoch: 10   Global Step: 21800   Required: 7 hours
Training: 2025-05-30 10:26:38,382-Speed 370.42 samples/sec   Loss 10.0395 Epoch: 10   Global Step: 21850   Required: 7 hours
Training: 2025-05-30 10:26:55,664-Speed 370.33 samples/sec   Loss 10.3439 Epoch: 10   Global Step: 21900   Required: 7 hours
Training: 2025-05-30 10:27:12,944-Speed 370.37 samples/sec   Loss 10.1892 Epoch: 10   Global Step: 21950   Required: 7 hours
Training: 2025-05-30 10:27:30,224-Speed 370.38 samples/sec   Loss 10.0827 Epoch: 10   Global Step: 22000   Required: 7 hours
Training: 2025-05-30 10:27:47,505-Speed 370.35 samples/sec   Loss 10.2771 Epoch: 10   Global Step: 22050   Required: 7 hours
Training: 2025-05-30 10:28:04,791-Speed 370.24 samples/sec   Loss 10.0827 Epoch: 10   Global Step: 22100   Required: 7 hours
Training: 2025-05-30 10:28:22,079-Speed 370.21 samples/sec   Loss 10.2904 Epoch: 10   Global Step: 22150   Required: 7 hours
Training: 2025-05-30 10:28:39,362-Speed 370.31 samples/sec   Loss 10.4176 Epoch: 10   Global Step: 22200   Required: 7 hours
Training: 2025-05-30 10:28:56,647-Speed 370.26 samples/sec   Loss 10.1519 Epoch: 10   Global Step: 22250   Required: 7 hours
Training: 2025-05-30 10:29:13,931-Speed 370.29 samples/sec   Loss 10.3526 Epoch: 10   Global Step: 22300   Required: 7 hours
Training: 2025-05-30 10:29:31,211-Speed 370.36 samples/sec   Loss 10.3722 Epoch: 10   Global Step: 22350   Required: 7 hours
Training: 2025-05-30 10:29:48,493-Speed 370.34 samples/sec   Loss 10.3043 Epoch: 10   Global Step: 22400   Required: 7 hours
Training: 2025-05-30 10:30:19,046-[lfw][22418]XNorm: 24.826429
Training: 2025-05-30 10:30:19,046-[lfw][22418]Accuracy-Flip: 0.98650+-0.00709
Training: 2025-05-30 10:30:19,046-[lfw][22418]Accuracy-Highest: 0.98917
Training: 2025-05-30 10:30:47,293-[cfp_fp][22418]XNorm: 21.601806
Training: 2025-05-30 10:30:47,293-[cfp_fp][22418]Accuracy-Flip: 0.88700+-0.01658
Training: 2025-05-30 10:30:47,293-[cfp_fp][22418]Accuracy-Highest: 0.89529
Training: 2025-05-30 10:31:11,621-[agedb_30][22418]XNorm: 23.469554
Training: 2025-05-30 10:31:11,621-[agedb_30][22418]Accuracy-Flip: 0.89367+-0.02068
Training: 2025-05-30 10:31:11,621-[agedb_30][22418]Accuracy-Highest: 0.90167
Training: 2025-05-30 10:31:36,033-[calfw][22418]XNorm: 24.336091
Training: 2025-05-30 10:31:36,033-[calfw][22418]Accuracy-Flip: 0.90833+-0.01418
Training: 2025-05-30 10:31:36,033-[calfw][22418]Accuracy-Highest: 0.91367
Training: 2025-05-30 10:32:00,471-[cplfw][22418]XNorm: 22.022962
Training: 2025-05-30 10:32:00,471-[cplfw][22418]Accuracy-Flip: 0.82883+-0.02405
Training: 2025-05-30 10:32:00,471-[cplfw][22418]Accuracy-Highest: 0.83767
Training: 2025-05-30 10:32:11,685-Speed 44.70 samples/sec   Loss 8.9895 Epoch: 11   Global Step: 22450   Required: 7 hours
Training: 2025-05-30 10:32:28,954-Speed 370.61 samples/sec   Loss 8.3934 Epoch: 11   Global Step: 22500   Required: 7 hours
Training: 2025-05-30 10:32:46,222-Speed 370.61 samples/sec   Loss 8.4624 Epoch: 11   Global Step: 22550   Required: 7 hours
Training: 2025-05-30 10:33:03,496-Speed 370.51 samples/sec   Loss 8.3817 Epoch: 11   Global Step: 22600   Required: 7 hours
Training: 2025-05-30 10:33:20,771-Speed 370.48 samples/sec   Loss 8.8258 Epoch: 11   Global Step: 22650   Required: 7 hours
Training: 2025-05-30 10:33:38,051-Speed 370.36 samples/sec   Loss 8.7328 Epoch: 11   Global Step: 22700   Required: 7 hours
Training: 2025-05-30 10:33:55,332-Speed 370.36 samples/sec   Loss 8.6936 Epoch: 11   Global Step: 22750   Required: 7 hours
Training: 2025-05-30 10:34:12,615-Speed 370.30 samples/sec   Loss 9.0233 Epoch: 11   Global Step: 22800   Required: 7 hours
Training: 2025-05-30 10:34:29,897-Speed 370.33 samples/sec   Loss 8.7427 Epoch: 11   Global Step: 22850   Required: 7 hours
Training: 2025-05-30 10:34:47,181-Speed 370.30 samples/sec   Loss 9.1335 Epoch: 11   Global Step: 22900   Required: 7 hours
Training: 2025-05-30 10:35:04,467-Speed 370.24 samples/sec   Loss 9.1803 Epoch: 11   Global Step: 22950   Required: 7 hours
Training: 2025-05-30 10:35:21,755-Speed 370.19 samples/sec   Loss 9.3690 Epoch: 11   Global Step: 23000   Required: 7 hours
Training: 2025-05-30 10:35:39,041-Speed 370.25 samples/sec   Loss 9.3601 Epoch: 11   Global Step: 23050   Required: 7 hours
Training: 2025-05-30 10:35:56,324-Speed 370.32 samples/sec   Loss 9.4328 Epoch: 11   Global Step: 23100   Required: 7 hours
Training: 2025-05-30 10:36:13,602-Speed 370.41 samples/sec   Loss 9.2692 Epoch: 11   Global Step: 23150   Required: 7 hours
Training: 2025-05-30 10:36:30,880-Speed 370.41 samples/sec   Loss 9.2490 Epoch: 11   Global Step: 23200   Required: 7 hours
Training: 2025-05-30 10:36:48,158-Speed 370.41 samples/sec   Loss 9.4921 Epoch: 11   Global Step: 23250   Required: 7 hours
Training: 2025-05-30 10:37:05,442-Speed 370.29 samples/sec   Loss 9.7276 Epoch: 11   Global Step: 23300   Required: 7 hours
Training: 2025-05-30 10:37:22,718-Speed 370.46 samples/sec   Loss 9.4081 Epoch: 11   Global Step: 23350   Required: 7 hours
Training: 2025-05-30 10:37:39,994-Speed 370.46 samples/sec   Loss 9.6290 Epoch: 11   Global Step: 23400   Required: 7 hours
Training: 2025-05-30 10:37:57,272-Speed 370.42 samples/sec   Loss 9.6264 Epoch: 11   Global Step: 23450   Required: 7 hours
Training: 2025-05-30 10:38:14,544-Speed 370.56 samples/sec   Loss 9.7130 Epoch: 11   Global Step: 23500   Required: 7 hours
Training: 2025-05-30 10:38:31,818-Speed 370.49 samples/sec   Loss 9.8497 Epoch: 11   Global Step: 23550   Required: 7 hours
Training: 2025-05-30 10:38:49,089-Speed 370.56 samples/sec   Loss 9.6089 Epoch: 11   Global Step: 23600   Required: 7 hours
Training: 2025-05-30 10:39:06,362-Speed 370.53 samples/sec   Loss 9.8333 Epoch: 11   Global Step: 23650   Required: 7 hours
Training: 2025-05-30 10:39:23,637-Speed 370.49 samples/sec   Loss 9.8323 Epoch: 11   Global Step: 23700   Required: 6 hours
Training: 2025-05-30 10:39:40,918-Speed 370.35 samples/sec   Loss 9.9685 Epoch: 11   Global Step: 23750   Required: 6 hours
Training: 2025-05-30 10:39:58,198-Speed 370.37 samples/sec   Loss 9.6662 Epoch: 11   Global Step: 23800   Required: 6 hours
Training: 2025-05-30 10:40:15,476-Speed 370.41 samples/sec   Loss 9.8429 Epoch: 11   Global Step: 23850   Required: 6 hours
Training: 2025-05-30 10:40:32,756-Speed 370.38 samples/sec   Loss 10.2545 Epoch: 11   Global Step: 23900   Required: 6 hours
Training: 2025-05-30 10:40:50,033-Speed 370.44 samples/sec   Loss 10.0888 Epoch: 11   Global Step: 23950   Required: 6 hours
Training: 2025-05-30 10:41:07,313-Speed 370.37 samples/sec   Loss 10.1919 Epoch: 11   Global Step: 24000   Required: 6 hours
Training: 2025-05-30 10:41:24,593-Speed 370.37 samples/sec   Loss 9.7699 Epoch: 11   Global Step: 24050   Required: 6 hours
Training: 2025-05-30 10:41:41,874-Speed 370.35 samples/sec   Loss 9.9578 Epoch: 11   Global Step: 24100   Required: 6 hours
Training: 2025-05-30 10:41:59,155-Speed 370.36 samples/sec   Loss 9.9863 Epoch: 11   Global Step: 24150   Required: 6 hours
Training: 2025-05-30 10:42:16,441-Speed 370.24 samples/sec   Loss 10.0976 Epoch: 11   Global Step: 24200   Required: 6 hours
Training: 2025-05-30 10:42:33,721-Speed 370.37 samples/sec   Loss 10.0723 Epoch: 11   Global Step: 24250   Required: 6 hours
Training: 2025-05-30 10:42:50,997-Speed 370.44 samples/sec   Loss 10.0876 Epoch: 11   Global Step: 24300   Required: 6 hours
Training: 2025-05-30 10:43:08,273-Speed 370.47 samples/sec   Loss 10.0528 Epoch: 11   Global Step: 24350   Required: 6 hours
Training: 2025-05-30 10:43:25,550-Speed 370.44 samples/sec   Loss 10.2325 Epoch: 11   Global Step: 24400   Required: 6 hours
Training: 2025-05-30 10:43:42,827-Speed 370.43 samples/sec   Loss 10.1483 Epoch: 11   Global Step: 24450   Required: 6 hours
Training: 2025-05-30 10:44:09,223-[lfw][24456]XNorm: 23.318600
Training: 2025-05-30 10:44:09,223-[lfw][24456]Accuracy-Flip: 0.98583+-0.00593
Training: 2025-05-30 10:44:09,223-[lfw][24456]Accuracy-Highest: 0.98917
Training: 2025-05-30 10:44:37,467-[cfp_fp][24456]XNorm: 20.378325
Training: 2025-05-30 10:44:37,467-[cfp_fp][24456]Accuracy-Flip: 0.89157+-0.01600
Training: 2025-05-30 10:44:37,467-[cfp_fp][24456]Accuracy-Highest: 0.89529
Training: 2025-05-30 10:45:01,774-[agedb_30][24456]XNorm: 22.198650
Training: 2025-05-30 10:45:01,774-[agedb_30][24456]Accuracy-Flip: 0.90167+-0.01390
Training: 2025-05-30 10:45:01,774-[agedb_30][24456]Accuracy-Highest: 0.90167
Training: 2025-05-30 10:45:26,170-[calfw][24456]XNorm: 22.956743
Training: 2025-05-30 10:45:26,170-[calfw][24456]Accuracy-Flip: 0.90533+-0.01394
Training: 2025-05-30 10:45:26,170-[calfw][24456]Accuracy-Highest: 0.91367
Training: 2025-05-30 10:45:50,540-[cplfw][24456]XNorm: 20.932612
Training: 2025-05-30 10:45:50,540-[cplfw][24456]Accuracy-Flip: 0.82267+-0.01756
Training: 2025-05-30 10:45:50,540-[cplfw][24456]Accuracy-Highest: 0.83767
Training: 2025-05-30 10:46:05,902-Speed 44.73 samples/sec   Loss 8.1985 Epoch: 12   Global Step: 24500   Required: 6 hours
Training: 2025-05-30 10:46:23,166-Speed 370.73 samples/sec   Loss 7.9650 Epoch: 12   Global Step: 24550   Required: 6 hours
Training: 2025-05-30 10:46:40,427-Speed 370.76 samples/sec   Loss 8.4398 Epoch: 12   Global Step: 24600   Required: 6 hours
Training: 2025-05-30 10:46:57,694-Speed 370.67 samples/sec   Loss 8.3940 Epoch: 12   Global Step: 24650   Required: 6 hours
Training: 2025-05-30 10:47:14,963-Speed 370.60 samples/sec   Loss 8.4973 Epoch: 12   Global Step: 24700   Required: 6 hours
Training: 2025-05-30 10:47:32,236-Speed 370.52 samples/sec   Loss 8.6783 Epoch: 12   Global Step: 24750   Required: 6 hours
Training: 2025-05-30 10:47:49,503-Speed 370.66 samples/sec   Loss 8.6541 Epoch: 12   Global Step: 24800   Required: 6 hours
Training: 2025-05-30 10:48:06,772-Speed 370.60 samples/sec   Loss 8.6598 Epoch: 12   Global Step: 24850   Required: 6 hours
Training: 2025-05-30 10:48:24,050-Speed 370.41 samples/sec   Loss 8.7036 Epoch: 12   Global Step: 24900   Required: 6 hours
Training: 2025-05-30 10:48:41,328-Speed 370.43 samples/sec   Loss 8.9262 Epoch: 12   Global Step: 24950   Required: 6 hours
Training: 2025-05-30 10:48:58,602-Speed 370.50 samples/sec   Loss 9.1336 Epoch: 12   Global Step: 25000   Required: 6 hours
Training: 2025-05-30 10:49:15,874-Speed 370.55 samples/sec   Loss 8.9518 Epoch: 12   Global Step: 25050   Required: 6 hours
Training: 2025-05-30 10:49:33,146-Speed 370.55 samples/sec   Loss 9.1228 Epoch: 12   Global Step: 25100   Required: 6 hours
Training: 2025-05-30 10:49:50,418-Speed 370.54 samples/sec   Loss 9.1931 Epoch: 12   Global Step: 25150   Required: 6 hours
Training: 2025-05-30 10:50:07,696-Speed 370.40 samples/sec   Loss 9.2378 Epoch: 12   Global Step: 25200   Required: 6 hours
Training: 2025-05-30 10:50:24,972-Speed 370.46 samples/sec   Loss 9.5001 Epoch: 12   Global Step: 25250   Required: 6 hours
Training: 2025-05-30 10:50:42,257-Speed 370.28 samples/sec   Loss 9.3497 Epoch: 12   Global Step: 25300   Required: 6 hours
Training: 2025-05-30 10:50:59,534-Speed 370.44 samples/sec   Loss 9.5806 Epoch: 12   Global Step: 25350   Required: 6 hours
Training: 2025-05-30 10:51:16,810-Speed 370.46 samples/sec   Loss 9.3283 Epoch: 12   Global Step: 25400   Required: 6 hours
Training: 2025-05-30 10:51:34,086-Speed 370.45 samples/sec   Loss 9.5084 Epoch: 12   Global Step: 25450   Required: 6 hours
Training: 2025-05-30 10:51:51,371-Speed 370.26 samples/sec   Loss 9.5541 Epoch: 12   Global Step: 25500   Required: 6 hours
Training: 2025-05-30 10:52:08,651-Speed 370.38 samples/sec   Loss 9.5597 Epoch: 12   Global Step: 25550   Required: 6 hours
Training: 2025-05-30 10:52:25,933-Speed 370.33 samples/sec   Loss 9.5350 Epoch: 12   Global Step: 25600   Required: 6 hours
Training: 2025-05-30 10:52:43,212-Speed 370.40 samples/sec   Loss 9.4934 Epoch: 12   Global Step: 25650   Required: 6 hours
Training: 2025-05-30 10:53:00,490-Speed 370.40 samples/sec   Loss 9.8192 Epoch: 12   Global Step: 25700   Required: 6 hours
Training: 2025-05-30 10:53:17,769-Speed 370.39 samples/sec   Loss 9.4019 Epoch: 12   Global Step: 25750   Required: 6 hours
Training: 2025-05-30 10:53:35,045-Speed 370.48 samples/sec   Loss 9.6497 Epoch: 12   Global Step: 25800   Required: 6 hours
Training: 2025-05-30 10:53:52,319-Speed 370.49 samples/sec   Loss 9.9145 Epoch: 12   Global Step: 25850   Required: 6 hours
Training: 2025-05-30 10:54:09,594-Speed 370.49 samples/sec   Loss 9.5491 Epoch: 12   Global Step: 25900   Required: 6 hours
Training: 2025-05-30 10:54:26,869-Speed 370.49 samples/sec   Loss 9.6617 Epoch: 12   Global Step: 25950   Required: 6 hours
Training: 2025-05-30 10:54:44,143-Speed 370.48 samples/sec   Loss 9.7796 Epoch: 12   Global Step: 26000   Required: 6 hours
Training: 2025-05-30 10:55:01,415-Speed 370.56 samples/sec   Loss 9.9146 Epoch: 12   Global Step: 26050   Required: 6 hours
Training: 2025-05-30 10:55:18,685-Speed 370.58 samples/sec   Loss 9.9982 Epoch: 12   Global Step: 26100   Required: 6 hours
Training: 2025-05-30 10:55:35,954-Speed 370.62 samples/sec   Loss 9.6796 Epoch: 12   Global Step: 26150   Required: 6 hours
Training: 2025-05-30 10:55:53,225-Speed 370.55 samples/sec   Loss 9.7901 Epoch: 12   Global Step: 26200   Required: 6 hours
Training: 2025-05-30 10:56:10,498-Speed 370.53 samples/sec   Loss 9.8682 Epoch: 12   Global Step: 26250   Required: 6 hours
Training: 2025-05-30 10:56:27,769-Speed 370.56 samples/sec   Loss 9.8129 Epoch: 12   Global Step: 26300   Required: 6 hours
Training: 2025-05-30 10:56:45,043-Speed 370.51 samples/sec   Loss 9.9617 Epoch: 12   Global Step: 26350   Required: 6 hours
Training: 2025-05-30 10:57:02,318-Speed 370.48 samples/sec   Loss 9.8103 Epoch: 12   Global Step: 26400   Required: 6 hours
Training: 2025-05-30 10:57:19,591-Speed 370.51 samples/sec   Loss 10.0006 Epoch: 12   Global Step: 26450   Required: 6 hours
Training: 2025-05-30 10:57:59,119-[lfw][26494]XNorm: 25.027238
Training: 2025-05-30 10:57:59,120-[lfw][26494]Accuracy-Flip: 0.98917+-0.00484
Training: 2025-05-30 10:57:59,120-[lfw][26494]Accuracy-Highest: 0.98917
Training: 2025-05-30 10:58:27,367-[cfp_fp][26494]XNorm: 21.916749
Training: 2025-05-30 10:58:27,367-[cfp_fp][26494]Accuracy-Flip: 0.89257+-0.00779
Training: 2025-05-30 10:58:27,367-[cfp_fp][26494]Accuracy-Highest: 0.89529
Training: 2025-05-30 10:58:51,672-[agedb_30][26494]XNorm: 24.202365
Training: 2025-05-30 10:58:51,672-[agedb_30][26494]Accuracy-Flip: 0.90783+-0.01890
Training: 2025-05-30 10:58:51,672-[agedb_30][26494]Accuracy-Highest: 0.90783
Training: 2025-05-30 10:59:16,064-[calfw][26494]XNorm: 24.996962
Training: 2025-05-30 10:59:16,064-[calfw][26494]Accuracy-Flip: 0.91233+-0.01119
Training: 2025-05-30 10:59:16,064-[calfw][26494]Accuracy-Highest: 0.91367
Training: 2025-05-30 10:59:40,446-[cplfw][26494]XNorm: 21.808688
Training: 2025-05-30 10:59:40,446-[cplfw][26494]Accuracy-Flip: 0.83583+-0.02599
Training: 2025-05-30 10:59:40,446-[cplfw][26494]Accuracy-Highest: 0.83767
Training: 2025-05-30 10:59:42,690-Speed 44.72 samples/sec   Loss 10.0342 Epoch: 13   Global Step: 26500   Required: 6 hours
Training: 2025-05-30 10:59:59,946-Speed 370.89 samples/sec   Loss 7.9023 Epoch: 13   Global Step: 26550   Required: 6 hours
Training: 2025-05-30 11:00:17,213-Speed 370.65 samples/sec   Loss 8.2644 Epoch: 13   Global Step: 26600   Required: 6 hours
Training: 2025-05-30 11:00:34,487-Speed 370.51 samples/sec   Loss 8.2051 Epoch: 13   Global Step: 26650   Required: 6 hours
Training: 2025-05-30 11:00:51,758-Speed 370.56 samples/sec   Loss 8.3125 Epoch: 13   Global Step: 26700   Required: 6 hours
Training: 2025-05-30 11:01:09,036-Speed 370.41 samples/sec   Loss 8.2025 Epoch: 13   Global Step: 26750   Required: 6 hours
Training: 2025-05-30 11:01:26,313-Speed 370.44 samples/sec   Loss 8.5246 Epoch: 13   Global Step: 26800   Required: 6 hours
Training: 2025-05-30 11:01:43,586-Speed 370.52 samples/sec   Loss 8.5841 Epoch: 13   Global Step: 26850   Required: 6 hours
Training: 2025-05-30 11:02:00,864-Speed 370.43 samples/sec   Loss 8.4138 Epoch: 13   Global Step: 26900   Required: 6 hours
Training: 2025-05-30 11:02:18,142-Speed 370.40 samples/sec   Loss 8.5371 Epoch: 13   Global Step: 26950   Required: 6 hours
Training: 2025-05-30 11:02:35,425-Speed 370.32 samples/sec   Loss 8.5617 Epoch: 13   Global Step: 27000   Required: 6 hours
Training: 2025-05-30 11:02:52,706-Speed 370.35 samples/sec   Loss 8.6680 Epoch: 13   Global Step: 27050   Required: 6 hours
Training: 2025-05-30 11:03:09,987-Speed 370.34 samples/sec   Loss 9.0749 Epoch: 13   Global Step: 27100   Required: 6 hours
Training: 2025-05-30 11:03:27,265-Speed 370.41 samples/sec   Loss 8.8896 Epoch: 13   Global Step: 27150   Required: 6 hours
Training: 2025-05-30 11:03:44,544-Speed 370.40 samples/sec   Loss 9.1722 Epoch: 13   Global Step: 27200   Required: 6 hours
Training: 2025-05-30 11:04:01,819-Speed 370.49 samples/sec   Loss 8.8378 Epoch: 13   Global Step: 27250   Required: 6 hours
Training: 2025-05-30 11:04:19,091-Speed 370.53 samples/sec   Loss 9.1328 Epoch: 13   Global Step: 27300   Required: 6 hours
Training: 2025-05-30 11:04:36,363-Speed 370.54 samples/sec   Loss 8.9760 Epoch: 13   Global Step: 27350   Required: 6 hours
Training: 2025-05-30 11:04:53,636-Speed 370.53 samples/sec   Loss 9.3779 Epoch: 13   Global Step: 27400   Required: 6 hours
Training: 2025-05-30 11:05:10,908-Speed 370.55 samples/sec   Loss 9.3945 Epoch: 13   Global Step: 27450   Required: 6 hours
Training: 2025-05-30 11:05:28,182-Speed 370.50 samples/sec   Loss 9.2519 Epoch: 13   Global Step: 27500   Required: 6 hours
Training: 2025-05-30 11:05:45,450-Speed 370.62 samples/sec   Loss 9.2260 Epoch: 13   Global Step: 27550   Required: 6 hours
Training: 2025-05-30 11:06:02,721-Speed 370.55 samples/sec   Loss 9.4995 Epoch: 13   Global Step: 27600   Required: 6 hours
Training: 2025-05-30 11:06:19,996-Speed 370.49 samples/sec   Loss 9.4800 Epoch: 13   Global Step: 27650   Required: 6 hours
Training: 2025-05-30 11:06:37,271-Speed 370.49 samples/sec   Loss 9.3233 Epoch: 13   Global Step: 27700   Required: 6 hours
Training: 2025-05-30 11:06:54,543-Speed 370.54 samples/sec   Loss 9.2552 Epoch: 13   Global Step: 27750   Required: 6 hours
Training: 2025-05-30 11:07:11,820-Speed 370.44 samples/sec   Loss 9.5677 Epoch: 13   Global Step: 27800   Required: 6 hours
Training: 2025-05-30 11:07:29,096-Speed 370.45 samples/sec   Loss 9.6312 Epoch: 13   Global Step: 27850   Required: 6 hours
Training: 2025-05-30 11:07:46,375-Speed 370.41 samples/sec   Loss 9.5400 Epoch: 13   Global Step: 27900   Required: 6 hours
Training: 2025-05-30 11:08:03,654-Speed 370.39 samples/sec   Loss 9.4765 Epoch: 13   Global Step: 27950   Required: 6 hours
Training: 2025-05-30 11:08:20,932-Speed 370.41 samples/sec   Loss 9.6874 Epoch: 13   Global Step: 28000   Required: 6 hours
Training: 2025-05-30 11:08:38,207-Speed 370.48 samples/sec   Loss 9.6444 Epoch: 13   Global Step: 28050   Required: 6 hours
Training: 2025-05-30 11:08:55,485-Speed 370.41 samples/sec   Loss 9.5232 Epoch: 13   Global Step: 28100   Required: 6 hours
Training: 2025-05-30 11:09:12,764-Speed 370.41 samples/sec   Loss 9.5471 Epoch: 13   Global Step: 28150   Required: 6 hours
Training: 2025-05-30 11:09:30,044-Speed 370.37 samples/sec   Loss 9.5575 Epoch: 13   Global Step: 28200   Required: 6 hours
Training: 2025-05-30 11:09:47,324-Speed 370.37 samples/sec   Loss 9.8752 Epoch: 13   Global Step: 28250   Required: 6 hours
Training: 2025-05-30 11:10:04,599-Speed 370.48 samples/sec   Loss 9.8056 Epoch: 13   Global Step: 28300   Required: 6 hours
Training: 2025-05-30 11:10:21,876-Speed 370.44 samples/sec   Loss 9.8366 Epoch: 13   Global Step: 28350   Required: 6 hours
Training: 2025-05-30 11:10:39,148-Speed 370.54 samples/sec   Loss 9.6410 Epoch: 13   Global Step: 28400   Required: 6 hours
Training: 2025-05-30 11:10:56,420-Speed 370.54 samples/sec   Loss 9.7745 Epoch: 13   Global Step: 28450   Required: 6 hours
Training: 2025-05-30 11:11:13,697-Speed 370.45 samples/sec   Loss 9.8213 Epoch: 13   Global Step: 28500   Required: 6 hours
Training: 2025-05-30 11:11:49,075-[lfw][28532]XNorm: 22.883902
Training: 2025-05-30 11:11:49,076-[lfw][28532]Accuracy-Flip: 0.98950+-0.00373
Training: 2025-05-30 11:11:49,076-[lfw][28532]Accuracy-Highest: 0.98950
Training: 2025-05-30 11:12:17,470-[cfp_fp][28532]XNorm: 19.799653
Training: 2025-05-30 11:12:17,470-[cfp_fp][28532]Accuracy-Flip: 0.89829+-0.01424
Training: 2025-05-30 11:12:17,470-[cfp_fp][28532]Accuracy-Highest: 0.89829
Training: 2025-05-30 11:12:41,762-[agedb_30][28532]XNorm: 22.011926
Training: 2025-05-30 11:12:41,762-[agedb_30][28532]Accuracy-Flip: 0.90967+-0.01881
Training: 2025-05-30 11:12:41,762-[agedb_30][28532]Accuracy-Highest: 0.90967
Training: 2025-05-30 11:13:06,135-[calfw][28532]XNorm: 22.496956
Training: 2025-05-30 11:13:06,135-[calfw][28532]Accuracy-Flip: 0.91867+-0.01410
Training: 2025-05-30 11:13:06,135-[calfw][28532]Accuracy-Highest: 0.91867
Training: 2025-05-30 11:13:30,502-[cplfw][28532]XNorm: 19.662371
Training: 2025-05-30 11:13:30,503-[cplfw][28532]Accuracy-Flip: 0.84617+-0.02044
Training: 2025-05-30 11:13:30,503-[cplfw][28532]Accuracy-Highest: 0.84617
Training: 2025-05-30 11:13:36,932-Speed 44.68 samples/sec   Loss 9.0891 Epoch: 14   Global Step: 28550   Required: 6 hours
Training: 2025-05-30 11:13:54,184-Speed 370.97 samples/sec   Loss 7.7431 Epoch: 14   Global Step: 28600   Required: 6 hours
Training: 2025-05-30 11:14:11,446-Speed 370.75 samples/sec   Loss 7.6685 Epoch: 14   Global Step: 28650   Required: 6 hours
Training: 2025-05-30 11:14:28,712-Speed 370.69 samples/sec   Loss 8.0548 Epoch: 14   Global Step: 28700   Required: 6 hours
Training: 2025-05-30 11:14:45,979-Speed 370.64 samples/sec   Loss 8.2646 Epoch: 14   Global Step: 28750   Required: 6 hours
Training: 2025-05-30 11:15:03,247-Speed 370.63 samples/sec   Loss 8.0987 Epoch: 14   Global Step: 28800   Required: 6 hours
Training: 2025-05-30 11:15:20,519-Speed 370.55 samples/sec   Loss 8.3293 Epoch: 14   Global Step: 28850   Required: 6 hours
Training: 2025-05-30 11:15:37,794-Speed 370.47 samples/sec   Loss 8.1227 Epoch: 14   Global Step: 28900   Required: 6 hours
Training: 2025-05-30 11:15:55,069-Speed 370.48 samples/sec   Loss 8.4443 Epoch: 14   Global Step: 28950   Required: 6 hours
Training: 2025-05-30 11:16:12,346-Speed 370.44 samples/sec   Loss 8.6993 Epoch: 14   Global Step: 29000   Required: 6 hours
Training: 2025-05-30 11:16:29,626-Speed 370.37 samples/sec   Loss 8.5752 Epoch: 14   Global Step: 29050   Required: 6 hours
Training: 2025-05-30 11:16:46,902-Speed 370.47 samples/sec   Loss 8.7045 Epoch: 14   Global Step: 29100   Required: 6 hours
Training: 2025-05-30 11:17:04,180-Speed 370.42 samples/sec   Loss 8.7186 Epoch: 14   Global Step: 29150   Required: 6 hours
Training: 2025-05-30 11:17:21,459-Speed 370.39 samples/sec   Loss 8.8890 Epoch: 14   Global Step: 29200   Required: 6 hours
Training: 2025-05-30 11:17:38,743-Speed 370.29 samples/sec   Loss 8.8435 Epoch: 14   Global Step: 29250   Required: 6 hours
Training: 2025-05-30 11:17:56,020-Speed 370.43 samples/sec   Loss 8.8797 Epoch: 14   Global Step: 29300   Required: 6 hours
Training: 2025-05-30 11:18:13,297-Speed 370.43 samples/sec   Loss 9.0377 Epoch: 14   Global Step: 29350   Required: 6 hours
Training: 2025-05-30 11:18:30,576-Speed 370.41 samples/sec   Loss 9.1073 Epoch: 14   Global Step: 29400   Required: 6 hours
Training: 2025-05-30 11:18:47,854-Speed 370.41 samples/sec   Loss 9.0464 Epoch: 14   Global Step: 29450   Required: 6 hours
Training: 2025-05-30 11:19:05,135-Speed 370.35 samples/sec   Loss 9.2732 Epoch: 14   Global Step: 29500   Required: 6 hours
Training: 2025-05-30 11:19:22,412-Speed 370.45 samples/sec   Loss 8.9459 Epoch: 14   Global Step: 29550   Required: 6 hours
Training: 2025-05-30 11:19:39,687-Speed 370.47 samples/sec   Loss 9.1366 Epoch: 14   Global Step: 29600   Required: 6 hours
Training: 2025-05-30 11:19:56,958-Speed 370.57 samples/sec   Loss 9.2000 Epoch: 14   Global Step: 29650   Required: 6 hours
Training: 2025-05-30 11:20:14,229-Speed 370.57 samples/sec   Loss 9.4602 Epoch: 14   Global Step: 29700   Required: 6 hours
Training: 2025-05-30 11:20:31,505-Speed 370.46 samples/sec   Loss 9.2418 Epoch: 14   Global Step: 29750   Required: 6 hours
Training: 2025-05-30 11:20:48,781-Speed 370.45 samples/sec   Loss 9.1235 Epoch: 14   Global Step: 29800   Required: 6 hours
Training: 2025-05-30 11:21:06,054-Speed 370.53 samples/sec   Loss 9.2682 Epoch: 14   Global Step: 29850   Required: 6 hours
Training: 2025-05-30 11:21:23,332-Speed 370.42 samples/sec   Loss 9.3111 Epoch: 14   Global Step: 29900   Required: 6 hours
Training: 2025-05-30 11:21:40,611-Speed 370.38 samples/sec   Loss 9.3509 Epoch: 14   Global Step: 29950   Required: 6 hours
Training: 2025-05-30 11:21:57,887-Speed 370.48 samples/sec   Loss 9.4730 Epoch: 14   Global Step: 30000   Required: 6 hours
Training: 2025-05-30 11:22:15,160-Speed 370.51 samples/sec   Loss 9.6205 Epoch: 14   Global Step: 30050   Required: 6 hours
Training: 2025-05-30 11:22:32,435-Speed 370.49 samples/sec   Loss 9.5177 Epoch: 14   Global Step: 30100   Required: 6 hours
Training: 2025-05-30 11:22:49,711-Speed 370.45 samples/sec   Loss 9.3790 Epoch: 14   Global Step: 30150   Required: 6 hours
Training: 2025-05-30 11:23:06,982-Speed 370.57 samples/sec   Loss 9.6799 Epoch: 14   Global Step: 30200   Required: 6 hours
Training: 2025-05-30 11:23:24,253-Speed 370.57 samples/sec   Loss 9.3718 Epoch: 14   Global Step: 30250   Required: 6 hours
Training: 2025-05-30 11:23:41,521-Speed 370.63 samples/sec   Loss 9.4857 Epoch: 14   Global Step: 30300   Required: 6 hours
Training: 2025-05-30 11:23:58,794-Speed 370.52 samples/sec   Loss 9.4455 Epoch: 14   Global Step: 30350   Required: 6 hours
Training: 2025-05-30 11:24:16,069-Speed 370.49 samples/sec   Loss 9.4358 Epoch: 14   Global Step: 30400   Required: 6 hours
Training: 2025-05-30 11:24:33,344-Speed 370.48 samples/sec   Loss 9.5653 Epoch: 14   Global Step: 30450   Required: 6 hours
Training: 2025-05-30 11:24:50,620-Speed 370.46 samples/sec   Loss 9.6836 Epoch: 14   Global Step: 30500   Required: 6 hours
Training: 2025-05-30 11:25:07,893-Speed 370.51 samples/sec   Loss 9.8793 Epoch: 14   Global Step: 30550   Required: 6 hours
Training: 2025-05-30 11:25:39,122-[lfw][30570]XNorm: 22.921234
Training: 2025-05-30 11:25:39,122-[lfw][30570]Accuracy-Flip: 0.98850+-0.00550
Training: 2025-05-30 11:25:39,122-[lfw][30570]Accuracy-Highest: 0.98950
Training: 2025-05-30 11:26:07,416-[cfp_fp][30570]XNorm: 20.251565
Training: 2025-05-30 11:26:07,416-[cfp_fp][30570]Accuracy-Flip: 0.90886+-0.01258
Training: 2025-05-30 11:26:07,416-[cfp_fp][30570]Accuracy-Highest: 0.90886
Training: 2025-05-30 11:26:31,718-[agedb_30][30570]XNorm: 21.830540
Training: 2025-05-30 11:26:31,718-[agedb_30][30570]Accuracy-Flip: 0.88950+-0.01814
Training: 2025-05-30 11:26:31,718-[agedb_30][30570]Accuracy-Highest: 0.90967
Training: 2025-05-30 11:26:56,104-[calfw][30570]XNorm: 22.405395
Training: 2025-05-30 11:26:56,104-[calfw][30570]Accuracy-Flip: 0.90733+-0.01289
Training: 2025-05-30 11:26:56,104-[calfw][30570]Accuracy-Highest: 0.91867
Training: 2025-05-30 11:27:20,479-[cplfw][30570]XNorm: 20.673656
Training: 2025-05-30 11:27:20,479-[cplfw][30570]Accuracy-Flip: 0.83550+-0.02346
Training: 2025-05-30 11:27:20,479-[cplfw][30570]Accuracy-Highest: 0.84617
Training: 2025-05-30 11:27:30,987-Speed 44.73 samples/sec   Loss 8.4118 Epoch: 15   Global Step: 30600   Required: 6 hours
Training: 2025-05-30 11:27:48,254-Speed 370.65 samples/sec   Loss 7.5860 Epoch: 15   Global Step: 30650   Required: 6 hours
Training: 2025-05-30 11:28:05,525-Speed 370.57 samples/sec   Loss 7.5595 Epoch: 15   Global Step: 30700   Required: 6 hours
Training: 2025-05-30 11:28:22,796-Speed 370.57 samples/sec   Loss 7.8681 Epoch: 15   Global Step: 30750   Required: 6 hours
Training: 2025-05-30 11:28:40,065-Speed 370.60 samples/sec   Loss 7.8598 Epoch: 15   Global Step: 30800   Required: 6 hours
Training: 2025-05-30 11:28:57,340-Speed 370.49 samples/sec   Loss 8.0401 Epoch: 15   Global Step: 30850   Required: 6 hours
Training: 2025-05-30 11:29:14,615-Speed 370.47 samples/sec   Loss 8.1971 Epoch: 15   Global Step: 30900   Required: 6 hours
Training: 2025-05-30 11:29:31,896-Speed 370.36 samples/sec   Loss 8.3639 Epoch: 15   Global Step: 30950   Required: 6 hours
Training: 2025-05-30 11:29:49,177-Speed 370.35 samples/sec   Loss 8.4076 Epoch: 15   Global Step: 31000   Required: 6 hours
Training: 2025-05-30 11:30:06,459-Speed 370.34 samples/sec   Loss 8.3245 Epoch: 15   Global Step: 31050   Required: 6 hours
Training: 2025-05-30 11:30:23,740-Speed 370.36 samples/sec   Loss 8.5093 Epoch: 15   Global Step: 31100   Required: 6 hours
Training: 2025-05-30 11:30:41,023-Speed 370.31 samples/sec   Loss 8.4867 Epoch: 15   Global Step: 31150   Required: 6 hours
Training: 2025-05-30 11:30:58,302-Speed 370.38 samples/sec   Loss 8.5594 Epoch: 15   Global Step: 31200   Required: 6 hours
Training: 2025-05-30 11:31:15,585-Speed 370.32 samples/sec   Loss 8.5790 Epoch: 15   Global Step: 31250   Required: 6 hours
Training: 2025-05-30 11:31:32,866-Speed 370.35 samples/sec   Loss 8.7703 Epoch: 15   Global Step: 31300   Required: 6 hours
Training: 2025-05-30 11:31:50,145-Speed 370.40 samples/sec   Loss 8.6269 Epoch: 15   Global Step: 31350   Required: 6 hours
Training: 2025-05-30 11:32:07,423-Speed 370.42 samples/sec   Loss 8.9452 Epoch: 15   Global Step: 31400   Required: 6 hours
Training: 2025-05-30 11:32:24,703-Speed 370.36 samples/sec   Loss 9.0426 Epoch: 15   Global Step: 31450   Required: 6 hours
Training: 2025-05-30 11:32:41,980-Speed 370.45 samples/sec   Loss 9.0035 Epoch: 15   Global Step: 31500   Required: 6 hours
Training: 2025-05-30 11:32:59,257-Speed 370.43 samples/sec   Loss 9.1487 Epoch: 15   Global Step: 31550   Required: 6 hours
Training: 2025-05-30 11:33:16,534-Speed 370.45 samples/sec   Loss 8.9139 Epoch: 15   Global Step: 31600   Required: 6 hours
Training: 2025-05-30 11:33:33,812-Speed 370.41 samples/sec   Loss 8.8305 Epoch: 15   Global Step: 31650   Required: 6 hours
Training: 2025-05-30 11:33:51,092-Speed 370.37 samples/sec   Loss 9.1412 Epoch: 15   Global Step: 31700   Required: 6 hours
Training: 2025-05-30 11:34:08,372-Speed 370.38 samples/sec   Loss 9.1586 Epoch: 15   Global Step: 31750   Required: 6 hours
Training: 2025-05-30 11:34:25,653-Speed 370.35 samples/sec   Loss 9.0825 Epoch: 15   Global Step: 31800   Required: 6 hours
Training: 2025-05-30 11:34:42,934-Speed 370.35 samples/sec   Loss 9.1578 Epoch: 15   Global Step: 31850   Required: 6 hours
Training: 2025-05-30 11:35:00,218-Speed 370.28 samples/sec   Loss 9.2469 Epoch: 15   Global Step: 31900   Required: 6 hours
Training: 2025-05-30 11:35:17,501-Speed 370.31 samples/sec   Loss 9.1720 Epoch: 15   Global Step: 31950   Required: 6 hours
Training: 2025-05-30 11:35:34,778-Speed 370.44 samples/sec   Loss 9.3186 Epoch: 15   Global Step: 32000   Required: 6 hours
Training: 2025-05-30 11:35:52,060-Speed 370.34 samples/sec   Loss 9.2888 Epoch: 15   Global Step: 32050   Required: 6 hours
Training: 2025-05-30 11:36:09,342-Speed 370.32 samples/sec   Loss 9.3932 Epoch: 15   Global Step: 32100   Required: 6 hours
Training: 2025-05-30 11:36:26,621-Speed 370.39 samples/sec   Loss 9.4521 Epoch: 15   Global Step: 32150   Required: 6 hours
Training: 2025-05-30 11:36:43,900-Speed 370.39 samples/sec   Loss 9.3767 Epoch: 15   Global Step: 32200   Required: 6 hours
Training: 2025-05-30 11:37:01,185-Speed 370.27 samples/sec   Loss 9.4652 Epoch: 15   Global Step: 32250   Required: 6 hours
Training: 2025-05-30 11:37:18,463-Speed 370.43 samples/sec   Loss 9.6374 Epoch: 15   Global Step: 32300   Required: 6 hours
Training: 2025-05-30 11:37:35,745-Speed 370.32 samples/sec   Loss 9.2675 Epoch: 15   Global Step: 32350   Required: 6 hours
Training: 2025-05-30 11:37:53,032-Speed 370.24 samples/sec   Loss 9.3640 Epoch: 15   Global Step: 32400   Required: 6 hours
Training: 2025-05-30 11:38:10,320-Speed 370.19 samples/sec   Loss 9.5195 Epoch: 15   Global Step: 32450   Required: 6 hours
Training: 2025-05-30 11:38:27,603-Speed 370.31 samples/sec   Loss 9.4293 Epoch: 15   Global Step: 32500   Required: 6 hours
Training: 2025-05-30 11:38:44,882-Speed 370.40 samples/sec   Loss 9.5232 Epoch: 15   Global Step: 32550   Required: 5 hours
Training: 2025-05-30 11:39:02,158-Speed 370.45 samples/sec   Loss 9.4951 Epoch: 15   Global Step: 32600   Required: 5 hours
Training: 2025-05-30 11:39:29,359-[lfw][32608]XNorm: 23.850323
Training: 2025-05-30 11:39:29,359-[lfw][32608]Accuracy-Flip: 0.98833+-0.00537
Training: 2025-05-30 11:39:29,359-[lfw][32608]Accuracy-Highest: 0.98950
Training: 2025-05-30 11:39:57,725-[cfp_fp][32608]XNorm: 20.917977
Training: 2025-05-30 11:39:57,725-[cfp_fp][32608]Accuracy-Flip: 0.90171+-0.01248
Training: 2025-05-30 11:39:57,725-[cfp_fp][32608]Accuracy-Highest: 0.90886
Training: 2025-05-30 11:40:22,045-[agedb_30][32608]XNorm: 22.864196
Training: 2025-05-30 11:40:22,045-[agedb_30][32608]Accuracy-Flip: 0.90633+-0.01784
Training: 2025-05-30 11:40:22,045-[agedb_30][32608]Accuracy-Highest: 0.90967
Training: 2025-05-30 11:40:46,440-[calfw][32608]XNorm: 23.656082
Training: 2025-05-30 11:40:46,440-[calfw][32608]Accuracy-Flip: 0.91450+-0.01059
Training: 2025-05-30 11:40:46,440-[calfw][32608]Accuracy-Highest: 0.91867
Training: 2025-05-30 11:41:10,890-[cplfw][32608]XNorm: 20.722144
Training: 2025-05-30 11:41:10,891-[cplfw][32608]Accuracy-Flip: 0.84583+-0.01915
Training: 2025-05-30 11:41:10,891-[cplfw][32608]Accuracy-Highest: 0.84617
Training: 2025-05-30 11:41:25,547-Speed 44.63 samples/sec   Loss 7.8211 Epoch: 16   Global Step: 32650   Required: 6 hours
Training: 2025-05-30 11:41:42,808-Speed 370.79 samples/sec   Loss 7.4130 Epoch: 16   Global Step: 32700   Required: 6 hours
Training: 2025-05-30 11:42:00,069-Speed 370.77 samples/sec   Loss 7.5821 Epoch: 16   Global Step: 32750   Required: 6 hours
Training: 2025-05-30 11:42:17,336-Speed 370.66 samples/sec   Loss 7.8887 Epoch: 16   Global Step: 32800   Required: 6 hours
Training: 2025-05-30 11:42:34,606-Speed 370.59 samples/sec   Loss 7.8033 Epoch: 16   Global Step: 32850   Required: 6 hours
Training: 2025-05-30 11:42:51,878-Speed 370.54 samples/sec   Loss 7.9500 Epoch: 16   Global Step: 32900   Required: 5 hours
Training: 2025-05-30 11:43:09,154-Speed 370.47 samples/sec   Loss 8.1598 Epoch: 16   Global Step: 32950   Required: 5 hours
Training: 2025-05-30 11:43:26,426-Speed 370.55 samples/sec   Loss 8.2965 Epoch: 16   Global Step: 33000   Required: 5 hours
Training: 2025-05-30 11:43:43,699-Speed 370.52 samples/sec   Loss 7.9967 Epoch: 16   Global Step: 33050   Required: 5 hours
Training: 2025-05-30 11:44:00,972-Speed 370.52 samples/sec   Loss 8.2642 Epoch: 16   Global Step: 33100   Required: 5 hours
Training: 2025-05-30 11:44:18,243-Speed 370.56 samples/sec   Loss 8.2750 Epoch: 16   Global Step: 33150   Required: 5 hours
Training: 2025-05-30 11:44:35,519-Speed 370.48 samples/sec   Loss 8.6118 Epoch: 16   Global Step: 33200   Required: 5 hours
Training: 2025-05-30 11:44:52,792-Speed 370.52 samples/sec   Loss 8.3412 Epoch: 16   Global Step: 33250   Required: 5 hours
Training: 2025-05-30 11:45:10,064-Speed 370.54 samples/sec   Loss 8.6193 Epoch: 16   Global Step: 33300   Required: 5 hours
Training: 2025-05-30 11:45:27,338-Speed 370.51 samples/sec   Loss 8.7886 Epoch: 16   Global Step: 33350   Required: 5 hours
Training: 2025-05-30 11:45:44,612-Speed 370.50 samples/sec   Loss 8.8306 Epoch: 16   Global Step: 33400   Required: 5 hours
Training: 2025-05-30 11:46:01,886-Speed 370.49 samples/sec   Loss 8.7463 Epoch: 16   Global Step: 33450   Required: 5 hours
Training: 2025-05-30 11:46:19,159-Speed 370.53 samples/sec   Loss 8.8241 Epoch: 16   Global Step: 33500   Required: 5 hours
Training: 2025-05-30 11:46:36,434-Speed 370.47 samples/sec   Loss 8.5632 Epoch: 16   Global Step: 33550   Required: 5 hours
Training: 2025-05-30 11:46:53,709-Speed 370.49 samples/sec   Loss 8.9253 Epoch: 16   Global Step: 33600   Required: 5 hours
Training: 2025-05-30 11:47:10,988-Speed 370.40 samples/sec   Loss 8.9783 Epoch: 16   Global Step: 33650   Required: 5 hours
Training: 2025-05-30 11:47:28,261-Speed 370.52 samples/sec   Loss 8.8620 Epoch: 16   Global Step: 33700   Required: 5 hours
Training: 2025-05-30 11:47:45,533-Speed 370.54 samples/sec   Loss 8.8750 Epoch: 16   Global Step: 33750   Required: 5 hours
Training: 2025-05-30 11:48:02,808-Speed 370.48 samples/sec   Loss 9.0457 Epoch: 16   Global Step: 33800   Required: 5 hours
Training: 2025-05-30 11:48:20,081-Speed 370.54 samples/sec   Loss 9.0410 Epoch: 16   Global Step: 33850   Required: 5 hours
Training: 2025-05-30 11:48:37,350-Speed 370.60 samples/sec   Loss 9.2764 Epoch: 16   Global Step: 33900   Required: 5 hours
Training: 2025-05-30 11:48:54,625-Speed 370.47 samples/sec   Loss 9.1532 Epoch: 16   Global Step: 33950   Required: 5 hours
Training: 2025-05-30 11:49:11,899-Speed 370.51 samples/sec   Loss 9.0358 Epoch: 16   Global Step: 34000   Required: 5 hours
Training: 2025-05-30 11:49:29,169-Speed 370.59 samples/sec   Loss 9.4216 Epoch: 16   Global Step: 34050   Required: 5 hours
Training: 2025-05-30 11:49:46,436-Speed 370.64 samples/sec   Loss 9.2982 Epoch: 16   Global Step: 34100   Required: 5 hours
Training: 2025-05-30 11:50:03,697-Speed 370.79 samples/sec   Loss 9.2866 Epoch: 16   Global Step: 34150   Required: 5 hours
Training: 2025-05-30 11:50:20,963-Speed 370.66 samples/sec   Loss 9.0720 Epoch: 16   Global Step: 34200   Required: 5 hours
Training: 2025-05-30 11:50:38,231-Speed 370.63 samples/sec   Loss 9.0566 Epoch: 16   Global Step: 34250   Required: 5 hours
Training: 2025-05-30 11:50:55,503-Speed 370.54 samples/sec   Loss 9.1502 Epoch: 16   Global Step: 34300   Required: 5 hours
Training: 2025-05-30 11:51:12,777-Speed 370.50 samples/sec   Loss 9.1131 Epoch: 16   Global Step: 34350   Required: 5 hours
Training: 2025-05-30 11:51:30,051-Speed 370.52 samples/sec   Loss 9.2786 Epoch: 16   Global Step: 34400   Required: 5 hours
Training: 2025-05-30 11:51:47,320-Speed 370.60 samples/sec   Loss 9.2593 Epoch: 16   Global Step: 34450   Required: 5 hours
Training: 2025-05-30 11:52:04,594-Speed 370.50 samples/sec   Loss 9.3062 Epoch: 16   Global Step: 34500   Required: 5 hours
Training: 2025-05-30 11:52:21,862-Speed 370.62 samples/sec   Loss 9.3189 Epoch: 16   Global Step: 34550   Required: 5 hours
Training: 2025-05-30 11:52:39,128-Speed 370.68 samples/sec   Loss 9.2178 Epoch: 16   Global Step: 34600   Required: 5 hours
Training: 2025-05-30 11:53:19,319-[lfw][34646]XNorm: 22.268819
Training: 2025-05-30 11:53:19,319-[lfw][34646]Accuracy-Flip: 0.98967+-0.00464
Training: 2025-05-30 11:53:19,319-[lfw][34646]Accuracy-Highest: 0.98967
Training: 2025-05-30 11:53:47,558-[cfp_fp][34646]XNorm: 19.274235
Training: 2025-05-30 11:53:47,558-[cfp_fp][34646]Accuracy-Flip: 0.89429+-0.01602
Training: 2025-05-30 11:53:47,558-[cfp_fp][34646]Accuracy-Highest: 0.90886
Training: 2025-05-30 11:54:11,861-[agedb_30][34646]XNorm: 21.457910
Training: 2025-05-30 11:54:11,861-[agedb_30][34646]Accuracy-Flip: 0.90917+-0.01502
Training: 2025-05-30 11:54:11,861-[agedb_30][34646]Accuracy-Highest: 0.90967
Training: 2025-05-30 11:54:36,241-[calfw][34646]XNorm: 22.075946
Training: 2025-05-30 11:54:36,241-[calfw][34646]Accuracy-Flip: 0.91867+-0.01364
Training: 2025-05-30 11:54:36,241-[calfw][34646]Accuracy-Highest: 0.91867
Training: 2025-05-30 11:55:00,679-[cplfw][34646]XNorm: 19.664758
Training: 2025-05-30 11:55:00,679-[cplfw][34646]Accuracy-Flip: 0.83700+-0.01810
Training: 2025-05-30 11:55:00,680-[cplfw][34646]Accuracy-Highest: 0.84617
Training: 2025-05-30 11:55:02,218-Speed 44.73 samples/sec   Loss 9.2981 Epoch: 17   Global Step: 34650   Required: 5 hours
Training: 2025-05-30 11:55:19,469-Speed 370.99 samples/sec   Loss 7.4088 Epoch: 17   Global Step: 34700   Required: 5 hours
Training: 2025-05-30 11:55:36,723-Speed 370.92 samples/sec   Loss 7.3870 Epoch: 17   Global Step: 34750   Required: 5 hours
Training: 2025-05-30 11:55:53,984-Speed 370.78 samples/sec   Loss 7.5795 Epoch: 17   Global Step: 34800   Required: 5 hours
Training: 2025-05-30 11:56:11,248-Speed 370.71 samples/sec   Loss 7.7383 Epoch: 17   Global Step: 34850   Required: 5 hours
Training: 2025-05-30 11:56:28,516-Speed 370.64 samples/sec   Loss 7.9206 Epoch: 17   Global Step: 34900   Required: 5 hours
Training: 2025-05-30 11:56:45,784-Speed 370.64 samples/sec   Loss 7.9293 Epoch: 17   Global Step: 34950   Required: 5 hours
Training: 2025-05-30 11:57:03,056-Speed 370.54 samples/sec   Loss 8.0080 Epoch: 17   Global Step: 35000   Required: 5 hours
Training: 2025-05-30 11:57:20,328-Speed 370.55 samples/sec   Loss 8.0132 Epoch: 17   Global Step: 35050   Required: 5 hours
Training: 2025-05-30 11:57:37,599-Speed 370.57 samples/sec   Loss 8.0691 Epoch: 17   Global Step: 35100   Required: 5 hours
Training: 2025-05-30 11:57:54,865-Speed 370.66 samples/sec   Loss 8.3823 Epoch: 17   Global Step: 35150   Required: 5 hours
Training: 2025-05-30 11:58:12,137-Speed 370.55 samples/sec   Loss 8.2160 Epoch: 17   Global Step: 35200   Required: 5 hours
Training: 2025-05-30 11:58:29,406-Speed 370.61 samples/sec   Loss 8.4335 Epoch: 17   Global Step: 35250   Required: 5 hours
Training: 2025-05-30 11:58:46,676-Speed 370.59 samples/sec   Loss 8.3088 Epoch: 17   Global Step: 35300   Required: 5 hours
Training: 2025-05-30 11:59:03,953-Speed 370.44 samples/sec   Loss 8.4265 Epoch: 17   Global Step: 35350   Required: 5 hours
Training: 2025-05-30 11:59:21,226-Speed 370.51 samples/sec   Loss 8.5118 Epoch: 17   Global Step: 35400   Required: 5 hours
Training: 2025-05-30 11:59:38,498-Speed 370.55 samples/sec   Loss 8.5465 Epoch: 17   Global Step: 35450   Required: 5 hours
Training: 2025-05-30 11:59:55,770-Speed 370.55 samples/sec   Loss 8.3648 Epoch: 17   Global Step: 35500   Required: 5 hours
Training: 2025-05-30 12:00:13,038-Speed 370.62 samples/sec   Loss 8.6052 Epoch: 17   Global Step: 35550   Required: 5 hours
Training: 2025-05-30 12:00:30,307-Speed 370.61 samples/sec   Loss 8.6078 Epoch: 17   Global Step: 35600   Required: 5 hours
Training: 2025-05-30 12:00:47,579-Speed 370.54 samples/sec   Loss 8.7921 Epoch: 17   Global Step: 35650   Required: 5 hours
Training: 2025-05-30 12:01:04,851-Speed 370.55 samples/sec   Loss 8.6708 Epoch: 17   Global Step: 35700   Required: 5 hours
Training: 2025-05-30 12:01:22,123-Speed 370.55 samples/sec   Loss 8.5646 Epoch: 17   Global Step: 35750   Required: 5 hours
Training: 2025-05-30 12:01:39,397-Speed 370.50 samples/sec   Loss 8.9967 Epoch: 17   Global Step: 35800   Required: 5 hours
Training: 2025-05-30 12:01:56,671-Speed 370.50 samples/sec   Loss 8.8643 Epoch: 17   Global Step: 35850   Required: 5 hours
Training: 2025-05-30 12:02:13,944-Speed 370.54 samples/sec   Loss 8.8624 Epoch: 17   Global Step: 35900   Required: 5 hours
Training: 2025-05-30 12:02:31,223-Speed 370.39 samples/sec   Loss 8.8862 Epoch: 17   Global Step: 35950   Required: 5 hours
Training: 2025-05-30 12:02:48,496-Speed 370.53 samples/sec   Loss 9.2462 Epoch: 17   Global Step: 36000   Required: 5 hours
Training: 2025-05-30 12:03:05,770-Speed 370.50 samples/sec   Loss 8.8341 Epoch: 17   Global Step: 36050   Required: 5 hours
Training: 2025-05-30 12:03:23,042-Speed 370.53 samples/sec   Loss 8.8451 Epoch: 17   Global Step: 36100   Required: 5 hours
Training: 2025-05-30 12:03:40,318-Speed 370.46 samples/sec   Loss 8.9463 Epoch: 17   Global Step: 36150   Required: 5 hours
Training: 2025-05-30 12:03:57,592-Speed 370.51 samples/sec   Loss 9.0272 Epoch: 17   Global Step: 36200   Required: 5 hours
Training: 2025-05-30 12:04:14,868-Speed 370.46 samples/sec   Loss 9.1702 Epoch: 17   Global Step: 36250   Required: 5 hours
Training: 2025-05-30 12:04:32,137-Speed 370.62 samples/sec   Loss 9.0682 Epoch: 17   Global Step: 36300   Required: 5 hours
Training: 2025-05-30 12:04:49,407-Speed 370.57 samples/sec   Loss 9.2545 Epoch: 17   Global Step: 36350   Required: 5 hours
Training: 2025-05-30 12:05:06,675-Speed 370.64 samples/sec   Loss 9.2586 Epoch: 17   Global Step: 36400   Required: 5 hours
Training: 2025-05-30 12:05:23,943-Speed 370.63 samples/sec   Loss 9.5475 Epoch: 17   Global Step: 36450   Required: 5 hours
Training: 2025-05-30 12:05:41,209-Speed 370.67 samples/sec   Loss 9.4104 Epoch: 17   Global Step: 36500   Required: 5 hours
Training: 2025-05-30 12:05:58,478-Speed 370.60 samples/sec   Loss 9.1757 Epoch: 17   Global Step: 36550   Required: 5 hours
Training: 2025-05-30 12:06:15,754-Speed 370.46 samples/sec   Loss 9.1682 Epoch: 17   Global Step: 36600   Required: 5 hours
Training: 2025-05-30 12:06:33,026-Speed 370.54 samples/sec   Loss 9.0748 Epoch: 17   Global Step: 36650   Required: 5 hours
Training: 2025-05-30 12:07:09,093-[lfw][36684]XNorm: 23.125393
Training: 2025-05-30 12:07:09,093-[lfw][36684]Accuracy-Flip: 0.99117+-0.00478
Training: 2025-05-30 12:07:09,093-[lfw][36684]Accuracy-Highest: 0.99117
Training: 2025-05-30 12:07:37,338-[cfp_fp][36684]XNorm: 19.980462
Training: 2025-05-30 12:07:37,338-[cfp_fp][36684]Accuracy-Flip: 0.90000+-0.01376
Training: 2025-05-30 12:07:37,338-[cfp_fp][36684]Accuracy-Highest: 0.90886
Training: 2025-05-30 12:08:01,649-[agedb_30][36684]XNorm: 22.214272
Training: 2025-05-30 12:08:01,650-[agedb_30][36684]Accuracy-Flip: 0.91433+-0.01344
Training: 2025-05-30 12:08:01,650-[agedb_30][36684]Accuracy-Highest: 0.91433
Training: 2025-05-30 12:08:26,050-[calfw][36684]XNorm: 23.070482
Training: 2025-05-30 12:08:26,050-[calfw][36684]Accuracy-Flip: 0.92100+-0.01327
Training: 2025-05-30 12:08:26,050-[calfw][36684]Accuracy-Highest: 0.92100
Training: 2025-05-30 12:08:50,488-[cplfw][36684]XNorm: 19.935624
Training: 2025-05-30 12:08:50,488-[cplfw][36684]Accuracy-Flip: 0.84400+-0.01693
Training: 2025-05-30 12:08:50,488-[cplfw][36684]Accuracy-Highest: 0.84617
Training: 2025-05-30 12:08:56,191-Speed 44.70 samples/sec   Loss 8.5179 Epoch: 18   Global Step: 36700   Required: 5 hours
Training: 2025-05-30 12:09:13,438-Speed 371.09 samples/sec   Loss 7.2809 Epoch: 18   Global Step: 36750   Required: 5 hours
Training: 2025-05-30 12:09:30,692-Speed 370.93 samples/sec   Loss 7.5021 Epoch: 18   Global Step: 36800   Required: 5 hours
Training: 2025-05-30 12:09:47,955-Speed 370.73 samples/sec   Loss 7.2440 Epoch: 18   Global Step: 36850   Required: 5 hours
Training: 2025-05-30 12:10:05,220-Speed 370.69 samples/sec   Loss 7.5221 Epoch: 18   Global Step: 36900   Required: 5 hours
Training: 2025-05-30 12:10:22,491-Speed 370.58 samples/sec   Loss 7.6724 Epoch: 18   Global Step: 36950   Required: 5 hours
Training: 2025-05-30 12:10:39,770-Speed 370.39 samples/sec   Loss 7.8758 Epoch: 18   Global Step: 37000   Required: 5 hours
Training: 2025-05-30 12:10:57,038-Speed 370.63 samples/sec   Loss 7.8510 Epoch: 18   Global Step: 37050   Required: 5 hours
Training: 2025-05-30 12:11:14,313-Speed 370.47 samples/sec   Loss 8.0920 Epoch: 18   Global Step: 37100   Required: 5 hours
Training: 2025-05-30 12:11:31,592-Speed 370.40 samples/sec   Loss 7.8821 Epoch: 18   Global Step: 37150   Required: 5 hours
Training: 2025-05-30 12:11:48,874-Speed 370.33 samples/sec   Loss 8.1484 Epoch: 18   Global Step: 37200   Required: 5 hours
Training: 2025-05-30 12:12:06,149-Speed 370.48 samples/sec   Loss 8.0999 Epoch: 18   Global Step: 37250   Required: 5 hours
Training: 2025-05-30 12:12:23,424-Speed 370.50 samples/sec   Loss 8.1540 Epoch: 18   Global Step: 37300   Required: 5 hours
Training: 2025-05-30 12:12:40,697-Speed 370.50 samples/sec   Loss 8.2557 Epoch: 18   Global Step: 37350   Required: 5 hours
Training: 2025-05-30 12:12:57,973-Speed 370.46 samples/sec   Loss 8.1787 Epoch: 18   Global Step: 37400   Required: 5 hours
Training: 2025-05-30 12:13:15,249-Speed 370.47 samples/sec   Loss 8.4146 Epoch: 18   Global Step: 37450   Required: 5 hours
Training: 2025-05-30 12:13:32,524-Speed 370.47 samples/sec   Loss 8.4900 Epoch: 18   Global Step: 37500   Required: 5 hours
Training: 2025-05-30 12:13:49,797-Speed 370.52 samples/sec   Loss 8.6037 Epoch: 18   Global Step: 37550   Required: 5 hours
Training: 2025-05-30 12:14:07,066-Speed 370.61 samples/sec   Loss 8.4964 Epoch: 18   Global Step: 37600   Required: 5 hours
Training: 2025-05-30 12:14:24,336-Speed 370.58 samples/sec   Loss 8.7032 Epoch: 18   Global Step: 37650   Required: 5 hours
Training: 2025-05-30 12:14:41,609-Speed 370.53 samples/sec   Loss 8.4066 Epoch: 18   Global Step: 37700   Required: 5 hours
Training: 2025-05-30 12:14:58,884-Speed 370.47 samples/sec   Loss 8.7895 Epoch: 18   Global Step: 37750   Required: 5 hours
Training: 2025-05-30 12:15:16,159-Speed 370.50 samples/sec   Loss 8.7563 Epoch: 18   Global Step: 37800   Required: 5 hours
Training: 2025-05-30 12:15:33,431-Speed 370.53 samples/sec   Loss 8.8602 Epoch: 18   Global Step: 37850   Required: 5 hours
Training: 2025-05-30 12:15:50,708-Speed 370.44 samples/sec   Loss 8.7857 Epoch: 18   Global Step: 37900   Required: 5 hours
Training: 2025-05-30 12:16:07,983-Speed 370.48 samples/sec   Loss 8.8696 Epoch: 18   Global Step: 37950   Required: 5 hours
Training: 2025-05-30 12:16:25,260-Speed 370.44 samples/sec   Loss 8.8203 Epoch: 18   Global Step: 38000   Required: 5 hours
Training: 2025-05-30 12:16:42,536-Speed 370.46 samples/sec   Loss 8.8338 Epoch: 18   Global Step: 38050   Required: 5 hours
Training: 2025-05-30 12:16:59,813-Speed 370.44 samples/sec   Loss 9.0732 Epoch: 18   Global Step: 38100   Required: 5 hours
Training: 2025-05-30 12:17:17,084-Speed 370.56 samples/sec   Loss 8.9729 Epoch: 18   Global Step: 38150   Required: 5 hours
Training: 2025-05-30 12:17:34,359-Speed 370.49 samples/sec   Loss 8.9838 Epoch: 18   Global Step: 38200   Required: 5 hours
Training: 2025-05-30 12:17:51,632-Speed 370.52 samples/sec   Loss 9.0230 Epoch: 18   Global Step: 38250   Required: 5 hours
Training: 2025-05-30 12:18:08,905-Speed 370.52 samples/sec   Loss 8.9395 Epoch: 18   Global Step: 38300   Required: 5 hours
Training: 2025-05-30 12:18:26,182-Speed 370.44 samples/sec   Loss 8.9034 Epoch: 18   Global Step: 38350   Required: 5 hours
Training: 2025-05-30 12:18:43,453-Speed 370.56 samples/sec   Loss 8.8352 Epoch: 18   Global Step: 38400   Required: 5 hours
Training: 2025-05-30 12:19:00,729-Speed 370.45 samples/sec   Loss 8.9947 Epoch: 18   Global Step: 38450   Required: 5 hours
Training: 2025-05-30 12:19:18,005-Speed 370.47 samples/sec   Loss 9.1299 Epoch: 18   Global Step: 38500   Required: 5 hours
Training: 2025-05-30 12:19:35,285-Speed 370.38 samples/sec   Loss 9.1291 Epoch: 18   Global Step: 38550   Required: 5 hours
Training: 2025-05-30 12:19:52,561-Speed 370.46 samples/sec   Loss 9.1126 Epoch: 18   Global Step: 38600   Required: 5 hours
Training: 2025-05-30 12:20:09,840-Speed 370.39 samples/sec   Loss 9.2153 Epoch: 18   Global Step: 38650   Required: 5 hours
Training: 2025-05-30 12:20:27,113-Speed 370.52 samples/sec   Loss 9.0329 Epoch: 18   Global Step: 38700   Required: 5 hours
Training: 2025-05-30 12:20:59,032-[lfw][38722]XNorm: 21.513450
Training: 2025-05-30 12:20:59,032-[lfw][38722]Accuracy-Flip: 0.98967+-0.00488
Training: 2025-05-30 12:20:59,032-[lfw][38722]Accuracy-Highest: 0.99117
Training: 2025-05-30 12:21:27,263-[cfp_fp][38722]XNorm: 18.618255
Training: 2025-05-30 12:21:27,263-[cfp_fp][38722]Accuracy-Flip: 0.90771+-0.01324
Training: 2025-05-30 12:21:27,263-[cfp_fp][38722]Accuracy-Highest: 0.90886
Training: 2025-05-30 12:21:51,561-[agedb_30][38722]XNorm: 20.831377
Training: 2025-05-30 12:21:51,561-[agedb_30][38722]Accuracy-Flip: 0.90600+-0.01621
Training: 2025-05-30 12:21:51,561-[agedb_30][38722]Accuracy-Highest: 0.91433
Training: 2025-05-30 12:22:15,941-[calfw][38722]XNorm: 21.299112
Training: 2025-05-30 12:22:15,941-[calfw][38722]Accuracy-Flip: 0.91300+-0.01310
Training: 2025-05-30 12:22:15,941-[calfw][38722]Accuracy-Highest: 0.92100
Training: 2025-05-30 12:22:40,320-[cplfw][38722]XNorm: 18.715745
Training: 2025-05-30 12:22:40,320-[cplfw][38722]Accuracy-Flip: 0.84683+-0.01991
Training: 2025-05-30 12:22:40,320-[cplfw][38722]Accuracy-Highest: 0.84683
Training: 2025-05-30 12:22:50,123-Speed 44.75 samples/sec   Loss 7.9848 Epoch: 19   Global Step: 38750   Required: 5 hours
Training: 2025-05-30 12:23:07,378-Speed 370.91 samples/sec   Loss 7.3081 Epoch: 19   Global Step: 38800   Required: 5 hours
Training: 2025-05-30 12:23:24,644-Speed 370.67 samples/sec   Loss 7.2137 Epoch: 19   Global Step: 38850   Required: 5 hours
Training: 2025-05-30 12:23:41,911-Speed 370.66 samples/sec   Loss 7.4300 Epoch: 19   Global Step: 38900   Required: 5 hours
Training: 2025-05-30 12:23:59,179-Speed 370.62 samples/sec   Loss 7.6857 Epoch: 19   Global Step: 38950   Required: 5 hours
Training: 2025-05-30 12:24:16,448-Speed 370.61 samples/sec   Loss 7.5414 Epoch: 19   Global Step: 39000   Required: 5 hours
Training: 2025-05-30 12:24:33,718-Speed 370.59 samples/sec   Loss 7.7490 Epoch: 19   Global Step: 39050   Required: 5 hours
Training: 2025-05-30 12:24:50,988-Speed 370.58 samples/sec   Loss 7.6627 Epoch: 19   Global Step: 39100   Required: 5 hours
Training: 2025-05-30 12:25:08,262-Speed 370.50 samples/sec   Loss 7.9821 Epoch: 19   Global Step: 39150   Required: 5 hours
Training: 2025-05-30 12:25:25,540-Speed 370.43 samples/sec   Loss 7.8815 Epoch: 19   Global Step: 39200   Required: 5 hours
Training: 2025-05-30 12:25:42,813-Speed 370.51 samples/sec   Loss 8.0470 Epoch: 19   Global Step: 39250   Required: 5 hours
Training: 2025-05-30 12:26:00,085-Speed 370.54 samples/sec   Loss 8.1081 Epoch: 19   Global Step: 39300   Required: 5 hours
Training: 2025-05-30 12:26:17,358-Speed 370.53 samples/sec   Loss 8.2041 Epoch: 19   Global Step: 39350   Required: 5 hours
Training: 2025-05-30 12:26:34,637-Speed 370.40 samples/sec   Loss 8.1583 Epoch: 19   Global Step: 39400   Required: 5 hours
Training: 2025-05-30 12:26:51,919-Speed 370.33 samples/sec   Loss 8.2609 Epoch: 19   Global Step: 39450   Required: 5 hours
Training: 2025-05-30 12:27:09,194-Speed 370.47 samples/sec   Loss 8.3753 Epoch: 19   Global Step: 39500   Required: 5 hours
Training: 2025-05-30 12:27:26,473-Speed 370.41 samples/sec   Loss 8.2074 Epoch: 19   Global Step: 39550   Required: 5 hours
Training: 2025-05-30 12:27:43,751-Speed 370.42 samples/sec   Loss 8.2477 Epoch: 19   Global Step: 39600   Required: 5 hours
Training: 2025-05-30 12:28:01,025-Speed 370.49 samples/sec   Loss 8.4039 Epoch: 19   Global Step: 39650   Required: 5 hours
Training: 2025-05-30 12:28:18,302-Speed 370.44 samples/sec   Loss 8.5144 Epoch: 19   Global Step: 39700   Required: 5 hours
Training: 2025-05-30 12:28:35,573-Speed 370.56 samples/sec   Loss 8.8688 Epoch: 19   Global Step: 39750   Required: 5 hours
Training: 2025-05-30 12:28:52,847-Speed 370.52 samples/sec   Loss 8.8347 Epoch: 19   Global Step: 39800   Required: 5 hours
Training: 2025-05-30 12:29:10,122-Speed 370.48 samples/sec   Loss 8.7106 Epoch: 19   Global Step: 39850   Required: 5 hours
Training: 2025-05-30 12:29:27,392-Speed 370.58 samples/sec   Loss 8.6809 Epoch: 19   Global Step: 39900   Required: 5 hours
Training: 2025-05-30 12:29:44,664-Speed 370.54 samples/sec   Loss 8.7878 Epoch: 19   Global Step: 39950   Required: 5 hours
Training: 2025-05-30 12:30:01,939-Speed 370.48 samples/sec   Loss 8.7067 Epoch: 19   Global Step: 40000   Required: 5 hours
Training: 2025-05-30 12:30:19,216-Speed 370.45 samples/sec   Loss 8.7318 Epoch: 19   Global Step: 40050   Required: 5 hours
Training: 2025-05-30 12:30:36,494-Speed 370.42 samples/sec   Loss 8.7492 Epoch: 19   Global Step: 40100   Required: 5 hours
Training: 2025-05-30 12:30:53,771-Speed 370.42 samples/sec   Loss 8.6545 Epoch: 19   Global Step: 40150   Required: 5 hours
Training: 2025-05-30 12:31:11,043-Speed 370.54 samples/sec   Loss 8.8732 Epoch: 19   Global Step: 40200   Required: 5 hours
Training: 2025-05-30 12:31:28,313-Speed 370.59 samples/sec   Loss 8.9629 Epoch: 19   Global Step: 40250   Required: 5 hours
Training: 2025-05-30 12:31:45,589-Speed 370.46 samples/sec   Loss 8.7045 Epoch: 19   Global Step: 40300   Required: 5 hours
Training: 2025-05-30 12:32:02,864-Speed 370.48 samples/sec   Loss 9.0451 Epoch: 19   Global Step: 40350   Required: 5 hours
Training: 2025-05-30 12:32:20,142-Speed 370.41 samples/sec   Loss 8.8439 Epoch: 19   Global Step: 40400   Required: 5 hours
Training: 2025-05-30 12:32:37,418-Speed 370.45 samples/sec   Loss 8.9946 Epoch: 19   Global Step: 40450   Required: 5 hours
Training: 2025-05-30 12:32:54,690-Speed 370.55 samples/sec   Loss 8.9803 Epoch: 19   Global Step: 40500   Required: 5 hours
Training: 2025-05-30 12:33:11,962-Speed 370.54 samples/sec   Loss 8.9562 Epoch: 19   Global Step: 40550   Required: 5 hours
Training: 2025-05-30 12:33:29,234-Speed 370.55 samples/sec   Loss 8.9808 Epoch: 19   Global Step: 40600   Required: 5 hours
Training: 2025-05-30 12:33:46,511-Speed 370.44 samples/sec   Loss 9.0550 Epoch: 19   Global Step: 40650   Required: 5 hours
Training: 2025-05-30 12:34:03,784-Speed 370.52 samples/sec   Loss 8.9509 Epoch: 19   Global Step: 40700   Required: 5 hours
Training: 2025-05-30 12:34:21,052-Speed 370.62 samples/sec   Loss 9.1160 Epoch: 19   Global Step: 40750   Required: 5 hours
Training: 2025-05-30 12:34:48,808-[lfw][40760]XNorm: 21.241055
Training: 2025-05-30 12:34:48,809-[lfw][40760]Accuracy-Flip: 0.98817+-0.00555
Training: 2025-05-30 12:34:48,809-[lfw][40760]Accuracy-Highest: 0.99117
Training: 2025-05-30 12:35:17,078-[cfp_fp][40760]XNorm: 18.332663
Training: 2025-05-30 12:35:17,078-[cfp_fp][40760]Accuracy-Flip: 0.90857+-0.01032
Training: 2025-05-30 12:35:17,078-[cfp_fp][40760]Accuracy-Highest: 0.90886
Training: 2025-05-30 12:35:41,378-[agedb_30][40760]XNorm: 20.732076
Training: 2025-05-30 12:35:41,378-[agedb_30][40760]Accuracy-Flip: 0.90650+-0.01707
Training: 2025-05-30 12:35:41,378-[agedb_30][40760]Accuracy-Highest: 0.91433
Training: 2025-05-30 12:36:05,763-[calfw][40760]XNorm: 21.058441
Training: 2025-05-30 12:36:05,763-[calfw][40760]Accuracy-Flip: 0.91850+-0.01250
Training: 2025-05-30 12:36:05,763-[calfw][40760]Accuracy-Highest: 0.92100
Training: 2025-05-30 12:36:30,253-[cplfw][40760]XNorm: 18.077467
Training: 2025-05-30 12:36:30,253-[cplfw][40760]Accuracy-Flip: 0.84383+-0.01932
Training: 2025-05-30 12:36:30,253-[cplfw][40760]Accuracy-Highest: 0.84683
Training: 2025-05-30 12:36:44,223-Speed 44.70 samples/sec   Loss 7.4944 Epoch: 20   Global Step: 40800   Required: 5 hours
Training: 2025-05-30 12:37:01,482-Speed 370.84 samples/sec   Loss 7.0372 Epoch: 20   Global Step: 40850   Required: 5 hours
Training: 2025-05-30 12:37:18,744-Speed 370.76 samples/sec   Loss 7.1256 Epoch: 20   Global Step: 40900   Required: 5 hours
Training: 2025-05-30 12:37:36,014-Speed 370.58 samples/sec   Loss 7.1953 Epoch: 20   Global Step: 40950   Required: 5 hours
Training: 2025-05-30 12:37:53,288-Speed 370.51 samples/sec   Loss 7.5035 Epoch: 20   Global Step: 41000   Required: 5 hours
Training: 2025-05-30 12:38:10,563-Speed 370.47 samples/sec   Loss 7.7756 Epoch: 20   Global Step: 41050   Required: 5 hours
Training: 2025-05-30 12:38:27,837-Speed 370.51 samples/sec   Loss 7.7078 Epoch: 20   Global Step: 41100   Required: 5 hours
Training: 2025-05-30 12:38:45,111-Speed 370.50 samples/sec   Loss 7.9568 Epoch: 20   Global Step: 41150   Required: 5 hours
Training: 2025-05-30 12:39:02,389-Speed 370.42 samples/sec   Loss 7.8499 Epoch: 20   Global Step: 41200   Required: 5 hours
Training: 2025-05-30 12:39:19,665-Speed 370.45 samples/sec   Loss 7.8233 Epoch: 20   Global Step: 41250   Required: 5 hours
Training: 2025-05-30 12:39:36,942-Speed 370.45 samples/sec   Loss 7.6862 Epoch: 20   Global Step: 41300   Required: 5 hours
Training: 2025-05-30 12:39:54,216-Speed 370.48 samples/sec   Loss 7.8951 Epoch: 20   Global Step: 41350   Required: 5 hours
Training: 2025-05-30 12:40:11,494-Speed 370.42 samples/sec   Loss 8.1500 Epoch: 20   Global Step: 41400   Required: 5 hours
Training: 2025-05-30 12:40:28,766-Speed 370.54 samples/sec   Loss 8.1916 Epoch: 20   Global Step: 41450   Required: 5 hours
Training: 2025-05-30 12:40:46,042-Speed 370.45 samples/sec   Loss 8.1519 Epoch: 20   Global Step: 41500   Required: 5 hours
Training: 2025-05-30 12:41:03,318-Speed 370.46 samples/sec   Loss 8.3074 Epoch: 20   Global Step: 41550   Required: 5 hours
Training: 2025-05-30 12:41:20,590-Speed 370.55 samples/sec   Loss 8.0918 Epoch: 20   Global Step: 41600   Required: 5 hours
Training: 2025-05-30 12:41:37,868-Speed 370.42 samples/sec   Loss 8.1935 Epoch: 20   Global Step: 41650   Required: 4 hours
Training: 2025-05-30 12:41:55,141-Speed 370.53 samples/sec   Loss 8.3462 Epoch: 20   Global Step: 41700   Required: 4 hours
Training: 2025-05-30 12:42:12,414-Speed 370.51 samples/sec   Loss 8.4920 Epoch: 20   Global Step: 41750   Required: 4 hours
Training: 2025-05-30 12:42:29,686-Speed 370.55 samples/sec   Loss 8.3737 Epoch: 20   Global Step: 41800   Required: 4 hours
Training: 2025-05-30 12:42:46,961-Speed 370.47 samples/sec   Loss 8.5440 Epoch: 20   Global Step: 41850   Required: 4 hours
Training: 2025-05-30 12:43:04,239-Speed 370.43 samples/sec   Loss 8.2181 Epoch: 20   Global Step: 41900   Required: 4 hours
Training: 2025-05-30 12:43:21,514-Speed 370.47 samples/sec   Loss 8.6623 Epoch: 20   Global Step: 41950   Required: 4 hours
Training: 2025-05-30 12:43:38,790-Speed 370.45 samples/sec   Loss 8.4825 Epoch: 20   Global Step: 42000   Required: 4 hours
Training: 2025-05-30 12:43:56,069-Speed 370.40 samples/sec   Loss 8.6759 Epoch: 20   Global Step: 42050   Required: 4 hours
Training: 2025-05-30 12:44:13,348-Speed 370.41 samples/sec   Loss 8.6013 Epoch: 20   Global Step: 42100   Required: 4 hours
Training: 2025-05-30 12:44:30,627-Speed 370.38 samples/sec   Loss 8.8655 Epoch: 20   Global Step: 42150   Required: 4 hours
Training: 2025-05-30 12:44:47,898-Speed 370.56 samples/sec   Loss 8.6756 Epoch: 20   Global Step: 42200   Required: 4 hours
Training: 2025-05-30 12:45:05,173-Speed 370.50 samples/sec   Loss 8.9482 Epoch: 20   Global Step: 42250   Required: 4 hours
Training: 2025-05-30 12:45:22,449-Speed 370.45 samples/sec   Loss 8.8406 Epoch: 20   Global Step: 42300   Required: 4 hours
Training: 2025-05-30 12:45:39,724-Speed 370.48 samples/sec   Loss 8.6380 Epoch: 20   Global Step: 42350   Required: 4 hours
Training: 2025-05-30 12:45:56,999-Speed 370.48 samples/sec   Loss 8.8370 Epoch: 20   Global Step: 42400   Required: 4 hours
Training: 2025-05-30 12:46:14,272-Speed 370.53 samples/sec   Loss 9.0331 Epoch: 20   Global Step: 42450   Required: 4 hours
Training: 2025-05-30 12:46:31,547-Speed 370.49 samples/sec   Loss 9.0010 Epoch: 20   Global Step: 42500   Required: 4 hours
Training: 2025-05-30 12:46:48,823-Speed 370.45 samples/sec   Loss 8.8674 Epoch: 20   Global Step: 42550   Required: 4 hours
Training: 2025-05-30 12:47:06,100-Speed 370.44 samples/sec   Loss 8.7563 Epoch: 20   Global Step: 42600   Required: 4 hours
Training: 2025-05-30 12:47:23,373-Speed 370.51 samples/sec   Loss 8.8656 Epoch: 20   Global Step: 42650   Required: 4 hours
Training: 2025-05-30 12:47:40,645-Speed 370.56 samples/sec   Loss 8.8990 Epoch: 20   Global Step: 42700   Required: 4 hours
Training: 2025-05-30 12:47:57,919-Speed 370.50 samples/sec   Loss 8.8218 Epoch: 20   Global Step: 42750   Required: 4 hours
Training: 2025-05-30 12:48:38,815-[lfw][42798]XNorm: 22.779343
Training: 2025-05-30 12:48:38,815-[lfw][42798]Accuracy-Flip: 0.99033+-0.00572
Training: 2025-05-30 12:48:38,815-[lfw][42798]Accuracy-Highest: 0.99117
Training: 2025-05-30 12:49:07,184-[cfp_fp][42798]XNorm: 20.128417
Training: 2025-05-30 12:49:07,184-[cfp_fp][42798]Accuracy-Flip: 0.90429+-0.01758
Training: 2025-05-30 12:49:07,184-[cfp_fp][42798]Accuracy-Highest: 0.90886
Training: 2025-05-30 12:49:31,478-[agedb_30][42798]XNorm: 22.089978
Training: 2025-05-30 12:49:31,478-[agedb_30][42798]Accuracy-Flip: 0.90800+-0.01291
Training: 2025-05-30 12:49:31,478-[agedb_30][42798]Accuracy-Highest: 0.91433
Training: 2025-05-30 12:49:55,857-[calfw][42798]XNorm: 22.486462
Training: 2025-05-30 12:49:55,857-[calfw][42798]Accuracy-Flip: 0.92400+-0.01239
Training: 2025-05-30 12:49:55,857-[calfw][42798]Accuracy-Highest: 0.92400
Training: 2025-05-30 12:50:20,279-[cplfw][42798]XNorm: 20.151791
Training: 2025-05-30 12:50:20,279-[cplfw][42798]Accuracy-Flip: 0.85167+-0.01804
Training: 2025-05-30 12:50:20,279-[cplfw][42798]Accuracy-Highest: 0.85167
Training: 2025-05-30 12:50:21,134-Speed 44.69 samples/sec   Loss 8.9623 Epoch: 21   Global Step: 42800   Required: 4 hours
Training: 2025-05-30 12:50:38,396-Speed 370.75 samples/sec   Loss 6.6662 Epoch: 21   Global Step: 42850   Required: 4 hours
Training: 2025-05-30 12:50:55,664-Speed 370.64 samples/sec   Loss 6.3755 Epoch: 21   Global Step: 42900   Required: 4 hours
Training: 2025-05-30 12:51:12,935-Speed 370.57 samples/sec   Loss 6.0023 Epoch: 21   Global Step: 42950   Required: 4 hours
Training: 2025-05-30 12:51:30,206-Speed 370.56 samples/sec   Loss 5.8528 Epoch: 21   Global Step: 43000   Required: 4 hours
Training: 2025-05-30 12:51:47,482-Speed 370.46 samples/sec   Loss 5.7026 Epoch: 21   Global Step: 43050   Required: 4 hours
Training: 2025-05-30 12:52:04,759-Speed 370.43 samples/sec   Loss 5.8181 Epoch: 21   Global Step: 43100   Required: 4 hours
Training: 2025-05-30 12:52:22,040-Speed 370.35 samples/sec   Loss 5.6641 Epoch: 21   Global Step: 43150   Required: 4 hours
Training: 2025-05-30 12:52:39,321-Speed 370.37 samples/sec   Loss 5.7572 Epoch: 21   Global Step: 43200   Required: 4 hours
Training: 2025-05-30 12:52:56,599-Speed 370.41 samples/sec   Loss 5.5627 Epoch: 21   Global Step: 43250   Required: 4 hours
Training: 2025-05-30 12:53:13,875-Speed 370.45 samples/sec   Loss 5.5020 Epoch: 21   Global Step: 43300   Required: 4 hours
Training: 2025-05-30 12:53:31,152-Speed 370.44 samples/sec   Loss 5.3541 Epoch: 21   Global Step: 43350   Required: 4 hours
Training: 2025-05-30 12:53:48,433-Speed 370.36 samples/sec   Loss 5.4828 Epoch: 21   Global Step: 43400   Required: 4 hours
Training: 2025-05-30 12:54:05,716-Speed 370.30 samples/sec   Loss 5.5693 Epoch: 21   Global Step: 43450   Required: 4 hours
Training: 2025-05-30 12:54:22,993-Speed 370.44 samples/sec   Loss 5.6002 Epoch: 21   Global Step: 43500   Required: 4 hours
Training: 2025-05-30 12:54:40,272-Speed 370.38 samples/sec   Loss 5.5812 Epoch: 21   Global Step: 43550   Required: 4 hours
Training: 2025-05-30 12:54:57,555-Speed 370.31 samples/sec   Loss 5.5353 Epoch: 21   Global Step: 43600   Required: 4 hours
Training: 2025-05-30 12:55:14,832-Speed 370.44 samples/sec   Loss 5.4007 Epoch: 21   Global Step: 43650   Required: 4 hours
Training: 2025-05-30 12:55:32,115-Speed 370.32 samples/sec   Loss 5.4187 Epoch: 21   Global Step: 43700   Required: 4 hours
Training: 2025-05-30 12:55:49,399-Speed 370.28 samples/sec   Loss 5.0988 Epoch: 21   Global Step: 43750   Required: 4 hours
Training: 2025-05-30 12:56:06,677-Speed 370.41 samples/sec   Loss 5.2705 Epoch: 21   Global Step: 43800   Required: 4 hours
Training: 2025-05-30 12:56:23,956-Speed 370.39 samples/sec   Loss 5.3977 Epoch: 21   Global Step: 43850   Required: 4 hours
Training: 2025-05-30 12:56:41,233-Speed 370.44 samples/sec   Loss 5.2472 Epoch: 21   Global Step: 43900   Required: 4 hours
Training: 2025-05-30 12:56:58,510-Speed 370.44 samples/sec   Loss 5.1854 Epoch: 21   Global Step: 43950   Required: 4 hours
Training: 2025-05-30 12:57:15,786-Speed 370.46 samples/sec   Loss 5.3430 Epoch: 21   Global Step: 44000   Required: 4 hours
Training: 2025-05-30 12:57:33,060-Speed 370.49 samples/sec   Loss 5.4785 Epoch: 21   Global Step: 44050   Required: 4 hours
Training: 2025-05-30 12:57:50,336-Speed 370.47 samples/sec   Loss 5.3204 Epoch: 21   Global Step: 44100   Required: 4 hours
Training: 2025-05-30 12:58:07,612-Speed 370.47 samples/sec   Loss 5.1144 Epoch: 21   Global Step: 44150   Required: 4 hours
Training: 2025-05-30 12:58:24,885-Speed 370.51 samples/sec   Loss 5.0509 Epoch: 21   Global Step: 44200   Required: 4 hours
Training: 2025-05-30 12:58:42,165-Speed 370.37 samples/sec   Loss 5.2412 Epoch: 21   Global Step: 44250   Required: 4 hours
Training: 2025-05-30 12:58:59,446-Speed 370.37 samples/sec   Loss 5.2259 Epoch: 21   Global Step: 44300   Required: 4 hours
Training: 2025-05-30 12:59:16,721-Speed 370.47 samples/sec   Loss 5.1637 Epoch: 21   Global Step: 44350   Required: 4 hours
Training: 2025-05-30 12:59:33,998-Speed 370.45 samples/sec   Loss 5.1810 Epoch: 21   Global Step: 44400   Required: 4 hours
Training: 2025-05-30 12:59:51,273-Speed 370.46 samples/sec   Loss 5.0998 Epoch: 21   Global Step: 44450   Required: 4 hours
Training: 2025-05-30 13:00:08,546-Speed 370.53 samples/sec   Loss 4.9602 Epoch: 21   Global Step: 44500   Required: 4 hours
Training: 2025-05-30 13:00:25,824-Speed 370.42 samples/sec   Loss 5.1920 Epoch: 21   Global Step: 44550   Required: 4 hours
Training: 2025-05-30 13:00:43,099-Speed 370.48 samples/sec   Loss 5.2430 Epoch: 21   Global Step: 44600   Required: 4 hours
Training: 2025-05-30 13:01:00,373-Speed 370.49 samples/sec   Loss 5.2508 Epoch: 21   Global Step: 44650   Required: 4 hours
Training: 2025-05-30 13:01:17,650-Speed 370.45 samples/sec   Loss 5.4106 Epoch: 21   Global Step: 44700   Required: 4 hours
Training: 2025-05-30 13:01:34,925-Speed 370.47 samples/sec   Loss 5.2143 Epoch: 21   Global Step: 44750   Required: 4 hours
Training: 2025-05-30 13:01:52,199-Speed 370.50 samples/sec   Loss 5.1545 Epoch: 21   Global Step: 44800   Required: 4 hours
Training: 2025-05-30 13:02:28,963-[lfw][44836]XNorm: 22.284751
Training: 2025-05-30 13:02:28,964-[lfw][44836]Accuracy-Flip: 0.99183+-0.00456
Training: 2025-05-30 13:02:28,964-[lfw][44836]Accuracy-Highest: 0.99183
Training: 2025-05-30 13:02:57,444-[cfp_fp][44836]XNorm: 19.618647
Training: 2025-05-30 13:02:57,444-[cfp_fp][44836]Accuracy-Flip: 0.93200+-0.00879
Training: 2025-05-30 13:02:57,444-[cfp_fp][44836]Accuracy-Highest: 0.93200
Training: 2025-05-30 13:03:21,787-[agedb_30][44836]XNorm: 21.861303
Training: 2025-05-30 13:03:21,787-[agedb_30][44836]Accuracy-Flip: 0.93117+-0.01204
Training: 2025-05-30 13:03:21,787-[agedb_30][44836]Accuracy-Highest: 0.93117
Training: 2025-05-30 13:03:46,206-[calfw][44836]XNorm: 21.990611
Training: 2025-05-30 13:03:46,206-[calfw][44836]Accuracy-Flip: 0.92650+-0.01214
Training: 2025-05-30 13:03:46,206-[calfw][44836]Accuracy-Highest: 0.92650
Training: 2025-05-30 13:04:10,668-[cplfw][44836]XNorm: 20.036519
Training: 2025-05-30 13:04:10,668-[cplfw][44836]Accuracy-Flip: 0.87483+-0.01786
Training: 2025-05-30 13:04:10,668-[cplfw][44836]Accuracy-Highest: 0.87483
Training: 2025-05-30 13:04:15,690-Speed 44.60 samples/sec   Loss 5.0802 Epoch: 22   Global Step: 44850   Required: 4 hours
Training: 2025-05-30 13:04:32,947-Speed 370.86 samples/sec   Loss 4.4971 Epoch: 22   Global Step: 44900   Required: 4 hours
Training: 2025-05-30 13:04:50,211-Speed 370.72 samples/sec   Loss 4.4213 Epoch: 22   Global Step: 44950   Required: 4 hours
Training: 2025-05-30 13:05:07,480-Speed 370.59 samples/sec   Loss 4.4674 Epoch: 22   Global Step: 45000   Required: 4 hours
Training: 2025-05-30 13:05:24,752-Speed 370.56 samples/sec   Loss 4.5619 Epoch: 22   Global Step: 45050   Required: 4 hours
Training: 2025-05-30 13:05:42,026-Speed 370.49 samples/sec   Loss 4.5662 Epoch: 22   Global Step: 45100   Required: 4 hours
Training: 2025-05-30 13:05:59,304-Speed 370.43 samples/sec   Loss 4.4817 Epoch: 22   Global Step: 45150   Required: 4 hours
Training: 2025-05-30 13:06:16,583-Speed 370.39 samples/sec   Loss 4.4667 Epoch: 22   Global Step: 45200   Required: 4 hours
Training: 2025-05-30 13:06:33,859-Speed 370.46 samples/sec   Loss 4.5681 Epoch: 22   Global Step: 45250   Required: 4 hours
Training: 2025-05-30 13:06:51,137-Speed 370.42 samples/sec   Loss 4.4592 Epoch: 22   Global Step: 45300   Required: 4 hours
Training: 2025-05-30 13:07:08,413-Speed 370.45 samples/sec   Loss 4.5532 Epoch: 22   Global Step: 45350   Required: 4 hours
Training: 2025-05-30 13:07:25,696-Speed 370.30 samples/sec   Loss 4.4991 Epoch: 22   Global Step: 45400   Required: 4 hours
Training: 2025-05-30 13:07:42,978-Speed 370.34 samples/sec   Loss 4.3838 Epoch: 22   Global Step: 45450   Required: 4 hours
Training: 2025-05-30 13:08:00,261-Speed 370.31 samples/sec   Loss 4.5542 Epoch: 22   Global Step: 45500   Required: 4 hours
Training: 2025-05-30 13:08:17,542-Speed 370.33 samples/sec   Loss 4.5215 Epoch: 22   Global Step: 45550   Required: 4 hours
Training: 2025-05-30 13:08:34,825-Speed 370.33 samples/sec   Loss 4.4680 Epoch: 22   Global Step: 45600   Required: 4 hours
Training: 2025-05-30 13:08:52,102-Speed 370.42 samples/sec   Loss 4.4749 Epoch: 22   Global Step: 45650   Required: 4 hours
Training: 2025-05-30 13:09:09,381-Speed 370.39 samples/sec   Loss 4.4808 Epoch: 22   Global Step: 45700   Required: 4 hours
Training: 2025-05-30 13:09:26,661-Speed 370.37 samples/sec   Loss 4.5715 Epoch: 22   Global Step: 45750   Required: 4 hours
Training: 2025-05-30 13:09:43,945-Speed 370.29 samples/sec   Loss 4.4551 Epoch: 22   Global Step: 45800   Required: 4 hours
Training: 2025-05-30 13:10:01,224-Speed 370.41 samples/sec   Loss 4.6658 Epoch: 22   Global Step: 45850   Required: 4 hours
Training: 2025-05-30 13:10:18,503-Speed 370.40 samples/sec   Loss 4.3707 Epoch: 22   Global Step: 45900   Required: 4 hours
Training: 2025-05-30 13:10:35,780-Speed 370.42 samples/sec   Loss 4.3412 Epoch: 22   Global Step: 45950   Required: 4 hours
Training: 2025-05-30 13:10:53,056-Speed 370.47 samples/sec   Loss 4.4760 Epoch: 22   Global Step: 46000   Required: 4 hours
Training: 2025-05-30 13:11:10,332-Speed 370.45 samples/sec   Loss 4.4480 Epoch: 22   Global Step: 46050   Required: 4 hours
Training: 2025-05-30 13:11:27,610-Speed 370.42 samples/sec   Loss 4.3077 Epoch: 22   Global Step: 46100   Required: 4 hours
Training: 2025-05-30 13:11:44,884-Speed 370.51 samples/sec   Loss 4.3212 Epoch: 22   Global Step: 46150   Required: 4 hours
Training: 2025-05-30 13:12:02,158-Speed 370.50 samples/sec   Loss 4.7086 Epoch: 22   Global Step: 46200   Required: 4 hours
Training: 2025-05-30 13:12:19,434-Speed 370.46 samples/sec   Loss 4.4771 Epoch: 22   Global Step: 46250   Required: 4 hours
Training: 2025-05-30 13:12:36,708-Speed 370.50 samples/sec   Loss 4.5124 Epoch: 22   Global Step: 46300   Required: 4 hours
Training: 2025-05-30 13:12:53,984-Speed 370.45 samples/sec   Loss 4.5608 Epoch: 22   Global Step: 46350   Required: 4 hours
Training: 2025-05-30 13:13:11,263-Speed 370.40 samples/sec   Loss 4.6209 Epoch: 22   Global Step: 46400   Required: 4 hours
Training: 2025-05-30 13:13:28,538-Speed 370.47 samples/sec   Loss 4.4999 Epoch: 22   Global Step: 46450   Required: 4 hours
Training: 2025-05-30 13:13:45,817-Speed 370.40 samples/sec   Loss 4.5702 Epoch: 22   Global Step: 46500   Required: 4 hours
Training: 2025-05-30 13:14:03,098-Speed 370.36 samples/sec   Loss 4.4736 Epoch: 22   Global Step: 46550   Required: 4 hours
Training: 2025-05-30 13:14:20,379-Speed 370.36 samples/sec   Loss 4.3892 Epoch: 22   Global Step: 46600   Required: 4 hours
Training: 2025-05-30 13:14:37,656-Speed 370.43 samples/sec   Loss 4.1798 Epoch: 22   Global Step: 46650   Required: 4 hours
Training: 2025-05-30 13:14:54,934-Speed 370.41 samples/sec   Loss 4.4384 Epoch: 22   Global Step: 46700   Required: 4 hours
Training: 2025-05-30 13:15:12,213-Speed 370.40 samples/sec   Loss 4.5845 Epoch: 22   Global Step: 46750   Required: 4 hours
Training: 2025-05-30 13:15:29,493-Speed 370.38 samples/sec   Loss 4.4554 Epoch: 22   Global Step: 46800   Required: 4 hours
Training: 2025-05-30 13:15:46,770-Speed 370.42 samples/sec   Loss 4.4566 Epoch: 22   Global Step: 46850   Required: 4 hours
Training: 2025-05-30 13:16:19,376-[lfw][46874]XNorm: 21.949963
Training: 2025-05-30 13:16:19,376-[lfw][46874]Accuracy-Flip: 0.99250+-0.00518
Training: 2025-05-30 13:16:19,376-[lfw][46874]Accuracy-Highest: 0.99250
Training: 2025-05-30 13:16:47,654-[cfp_fp][46874]XNorm: 19.470569
Training: 2025-05-30 13:16:47,654-[cfp_fp][46874]Accuracy-Flip: 0.93186+-0.01026
Training: 2025-05-30 13:16:47,654-[cfp_fp][46874]Accuracy-Highest: 0.93200
Training: 2025-05-30 13:17:11,962-[agedb_30][46874]XNorm: 21.507574
Training: 2025-05-30 13:17:11,962-[agedb_30][46874]Accuracy-Flip: 0.92983+-0.01421
Training: 2025-05-30 13:17:11,962-[agedb_30][46874]Accuracy-Highest: 0.93117
Training: 2025-05-30 13:17:36,354-[calfw][46874]XNorm: 21.494241
Training: 2025-05-30 13:17:36,354-[calfw][46874]Accuracy-Flip: 0.93117+-0.01096
Training: 2025-05-30 13:17:36,354-[calfw][46874]Accuracy-Highest: 0.93117
Training: 2025-05-30 13:18:00,821-[cplfw][46874]XNorm: 20.023434
Training: 2025-05-30 13:18:00,822-[cplfw][46874]Accuracy-Flip: 0.87517+-0.01794
Training: 2025-05-30 13:18:00,822-[cplfw][46874]Accuracy-Highest: 0.87517
Training: 2025-05-30 13:18:09,952-Speed 44.70 samples/sec   Loss 3.9971 Epoch: 23   Global Step: 46900   Required: 4 hours
Training: 2025-05-30 13:18:27,216-Speed 370.71 samples/sec   Loss 3.8307 Epoch: 23   Global Step: 46950   Required: 4 hours
Training: 2025-05-30 13:18:44,482-Speed 370.68 samples/sec   Loss 3.8677 Epoch: 23   Global Step: 47000   Required: 4 hours
Training: 2025-05-30 13:19:01,753-Speed 370.57 samples/sec   Loss 3.8265 Epoch: 23   Global Step: 47050   Required: 4 hours
Training: 2025-05-30 13:19:19,028-Speed 370.47 samples/sec   Loss 3.8414 Epoch: 23   Global Step: 47100   Required: 4 hours
Training: 2025-05-30 13:19:36,304-Speed 370.45 samples/sec   Loss 3.7711 Epoch: 23   Global Step: 47150   Required: 4 hours
Training: 2025-05-30 13:19:53,584-Speed 370.38 samples/sec   Loss 3.9226 Epoch: 23   Global Step: 47200   Required: 4 hours
Training: 2025-05-30 13:20:10,864-Speed 370.38 samples/sec   Loss 3.9599 Epoch: 23   Global Step: 47250   Required: 4 hours
Training: 2025-05-30 13:20:28,146-Speed 370.33 samples/sec   Loss 4.0150 Epoch: 23   Global Step: 47300   Required: 4 hours
Training: 2025-05-30 13:20:45,428-Speed 370.32 samples/sec   Loss 4.0237 Epoch: 23   Global Step: 47350   Required: 4 hours
Training: 2025-05-30 13:21:02,709-Speed 370.35 samples/sec   Loss 3.7882 Epoch: 23   Global Step: 47400   Required: 4 hours
Training: 2025-05-30 13:21:19,989-Speed 370.38 samples/sec   Loss 3.8798 Epoch: 23   Global Step: 47450   Required: 4 hours
Training: 2025-05-30 13:21:37,272-Speed 370.31 samples/sec   Loss 4.0433 Epoch: 23   Global Step: 47500   Required: 4 hours
Training: 2025-05-30 13:21:54,555-Speed 370.30 samples/sec   Loss 4.0610 Epoch: 23   Global Step: 47550   Required: 4 hours
Training: 2025-05-30 13:22:11,843-Speed 370.22 samples/sec   Loss 3.9949 Epoch: 23   Global Step: 47600   Required: 4 hours
Training: 2025-05-30 13:22:29,129-Speed 370.24 samples/sec   Loss 3.9498 Epoch: 23   Global Step: 47650   Required: 4 hours
Training: 2025-05-30 13:22:46,416-Speed 370.23 samples/sec   Loss 4.1023 Epoch: 23   Global Step: 47700   Required: 4 hours
Training: 2025-05-30 13:23:03,705-Speed 370.17 samples/sec   Loss 4.1285 Epoch: 23   Global Step: 47750   Required: 4 hours
Training: 2025-05-30 13:23:20,989-Speed 370.28 samples/sec   Loss 4.0483 Epoch: 23   Global Step: 47800   Required: 4 hours
Training: 2025-05-30 13:23:38,272-Speed 370.33 samples/sec   Loss 3.8143 Epoch: 23   Global Step: 47850   Required: 4 hours
Training: 2025-05-30 13:23:55,554-Speed 370.32 samples/sec   Loss 3.8665 Epoch: 23   Global Step: 47900   Required: 4 hours
Training: 2025-05-30 13:24:12,832-Speed 370.41 samples/sec   Loss 4.0628 Epoch: 23   Global Step: 47950   Required: 4 hours
Training: 2025-05-30 13:24:30,106-Speed 370.51 samples/sec   Loss 3.8862 Epoch: 23   Global Step: 48000   Required: 4 hours
Training: 2025-05-30 13:24:47,380-Speed 370.50 samples/sec   Loss 3.9595 Epoch: 23   Global Step: 48050   Required: 4 hours
Training: 2025-05-30 13:25:04,653-Speed 370.52 samples/sec   Loss 3.8476 Epoch: 23   Global Step: 48100   Required: 4 hours
Training: 2025-05-30 13:25:21,926-Speed 370.53 samples/sec   Loss 3.9868 Epoch: 23   Global Step: 48150   Required: 4 hours
Training: 2025-05-30 13:25:39,199-Speed 370.52 samples/sec   Loss 4.1318 Epoch: 23   Global Step: 48200   Required: 4 hours
Training: 2025-05-30 13:25:56,474-Speed 370.47 samples/sec   Loss 4.0234 Epoch: 23   Global Step: 48250   Required: 4 hours
Training: 2025-05-30 13:26:13,746-Speed 370.54 samples/sec   Loss 3.9595 Epoch: 23   Global Step: 48300   Required: 4 hours
Training: 2025-05-30 13:26:31,020-Speed 370.51 samples/sec   Loss 3.8228 Epoch: 23   Global Step: 48350   Required: 4 hours
Training: 2025-05-30 13:26:48,296-Speed 370.44 samples/sec   Loss 4.0517 Epoch: 23   Global Step: 48400   Required: 4 hours
Training: 2025-05-30 13:27:05,575-Speed 370.41 samples/sec   Loss 4.0942 Epoch: 23   Global Step: 48450   Required: 4 hours
Training: 2025-05-30 13:27:22,853-Speed 370.41 samples/sec   Loss 3.8506 Epoch: 23   Global Step: 48500   Required: 4 hours
Training: 2025-05-30 13:27:40,131-Speed 370.42 samples/sec   Loss 3.9441 Epoch: 23   Global Step: 48550   Required: 4 hours
Training: 2025-05-30 13:27:57,413-Speed 370.32 samples/sec   Loss 3.9045 Epoch: 23   Global Step: 48600   Required: 4 hours
Training: 2025-05-30 13:28:14,686-Speed 370.53 samples/sec   Loss 4.0258 Epoch: 23   Global Step: 48650   Required: 4 hours
Training: 2025-05-30 13:28:31,959-Speed 370.52 samples/sec   Loss 4.0198 Epoch: 23   Global Step: 48700   Required: 4 hours
Training: 2025-05-30 13:28:49,234-Speed 370.48 samples/sec   Loss 4.0614 Epoch: 23   Global Step: 48750   Required: 4 hours
Training: 2025-05-30 13:29:06,509-Speed 370.50 samples/sec   Loss 4.0047 Epoch: 23   Global Step: 48800   Required: 4 hours
Training: 2025-05-30 13:29:23,782-Speed 370.51 samples/sec   Loss 3.9319 Epoch: 23   Global Step: 48850   Required: 4 hours
Training: 2025-05-30 13:29:41,054-Speed 370.55 samples/sec   Loss 3.9989 Epoch: 23   Global Step: 48900   Required: 4 hours
Training: 2025-05-30 13:30:09,508-[lfw][48912]XNorm: 21.252720
Training: 2025-05-30 13:30:09,508-[lfw][48912]Accuracy-Flip: 0.99350+-0.00411
Training: 2025-05-30 13:30:09,508-[lfw][48912]Accuracy-Highest: 0.99350
Training: 2025-05-30 13:30:37,755-[cfp_fp][48912]XNorm: 18.768068
Training: 2025-05-30 13:30:37,756-[cfp_fp][48912]Accuracy-Flip: 0.92957+-0.01311
Training: 2025-05-30 13:30:37,756-[cfp_fp][48912]Accuracy-Highest: 0.93200
Training: 2025-05-30 13:31:02,066-[agedb_30][48912]XNorm: 20.960175
Training: 2025-05-30 13:31:02,066-[agedb_30][48912]Accuracy-Flip: 0.93067+-0.01330
Training: 2025-05-30 13:31:02,066-[agedb_30][48912]Accuracy-Highest: 0.93117
Training: 2025-05-30 13:31:26,476-[calfw][48912]XNorm: 20.801329
Training: 2025-05-30 13:31:26,476-[calfw][48912]Accuracy-Flip: 0.92967+-0.01122
Training: 2025-05-30 13:31:26,476-[calfw][48912]Accuracy-Highest: 0.93117
Training: 2025-05-30 13:31:50,862-[cplfw][48912]XNorm: 19.375153
Training: 2025-05-30 13:31:50,862-[cplfw][48912]Accuracy-Flip: 0.87700+-0.01856
Training: 2025-05-30 13:31:50,862-[cplfw][48912]Accuracy-Highest: 0.87700
Training: 2025-05-30 13:32:04,150-Speed 44.73 samples/sec   Loss 3.4990 Epoch: 24   Global Step: 48950   Required: 4 hours
Training: 2025-05-30 13:32:21,414-Speed 370.72 samples/sec   Loss 3.5255 Epoch: 24   Global Step: 49000   Required: 4 hours
Training: 2025-05-30 13:32:38,687-Speed 370.52 samples/sec   Loss 3.2838 Epoch: 24   Global Step: 49050   Required: 4 hours
Training: 2025-05-30 13:32:55,964-Speed 370.44 samples/sec   Loss 3.1847 Epoch: 24   Global Step: 49100   Required: 4 hours
Training: 2025-05-30 13:33:13,244-Speed 370.38 samples/sec   Loss 3.3969 Epoch: 24   Global Step: 49150   Required: 4 hours
Training: 2025-05-30 13:33:30,520-Speed 370.46 samples/sec   Loss 3.4223 Epoch: 24   Global Step: 49200   Required: 4 hours
Training: 2025-05-30 13:33:47,802-Speed 370.32 samples/sec   Loss 3.2748 Epoch: 24   Global Step: 49250   Required: 4 hours
Training: 2025-05-30 13:34:05,083-Speed 370.34 samples/sec   Loss 3.4241 Epoch: 24   Global Step: 49300   Required: 4 hours
Training: 2025-05-30 13:34:22,366-Speed 370.33 samples/sec   Loss 3.5619 Epoch: 24   Global Step: 49350   Required: 4 hours
Training: 2025-05-30 13:34:39,648-Speed 370.33 samples/sec   Loss 3.4538 Epoch: 24   Global Step: 49400   Required: 4 hours
Training: 2025-05-30 13:34:56,933-Speed 370.25 samples/sec   Loss 3.5748 Epoch: 24   Global Step: 49450   Required: 4 hours
Training: 2025-05-30 13:35:14,223-Speed 370.17 samples/sec   Loss 3.4758 Epoch: 24   Global Step: 49500   Required: 4 hours
Training: 2025-05-30 13:35:31,512-Speed 370.19 samples/sec   Loss 3.5363 Epoch: 24   Global Step: 49550   Required: 4 hours
Training: 2025-05-30 13:35:48,797-Speed 370.26 samples/sec   Loss 3.5092 Epoch: 24   Global Step: 49600   Required: 4 hours
Training: 2025-05-30 13:36:06,077-Speed 370.36 samples/sec   Loss 3.3575 Epoch: 24   Global Step: 49650   Required: 4 hours
Training: 2025-05-30 13:36:23,358-Speed 370.35 samples/sec   Loss 3.4886 Epoch: 24   Global Step: 49700   Required: 4 hours
Training: 2025-05-30 13:36:40,643-Speed 370.27 samples/sec   Loss 3.5224 Epoch: 24   Global Step: 49750   Required: 4 hours
Training: 2025-05-30 13:36:57,926-Speed 370.30 samples/sec   Loss 3.5464 Epoch: 24   Global Step: 49800   Required: 4 hours
Training: 2025-05-30 13:37:15,214-Speed 370.21 samples/sec   Loss 3.4723 Epoch: 24   Global Step: 49850   Required: 4 hours
Training: 2025-05-30 13:37:32,499-Speed 370.27 samples/sec   Loss 3.4194 Epoch: 24   Global Step: 49900   Required: 4 hours
Training: 2025-05-30 13:37:49,783-Speed 370.28 samples/sec   Loss 3.4486 Epoch: 24   Global Step: 49950   Required: 4 hours
Training: 2025-05-30 13:38:07,066-Speed 370.30 samples/sec   Loss 3.5720 Epoch: 24   Global Step: 50000   Required: 4 hours
Training: 2025-05-30 13:38:24,351-Speed 370.27 samples/sec   Loss 3.6705 Epoch: 24   Global Step: 50050   Required: 4 hours
Training: 2025-05-30 13:38:41,632-Speed 370.35 samples/sec   Loss 3.5523 Epoch: 24   Global Step: 50100   Required: 4 hours
Training: 2025-05-30 13:38:58,914-Speed 370.34 samples/sec   Loss 3.6754 Epoch: 24   Global Step: 50150   Required: 4 hours
Training: 2025-05-30 13:39:16,196-Speed 370.34 samples/sec   Loss 3.4130 Epoch: 24   Global Step: 50200   Required: 4 hours
Training: 2025-05-30 13:39:33,479-Speed 370.30 samples/sec   Loss 3.5792 Epoch: 24   Global Step: 50250   Required: 4 hours
Training: 2025-05-30 13:39:50,764-Speed 370.28 samples/sec   Loss 3.7021 Epoch: 24   Global Step: 50300   Required: 4 hours
Training: 2025-05-30 13:40:08,046-Speed 370.31 samples/sec   Loss 3.5868 Epoch: 24   Global Step: 50350   Required: 4 hours
Training: 2025-05-30 13:40:25,329-Speed 370.31 samples/sec   Loss 3.4813 Epoch: 24   Global Step: 50400   Required: 4 hours
Training: 2025-05-30 13:40:42,610-Speed 370.36 samples/sec   Loss 3.5679 Epoch: 24   Global Step: 50450   Required: 4 hours
Training: 2025-05-30 13:40:59,888-Speed 370.40 samples/sec   Loss 3.6488 Epoch: 24   Global Step: 50500   Required: 3 hours
Training: 2025-05-30 13:41:17,166-Speed 370.42 samples/sec   Loss 3.8090 Epoch: 24   Global Step: 50550   Required: 3 hours
Training: 2025-05-30 13:41:34,445-Speed 370.39 samples/sec   Loss 3.5511 Epoch: 24   Global Step: 50600   Required: 3 hours
Training: 2025-05-30 13:41:51,724-Speed 370.39 samples/sec   Loss 3.5743 Epoch: 24   Global Step: 50650   Required: 3 hours
Training: 2025-05-30 13:42:09,006-Speed 370.34 samples/sec   Loss 3.6705 Epoch: 24   Global Step: 50700   Required: 3 hours
Training: 2025-05-30 13:42:26,287-Speed 370.36 samples/sec   Loss 3.8786 Epoch: 24   Global Step: 50750   Required: 3 hours
Training: 2025-05-30 13:42:43,566-Speed 370.38 samples/sec   Loss 3.5767 Epoch: 24   Global Step: 50800   Required: 3 hours
Training: 2025-05-30 13:43:00,848-Speed 370.33 samples/sec   Loss 3.8629 Epoch: 24   Global Step: 50850   Required: 3 hours
Training: 2025-05-30 13:43:18,130-Speed 370.34 samples/sec   Loss 3.7037 Epoch: 24   Global Step: 50900   Required: 3 hours
Training: 2025-05-30 13:43:35,409-Speed 370.38 samples/sec   Loss 3.7145 Epoch: 24   Global Step: 50950   Required: 3 hours
Training: 2025-05-30 13:43:59,735-[lfw][50950]XNorm: 22.028063
Training: 2025-05-30 13:43:59,735-[lfw][50950]Accuracy-Flip: 0.99283+-0.00422
Training: 2025-05-30 13:43:59,735-[lfw][50950]Accuracy-Highest: 0.99350
Training: 2025-05-30 13:44:28,007-[cfp_fp][50950]XNorm: 19.727306
Training: 2025-05-30 13:44:28,008-[cfp_fp][50950]Accuracy-Flip: 0.93357+-0.01308
Training: 2025-05-30 13:44:28,008-[cfp_fp][50950]Accuracy-Highest: 0.93357
Training: 2025-05-30 13:44:52,307-[agedb_30][50950]XNorm: 21.773659
Training: 2025-05-30 13:44:52,307-[agedb_30][50950]Accuracy-Flip: 0.92983+-0.01375
Training: 2025-05-30 13:44:52,307-[agedb_30][50950]Accuracy-Highest: 0.93117
Training: 2025-05-30 13:45:16,699-[calfw][50950]XNorm: 21.560072
Training: 2025-05-30 13:45:16,699-[calfw][50950]Accuracy-Flip: 0.92717+-0.01093
Training: 2025-05-30 13:45:16,699-[calfw][50950]Accuracy-Highest: 0.93117
Training: 2025-05-30 13:45:41,074-[cplfw][50950]XNorm: 20.389447
Training: 2025-05-30 13:45:41,074-[cplfw][50950]Accuracy-Flip: 0.87600+-0.01535
Training: 2025-05-30 13:45:41,074-[cplfw][50950]Accuracy-Highest: 0.87700
Training: 2025-05-30 13:45:58,484-Speed 44.73 samples/sec   Loss 3.1464 Epoch: 25   Global Step: 51000   Required: 3 hours
Training: 2025-05-30 13:46:15,758-Speed 370.50 samples/sec   Loss 2.9478 Epoch: 25   Global Step: 51050   Required: 3 hours
Training: 2025-05-30 13:46:33,040-Speed 370.33 samples/sec   Loss 2.9113 Epoch: 25   Global Step: 51100   Required: 3 hours
Training: 2025-05-30 13:46:50,324-Speed 370.30 samples/sec   Loss 3.0948 Epoch: 25   Global Step: 51150   Required: 3 hours
Training: 2025-05-30 13:47:07,608-Speed 370.28 samples/sec   Loss 3.0114 Epoch: 25   Global Step: 51200   Required: 3 hours
Training: 2025-05-30 13:47:24,892-Speed 370.29 samples/sec   Loss 3.1667 Epoch: 25   Global Step: 51250   Required: 3 hours
Training: 2025-05-30 13:47:42,176-Speed 370.30 samples/sec   Loss 3.1544 Epoch: 25   Global Step: 51300   Required: 3 hours
Training: 2025-05-30 13:47:59,462-Speed 370.24 samples/sec   Loss 3.0754 Epoch: 25   Global Step: 51350   Required: 3 hours
Training: 2025-05-30 13:48:16,743-Speed 370.34 samples/sec   Loss 3.2003 Epoch: 25   Global Step: 51400   Required: 3 hours
Training: 2025-05-30 13:48:34,030-Speed 370.23 samples/sec   Loss 2.9914 Epoch: 25   Global Step: 51450   Required: 3 hours
Training: 2025-05-30 13:48:51,317-Speed 370.22 samples/sec   Loss 3.2178 Epoch: 25   Global Step: 51500   Required: 3 hours
Training: 2025-05-30 13:49:08,603-Speed 370.26 samples/sec   Loss 2.9808 Epoch: 25   Global Step: 51550   Required: 3 hours
Training: 2025-05-30 13:49:25,888-Speed 370.26 samples/sec   Loss 3.1366 Epoch: 25   Global Step: 51600   Required: 3 hours
Training: 2025-05-30 13:49:43,171-Speed 370.30 samples/sec   Loss 3.0974 Epoch: 25   Global Step: 51650   Required: 3 hours
Training: 2025-05-30 13:50:00,458-Speed 370.22 samples/sec   Loss 3.1000 Epoch: 25   Global Step: 51700   Required: 3 hours
Training: 2025-05-30 13:50:17,747-Speed 370.18 samples/sec   Loss 3.3731 Epoch: 25   Global Step: 51750   Required: 3 hours
Training: 2025-05-30 13:50:35,030-Speed 370.32 samples/sec   Loss 3.1911 Epoch: 25   Global Step: 51800   Required: 3 hours
Training: 2025-05-30 13:50:52,318-Speed 370.20 samples/sec   Loss 3.1893 Epoch: 25   Global Step: 51850   Required: 3 hours
Training: 2025-05-30 13:51:09,603-Speed 370.25 samples/sec   Loss 3.0863 Epoch: 25   Global Step: 51900   Required: 3 hours
Training: 2025-05-30 13:51:26,885-Speed 370.34 samples/sec   Loss 3.2363 Epoch: 25   Global Step: 51950   Required: 3 hours
Training: 2025-05-30 13:51:44,167-Speed 370.34 samples/sec   Loss 3.2433 Epoch: 25   Global Step: 52000   Required: 3 hours
Training: 2025-05-30 13:52:01,448-Speed 370.35 samples/sec   Loss 3.1165 Epoch: 25   Global Step: 52050   Required: 3 hours
Training: 2025-05-30 13:52:18,734-Speed 370.24 samples/sec   Loss 3.3570 Epoch: 25   Global Step: 52100   Required: 3 hours
Training: 2025-05-30 13:52:36,020-Speed 370.23 samples/sec   Loss 3.2014 Epoch: 25   Global Step: 52150   Required: 3 hours
Training: 2025-05-30 13:52:53,305-Speed 370.27 samples/sec   Loss 3.2878 Epoch: 25   Global Step: 52200   Required: 3 hours
Training: 2025-05-30 13:53:10,589-Speed 370.31 samples/sec   Loss 3.4033 Epoch: 25   Global Step: 52250   Required: 3 hours
Training: 2025-05-30 13:53:27,875-Speed 370.23 samples/sec   Loss 3.2850 Epoch: 25   Global Step: 52300   Required: 3 hours
Training: 2025-05-30 13:53:45,158-Speed 370.30 samples/sec   Loss 3.3664 Epoch: 25   Global Step: 52350   Required: 3 hours
Training: 2025-05-30 13:54:02,442-Speed 370.30 samples/sec   Loss 3.4197 Epoch: 25   Global Step: 52400   Required: 3 hours
Training: 2025-05-30 13:54:19,729-Speed 370.21 samples/sec   Loss 3.2562 Epoch: 25   Global Step: 52450   Required: 3 hours
Training: 2025-05-30 13:54:37,014-Speed 370.28 samples/sec   Loss 3.0740 Epoch: 25   Global Step: 52500   Required: 3 hours
Training: 2025-05-30 13:54:54,296-Speed 370.32 samples/sec   Loss 3.2262 Epoch: 25   Global Step: 52550   Required: 3 hours
Training: 2025-05-30 13:55:11,577-Speed 370.35 samples/sec   Loss 3.2651 Epoch: 25   Global Step: 52600   Required: 3 hours
Training: 2025-05-30 13:55:28,863-Speed 370.24 samples/sec   Loss 3.2960 Epoch: 25   Global Step: 52650   Required: 3 hours
Training: 2025-05-30 13:55:46,153-Speed 370.16 samples/sec   Loss 3.4104 Epoch: 25   Global Step: 52700   Required: 3 hours
Training: 2025-05-30 13:56:03,440-Speed 370.22 samples/sec   Loss 3.3119 Epoch: 25   Global Step: 52750   Required: 3 hours
Training: 2025-05-30 13:56:20,726-Speed 370.25 samples/sec   Loss 3.2048 Epoch: 25   Global Step: 52800   Required: 3 hours
Training: 2025-05-30 13:56:38,009-Speed 370.31 samples/sec   Loss 3.3146 Epoch: 25   Global Step: 52850   Required: 3 hours
Training: 2025-05-30 13:56:55,297-Speed 370.21 samples/sec   Loss 3.3953 Epoch: 25   Global Step: 52900   Required: 3 hours
Training: 2025-05-30 13:57:12,582-Speed 370.27 samples/sec   Loss 3.3454 Epoch: 25   Global Step: 52950   Required: 3 hours
Training: 2025-05-30 13:57:50,044-[lfw][52988]XNorm: 21.805579
Training: 2025-05-30 13:57:50,044-[lfw][52988]Accuracy-Flip: 0.99083+-0.00579
Training: 2025-05-30 13:57:50,044-[lfw][52988]Accuracy-Highest: 0.99350
Training: 2025-05-30 13:58:18,426-[cfp_fp][52988]XNorm: 19.484943
Training: 2025-05-30 13:58:18,426-[cfp_fp][52988]Accuracy-Flip: 0.92929+-0.01118
Training: 2025-05-30 13:58:18,426-[cfp_fp][52988]Accuracy-Highest: 0.93357
Training: 2025-05-30 13:58:42,750-[agedb_30][52988]XNorm: 21.590020
Training: 2025-05-30 13:58:42,751-[agedb_30][52988]Accuracy-Flip: 0.93050+-0.01528
Training: 2025-05-30 13:58:42,751-[agedb_30][52988]Accuracy-Highest: 0.93117
Training: 2025-05-30 13:59:07,159-[calfw][52988]XNorm: 21.348555
Training: 2025-05-30 13:59:07,159-[calfw][52988]Accuracy-Flip: 0.92900+-0.00961
Training: 2025-05-30 13:59:07,159-[calfw][52988]Accuracy-Highest: 0.93117
Training: 2025-05-30 13:59:31,552-[cplfw][52988]XNorm: 20.104941
Training: 2025-05-30 13:59:31,552-[cplfw][52988]Accuracy-Flip: 0.86933+-0.01718
Training: 2025-05-30 13:59:31,552-[cplfw][52988]Accuracy-Highest: 0.87700
Training: 2025-05-30 13:59:35,865-Speed 44.67 samples/sec   Loss 3.1326 Epoch: 26   Global Step: 53000   Required: 3 hours
Training: 2025-05-30 13:59:53,140-Speed 370.48 samples/sec   Loss 2.7110 Epoch: 26   Global Step: 53050   Required: 3 hours
Training: 2025-05-30 14:00:10,417-Speed 370.44 samples/sec   Loss 2.6892 Epoch: 26   Global Step: 53100   Required: 3 hours
Training: 2025-05-30 14:00:27,699-Speed 370.34 samples/sec   Loss 2.8034 Epoch: 26   Global Step: 53150   Required: 3 hours
Training: 2025-05-30 14:00:44,982-Speed 370.30 samples/sec   Loss 2.7927 Epoch: 26   Global Step: 53200   Required: 3 hours
Training: 2025-05-30 14:01:02,271-Speed 370.18 samples/sec   Loss 2.8192 Epoch: 26   Global Step: 53250   Required: 3 hours
Training: 2025-05-30 14:01:19,560-Speed 370.19 samples/sec   Loss 2.6563 Epoch: 26   Global Step: 53300   Required: 3 hours
Training: 2025-05-30 14:01:36,849-Speed 370.17 samples/sec   Loss 2.8987 Epoch: 26   Global Step: 53350   Required: 3 hours
Training: 2025-05-30 14:01:54,138-Speed 370.19 samples/sec   Loss 3.0317 Epoch: 26   Global Step: 53400   Required: 3 hours
Training: 2025-05-30 14:02:11,426-Speed 370.20 samples/sec   Loss 2.7890 Epoch: 26   Global Step: 53450   Required: 3 hours
Training: 2025-05-30 14:02:28,716-Speed 370.15 samples/sec   Loss 2.8192 Epoch: 26   Global Step: 53500   Required: 3 hours
Training: 2025-05-30 14:02:46,002-Speed 370.25 samples/sec   Loss 3.0066 Epoch: 26   Global Step: 53550   Required: 3 hours
Training: 2025-05-30 14:03:03,284-Speed 370.33 samples/sec   Loss 2.8143 Epoch: 26   Global Step: 53600   Required: 3 hours
Training: 2025-05-30 14:03:20,570-Speed 370.25 samples/sec   Loss 2.8536 Epoch: 26   Global Step: 53650   Required: 3 hours
Training: 2025-05-30 14:03:37,860-Speed 370.15 samples/sec   Loss 2.7850 Epoch: 26   Global Step: 53700   Required: 3 hours
Training: 2025-05-30 14:03:55,146-Speed 370.25 samples/sec   Loss 2.8702 Epoch: 26   Global Step: 53750   Required: 3 hours
Training: 2025-05-30 14:04:12,434-Speed 370.19 samples/sec   Loss 3.0515 Epoch: 26   Global Step: 53800   Required: 3 hours
Training: 2025-05-30 14:04:29,724-Speed 370.16 samples/sec   Loss 3.0187 Epoch: 26   Global Step: 53850   Required: 3 hours
Training: 2025-05-30 14:04:47,016-Speed 370.12 samples/sec   Loss 2.8967 Epoch: 26   Global Step: 53900   Required: 3 hours
Training: 2025-05-30 14:05:04,303-Speed 370.23 samples/sec   Loss 2.9863 Epoch: 26   Global Step: 53950   Required: 3 hours
Training: 2025-05-30 14:05:21,592-Speed 370.17 samples/sec   Loss 2.9824 Epoch: 26   Global Step: 54000   Required: 3 hours
Training: 2025-05-30 14:05:38,878-Speed 370.24 samples/sec   Loss 2.8594 Epoch: 26   Global Step: 54050   Required: 3 hours
Training: 2025-05-30 14:05:56,166-Speed 370.21 samples/sec   Loss 2.7627 Epoch: 26   Global Step: 54100   Required: 3 hours
Training: 2025-05-30 14:06:13,459-Speed 370.10 samples/sec   Loss 2.9575 Epoch: 26   Global Step: 54150   Required: 3 hours
Training: 2025-05-30 14:06:30,748-Speed 370.17 samples/sec   Loss 2.8143 Epoch: 26   Global Step: 54200   Required: 3 hours
Training: 2025-05-30 14:06:48,038-Speed 370.17 samples/sec   Loss 3.0436 Epoch: 26   Global Step: 54250   Required: 3 hours
Training: 2025-05-30 14:07:05,326-Speed 370.19 samples/sec   Loss 3.0552 Epoch: 26   Global Step: 54300   Required: 3 hours
Training: 2025-05-30 14:07:22,620-Speed 370.08 samples/sec   Loss 2.9921 Epoch: 26   Global Step: 54350   Required: 3 hours
Training: 2025-05-30 14:07:39,912-Speed 370.10 samples/sec   Loss 2.8341 Epoch: 26   Global Step: 54400   Required: 3 hours
Training: 2025-05-30 14:07:57,203-Speed 370.14 samples/sec   Loss 2.9011 Epoch: 26   Global Step: 54450   Required: 3 hours
Training: 2025-05-30 14:08:14,492-Speed 370.18 samples/sec   Loss 3.0354 Epoch: 26   Global Step: 54500   Required: 3 hours
Training: 2025-05-30 14:08:31,782-Speed 370.16 samples/sec   Loss 3.0624 Epoch: 26   Global Step: 54550   Required: 3 hours
Training: 2025-05-30 14:08:49,066-Speed 370.28 samples/sec   Loss 2.8299 Epoch: 26   Global Step: 54600   Required: 3 hours
Training: 2025-05-30 14:09:06,353-Speed 370.23 samples/sec   Loss 3.1835 Epoch: 26   Global Step: 54650   Required: 3 hours
Training: 2025-05-30 14:09:23,641-Speed 370.20 samples/sec   Loss 3.0437 Epoch: 26   Global Step: 54700   Required: 3 hours
Training: 2025-05-30 14:09:40,929-Speed 370.20 samples/sec   Loss 2.9544 Epoch: 26   Global Step: 54750   Required: 3 hours
Training: 2025-05-30 14:09:58,214-Speed 370.27 samples/sec   Loss 2.8467 Epoch: 26   Global Step: 54800   Required: 3 hours
Training: 2025-05-30 14:10:15,496-Speed 370.33 samples/sec   Loss 3.0112 Epoch: 26   Global Step: 54850   Required: 3 hours
Training: 2025-05-30 14:10:32,783-Speed 370.21 samples/sec   Loss 3.0332 Epoch: 26   Global Step: 54900   Required: 3 hours
Training: 2025-05-30 14:10:50,069-Speed 370.26 samples/sec   Loss 3.0169 Epoch: 26   Global Step: 54950   Required: 3 hours
Training: 2025-05-30 14:11:07,355-Speed 370.23 samples/sec   Loss 2.9264 Epoch: 26   Global Step: 55000   Required: 3 hours
Training: 2025-05-30 14:11:40,672-[lfw][55026]XNorm: 21.943021
Training: 2025-05-30 14:11:40,672-[lfw][55026]Accuracy-Flip: 0.99300+-0.00440
Training: 2025-05-30 14:11:40,672-[lfw][55026]Accuracy-Highest: 0.99350
Training: 2025-05-30 14:12:09,036-[cfp_fp][55026]XNorm: 19.674161
Training: 2025-05-30 14:12:09,036-[cfp_fp][55026]Accuracy-Flip: 0.93071+-0.01154
Training: 2025-05-30 14:12:09,036-[cfp_fp][55026]Accuracy-Highest: 0.93357
Training: 2025-05-30 14:12:33,348-[agedb_30][55026]XNorm: 21.824027
Training: 2025-05-30 14:12:33,349-[agedb_30][55026]Accuracy-Flip: 0.93367+-0.01306
Training: 2025-05-30 14:12:33,349-[agedb_30][55026]Accuracy-Highest: 0.93367
Training: 2025-05-30 14:12:57,744-[calfw][55026]XNorm: 21.556458
Training: 2025-05-30 14:12:57,744-[calfw][55026]Accuracy-Flip: 0.92817+-0.01201
Training: 2025-05-30 14:12:57,744-[calfw][55026]Accuracy-Highest: 0.93117
Training: 2025-05-30 14:13:22,133-[cplfw][55026]XNorm: 20.156688
Training: 2025-05-30 14:13:22,134-[cplfw][55026]Accuracy-Flip: 0.87417+-0.01606
Training: 2025-05-30 14:13:22,134-[cplfw][55026]Accuracy-Highest: 0.87700
Training: 2025-05-30 14:13:30,568-Speed 44.69 samples/sec   Loss 2.7744 Epoch: 27   Global Step: 55050   Required: 3 hours
Training: 2025-05-30 14:13:47,836-Speed 370.63 samples/sec   Loss 2.4475 Epoch: 27   Global Step: 55100   Required: 3 hours
Training: 2025-05-30 14:14:05,111-Speed 370.49 samples/sec   Loss 2.4093 Epoch: 27   Global Step: 55150   Required: 3 hours
Training: 2025-05-30 14:14:22,389-Speed 370.42 samples/sec   Loss 2.4274 Epoch: 27   Global Step: 55200   Required: 3 hours
Training: 2025-05-30 14:14:39,668-Speed 370.38 samples/sec   Loss 2.4063 Epoch: 27   Global Step: 55250   Required: 3 hours
Training: 2025-05-30 14:14:56,952-Speed 370.28 samples/sec   Loss 2.4545 Epoch: 27   Global Step: 55300   Required: 3 hours
Training: 2025-05-30 14:15:14,237-Speed 370.27 samples/sec   Loss 2.4837 Epoch: 27   Global Step: 55350   Required: 3 hours
Training: 2025-05-30 14:15:31,522-Speed 370.27 samples/sec   Loss 2.5802 Epoch: 27   Global Step: 55400   Required: 3 hours
Training: 2025-05-30 14:15:48,806-Speed 370.29 samples/sec   Loss 2.5796 Epoch: 27   Global Step: 55450   Required: 3 hours
Training: 2025-05-30 14:16:06,089-Speed 370.31 samples/sec   Loss 2.5926 Epoch: 27   Global Step: 55500   Required: 3 hours
Training: 2025-05-30 14:16:23,374-Speed 370.26 samples/sec   Loss 2.5679 Epoch: 27   Global Step: 55550   Required: 3 hours
Training: 2025-05-30 14:16:40,659-Speed 370.27 samples/sec   Loss 2.5162 Epoch: 27   Global Step: 55600   Required: 3 hours
Training: 2025-05-30 14:16:57,947-Speed 370.19 samples/sec   Loss 2.5568 Epoch: 27   Global Step: 55650   Required: 3 hours
Training: 2025-05-30 14:17:15,236-Speed 370.19 samples/sec   Loss 2.5972 Epoch: 27   Global Step: 55700   Required: 3 hours
Training: 2025-05-30 14:17:32,523-Speed 370.21 samples/sec   Loss 2.5131 Epoch: 27   Global Step: 55750   Required: 3 hours
Training: 2025-05-30 14:17:49,809-Speed 370.25 samples/sec   Loss 2.7421 Epoch: 27   Global Step: 55800   Required: 3 hours
Training: 2025-05-30 14:18:07,094-Speed 370.27 samples/sec   Loss 2.6447 Epoch: 27   Global Step: 55850   Required: 3 hours
Training: 2025-05-30 14:18:24,378-Speed 370.30 samples/sec   Loss 2.6935 Epoch: 27   Global Step: 55900   Required: 3 hours
Training: 2025-05-30 14:18:41,663-Speed 370.25 samples/sec   Loss 2.7765 Epoch: 27   Global Step: 55950   Required: 3 hours
Training: 2025-05-30 14:18:58,950-Speed 370.24 samples/sec   Loss 2.5994 Epoch: 27   Global Step: 56000   Required: 3 hours
Training: 2025-05-30 14:19:16,234-Speed 370.27 samples/sec   Loss 2.6571 Epoch: 27   Global Step: 56050   Required: 3 hours
Training: 2025-05-30 14:19:33,520-Speed 370.25 samples/sec   Loss 2.6656 Epoch: 27   Global Step: 56100   Required: 3 hours
Training: 2025-05-30 14:19:50,801-Speed 370.35 samples/sec   Loss 2.7792 Epoch: 27   Global Step: 56150   Required: 3 hours
Training: 2025-05-30 14:20:08,080-Speed 370.39 samples/sec   Loss 2.6912 Epoch: 27   Global Step: 56200   Required: 3 hours
Training: 2025-05-30 14:20:25,364-Speed 370.29 samples/sec   Loss 2.6610 Epoch: 27   Global Step: 56250   Required: 3 hours
Training: 2025-05-30 14:20:42,644-Speed 370.38 samples/sec   Loss 2.5485 Epoch: 27   Global Step: 56300   Required: 3 hours
Training: 2025-05-30 14:20:59,928-Speed 370.29 samples/sec   Loss 2.7225 Epoch: 27   Global Step: 56350   Required: 3 hours
Training: 2025-05-30 14:21:17,214-Speed 370.24 samples/sec   Loss 2.6799 Epoch: 27   Global Step: 56400   Required: 3 hours
Training: 2025-05-30 14:21:34,501-Speed 370.22 samples/sec   Loss 2.7033 Epoch: 27   Global Step: 56450   Required: 3 hours
Training: 2025-05-30 14:21:51,791-Speed 370.17 samples/sec   Loss 2.7195 Epoch: 27   Global Step: 56500   Required: 3 hours
Training: 2025-05-30 14:22:09,077-Speed 370.24 samples/sec   Loss 2.8575 Epoch: 27   Global Step: 56550   Required: 3 hours
Training: 2025-05-30 14:22:26,367-Speed 370.18 samples/sec   Loss 2.7328 Epoch: 27   Global Step: 56600   Required: 3 hours
Training: 2025-05-30 14:22:43,655-Speed 370.20 samples/sec   Loss 2.7590 Epoch: 27   Global Step: 56650   Required: 3 hours
Training: 2025-05-30 14:23:00,944-Speed 370.17 samples/sec   Loss 2.8861 Epoch: 27   Global Step: 56700   Required: 3 hours
Training: 2025-05-30 14:23:18,237-Speed 370.09 samples/sec   Loss 2.7576 Epoch: 27   Global Step: 56750   Required: 3 hours
Training: 2025-05-30 14:23:35,528-Speed 370.15 samples/sec   Loss 2.8348 Epoch: 27   Global Step: 56800   Required: 3 hours
Training: 2025-05-30 14:23:52,819-Speed 370.13 samples/sec   Loss 2.7889 Epoch: 27   Global Step: 56850   Required: 3 hours
Training: 2025-05-30 14:24:10,109-Speed 370.16 samples/sec   Loss 2.8598 Epoch: 27   Global Step: 56900   Required: 3 hours
Training: 2025-05-30 14:24:27,397-Speed 370.22 samples/sec   Loss 2.7913 Epoch: 27   Global Step: 56950   Required: 3 hours
Training: 2025-05-30 14:24:44,683-Speed 370.22 samples/sec   Loss 2.8651 Epoch: 27   Global Step: 57000   Required: 3 hours
Training: 2025-05-30 14:25:01,976-Speed 370.10 samples/sec   Loss 2.7495 Epoch: 27   Global Step: 57050   Required: 3 hours
Training: 2025-05-30 14:25:31,172-[lfw][57064]XNorm: 21.284488
Training: 2025-05-30 14:25:31,173-[lfw][57064]Accuracy-Flip: 0.99267+-0.00442
Training: 2025-05-30 14:25:31,173-[lfw][57064]Accuracy-Highest: 0.99350
Training: 2025-05-30 14:25:59,442-[cfp_fp][57064]XNorm: 19.039856
Training: 2025-05-30 14:25:59,442-[cfp_fp][57064]Accuracy-Flip: 0.92929+-0.01107
Training: 2025-05-30 14:25:59,442-[cfp_fp][57064]Accuracy-Highest: 0.93357
Training: 2025-05-30 14:26:23,770-[agedb_30][57064]XNorm: 21.225076
Training: 2025-05-30 14:26:23,770-[agedb_30][57064]Accuracy-Flip: 0.92850+-0.01696
Training: 2025-05-30 14:26:23,770-[agedb_30][57064]Accuracy-Highest: 0.93367
Training: 2025-05-30 14:26:48,179-[calfw][57064]XNorm: 20.824602
Training: 2025-05-30 14:26:48,179-[calfw][57064]Accuracy-Flip: 0.92517+-0.01158
Training: 2025-05-30 14:26:48,179-[calfw][57064]Accuracy-Highest: 0.93117
Training: 2025-05-30 14:27:12,594-[cplfw][57064]XNorm: 19.600001
Training: 2025-05-30 14:27:12,594-[cplfw][57064]Accuracy-Flip: 0.87433+-0.01794
Training: 2025-05-30 14:27:12,594-[cplfw][57064]Accuracy-Highest: 0.87700
Training: 2025-05-30 14:27:25,176-Speed 44.69 samples/sec   Loss 2.3791 Epoch: 28   Global Step: 57100   Required: 3 hours
Training: 2025-05-30 14:27:42,456-Speed 370.38 samples/sec   Loss 2.2727 Epoch: 28   Global Step: 57150   Required: 3 hours
Training: 2025-05-30 14:27:59,740-Speed 370.29 samples/sec   Loss 2.3347 Epoch: 28   Global Step: 57200   Required: 3 hours
Training: 2025-05-30 14:28:17,024-Speed 370.28 samples/sec   Loss 2.2071 Epoch: 28   Global Step: 57250   Required: 3 hours
Training: 2025-05-30 14:28:34,315-Speed 370.15 samples/sec   Loss 2.2723 Epoch: 28   Global Step: 57300   Required: 3 hours
Training: 2025-05-30 14:28:51,604-Speed 370.17 samples/sec   Loss 2.3119 Epoch: 28   Global Step: 57350   Required: 3 hours
Training: 2025-05-30 14:29:08,894-Speed 370.16 samples/sec   Loss 2.3525 Epoch: 28   Global Step: 57400   Required: 3 hours
Training: 2025-05-30 14:29:26,183-Speed 370.18 samples/sec   Loss 2.2633 Epoch: 28   Global Step: 57450   Required: 3 hours
Training: 2025-05-30 14:29:43,477-Speed 370.07 samples/sec   Loss 2.3355 Epoch: 28   Global Step: 57500   Required: 3 hours
Training: 2025-05-30 14:30:00,770-Speed 370.10 samples/sec   Loss 2.3420 Epoch: 28   Global Step: 57550   Required: 3 hours
Training: 2025-05-30 14:30:18,064-Speed 370.07 samples/sec   Loss 2.3531 Epoch: 28   Global Step: 57600   Required: 3 hours
Training: 2025-05-30 14:30:35,360-Speed 370.04 samples/sec   Loss 2.3724 Epoch: 28   Global Step: 57650   Required: 3 hours
Training: 2025-05-30 14:30:52,656-Speed 370.03 samples/sec   Loss 2.3639 Epoch: 28   Global Step: 57700   Required: 3 hours
Training: 2025-05-30 14:31:09,952-Speed 370.03 samples/sec   Loss 2.3942 Epoch: 28   Global Step: 57750   Required: 3 hours
Training: 2025-05-30 14:31:27,249-Speed 370.00 samples/sec   Loss 2.3379 Epoch: 28   Global Step: 57800   Required: 3 hours
Training: 2025-05-30 14:31:44,546-Speed 370.02 samples/sec   Loss 2.3485 Epoch: 28   Global Step: 57850   Required: 3 hours
Training: 2025-05-30 14:32:01,839-Speed 370.10 samples/sec   Loss 2.4153 Epoch: 28   Global Step: 57900   Required: 3 hours
Training: 2025-05-30 14:32:19,131-Speed 370.12 samples/sec   Loss 2.5101 Epoch: 28   Global Step: 57950   Required: 3 hours
Training: 2025-05-30 14:32:36,428-Speed 370.01 samples/sec   Loss 2.3373 Epoch: 28   Global Step: 58000   Required: 3 hours
Training: 2025-05-30 14:32:53,723-Speed 370.04 samples/sec   Loss 2.3977 Epoch: 28   Global Step: 58050   Required: 3 hours
Training: 2025-05-30 14:33:11,016-Speed 370.10 samples/sec   Loss 2.4011 Epoch: 28   Global Step: 58100   Required: 3 hours
Training: 2025-05-30 14:33:28,303-Speed 370.23 samples/sec   Loss 2.4163 Epoch: 28   Global Step: 58150   Required: 3 hours
Training: 2025-05-30 14:33:45,592-Speed 370.19 samples/sec   Loss 2.5299 Epoch: 28   Global Step: 58200   Required: 3 hours
Training: 2025-05-30 14:34:02,882-Speed 370.15 samples/sec   Loss 2.5217 Epoch: 28   Global Step: 58250   Required: 3 hours
Training: 2025-05-30 14:34:20,173-Speed 370.14 samples/sec   Loss 2.5194 Epoch: 28   Global Step: 58300   Required: 3 hours
Training: 2025-05-30 14:34:37,463-Speed 370.16 samples/sec   Loss 2.2995 Epoch: 28   Global Step: 58350   Required: 3 hours
Training: 2025-05-30 14:34:54,753-Speed 370.15 samples/sec   Loss 2.3953 Epoch: 28   Global Step: 58400   Required: 3 hours
Training: 2025-05-30 14:35:12,049-Speed 370.03 samples/sec   Loss 2.5436 Epoch: 28   Global Step: 58450   Required: 3 hours
Training: 2025-05-30 14:35:29,346-Speed 370.01 samples/sec   Loss 2.4525 Epoch: 28   Global Step: 58500   Required: 3 hours
Training: 2025-05-30 14:35:46,639-Speed 370.10 samples/sec   Loss 2.5919 Epoch: 28   Global Step: 58550   Required: 3 hours
Training: 2025-05-30 14:36:03,929-Speed 370.15 samples/sec   Loss 2.4083 Epoch: 28   Global Step: 58600   Required: 3 hours
Training: 2025-05-30 14:36:21,219-Speed 370.16 samples/sec   Loss 2.5108 Epoch: 28   Global Step: 58650   Required: 3 hours
Training: 2025-05-30 14:36:38,510-Speed 370.13 samples/sec   Loss 2.4990 Epoch: 28   Global Step: 58700   Required: 3 hours
Training: 2025-05-30 14:36:55,801-Speed 370.14 samples/sec   Loss 2.6510 Epoch: 28   Global Step: 58750   Required: 3 hours
Training: 2025-05-30 14:37:13,093-Speed 370.12 samples/sec   Loss 2.4489 Epoch: 28   Global Step: 58800   Required: 3 hours
Training: 2025-05-30 14:37:30,383-Speed 370.15 samples/sec   Loss 2.5240 Epoch: 28   Global Step: 58850   Required: 3 hours
Training: 2025-05-30 14:37:47,672-Speed 370.19 samples/sec   Loss 2.5680 Epoch: 28   Global Step: 58900   Required: 3 hours
Training: 2025-05-30 14:38:04,964-Speed 370.11 samples/sec   Loss 2.5798 Epoch: 28   Global Step: 58950   Required: 3 hours
Training: 2025-05-30 14:38:22,255-Speed 370.14 samples/sec   Loss 2.6159 Epoch: 28   Global Step: 59000   Required: 3 hours
Training: 2025-05-30 14:38:39,551-Speed 370.03 samples/sec   Loss 2.5838 Epoch: 28   Global Step: 59050   Required: 3 hours
Training: 2025-05-30 14:38:56,837-Speed 370.24 samples/sec   Loss 2.5401 Epoch: 28   Global Step: 59100   Required: 3 hours
Training: 2025-05-30 14:39:21,864-[lfw][59102]XNorm: 21.193134
Training: 2025-05-30 14:39:21,864-[lfw][59102]Accuracy-Flip: 0.99100+-0.00554
Training: 2025-05-30 14:39:21,864-[lfw][59102]Accuracy-Highest: 0.99350
Training: 2025-05-30 14:39:50,269-[cfp_fp][59102]XNorm: 19.087296
Training: 2025-05-30 14:39:50,269-[cfp_fp][59102]Accuracy-Flip: 0.92943+-0.01147
Training: 2025-05-30 14:39:50,269-[cfp_fp][59102]Accuracy-Highest: 0.93357
Training: 2025-05-30 14:40:14,598-[agedb_30][59102]XNorm: 21.270284
Training: 2025-05-30 14:40:14,598-[agedb_30][59102]Accuracy-Flip: 0.92533+-0.01339
Training: 2025-05-30 14:40:14,599-[agedb_30][59102]Accuracy-Highest: 0.93367
Training: 2025-05-30 14:40:39,004-[calfw][59102]XNorm: 20.782716
Training: 2025-05-30 14:40:39,004-[calfw][59102]Accuracy-Flip: 0.92850+-0.01233
Training: 2025-05-30 14:40:39,004-[calfw][59102]Accuracy-Highest: 0.93117
Training: 2025-05-30 14:41:03,401-[cplfw][59102]XNorm: 19.670693
Training: 2025-05-30 14:41:03,401-[cplfw][59102]Accuracy-Flip: 0.87233+-0.01519
Training: 2025-05-30 14:41:03,401-[cplfw][59102]Accuracy-Highest: 0.87700
Training: 2025-05-30 14:41:20,139-Speed 44.66 samples/sec   Loss 2.0779 Epoch: 29   Global Step: 59150   Required: 3 hours
Training: 2025-05-30 14:41:37,414-Speed 370.48 samples/sec   Loss 2.0857 Epoch: 29   Global Step: 59200   Required: 3 hours
Training: 2025-05-30 14:41:54,692-Speed 370.41 samples/sec   Loss 1.9970 Epoch: 29   Global Step: 59250   Required: 3 hours
Training: 2025-05-30 14:42:11,978-Speed 370.24 samples/sec   Loss 1.9663 Epoch: 29   Global Step: 59300   Required: 3 hours
Training: 2025-05-30 14:42:29,265-Speed 370.23 samples/sec   Loss 1.9398 Epoch: 29   Global Step: 59350   Required: 3 hours
Training: 2025-05-30 14:42:46,551-Speed 370.23 samples/sec   Loss 1.9741 Epoch: 29   Global Step: 59400   Required: 3 hours
Training: 2025-05-30 14:43:03,842-Speed 370.15 samples/sec   Loss 1.9455 Epoch: 29   Global Step: 59450   Required: 2 hours
Training: 2025-05-30 14:43:21,135-Speed 370.09 samples/sec   Loss 1.9759 Epoch: 29   Global Step: 59500   Required: 2 hours
Training: 2025-05-30 14:43:38,423-Speed 370.21 samples/sec   Loss 1.9923 Epoch: 29   Global Step: 59550   Required: 2 hours
Training: 2025-05-30 14:43:55,709-Speed 370.25 samples/sec   Loss 1.9600 Epoch: 29   Global Step: 59600   Required: 2 hours
Training: 2025-05-30 14:44:12,996-Speed 370.21 samples/sec   Loss 1.8663 Epoch: 29   Global Step: 59650   Required: 2 hours
Training: 2025-05-30 14:44:30,290-Speed 370.08 samples/sec   Loss 1.8011 Epoch: 29   Global Step: 59700   Required: 2 hours
Training: 2025-05-30 14:44:47,581-Speed 370.13 samples/sec   Loss 1.8713 Epoch: 29   Global Step: 59750   Required: 2 hours
Training: 2025-05-30 14:45:04,868-Speed 370.23 samples/sec   Loss 1.9890 Epoch: 29   Global Step: 59800   Required: 2 hours
Training: 2025-05-30 14:45:22,159-Speed 370.14 samples/sec   Loss 1.8935 Epoch: 29   Global Step: 59850   Required: 2 hours
Training: 2025-05-30 14:45:39,447-Speed 370.20 samples/sec   Loss 1.9174 Epoch: 29   Global Step: 59900   Required: 2 hours
Training: 2025-05-30 14:45:56,738-Speed 370.13 samples/sec   Loss 1.9068 Epoch: 29   Global Step: 59950   Required: 2 hours
Training: 2025-05-30 14:46:14,035-Speed 370.02 samples/sec   Loss 1.8465 Epoch: 29   Global Step: 60000   Required: 2 hours
Training: 2025-05-30 14:46:31,332-Speed 370.01 samples/sec   Loss 1.8996 Epoch: 29   Global Step: 60050   Required: 2 hours
Training: 2025-05-30 14:46:48,629-Speed 370.01 samples/sec   Loss 2.0067 Epoch: 29   Global Step: 60100   Required: 2 hours
Training: 2025-05-30 14:47:05,921-Speed 370.12 samples/sec   Loss 1.9874 Epoch: 29   Global Step: 60150   Required: 2 hours
Training: 2025-05-30 14:47:23,216-Speed 370.03 samples/sec   Loss 1.9695 Epoch: 29   Global Step: 60200   Required: 2 hours
Training: 2025-05-30 14:47:40,508-Speed 370.12 samples/sec   Loss 1.9417 Epoch: 29   Global Step: 60250   Required: 2 hours
Training: 2025-05-30 14:47:57,802-Speed 370.08 samples/sec   Loss 1.8632 Epoch: 29   Global Step: 60300   Required: 2 hours
Training: 2025-05-30 14:48:15,096-Speed 370.08 samples/sec   Loss 1.8553 Epoch: 29   Global Step: 60350   Required: 2 hours
Training: 2025-05-30 14:48:32,390-Speed 370.07 samples/sec   Loss 1.9455 Epoch: 29   Global Step: 60400   Required: 2 hours
Training: 2025-05-30 14:48:49,681-Speed 370.12 samples/sec   Loss 1.8424 Epoch: 29   Global Step: 60450   Required: 2 hours
Training: 2025-05-30 14:49:06,974-Speed 370.09 samples/sec   Loss 1.9061 Epoch: 29   Global Step: 60500   Required: 2 hours
Training: 2025-05-30 14:49:24,268-Speed 370.08 samples/sec   Loss 1.8902 Epoch: 29   Global Step: 60550   Required: 2 hours
Training: 2025-05-30 14:49:41,564-Speed 370.03 samples/sec   Loss 2.0596 Epoch: 29   Global Step: 60600   Required: 2 hours
Training: 2025-05-30 14:49:58,860-Speed 370.02 samples/sec   Loss 2.0238 Epoch: 29   Global Step: 60650   Required: 2 hours
Training: 2025-05-30 14:50:16,149-Speed 370.19 samples/sec   Loss 1.8742 Epoch: 29   Global Step: 60700   Required: 2 hours
Training: 2025-05-30 14:50:33,442-Speed 370.10 samples/sec   Loss 1.8637 Epoch: 29   Global Step: 60750   Required: 2 hours
Training: 2025-05-30 14:50:50,730-Speed 370.20 samples/sec   Loss 1.8676 Epoch: 29   Global Step: 60800   Required: 2 hours
Training: 2025-05-30 14:51:08,017-Speed 370.22 samples/sec   Loss 1.8836 Epoch: 29   Global Step: 60850   Required: 2 hours
Training: 2025-05-30 14:51:25,308-Speed 370.14 samples/sec   Loss 1.9931 Epoch: 29   Global Step: 60900   Required: 2 hours
Training: 2025-05-30 14:51:42,603-Speed 370.04 samples/sec   Loss 1.8999 Epoch: 29   Global Step: 60950   Required: 2 hours
Training: 2025-05-30 14:51:59,894-Speed 370.16 samples/sec   Loss 1.8638 Epoch: 29   Global Step: 61000   Required: 2 hours
Training: 2025-05-30 14:52:17,187-Speed 370.08 samples/sec   Loss 1.9494 Epoch: 29   Global Step: 61050   Required: 2 hours
Training: 2025-05-30 14:52:34,481-Speed 370.07 samples/sec   Loss 1.7923 Epoch: 29   Global Step: 61100   Required: 2 hours
Training: 2025-05-30 14:53:12,657-[lfw][61140]XNorm: 21.198645
Training: 2025-05-30 14:53:12,657-[lfw][61140]Accuracy-Flip: 0.99250+-0.00436
Training: 2025-05-30 14:53:12,657-[lfw][61140]Accuracy-Highest: 0.99350
Training: 2025-05-30 14:53:41,028-[cfp_fp][61140]XNorm: 19.222154
Training: 2025-05-30 14:53:41,028-[cfp_fp][61140]Accuracy-Flip: 0.92871+-0.01142
Training: 2025-05-30 14:53:41,028-[cfp_fp][61140]Accuracy-Highest: 0.93357
Training: 2025-05-30 14:54:05,344-[agedb_30][61140]XNorm: 21.264766
Training: 2025-05-30 14:54:05,344-[agedb_30][61140]Accuracy-Flip: 0.92700+-0.01260
Training: 2025-05-30 14:54:05,344-[agedb_30][61140]Accuracy-Highest: 0.93367
Training: 2025-05-30 14:54:29,755-[calfw][61140]XNorm: 20.727103
Training: 2025-05-30 14:54:29,755-[calfw][61140]Accuracy-Flip: 0.92633+-0.01108
Training: 2025-05-30 14:54:29,755-[calfw][61140]Accuracy-Highest: 0.93117
Training: 2025-05-30 14:54:54,157-[cplfw][61140]XNorm: 19.809768
Training: 2025-05-30 14:54:54,157-[cplfw][61140]Accuracy-Flip: 0.87333+-0.01578
Training: 2025-05-30 14:54:54,157-[cplfw][61140]Accuracy-Highest: 0.87700
Training: 2025-05-30 14:54:57,757-Speed 44.67 samples/sec   Loss 1.8581 Epoch: 30   Global Step: 61150   Required: 2 hours
Training: 2025-05-30 14:55:15,027-Speed 370.58 samples/sec   Loss 1.8537 Epoch: 30   Global Step: 61200   Required: 2 hours
Training: 2025-05-30 14:55:32,304-Speed 370.45 samples/sec   Loss 1.7952 Epoch: 30   Global Step: 61250   Required: 2 hours
Training: 2025-05-30 14:55:49,584-Speed 370.38 samples/sec   Loss 1.7366 Epoch: 30   Global Step: 61300   Required: 2 hours
Training: 2025-05-30 14:56:06,870-Speed 370.24 samples/sec   Loss 1.8504 Epoch: 30   Global Step: 61350   Required: 2 hours
Training: 2025-05-30 14:56:24,156-Speed 370.25 samples/sec   Loss 1.8482 Epoch: 30   Global Step: 61400   Required: 2 hours
Training: 2025-05-30 14:56:41,443-Speed 370.22 samples/sec   Loss 1.7653 Epoch: 30   Global Step: 61450   Required: 2 hours
Training: 2025-05-30 14:56:58,736-Speed 370.08 samples/sec   Loss 1.7759 Epoch: 30   Global Step: 61500   Required: 2 hours
Training: 2025-05-30 14:57:16,028-Speed 370.12 samples/sec   Loss 1.8226 Epoch: 30   Global Step: 61550   Required: 2 hours
Training: 2025-05-30 14:57:33,318-Speed 370.15 samples/sec   Loss 1.7648 Epoch: 30   Global Step: 61600   Required: 2 hours
Training: 2025-05-30 14:57:50,616-Speed 370.00 samples/sec   Loss 1.8238 Epoch: 30   Global Step: 61650   Required: 2 hours
Training: 2025-05-30 14:58:07,909-Speed 370.08 samples/sec   Loss 1.8248 Epoch: 30   Global Step: 61700   Required: 2 hours
Training: 2025-05-30 14:58:25,201-Speed 370.13 samples/sec   Loss 1.7763 Epoch: 30   Global Step: 61750   Required: 2 hours
Training: 2025-05-30 14:58:42,490-Speed 370.18 samples/sec   Loss 1.9658 Epoch: 30   Global Step: 61800   Required: 2 hours
Training: 2025-05-30 14:58:59,780-Speed 370.15 samples/sec   Loss 1.8518 Epoch: 30   Global Step: 61850   Required: 2 hours
Training: 2025-05-30 14:59:17,073-Speed 370.09 samples/sec   Loss 1.8070 Epoch: 30   Global Step: 61900   Required: 2 hours
Training: 2025-05-30 14:59:34,364-Speed 370.15 samples/sec   Loss 1.8992 Epoch: 30   Global Step: 61950   Required: 2 hours
Training: 2025-05-30 14:59:51,657-Speed 370.09 samples/sec   Loss 1.9029 Epoch: 30   Global Step: 62000   Required: 2 hours
Training: 2025-05-30 15:00:08,952-Speed 370.05 samples/sec   Loss 1.8643 Epoch: 30   Global Step: 62050   Required: 2 hours
Training: 2025-05-30 15:00:26,245-Speed 370.09 samples/sec   Loss 1.8870 Epoch: 30   Global Step: 62100   Required: 2 hours
Training: 2025-05-30 15:00:43,540-Speed 370.07 samples/sec   Loss 1.8703 Epoch: 30   Global Step: 62150   Required: 2 hours
Training: 2025-05-30 15:01:00,833-Speed 370.09 samples/sec   Loss 1.7953 Epoch: 30   Global Step: 62200   Required: 2 hours
Training: 2025-05-30 15:01:18,127-Speed 370.07 samples/sec   Loss 1.9118 Epoch: 30   Global Step: 62250   Required: 2 hours
Training: 2025-05-30 15:01:35,423-Speed 370.03 samples/sec   Loss 1.7975 Epoch: 30   Global Step: 62300   Required: 2 hours
Training: 2025-05-30 15:01:52,722-Speed 369.96 samples/sec   Loss 1.8340 Epoch: 30   Global Step: 62350   Required: 2 hours
Training: 2025-05-30 15:02:10,016-Speed 370.08 samples/sec   Loss 1.8640 Epoch: 30   Global Step: 62400   Required: 2 hours
Training: 2025-05-30 15:02:27,306-Speed 370.15 samples/sec   Loss 1.9496 Epoch: 30   Global Step: 62450   Required: 2 hours
Training: 2025-05-30 15:02:44,594-Speed 370.20 samples/sec   Loss 1.7435 Epoch: 30   Global Step: 62500   Required: 2 hours
Training: 2025-05-30 15:03:01,886-Speed 370.13 samples/sec   Loss 1.8556 Epoch: 30   Global Step: 62550   Required: 2 hours
Training: 2025-05-30 15:03:19,176-Speed 370.14 samples/sec   Loss 1.7816 Epoch: 30   Global Step: 62600   Required: 2 hours
Training: 2025-05-30 15:03:36,468-Speed 370.12 samples/sec   Loss 1.9447 Epoch: 30   Global Step: 62650   Required: 2 hours
Training: 2025-05-30 15:03:53,761-Speed 370.09 samples/sec   Loss 1.8060 Epoch: 30   Global Step: 62700   Required: 2 hours
Training: 2025-05-30 15:04:11,054-Speed 370.09 samples/sec   Loss 1.9316 Epoch: 30   Global Step: 62750   Required: 2 hours
Training: 2025-05-30 15:04:28,350-Speed 370.04 samples/sec   Loss 1.7784 Epoch: 30   Global Step: 62800   Required: 2 hours
Training: 2025-05-30 15:04:45,642-Speed 370.11 samples/sec   Loss 1.8191 Epoch: 30   Global Step: 62850   Required: 2 hours
Training: 2025-05-30 15:05:02,932-Speed 370.17 samples/sec   Loss 1.8288 Epoch: 30   Global Step: 62900   Required: 2 hours
Training: 2025-05-30 15:05:20,225-Speed 370.09 samples/sec   Loss 1.8862 Epoch: 30   Global Step: 62950   Required: 2 hours
Training: 2025-05-30 15:05:37,514-Speed 370.18 samples/sec   Loss 1.8266 Epoch: 30   Global Step: 63000   Required: 2 hours
Training: 2025-05-30 15:05:54,803-Speed 370.18 samples/sec   Loss 1.8752 Epoch: 30   Global Step: 63050   Required: 2 hours
Training: 2025-05-30 15:06:12,091-Speed 370.21 samples/sec   Loss 1.8925 Epoch: 30   Global Step: 63100   Required: 2 hours
Training: 2025-05-30 15:06:29,387-Speed 370.03 samples/sec   Loss 1.7516 Epoch: 30   Global Step: 63150   Required: 2 hours
Training: 2025-05-30 15:07:03,412-[lfw][63178]XNorm: 21.168064
Training: 2025-05-30 15:07:03,412-[lfw][63178]Accuracy-Flip: 0.99133+-0.00521
Training: 2025-05-30 15:07:03,412-[lfw][63178]Accuracy-Highest: 0.99350
Training: 2025-05-30 15:07:31,784-[cfp_fp][63178]XNorm: 19.224580
Training: 2025-05-30 15:07:31,784-[cfp_fp][63178]Accuracy-Flip: 0.93029+-0.00954
Training: 2025-05-30 15:07:31,784-[cfp_fp][63178]Accuracy-Highest: 0.93357
Training: 2025-05-30 15:07:56,127-[agedb_30][63178]XNorm: 21.273790
Training: 2025-05-30 15:07:56,127-[agedb_30][63178]Accuracy-Flip: 0.92667+-0.01265
Training: 2025-05-30 15:07:56,127-[agedb_30][63178]Accuracy-Highest: 0.93367
Training: 2025-05-30 15:08:20,548-[calfw][63178]XNorm: 20.700220
Training: 2025-05-30 15:08:20,548-[calfw][63178]Accuracy-Flip: 0.92650+-0.01104
Training: 2025-05-30 15:08:20,548-[calfw][63178]Accuracy-Highest: 0.93117
Training: 2025-05-30 15:08:44,954-[cplfw][63178]XNorm: 19.823201
Training: 2025-05-30 15:08:44,954-[cplfw][63178]Accuracy-Flip: 0.87300+-0.01420
Training: 2025-05-30 15:08:44,954-[cplfw][63178]Accuracy-Highest: 0.87700
Training: 2025-05-30 15:08:52,704-Speed 44.66 samples/sec   Loss 1.9035 Epoch: 31   Global Step: 63200   Required: 2 hours
Training: 2025-05-30 15:09:09,973-Speed 370.61 samples/sec   Loss 1.7776 Epoch: 31   Global Step: 63250   Required: 2 hours
Training: 2025-05-30 15:09:27,250-Speed 370.43 samples/sec   Loss 1.7586 Epoch: 31   Global Step: 63300   Required: 2 hours
Training: 2025-05-30 15:09:44,527-Speed 370.43 samples/sec   Loss 1.8976 Epoch: 31   Global Step: 63350   Required: 2 hours
Training: 2025-05-30 15:10:01,811-Speed 370.29 samples/sec   Loss 1.7209 Epoch: 31   Global Step: 63400   Required: 2 hours
Training: 2025-05-30 15:10:19,093-Speed 370.33 samples/sec   Loss 1.7668 Epoch: 31   Global Step: 63450   Required: 2 hours
Training: 2025-05-30 15:10:36,380-Speed 370.22 samples/sec   Loss 1.8309 Epoch: 31   Global Step: 63500   Required: 2 hours
Training: 2025-05-30 15:10:53,666-Speed 370.25 samples/sec   Loss 1.7758 Epoch: 31   Global Step: 63550   Required: 2 hours
Training: 2025-05-30 15:11:10,951-Speed 370.26 samples/sec   Loss 1.7699 Epoch: 31   Global Step: 63600   Required: 2 hours
Training: 2025-05-30 15:11:28,240-Speed 370.19 samples/sec   Loss 1.7564 Epoch: 31   Global Step: 63650   Required: 2 hours
Training: 2025-05-30 15:11:45,526-Speed 370.25 samples/sec   Loss 1.8476 Epoch: 31   Global Step: 63700   Required: 2 hours
Training: 2025-05-30 15:12:02,814-Speed 370.19 samples/sec   Loss 1.7450 Epoch: 31   Global Step: 63750   Required: 2 hours
Training: 2025-05-30 15:12:20,101-Speed 370.24 samples/sec   Loss 1.7208 Epoch: 31   Global Step: 63800   Required: 2 hours
Training: 2025-05-30 15:12:37,390-Speed 370.17 samples/sec   Loss 1.7064 Epoch: 31   Global Step: 63850   Required: 2 hours
Training: 2025-05-30 15:12:54,676-Speed 370.25 samples/sec   Loss 1.6463 Epoch: 31   Global Step: 63900   Required: 2 hours
Training: 2025-05-30 15:13:11,964-Speed 370.21 samples/sec   Loss 1.8266 Epoch: 31   Global Step: 63950   Required: 2 hours
Training: 2025-05-30 15:13:29,248-Speed 370.28 samples/sec   Loss 1.8873 Epoch: 31   Global Step: 64000   Required: 2 hours
Training: 2025-05-30 15:13:46,534-Speed 370.25 samples/sec   Loss 1.9428 Epoch: 31   Global Step: 64050   Required: 2 hours
Training: 2025-05-30 15:14:03,821-Speed 370.22 samples/sec   Loss 1.7462 Epoch: 31   Global Step: 64100   Required: 2 hours
Training: 2025-05-30 15:14:21,109-Speed 370.20 samples/sec   Loss 1.7245 Epoch: 31   Global Step: 64150   Required: 2 hours
Training: 2025-05-30 15:14:38,395-Speed 370.25 samples/sec   Loss 1.7300 Epoch: 31   Global Step: 64200   Required: 2 hours
Training: 2025-05-30 15:14:55,678-Speed 370.30 samples/sec   Loss 1.8173 Epoch: 31   Global Step: 64250   Required: 2 hours
Training: 2025-05-30 15:15:12,961-Speed 370.32 samples/sec   Loss 1.7764 Epoch: 31   Global Step: 64300   Required: 2 hours
Training: 2025-05-30 15:15:30,244-Speed 370.30 samples/sec   Loss 1.7977 Epoch: 31   Global Step: 64350   Required: 2 hours
Training: 2025-05-30 15:15:47,527-Speed 370.32 samples/sec   Loss 1.7888 Epoch: 31   Global Step: 64400   Required: 2 hours
Training: 2025-05-30 15:16:04,806-Speed 370.38 samples/sec   Loss 1.7751 Epoch: 31   Global Step: 64450   Required: 2 hours
Training: 2025-05-30 15:16:22,091-Speed 370.26 samples/sec   Loss 1.7488 Epoch: 31   Global Step: 64500   Required: 2 hours
Training: 2025-05-30 15:16:39,374-Speed 370.32 samples/sec   Loss 1.8118 Epoch: 31   Global Step: 64550   Required: 2 hours
Training: 2025-05-30 15:16:56,653-Speed 370.38 samples/sec   Loss 1.7057 Epoch: 31   Global Step: 64600   Required: 2 hours
Training: 2025-05-30 15:17:13,932-Speed 370.41 samples/sec   Loss 1.7548 Epoch: 31   Global Step: 64650   Required: 2 hours
Training: 2025-05-30 15:17:31,211-Speed 370.40 samples/sec   Loss 1.6512 Epoch: 31   Global Step: 64700   Required: 2 hours
Training: 2025-05-30 15:17:48,489-Speed 370.40 samples/sec   Loss 1.8503 Epoch: 31   Global Step: 64750   Required: 2 hours
Training: 2025-05-30 15:18:05,766-Speed 370.46 samples/sec   Loss 1.7961 Epoch: 31   Global Step: 64800   Required: 2 hours
Training: 2025-05-30 15:18:23,044-Speed 370.39 samples/sec   Loss 1.7824 Epoch: 31   Global Step: 64850   Required: 2 hours
Training: 2025-05-30 15:18:40,322-Speed 370.43 samples/sec   Loss 1.8688 Epoch: 31   Global Step: 64900   Required: 2 hours
Training: 2025-05-30 15:18:57,602-Speed 370.37 samples/sec   Loss 1.7925 Epoch: 31   Global Step: 64950   Required: 2 hours
Training: 2025-05-30 15:19:14,885-Speed 370.31 samples/sec   Loss 1.8264 Epoch: 31   Global Step: 65000   Required: 2 hours
Training: 2025-05-30 15:19:32,167-Speed 370.33 samples/sec   Loss 1.7055 Epoch: 31   Global Step: 65050   Required: 2 hours
Training: 2025-05-30 15:19:49,453-Speed 370.24 samples/sec   Loss 1.7507 Epoch: 31   Global Step: 65100   Required: 2 hours
Training: 2025-05-30 15:20:06,736-Speed 370.31 samples/sec   Loss 1.8123 Epoch: 31   Global Step: 65150   Required: 2 hours
Training: 2025-05-30 15:20:24,018-Speed 370.34 samples/sec   Loss 1.9282 Epoch: 31   Global Step: 65200   Required: 2 hours
Training: 2025-05-30 15:20:53,880-[lfw][65216]XNorm: 21.135623
Training: 2025-05-30 15:20:53,880-[lfw][65216]Accuracy-Flip: 0.99133+-0.00515
Training: 2025-05-30 15:20:53,880-[lfw][65216]Accuracy-Highest: 0.99350
Training: 2025-05-30 15:21:22,247-[cfp_fp][65216]XNorm: 19.204313
Training: 2025-05-30 15:21:22,247-[cfp_fp][65216]Accuracy-Flip: 0.93143+-0.01018
Training: 2025-05-30 15:21:22,247-[cfp_fp][65216]Accuracy-Highest: 0.93357
Training: 2025-05-30 15:21:46,565-[agedb_30][65216]XNorm: 21.239278
Training: 2025-05-30 15:21:46,565-[agedb_30][65216]Accuracy-Flip: 0.92533+-0.01422
Training: 2025-05-30 15:21:46,565-[agedb_30][65216]Accuracy-Highest: 0.93367
Training: 2025-05-30 15:22:10,965-[calfw][65216]XNorm: 20.656519
Training: 2025-05-30 15:22:10,965-[calfw][65216]Accuracy-Flip: 0.92617+-0.01044
Training: 2025-05-30 15:22:10,965-[calfw][65216]Accuracy-Highest: 0.93117
Training: 2025-05-30 15:22:35,350-[cplfw][65216]XNorm: 19.818029
Training: 2025-05-30 15:22:35,350-[cplfw][65216]Accuracy-Flip: 0.87350+-0.01697
Training: 2025-05-30 15:22:35,350-[cplfw][65216]Accuracy-Highest: 0.87700
Training: 2025-05-30 15:22:47,251-Speed 44.68 samples/sec   Loss 1.6977 Epoch: 32   Global Step: 65250   Required: 2 hours
Training: 2025-05-30 15:23:04,516-Speed 370.70 samples/sec   Loss 1.6523 Epoch: 32   Global Step: 65300   Required: 2 hours
Training: 2025-05-30 15:23:21,784-Speed 370.64 samples/sec   Loss 1.7823 Epoch: 32   Global Step: 65350   Required: 2 hours
Training: 2025-05-30 15:23:39,056-Speed 370.55 samples/sec   Loss 1.8274 Epoch: 32   Global Step: 65400   Required: 2 hours
Training: 2025-05-30 15:23:56,329-Speed 370.52 samples/sec   Loss 1.6672 Epoch: 32   Global Step: 65450   Required: 2 hours
Training: 2025-05-30 15:24:13,609-Speed 370.38 samples/sec   Loss 1.7375 Epoch: 32   Global Step: 65500   Required: 2 hours
Training: 2025-05-30 15:24:30,890-Speed 370.33 samples/sec   Loss 1.8868 Epoch: 32   Global Step: 65550   Required: 2 hours
Training: 2025-05-30 15:24:48,173-Speed 370.32 samples/sec   Loss 1.7287 Epoch: 32   Global Step: 65600   Required: 2 hours
Training: 2025-05-30 15:25:05,455-Speed 370.33 samples/sec   Loss 1.7227 Epoch: 32   Global Step: 65650   Required: 2 hours
Training: 2025-05-30 15:25:22,732-Speed 370.42 samples/sec   Loss 1.7533 Epoch: 32   Global Step: 65700   Required: 2 hours
Training: 2025-05-30 15:25:40,010-Speed 370.41 samples/sec   Loss 1.7065 Epoch: 32   Global Step: 65750   Required: 2 hours
Training: 2025-05-30 15:25:57,292-Speed 370.35 samples/sec   Loss 1.7258 Epoch: 32   Global Step: 65800   Required: 2 hours
Training: 2025-05-30 15:26:14,573-Speed 370.34 samples/sec   Loss 1.6704 Epoch: 32   Global Step: 65850   Required: 2 hours
Training: 2025-05-30 15:26:31,853-Speed 370.36 samples/sec   Loss 1.6890 Epoch: 32   Global Step: 65900   Required: 2 hours
Training: 2025-05-30 15:26:49,132-Speed 370.40 samples/sec   Loss 1.7055 Epoch: 32   Global Step: 65950   Required: 2 hours
Training: 2025-05-30 15:27:06,414-Speed 370.33 samples/sec   Loss 1.8660 Epoch: 32   Global Step: 66000   Required: 2 hours
Training: 2025-05-30 15:27:23,698-Speed 370.29 samples/sec   Loss 1.7377 Epoch: 32   Global Step: 66050   Required: 2 hours
Training: 2025-05-30 15:27:40,979-Speed 370.35 samples/sec   Loss 1.7435 Epoch: 32   Global Step: 66100   Required: 2 hours
Training: 2025-05-30 15:27:58,258-Speed 370.40 samples/sec   Loss 1.7737 Epoch: 32   Global Step: 66150   Required: 2 hours
Training: 2025-05-30 15:28:15,537-Speed 370.38 samples/sec   Loss 1.7156 Epoch: 32   Global Step: 66200   Required: 2 hours
Training: 2025-05-30 15:28:32,815-Speed 370.43 samples/sec   Loss 1.6389 Epoch: 32   Global Step: 66250   Required: 2 hours
Training: 2025-05-30 15:28:50,095-Speed 370.38 samples/sec   Loss 1.7006 Epoch: 32   Global Step: 66300   Required: 2 hours
Training: 2025-05-30 15:29:07,373-Speed 370.41 samples/sec   Loss 1.7690 Epoch: 32   Global Step: 66350   Required: 2 hours
Training: 2025-05-30 15:29:24,654-Speed 370.34 samples/sec   Loss 1.8093 Epoch: 32   Global Step: 66400   Required: 2 hours
Training: 2025-05-30 15:29:41,931-Speed 370.45 samples/sec   Loss 1.7064 Epoch: 32   Global Step: 66450   Required: 2 hours
Training: 2025-05-30 15:29:59,207-Speed 370.45 samples/sec   Loss 1.7506 Epoch: 32   Global Step: 66500   Required: 2 hours
Training: 2025-05-30 15:30:16,486-Speed 370.41 samples/sec   Loss 1.7818 Epoch: 32   Global Step: 66550   Required: 2 hours
Training: 2025-05-30 15:30:33,765-Speed 370.38 samples/sec   Loss 1.6959 Epoch: 32   Global Step: 66600   Required: 2 hours
Training: 2025-05-30 15:30:51,046-Speed 370.36 samples/sec   Loss 1.7946 Epoch: 32   Global Step: 66650   Required: 2 hours
Training: 2025-05-30 15:31:08,329-Speed 370.29 samples/sec   Loss 1.6090 Epoch: 32   Global Step: 66700   Required: 2 hours
Training: 2025-05-30 15:31:25,608-Speed 370.41 samples/sec   Loss 1.6635 Epoch: 32   Global Step: 66750   Required: 2 hours
Training: 2025-05-30 15:31:42,892-Speed 370.29 samples/sec   Loss 1.6949 Epoch: 32   Global Step: 66800   Required: 2 hours
Training: 2025-05-30 15:32:00,170-Speed 370.40 samples/sec   Loss 1.6927 Epoch: 32   Global Step: 66850   Required: 2 hours
Training: 2025-05-30 15:32:17,448-Speed 370.42 samples/sec   Loss 1.6355 Epoch: 32   Global Step: 66900   Required: 2 hours
Training: 2025-05-30 15:32:34,728-Speed 370.37 samples/sec   Loss 1.7684 Epoch: 32   Global Step: 66950   Required: 2 hours
Training: 2025-05-30 15:32:52,008-Speed 370.38 samples/sec   Loss 1.6502 Epoch: 32   Global Step: 67000   Required: 2 hours
Training: 2025-05-30 15:33:09,288-Speed 370.38 samples/sec   Loss 1.6978 Epoch: 32   Global Step: 67050   Required: 2 hours
Training: 2025-05-30 15:33:26,565-Speed 370.44 samples/sec   Loss 1.8895 Epoch: 32   Global Step: 67100   Required: 2 hours
Training: 2025-05-30 15:33:43,841-Speed 370.45 samples/sec   Loss 1.6711 Epoch: 32   Global Step: 67150   Required: 2 hours
Training: 2025-05-30 15:34:01,117-Speed 370.46 samples/sec   Loss 1.7539 Epoch: 32   Global Step: 67200   Required: 2 hours
Training: 2025-05-30 15:34:18,390-Speed 370.53 samples/sec   Loss 1.6985 Epoch: 32   Global Step: 67250   Required: 2 hours
Training: 2025-05-30 15:34:44,088-[lfw][67254]XNorm: 21.083829
Training: 2025-05-30 15:34:44,089-[lfw][67254]Accuracy-Flip: 0.99250+-0.00455
Training: 2025-05-30 15:34:44,089-[lfw][67254]Accuracy-Highest: 0.99350
Training: 2025-05-30 15:35:12,400-[cfp_fp][67254]XNorm: 19.147063
Training: 2025-05-30 15:35:12,400-[cfp_fp][67254]Accuracy-Flip: 0.93071+-0.01009
Training: 2025-05-30 15:35:12,400-[cfp_fp][67254]Accuracy-Highest: 0.93357
Training: 2025-05-30 15:35:36,709-[agedb_30][67254]XNorm: 21.196754
Training: 2025-05-30 15:35:36,709-[agedb_30][67254]Accuracy-Flip: 0.92583+-0.01440
Training: 2025-05-30 15:35:36,709-[agedb_30][67254]Accuracy-Highest: 0.93367
Training: 2025-05-30 15:36:01,096-[calfw][67254]XNorm: 20.601574
Training: 2025-05-30 15:36:01,096-[calfw][67254]Accuracy-Flip: 0.92700+-0.01120
Training: 2025-05-30 15:36:01,096-[calfw][67254]Accuracy-Highest: 0.93117
Training: 2025-05-30 15:36:25,472-[cplfw][67254]XNorm: 19.765109
Training: 2025-05-30 15:36:25,473-[cplfw][67254]Accuracy-Flip: 0.86967+-0.01424
Training: 2025-05-30 15:36:25,473-[cplfw][67254]Accuracy-Highest: 0.87700
Training: 2025-05-30 15:36:41,536-Speed 44.71 samples/sec   Loss 1.6547 Epoch: 33   Global Step: 67300   Required: 2 hours
Training: 2025-05-30 15:36:58,795-Speed 370.83 samples/sec   Loss 1.6662 Epoch: 33   Global Step: 67350   Required: 2 hours
Training: 2025-05-30 15:37:16,058-Speed 370.74 samples/sec   Loss 1.6014 Epoch: 33   Global Step: 67400   Required: 2 hours
Training: 2025-05-30 15:37:33,322-Speed 370.71 samples/sec   Loss 1.7257 Epoch: 33   Global Step: 67450   Required: 2 hours
Training: 2025-05-30 15:37:50,599-Speed 370.43 samples/sec   Loss 1.6099 Epoch: 33   Global Step: 67500   Required: 2 hours
Training: 2025-05-30 15:38:07,876-Speed 370.45 samples/sec   Loss 1.7011 Epoch: 33   Global Step: 67550   Required: 2 hours
Training: 2025-05-30 15:38:25,153-Speed 370.42 samples/sec   Loss 1.6787 Epoch: 33   Global Step: 67600   Required: 2 hours
Training: 2025-05-30 15:38:42,433-Speed 370.38 samples/sec   Loss 1.7006 Epoch: 33   Global Step: 67650   Required: 2 hours
Training: 2025-05-30 15:38:59,711-Speed 370.41 samples/sec   Loss 1.6421 Epoch: 33   Global Step: 67700   Required: 2 hours
Training: 2025-05-30 15:39:16,994-Speed 370.32 samples/sec   Loss 1.7279 Epoch: 33   Global Step: 67750   Required: 2 hours
Training: 2025-05-30 15:39:34,274-Speed 370.37 samples/sec   Loss 1.6693 Epoch: 33   Global Step: 67800   Required: 2 hours
Training: 2025-05-30 15:39:51,552-Speed 370.40 samples/sec   Loss 1.6226 Epoch: 33   Global Step: 67850   Required: 2 hours
Training: 2025-05-30 15:40:08,829-Speed 370.44 samples/sec   Loss 1.5160 Epoch: 33   Global Step: 67900   Required: 2 hours
Training: 2025-05-30 15:40:26,110-Speed 370.37 samples/sec   Loss 1.6867 Epoch: 33   Global Step: 67950   Required: 2 hours
Training: 2025-05-30 15:40:43,390-Speed 370.36 samples/sec   Loss 1.8323 Epoch: 33   Global Step: 68000   Required: 2 hours
Training: 2025-05-30 15:41:00,668-Speed 370.43 samples/sec   Loss 1.6926 Epoch: 33   Global Step: 68050   Required: 2 hours
Training: 2025-05-30 15:41:17,949-Speed 370.35 samples/sec   Loss 1.7446 Epoch: 33   Global Step: 68100   Required: 2 hours
Training: 2025-05-30 15:41:35,229-Speed 370.36 samples/sec   Loss 1.6783 Epoch: 33   Global Step: 68150   Required: 2 hours
Training: 2025-05-30 15:41:52,510-Speed 370.36 samples/sec   Loss 1.6133 Epoch: 33   Global Step: 68200   Required: 2 hours
Training: 2025-05-30 15:42:09,791-Speed 370.35 samples/sec   Loss 1.7204 Epoch: 33   Global Step: 68250   Required: 2 hours
Training: 2025-05-30 15:42:27,064-Speed 370.53 samples/sec   Loss 1.6333 Epoch: 33   Global Step: 68300   Required: 1 hours
Training: 2025-05-30 15:42:44,337-Speed 370.52 samples/sec   Loss 1.6571 Epoch: 33   Global Step: 68350   Required: 1 hours
Training: 2025-05-30 15:43:01,611-Speed 370.51 samples/sec   Loss 1.6697 Epoch: 33   Global Step: 68400   Required: 1 hours
Training: 2025-05-30 15:43:18,887-Speed 370.47 samples/sec   Loss 1.6881 Epoch: 33   Global Step: 68450   Required: 1 hours
Training: 2025-05-30 15:43:36,168-Speed 370.33 samples/sec   Loss 1.6913 Epoch: 33   Global Step: 68500   Required: 1 hours
Training: 2025-05-30 15:43:53,448-Speed 370.39 samples/sec   Loss 1.7647 Epoch: 33   Global Step: 68550   Required: 1 hours
Training: 2025-05-30 15:44:10,726-Speed 370.42 samples/sec   Loss 1.6154 Epoch: 33   Global Step: 68600   Required: 1 hours
Training: 2025-05-30 15:44:28,006-Speed 370.36 samples/sec   Loss 1.6580 Epoch: 33   Global Step: 68650   Required: 1 hours
Training: 2025-05-30 15:44:45,286-Speed 370.38 samples/sec   Loss 1.6670 Epoch: 33   Global Step: 68700   Required: 1 hours
Training: 2025-05-30 15:45:02,564-Speed 370.40 samples/sec   Loss 1.6958 Epoch: 33   Global Step: 68750   Required: 1 hours
Training: 2025-05-30 15:45:19,846-Speed 370.35 samples/sec   Loss 1.6113 Epoch: 33   Global Step: 68800   Required: 1 hours
Training: 2025-05-30 15:45:37,123-Speed 370.43 samples/sec   Loss 1.7135 Epoch: 33   Global Step: 68850   Required: 1 hours
Training: 2025-05-30 15:45:54,400-Speed 370.44 samples/sec   Loss 1.7517 Epoch: 33   Global Step: 68900   Required: 1 hours
Training: 2025-05-30 15:46:11,677-Speed 370.43 samples/sec   Loss 1.6732 Epoch: 33   Global Step: 68950   Required: 1 hours
Training: 2025-05-30 15:46:28,955-Speed 370.41 samples/sec   Loss 1.7125 Epoch: 33   Global Step: 69000   Required: 1 hours
Training: 2025-05-30 15:46:46,238-Speed 370.30 samples/sec   Loss 1.7233 Epoch: 33   Global Step: 69050   Required: 1 hours
Training: 2025-05-30 15:47:03,519-Speed 370.37 samples/sec   Loss 1.7092 Epoch: 33   Global Step: 69100   Required: 1 hours
Training: 2025-05-30 15:47:20,799-Speed 370.36 samples/sec   Loss 1.6506 Epoch: 33   Global Step: 69150   Required: 1 hours
Training: 2025-05-30 15:47:38,080-Speed 370.37 samples/sec   Loss 1.7602 Epoch: 33   Global Step: 69200   Required: 1 hours
Training: 2025-05-30 15:47:55,354-Speed 370.49 samples/sec   Loss 1.7071 Epoch: 33   Global Step: 69250   Required: 1 hours
Training: 2025-05-30 15:48:34,213-[lfw][69292]XNorm: 21.123871
Training: 2025-05-30 15:48:34,213-[lfw][69292]Accuracy-Flip: 0.99200+-0.00536
Training: 2025-05-30 15:48:34,213-[lfw][69292]Accuracy-Highest: 0.99350
Training: 2025-05-30 15:49:02,619-[cfp_fp][69292]XNorm: 19.214815
Training: 2025-05-30 15:49:02,619-[cfp_fp][69292]Accuracy-Flip: 0.93114+-0.01069
Training: 2025-05-30 15:49:02,619-[cfp_fp][69292]Accuracy-Highest: 0.93357
Training: 2025-05-30 15:49:26,932-[agedb_30][69292]XNorm: 21.247399
Training: 2025-05-30 15:49:26,933-[agedb_30][69292]Accuracy-Flip: 0.92883+-0.01551
Training: 2025-05-30 15:49:26,933-[agedb_30][69292]Accuracy-Highest: 0.93367
Training: 2025-05-30 15:49:51,336-[calfw][69292]XNorm: 20.650658
Training: 2025-05-30 15:49:51,336-[calfw][69292]Accuracy-Flip: 0.92483+-0.01149
Training: 2025-05-30 15:49:51,336-[calfw][69292]Accuracy-Highest: 0.93117
Training: 2025-05-30 15:50:15,730-[cplfw][69292]XNorm: 19.817784
Training: 2025-05-30 15:50:15,730-[cplfw][69292]Accuracy-Flip: 0.87217+-0.01556
Training: 2025-05-30 15:50:15,730-[cplfw][69292]Accuracy-Highest: 0.87700
Training: 2025-05-30 15:50:18,648-Speed 44.66 samples/sec   Loss 1.6878 Epoch: 34   Global Step: 69300   Required: 1 hours
Training: 2025-05-30 15:50:35,906-Speed 370.84 samples/sec   Loss 1.7025 Epoch: 34   Global Step: 69350   Required: 1 hours
Training: 2025-05-30 15:50:53,173-Speed 370.67 samples/sec   Loss 1.7304 Epoch: 34   Global Step: 69400   Required: 1 hours
Training: 2025-05-30 15:51:10,445-Speed 370.54 samples/sec   Loss 1.6230 Epoch: 34   Global Step: 69450   Required: 1 hours
Training: 2025-05-30 15:51:27,721-Speed 370.46 samples/sec   Loss 1.6241 Epoch: 34   Global Step: 69500   Required: 1 hours
Training: 2025-05-30 15:51:44,998-Speed 370.43 samples/sec   Loss 1.6292 Epoch: 34   Global Step: 69550   Required: 1 hours
Training: 2025-05-30 15:52:02,282-Speed 370.30 samples/sec   Loss 1.6008 Epoch: 34   Global Step: 69600   Required: 1 hours
Training: 2025-05-30 15:52:19,562-Speed 370.36 samples/sec   Loss 1.6820 Epoch: 34   Global Step: 69650   Required: 1 hours
Training: 2025-05-30 15:52:36,846-Speed 370.29 samples/sec   Loss 1.6351 Epoch: 34   Global Step: 69700   Required: 1 hours
Training: 2025-05-30 15:52:54,125-Speed 370.41 samples/sec   Loss 1.5582 Epoch: 34   Global Step: 69750   Required: 1 hours
Training: 2025-05-30 15:53:11,402-Speed 370.43 samples/sec   Loss 1.7046 Epoch: 34   Global Step: 69800   Required: 1 hours
Training: 2025-05-30 15:53:28,680-Speed 370.42 samples/sec   Loss 1.6456 Epoch: 34   Global Step: 69850   Required: 1 hours
Training: 2025-05-30 15:53:45,956-Speed 370.46 samples/sec   Loss 1.6370 Epoch: 34   Global Step: 69900   Required: 1 hours
Training: 2025-05-30 15:54:03,236-Speed 370.38 samples/sec   Loss 1.7265 Epoch: 34   Global Step: 69950   Required: 1 hours
Training: 2025-05-30 15:54:20,513-Speed 370.44 samples/sec   Loss 1.6379 Epoch: 34   Global Step: 70000   Required: 1 hours
Training: 2025-05-30 15:54:37,788-Speed 370.48 samples/sec   Loss 1.5811 Epoch: 34   Global Step: 70050   Required: 1 hours
Training: 2025-05-30 15:54:55,064-Speed 370.45 samples/sec   Loss 1.6397 Epoch: 34   Global Step: 70100   Required: 1 hours
Training: 2025-05-30 15:55:12,343-Speed 370.39 samples/sec   Loss 1.7400 Epoch: 34   Global Step: 70150   Required: 1 hours
Training: 2025-05-30 15:55:29,622-Speed 370.41 samples/sec   Loss 1.6229 Epoch: 34   Global Step: 70200   Required: 1 hours
Training: 2025-05-30 15:55:46,901-Speed 370.40 samples/sec   Loss 1.7514 Epoch: 34   Global Step: 70250   Required: 1 hours
Training: 2025-05-30 15:56:04,183-Speed 370.32 samples/sec   Loss 1.6496 Epoch: 34   Global Step: 70300   Required: 1 hours
Training: 2025-05-30 15:56:21,464-Speed 370.35 samples/sec   Loss 1.5882 Epoch: 34   Global Step: 70350   Required: 1 hours
Training: 2025-05-30 15:56:38,743-Speed 370.40 samples/sec   Loss 1.6217 Epoch: 34   Global Step: 70400   Required: 1 hours
Training: 2025-05-30 15:56:56,024-Speed 370.34 samples/sec   Loss 1.6760 Epoch: 34   Global Step: 70450   Required: 1 hours
Training: 2025-05-30 15:57:13,305-Speed 370.35 samples/sec   Loss 1.5850 Epoch: 34   Global Step: 70500   Required: 1 hours
Training: 2025-05-30 15:57:30,586-Speed 370.36 samples/sec   Loss 1.7047 Epoch: 34   Global Step: 70550   Required: 1 hours
Training: 2025-05-30 15:57:47,870-Speed 370.29 samples/sec   Loss 1.6533 Epoch: 34   Global Step: 70600   Required: 1 hours
Training: 2025-05-30 15:58:05,150-Speed 370.37 samples/sec   Loss 1.5947 Epoch: 34   Global Step: 70650   Required: 1 hours
Training: 2025-05-30 15:58:22,428-Speed 370.42 samples/sec   Loss 1.6197 Epoch: 34   Global Step: 70700   Required: 1 hours
Training: 2025-05-30 15:58:39,701-Speed 370.53 samples/sec   Loss 1.6947 Epoch: 34   Global Step: 70750   Required: 1 hours
Training: 2025-05-30 15:58:56,976-Speed 370.47 samples/sec   Loss 1.6639 Epoch: 34   Global Step: 70800   Required: 1 hours
Training: 2025-05-30 15:59:14,255-Speed 370.41 samples/sec   Loss 1.5937 Epoch: 34   Global Step: 70850   Required: 1 hours
Training: 2025-05-30 15:59:31,529-Speed 370.50 samples/sec   Loss 1.7036 Epoch: 34   Global Step: 70900   Required: 1 hours
Training: 2025-05-30 15:59:48,808-Speed 370.39 samples/sec   Loss 1.5988 Epoch: 34   Global Step: 70950   Required: 1 hours
Training: 2025-05-30 16:00:06,090-Speed 370.31 samples/sec   Loss 1.6366 Epoch: 34   Global Step: 71000   Required: 1 hours
Training: 2025-05-30 16:00:23,370-Speed 370.39 samples/sec   Loss 1.6689 Epoch: 34   Global Step: 71050   Required: 1 hours
Training: 2025-05-30 16:00:40,647-Speed 370.42 samples/sec   Loss 1.6341 Epoch: 34   Global Step: 71100   Required: 1 hours
Training: 2025-05-30 16:00:57,922-Speed 370.49 samples/sec   Loss 1.5899 Epoch: 34   Global Step: 71150   Required: 1 hours
Training: 2025-05-30 16:01:15,200-Speed 370.41 samples/sec   Loss 1.6508 Epoch: 34   Global Step: 71200   Required: 1 hours
Training: 2025-05-30 16:01:32,475-Speed 370.48 samples/sec   Loss 1.5836 Epoch: 34   Global Step: 71250   Required: 1 hours
Training: 2025-05-30 16:01:49,754-Speed 370.39 samples/sec   Loss 1.6450 Epoch: 34   Global Step: 71300   Required: 1 hours
Training: 2025-05-30 16:02:24,441-[lfw][71330]XNorm: 21.018699
Training: 2025-05-30 16:02:24,441-[lfw][71330]Accuracy-Flip: 0.99083+-0.00554
Training: 2025-05-30 16:02:24,441-[lfw][71330]Accuracy-Highest: 0.99350
Training: 2025-05-30 16:02:52,693-[cfp_fp][71330]XNorm: 19.129043
Training: 2025-05-30 16:02:52,693-[cfp_fp][71330]Accuracy-Flip: 0.92857+-0.00998
Training: 2025-05-30 16:02:52,693-[cfp_fp][71330]Accuracy-Highest: 0.93357
Training: 2025-05-30 16:03:17,004-[agedb_30][71330]XNorm: 21.167648
Training: 2025-05-30 16:03:17,004-[agedb_30][71330]Accuracy-Flip: 0.92567+-0.01567
Training: 2025-05-30 16:03:17,004-[agedb_30][71330]Accuracy-Highest: 0.93367
Training: 2025-05-30 16:03:41,393-[calfw][71330]XNorm: 20.538827
Training: 2025-05-30 16:03:41,393-[calfw][71330]Accuracy-Flip: 0.92300+-0.01166
Training: 2025-05-30 16:03:41,393-[calfw][71330]Accuracy-Highest: 0.93117
Training: 2025-05-30 16:04:05,774-[cplfw][71330]XNorm: 19.731786
Training: 2025-05-30 16:04:05,774-[cplfw][71330]Accuracy-Flip: 0.86867+-0.01645
Training: 2025-05-30 16:04:05,774-[cplfw][71330]Accuracy-Highest: 0.87700
Training: 2025-05-30 16:04:12,833-Speed 44.73 samples/sec   Loss 1.6209 Epoch: 35   Global Step: 71350   Required: 1 hours
Training: 2025-05-30 16:04:30,096-Speed 370.74 samples/sec   Loss 1.5310 Epoch: 35   Global Step: 71400   Required: 1 hours
Training: 2025-05-30 16:04:47,366-Speed 370.59 samples/sec   Loss 1.6051 Epoch: 35   Global Step: 71450   Required: 1 hours
Training: 2025-05-30 16:05:04,632-Speed 370.67 samples/sec   Loss 1.6383 Epoch: 35   Global Step: 71500   Required: 1 hours
Training: 2025-05-30 16:05:21,904-Speed 370.55 samples/sec   Loss 1.5274 Epoch: 35   Global Step: 71550   Required: 1 hours
Training: 2025-05-30 16:05:39,178-Speed 370.52 samples/sec   Loss 1.5681 Epoch: 35   Global Step: 71600   Required: 1 hours
Training: 2025-05-30 16:05:56,453-Speed 370.47 samples/sec   Loss 1.5785 Epoch: 35   Global Step: 71650   Required: 1 hours
Training: 2025-05-30 16:06:13,729-Speed 370.46 samples/sec   Loss 1.6375 Epoch: 35   Global Step: 71700   Required: 1 hours
Training: 2025-05-30 16:06:31,006-Speed 370.44 samples/sec   Loss 1.4912 Epoch: 35   Global Step: 71750   Required: 1 hours
Training: 2025-05-30 16:06:48,310-Speed 370.47 samples/sec   Loss 1.6659 Epoch: 35   Global Step: 71800   Required: 1 hours
Training: 2025-05-30 16:07:05,590-Speed 370.37 samples/sec   Loss 1.5585 Epoch: 35   Global Step: 71850   Required: 1 hours
Training: 2025-05-30 16:07:22,869-Speed 370.40 samples/sec   Loss 1.6583 Epoch: 35   Global Step: 71900   Required: 1 hours
Training: 2025-05-30 16:07:40,150-Speed 370.34 samples/sec   Loss 1.6030 Epoch: 35   Global Step: 71950   Required: 1 hours
Training: 2025-05-30 16:07:57,427-Speed 370.45 samples/sec   Loss 1.6244 Epoch: 35   Global Step: 72000   Required: 1 hours
Training: 2025-05-30 16:08:14,702-Speed 370.48 samples/sec   Loss 1.6325 Epoch: 35   Global Step: 72050   Required: 1 hours
Training: 2025-05-30 16:08:31,972-Speed 370.59 samples/sec   Loss 1.5929 Epoch: 35   Global Step: 72100   Required: 1 hours
Training: 2025-05-30 16:08:49,244-Speed 370.54 samples/sec   Loss 1.5235 Epoch: 35   Global Step: 72150   Required: 1 hours
Training: 2025-05-30 16:09:06,519-Speed 370.48 samples/sec   Loss 1.6266 Epoch: 35   Global Step: 72200   Required: 1 hours
Training: 2025-05-30 16:09:23,799-Speed 370.38 samples/sec   Loss 1.5139 Epoch: 35   Global Step: 72250   Required: 1 hours
Training: 2025-05-30 16:09:41,074-Speed 370.47 samples/sec   Loss 1.5305 Epoch: 35   Global Step: 72300   Required: 1 hours
Training: 2025-05-30 16:09:58,349-Speed 370.48 samples/sec   Loss 1.6057 Epoch: 35   Global Step: 72350   Required: 1 hours
Training: 2025-05-30 16:10:15,624-Speed 370.47 samples/sec   Loss 1.4873 Epoch: 35   Global Step: 72400   Required: 1 hours
Training: 2025-05-30 16:10:32,897-Speed 370.53 samples/sec   Loss 1.5918 Epoch: 35   Global Step: 72450   Required: 1 hours
Training: 2025-05-30 16:10:50,170-Speed 370.53 samples/sec   Loss 1.5645 Epoch: 35   Global Step: 72500   Required: 1 hours
Training: 2025-05-30 16:11:07,444-Speed 370.49 samples/sec   Loss 1.5684 Epoch: 35   Global Step: 72550   Required: 1 hours
Training: 2025-05-30 16:11:24,719-Speed 370.49 samples/sec   Loss 1.5417 Epoch: 35   Global Step: 72600   Required: 1 hours
Training: 2025-05-30 16:11:41,995-Speed 370.46 samples/sec   Loss 1.5396 Epoch: 35   Global Step: 72650   Required: 1 hours
Training: 2025-05-30 16:11:59,267-Speed 370.54 samples/sec   Loss 1.6434 Epoch: 35   Global Step: 72700   Required: 1 hours
Training: 2025-05-30 16:12:16,548-Speed 370.37 samples/sec   Loss 1.5215 Epoch: 35   Global Step: 72750   Required: 1 hours
Training: 2025-05-30 16:12:33,827-Speed 370.38 samples/sec   Loss 1.4710 Epoch: 35   Global Step: 72800   Required: 1 hours
Training: 2025-05-30 16:12:51,103-Speed 370.46 samples/sec   Loss 1.6096 Epoch: 35   Global Step: 72850   Required: 1 hours
Training: 2025-05-30 16:13:08,378-Speed 370.49 samples/sec   Loss 1.6432 Epoch: 35   Global Step: 72900   Required: 1 hours
Training: 2025-05-30 16:13:25,650-Speed 370.53 samples/sec   Loss 1.6270 Epoch: 35   Global Step: 72950   Required: 1 hours
Training: 2025-05-30 16:13:42,922-Speed 370.55 samples/sec   Loss 1.6662 Epoch: 35   Global Step: 73000   Required: 1 hours
Training: 2025-05-30 16:14:00,195-Speed 370.53 samples/sec   Loss 1.5102 Epoch: 35   Global Step: 73050   Required: 1 hours
Training: 2025-05-30 16:14:17,468-Speed 370.52 samples/sec   Loss 1.5339 Epoch: 35   Global Step: 73100   Required: 1 hours
Training: 2025-05-30 16:14:34,744-Speed 370.45 samples/sec   Loss 1.6388 Epoch: 35   Global Step: 73150   Required: 1 hours
Training: 2025-05-30 16:14:52,015-Speed 370.57 samples/sec   Loss 1.5280 Epoch: 35   Global Step: 73200   Required: 1 hours
Training: 2025-05-30 16:15:09,284-Speed 370.60 samples/sec   Loss 1.5325 Epoch: 35   Global Step: 73250   Required: 1 hours
Training: 2025-05-30 16:15:26,553-Speed 370.63 samples/sec   Loss 1.6154 Epoch: 35   Global Step: 73300   Required: 1 hours
Training: 2025-05-30 16:15:43,828-Speed 370.48 samples/sec   Loss 1.6796 Epoch: 35   Global Step: 73350   Required: 1 hours
Training: 2025-05-30 16:16:14,363-[lfw][73368]XNorm: 20.903715
Training: 2025-05-30 16:16:14,363-[lfw][73368]Accuracy-Flip: 0.99017+-0.00580
Training: 2025-05-30 16:16:14,363-[lfw][73368]Accuracy-Highest: 0.99350
Training: 2025-05-30 16:16:42,597-[cfp_fp][73368]XNorm: 19.036884
Training: 2025-05-30 16:16:42,597-[cfp_fp][73368]Accuracy-Flip: 0.93186+-0.00935
Training: 2025-05-30 16:16:42,597-[cfp_fp][73368]Accuracy-Highest: 0.93357
Training: 2025-05-30 16:17:06,903-[agedb_30][73368]XNorm: 21.060717
Training: 2025-05-30 16:17:06,904-[agedb_30][73368]Accuracy-Flip: 0.92567+-0.01356
Training: 2025-05-30 16:17:06,904-[agedb_30][73368]Accuracy-Highest: 0.93367
Training: 2025-05-30 16:17:31,287-[calfw][73368]XNorm: 20.437778
Training: 2025-05-30 16:17:31,287-[calfw][73368]Accuracy-Flip: 0.92400+-0.01106
Training: 2025-05-30 16:17:31,287-[calfw][73368]Accuracy-Highest: 0.93117
Training: 2025-05-30 16:17:55,662-[cplfw][73368]XNorm: 19.643138
Training: 2025-05-30 16:17:55,663-[cplfw][73368]Accuracy-Flip: 0.87150+-0.01656
Training: 2025-05-30 16:17:55,663-[cplfw][73368]Accuracy-Highest: 0.87700
Training: 2025-05-30 16:18:06,855-Speed 44.75 samples/sec   Loss 1.5738 Epoch: 36   Global Step: 73400   Required: 1 hours
Training: 2025-05-30 16:18:24,114-Speed 370.82 samples/sec   Loss 1.6663 Epoch: 36   Global Step: 73450   Required: 1 hours
Training: 2025-05-30 16:18:41,381-Speed 370.65 samples/sec   Loss 1.5558 Epoch: 36   Global Step: 73500   Required: 1 hours
Training: 2025-05-30 16:18:58,651-Speed 370.60 samples/sec   Loss 1.6696 Epoch: 36   Global Step: 73550   Required: 1 hours
Training: 2025-05-30 16:19:15,925-Speed 370.50 samples/sec   Loss 1.5686 Epoch: 36   Global Step: 73600   Required: 1 hours
Training: 2025-05-30 16:19:33,203-Speed 370.40 samples/sec   Loss 1.5354 Epoch: 36   Global Step: 73650   Required: 1 hours
Training: 2025-05-30 16:19:50,481-Speed 370.41 samples/sec   Loss 1.5177 Epoch: 36   Global Step: 73700   Required: 1 hours
Training: 2025-05-30 16:20:07,762-Speed 370.35 samples/sec   Loss 1.4801 Epoch: 36   Global Step: 73750   Required: 1 hours
Training: 2025-05-30 16:20:25,048-Speed 370.25 samples/sec   Loss 1.5213 Epoch: 36   Global Step: 73800   Required: 1 hours
Training: 2025-05-30 16:20:42,325-Speed 370.43 samples/sec   Loss 1.4607 Epoch: 36   Global Step: 73850   Required: 1 hours
Training: 2025-05-30 16:20:59,607-Speed 370.35 samples/sec   Loss 1.6491 Epoch: 36   Global Step: 73900   Required: 1 hours
Training: 2025-05-30 16:21:16,886-Speed 370.38 samples/sec   Loss 1.6111 Epoch: 36   Global Step: 73950   Required: 1 hours
Training: 2025-05-30 16:21:34,162-Speed 370.46 samples/sec   Loss 1.5877 Epoch: 36   Global Step: 74000   Required: 1 hours
Training: 2025-05-30 16:21:51,436-Speed 370.50 samples/sec   Loss 1.6141 Epoch: 36   Global Step: 74050   Required: 1 hours
Training: 2025-05-30 16:22:08,716-Speed 370.39 samples/sec   Loss 1.6653 Epoch: 36   Global Step: 74100   Required: 1 hours
Training: 2025-05-30 16:22:25,993-Speed 370.42 samples/sec   Loss 1.4850 Epoch: 36   Global Step: 74150   Required: 1 hours
Training: 2025-05-30 16:22:43,274-Speed 370.36 samples/sec   Loss 1.6081 Epoch: 36   Global Step: 74200   Required: 1 hours
Training: 2025-05-30 16:23:00,552-Speed 370.41 samples/sec   Loss 1.5601 Epoch: 36   Global Step: 74250   Required: 1 hours
Training: 2025-05-30 16:23:17,831-Speed 370.39 samples/sec   Loss 1.5430 Epoch: 36   Global Step: 74300   Required: 1 hours
Training: 2025-05-30 16:23:35,109-Speed 370.43 samples/sec   Loss 1.5569 Epoch: 36   Global Step: 74350   Required: 1 hours
Training: 2025-05-30 16:23:52,387-Speed 370.41 samples/sec   Loss 1.5685 Epoch: 36   Global Step: 74400   Required: 1 hours
Training: 2025-05-30 16:24:09,664-Speed 370.45 samples/sec   Loss 1.4788 Epoch: 36   Global Step: 74450   Required: 1 hours
Training: 2025-05-30 16:24:26,942-Speed 370.42 samples/sec   Loss 1.6010 Epoch: 36   Global Step: 74500   Required: 1 hours
Training: 2025-05-30 16:24:44,222-Speed 370.37 samples/sec   Loss 1.5215 Epoch: 36   Global Step: 74550   Required: 1 hours
Training: 2025-05-30 16:25:01,499-Speed 370.44 samples/sec   Loss 1.6496 Epoch: 36   Global Step: 74600   Required: 1 hours
Training: 2025-05-30 16:25:18,773-Speed 370.49 samples/sec   Loss 1.5966 Epoch: 36   Global Step: 74650   Required: 1 hours
Training: 2025-05-30 16:25:36,048-Speed 370.48 samples/sec   Loss 1.5795 Epoch: 36   Global Step: 74700   Required: 1 hours
Training: 2025-05-30 16:25:53,325-Speed 370.44 samples/sec   Loss 1.5477 Epoch: 36   Global Step: 74750   Required: 1 hours
Training: 2025-05-30 16:26:10,602-Speed 370.44 samples/sec   Loss 1.5700 Epoch: 36   Global Step: 74800   Required: 1 hours
Training: 2025-05-30 16:26:27,879-Speed 370.45 samples/sec   Loss 1.6194 Epoch: 36   Global Step: 74850   Required: 1 hours
Training: 2025-05-30 16:26:45,158-Speed 370.39 samples/sec   Loss 1.5602 Epoch: 36   Global Step: 74900   Required: 1 hours
Training: 2025-05-30 16:27:02,438-Speed 370.37 samples/sec   Loss 1.4962 Epoch: 36   Global Step: 74950   Required: 1 hours
Training: 2025-05-30 16:27:19,714-Speed 370.46 samples/sec   Loss 1.5198 Epoch: 36   Global Step: 75000   Required: 1 hours
Training: 2025-05-30 16:27:36,994-Speed 370.37 samples/sec   Loss 1.6474 Epoch: 36   Global Step: 75050   Required: 1 hours
Training: 2025-05-30 16:27:54,273-Speed 370.40 samples/sec   Loss 1.4815 Epoch: 36   Global Step: 75100   Required: 1 hours
Training: 2025-05-30 16:28:11,557-Speed 370.28 samples/sec   Loss 1.5110 Epoch: 36   Global Step: 75150   Required: 1 hours
Training: 2025-05-30 16:28:28,838-Speed 370.35 samples/sec   Loss 1.5857 Epoch: 36   Global Step: 75200   Required: 1 hours
Training: 2025-05-30 16:28:46,119-Speed 370.35 samples/sec   Loss 1.6638 Epoch: 36   Global Step: 75250   Required: 1 hours
Training: 2025-05-30 16:29:03,401-Speed 370.35 samples/sec   Loss 1.5748 Epoch: 36   Global Step: 75300   Required: 1 hours
Training: 2025-05-30 16:29:20,676-Speed 370.47 samples/sec   Loss 1.6680 Epoch: 36   Global Step: 75350   Required: 1 hours
Training: 2025-05-30 16:29:37,950-Speed 370.49 samples/sec   Loss 1.5552 Epoch: 36   Global Step: 75400   Required: 1 hours
Training: 2025-05-30 16:30:04,345-[lfw][75406]XNorm: 20.962393
Training: 2025-05-30 16:30:04,345-[lfw][75406]Accuracy-Flip: 0.99150+-0.00474
Training: 2025-05-30 16:30:04,346-[lfw][75406]Accuracy-Highest: 0.99350
Training: 2025-05-30 16:30:32,772-[cfp_fp][75406]XNorm: 19.100220
Training: 2025-05-30 16:30:32,772-[cfp_fp][75406]Accuracy-Flip: 0.92914+-0.00935
Training: 2025-05-30 16:30:32,772-[cfp_fp][75406]Accuracy-Highest: 0.93357
Training: 2025-05-30 16:30:57,082-[agedb_30][75406]XNorm: 21.107319
Training: 2025-05-30 16:30:57,082-[agedb_30][75406]Accuracy-Flip: 0.92917+-0.01243
Training: 2025-05-30 16:30:57,082-[agedb_30][75406]Accuracy-Highest: 0.93367
Training: 2025-05-30 16:31:21,481-[calfw][75406]XNorm: 20.487675
Training: 2025-05-30 16:31:21,482-[calfw][75406]Accuracy-Flip: 0.92567+-0.01123
Training: 2025-05-30 16:31:21,482-[calfw][75406]Accuracy-Highest: 0.93117
Training: 2025-05-30 16:31:45,862-[cplfw][75406]XNorm: 19.713081
Training: 2025-05-30 16:31:45,862-[cplfw][75406]Accuracy-Flip: 0.87083+-0.01667
Training: 2025-05-30 16:31:45,862-[cplfw][75406]Accuracy-Highest: 0.87700
Training: 2025-05-30 16:32:01,197-Speed 44.68 samples/sec   Loss 1.5911 Epoch: 37   Global Step: 75450   Required: 1 hours
Training: 2025-05-30 16:32:18,465-Speed 370.65 samples/sec   Loss 1.3698 Epoch: 37   Global Step: 75500   Required: 1 hours
Training: 2025-05-30 16:32:35,734-Speed 370.59 samples/sec   Loss 1.5155 Epoch: 37   Global Step: 75550   Required: 1 hours
Training: 2025-05-30 16:32:53,007-Speed 370.53 samples/sec   Loss 1.5109 Epoch: 37   Global Step: 75600   Required: 1 hours
Training: 2025-05-30 16:33:10,285-Speed 370.42 samples/sec   Loss 1.5356 Epoch: 37   Global Step: 75650   Required: 1 hours
Training: 2025-05-30 16:33:27,566-Speed 370.34 samples/sec   Loss 1.5544 Epoch: 37   Global Step: 75700   Required: 1 hours
Training: 2025-05-30 16:33:44,845-Speed 370.40 samples/sec   Loss 1.5711 Epoch: 37   Global Step: 75750   Required: 1 hours
Training: 2025-05-30 16:34:02,123-Speed 370.42 samples/sec   Loss 1.5150 Epoch: 37   Global Step: 75800   Required: 1 hours
Training: 2025-05-30 16:34:19,402-Speed 370.39 samples/sec   Loss 1.6115 Epoch: 37   Global Step: 75850   Required: 1 hours
Training: 2025-05-30 16:34:36,683-Speed 370.34 samples/sec   Loss 1.5985 Epoch: 37   Global Step: 75900   Required: 1 hours
Training: 2025-05-30 16:34:53,965-Speed 370.34 samples/sec   Loss 1.5995 Epoch: 37   Global Step: 75950   Required: 1 hours
Training: 2025-05-30 16:35:11,247-Speed 370.33 samples/sec   Loss 1.5078 Epoch: 37   Global Step: 76000   Required: 1 hours
Training: 2025-05-30 16:35:28,533-Speed 370.25 samples/sec   Loss 1.5004 Epoch: 37   Global Step: 76050   Required: 1 hours
Training: 2025-05-30 16:35:45,818-Speed 370.26 samples/sec   Loss 1.5736 Epoch: 37   Global Step: 76100   Required: 1 hours
Training: 2025-05-30 16:36:03,099-Speed 370.36 samples/sec   Loss 1.5764 Epoch: 37   Global Step: 76150   Required: 1 hours
Training: 2025-05-30 16:36:20,384-Speed 370.26 samples/sec   Loss 1.6126 Epoch: 37   Global Step: 76200   Required: 1 hours
Training: 2025-05-30 16:36:37,665-Speed 370.34 samples/sec   Loss 1.5905 Epoch: 37   Global Step: 76250   Required: 1 hours
Training: 2025-05-30 16:36:54,940-Speed 370.50 samples/sec   Loss 1.6514 Epoch: 37   Global Step: 76300   Required: 1 hours
Training: 2025-05-30 16:37:12,219-Speed 370.38 samples/sec   Loss 1.5409 Epoch: 37   Global Step: 76350   Required: 1 hours
Training: 2025-05-30 16:37:29,496-Speed 370.45 samples/sec   Loss 1.5347 Epoch: 37   Global Step: 76400   Required: 1 hours
Training: 2025-05-30 16:37:46,774-Speed 370.41 samples/sec   Loss 1.5568 Epoch: 37   Global Step: 76450   Required: 1 hours
Training: 2025-05-30 16:38:04,049-Speed 370.47 samples/sec   Loss 1.4819 Epoch: 37   Global Step: 76500   Required: 1 hours
Training: 2025-05-30 16:38:21,327-Speed 370.43 samples/sec   Loss 1.6225 Epoch: 37   Global Step: 76550   Required: 1 hours
Training: 2025-05-30 16:38:38,599-Speed 370.53 samples/sec   Loss 1.6233 Epoch: 37   Global Step: 76600   Required: 1 hours
Training: 2025-05-30 16:38:55,874-Speed 370.50 samples/sec   Loss 1.6104 Epoch: 37   Global Step: 76650   Required: 1 hours
Training: 2025-05-30 16:39:13,152-Speed 370.40 samples/sec   Loss 1.5119 Epoch: 37   Global Step: 76700   Required: 1 hours
Training: 2025-05-30 16:39:30,427-Speed 370.49 samples/sec   Loss 1.5239 Epoch: 37   Global Step: 76750   Required: 1 hours
Training: 2025-05-30 16:39:47,700-Speed 370.52 samples/sec   Loss 1.4895 Epoch: 37   Global Step: 76800   Required: 1 hours
Training: 2025-05-30 16:40:04,974-Speed 370.51 samples/sec   Loss 1.5903 Epoch: 37   Global Step: 76850   Required: 1 hours
Training: 2025-05-30 16:40:22,253-Speed 370.40 samples/sec   Loss 1.5586 Epoch: 37   Global Step: 76900   Required: 1 hours
Training: 2025-05-30 16:40:39,529-Speed 370.45 samples/sec   Loss 1.6397 Epoch: 37   Global Step: 76950   Required: 1 hours
Training: 2025-05-30 16:40:56,805-Speed 370.47 samples/sec   Loss 1.5477 Epoch: 37   Global Step: 77000   Required: 1 hours
Training: 2025-05-30 16:41:14,078-Speed 370.52 samples/sec   Loss 1.6250 Epoch: 37   Global Step: 77050   Required: 1 hours
Training: 2025-05-30 16:41:31,354-Speed 370.45 samples/sec   Loss 1.6301 Epoch: 37   Global Step: 77100   Required: 1 hours
Training: 2025-05-30 16:41:48,630-Speed 370.47 samples/sec   Loss 1.6289 Epoch: 37   Global Step: 77150   Required: 0 hours
Training: 2025-05-30 16:42:05,904-Speed 370.50 samples/sec   Loss 1.6248 Epoch: 37   Global Step: 77200   Required: 0 hours
Training: 2025-05-30 16:42:23,178-Speed 370.50 samples/sec   Loss 1.6192 Epoch: 37   Global Step: 77250   Required: 0 hours
Training: 2025-05-30 16:42:40,449-Speed 370.57 samples/sec   Loss 1.6340 Epoch: 37   Global Step: 77300   Required: 0 hours
Training: 2025-05-30 16:42:57,721-Speed 370.53 samples/sec   Loss 1.5365 Epoch: 37   Global Step: 77350   Required: 0 hours
Training: 2025-05-30 16:43:14,995-Speed 370.51 samples/sec   Loss 1.6308 Epoch: 37   Global Step: 77400   Required: 0 hours
Training: 2025-05-30 16:43:54,513-[lfw][77444]XNorm: 20.981032
Training: 2025-05-30 16:43:54,513-[lfw][77444]Accuracy-Flip: 0.99100+-0.00544
Training: 2025-05-30 16:43:54,513-[lfw][77444]Accuracy-Highest: 0.99350
Training: 2025-05-30 16:44:22,754-[cfp_fp][77444]XNorm: 19.117432
Training: 2025-05-30 16:44:22,754-[cfp_fp][77444]Accuracy-Flip: 0.93129+-0.00966
Training: 2025-05-30 16:44:22,754-[cfp_fp][77444]Accuracy-Highest: 0.93357
Training: 2025-05-30 16:44:47,056-[agedb_30][77444]XNorm: 21.127960
Training: 2025-05-30 16:44:47,056-[agedb_30][77444]Accuracy-Flip: 0.92633+-0.01337
Training: 2025-05-30 16:44:47,057-[agedb_30][77444]Accuracy-Highest: 0.93367
Training: 2025-05-30 16:45:11,443-[calfw][77444]XNorm: 20.509307
Training: 2025-05-30 16:45:11,444-[calfw][77444]Accuracy-Flip: 0.92517+-0.01117
Training: 2025-05-30 16:45:11,444-[calfw][77444]Accuracy-Highest: 0.93117
Training: 2025-05-30 16:45:35,820-[cplfw][77444]XNorm: 19.727492
Training: 2025-05-30 16:45:35,820-[cplfw][77444]Accuracy-Flip: 0.87150+-0.01667
Training: 2025-05-30 16:45:35,820-[cplfw][77444]Accuracy-Highest: 0.87700
Training: 2025-05-30 16:45:38,043-Speed 44.74 samples/sec   Loss 1.5305 Epoch: 38   Global Step: 77450   Required: 0 hours
Training: 2025-05-30 16:45:55,293-Speed 371.03 samples/sec   Loss 1.4700 Epoch: 38   Global Step: 77500   Required: 0 hours
Training: 2025-05-30 16:46:12,547-Speed 370.92 samples/sec   Loss 1.4717 Epoch: 38   Global Step: 77550   Required: 0 hours
Training: 2025-05-30 16:46:29,806-Speed 370.82 samples/sec   Loss 1.5973 Epoch: 38   Global Step: 77600   Required: 0 hours
Training: 2025-05-30 16:46:47,071-Speed 370.70 samples/sec   Loss 1.5557 Epoch: 38   Global Step: 77650   Required: 0 hours
Training: 2025-05-30 16:47:04,340-Speed 370.61 samples/sec   Loss 1.5958 Epoch: 38   Global Step: 77700   Required: 0 hours
Training: 2025-05-30 16:47:21,615-Speed 370.49 samples/sec   Loss 1.6204 Epoch: 38   Global Step: 77750   Required: 0 hours
Training: 2025-05-30 16:47:38,892-Speed 370.44 samples/sec   Loss 1.5407 Epoch: 38   Global Step: 77800   Required: 0 hours
Training: 2025-05-30 16:47:56,170-Speed 370.41 samples/sec   Loss 1.5214 Epoch: 38   Global Step: 77850   Required: 0 hours
Training: 2025-05-30 16:48:13,449-Speed 370.41 samples/sec   Loss 1.7096 Epoch: 38   Global Step: 77900   Required: 0 hours
Training: 2025-05-30 16:48:30,724-Speed 370.47 samples/sec   Loss 1.5631 Epoch: 38   Global Step: 77950   Required: 0 hours
Training: 2025-05-30 16:48:48,003-Speed 370.38 samples/sec   Loss 1.6057 Epoch: 38   Global Step: 78000   Required: 0 hours
Training: 2025-05-30 16:49:05,282-Speed 370.40 samples/sec   Loss 1.5583 Epoch: 38   Global Step: 78050   Required: 0 hours
Training: 2025-05-30 16:49:22,560-Speed 370.42 samples/sec   Loss 1.5483 Epoch: 38   Global Step: 78100   Required: 0 hours
Training: 2025-05-30 16:49:39,836-Speed 370.46 samples/sec   Loss 1.5688 Epoch: 38   Global Step: 78150   Required: 0 hours
Training: 2025-05-30 16:49:57,119-Speed 370.31 samples/sec   Loss 1.6429 Epoch: 38   Global Step: 78200   Required: 0 hours
Training: 2025-05-30 16:50:14,398-Speed 370.40 samples/sec   Loss 1.4939 Epoch: 38   Global Step: 78250   Required: 0 hours
Training: 2025-05-30 16:50:31,676-Speed 370.40 samples/sec   Loss 1.5375 Epoch: 38   Global Step: 78300   Required: 0 hours
Training: 2025-05-30 16:50:48,950-Speed 370.50 samples/sec   Loss 1.5749 Epoch: 38   Global Step: 78350   Required: 0 hours
Training: 2025-05-30 16:51:06,232-Speed 370.35 samples/sec   Loss 1.5415 Epoch: 38   Global Step: 78400   Required: 0 hours
Training: 2025-05-30 16:51:23,507-Speed 370.47 samples/sec   Loss 1.6627 Epoch: 38   Global Step: 78450   Required: 0 hours
Training: 2025-05-30 16:51:40,782-Speed 370.47 samples/sec   Loss 1.5281 Epoch: 38   Global Step: 78500   Required: 0 hours
Training: 2025-05-30 16:51:58,060-Speed 370.42 samples/sec   Loss 1.4871 Epoch: 38   Global Step: 78550   Required: 0 hours
Training: 2025-05-30 16:52:15,337-Speed 370.43 samples/sec   Loss 1.6700 Epoch: 38   Global Step: 78600   Required: 0 hours
Training: 2025-05-30 16:52:32,612-Speed 370.49 samples/sec   Loss 1.5979 Epoch: 38   Global Step: 78650   Required: 0 hours
Training: 2025-05-30 16:52:49,887-Speed 370.47 samples/sec   Loss 1.4724 Epoch: 38   Global Step: 78700   Required: 0 hours
Training: 2025-05-30 16:53:07,162-Speed 370.48 samples/sec   Loss 1.5559 Epoch: 38   Global Step: 78750   Required: 0 hours
Training: 2025-05-30 16:53:24,437-Speed 370.48 samples/sec   Loss 1.5126 Epoch: 38   Global Step: 78800   Required: 0 hours
Training: 2025-05-30 16:53:41,709-Speed 370.56 samples/sec   Loss 1.6046 Epoch: 38   Global Step: 78850   Required: 0 hours
Training: 2025-05-30 16:53:58,981-Speed 370.54 samples/sec   Loss 1.5125 Epoch: 38   Global Step: 78900   Required: 0 hours
Training: 2025-05-30 16:54:16,255-Speed 370.50 samples/sec   Loss 1.6021 Epoch: 38   Global Step: 78950   Required: 0 hours
Training: 2025-05-30 16:54:33,523-Speed 370.64 samples/sec   Loss 1.4587 Epoch: 38   Global Step: 79000   Required: 0 hours
Training: 2025-05-30 16:54:50,797-Speed 370.50 samples/sec   Loss 1.4993 Epoch: 38   Global Step: 79050   Required: 0 hours
Training: 2025-05-30 16:55:08,072-Speed 370.48 samples/sec   Loss 1.5020 Epoch: 38   Global Step: 79100   Required: 0 hours
Training: 2025-05-30 16:55:25,348-Speed 370.44 samples/sec   Loss 1.5853 Epoch: 38   Global Step: 79150   Required: 0 hours
Training: 2025-05-30 16:55:42,619-Speed 370.58 samples/sec   Loss 1.4800 Epoch: 38   Global Step: 79200   Required: 0 hours
Training: 2025-05-30 16:55:59,893-Speed 370.50 samples/sec   Loss 1.6185 Epoch: 38   Global Step: 79250   Required: 0 hours
Training: 2025-05-30 16:56:17,163-Speed 370.60 samples/sec   Loss 1.5398 Epoch: 38   Global Step: 79300   Required: 0 hours
Training: 2025-05-30 16:56:34,431-Speed 370.62 samples/sec   Loss 1.5294 Epoch: 38   Global Step: 79350   Required: 0 hours
Training: 2025-05-30 16:56:51,697-Speed 370.67 samples/sec   Loss 1.5987 Epoch: 38   Global Step: 79400   Required: 0 hours
Training: 2025-05-30 16:57:08,981-Speed 370.62 samples/sec   Loss 1.5770 Epoch: 38   Global Step: 79450   Required: 0 hours
Training: 2025-05-30 16:57:44,345-[lfw][79482]XNorm: 20.904814
Training: 2025-05-30 16:57:44,345-[lfw][79482]Accuracy-Flip: 0.99200+-0.00488
Training: 2025-05-30 16:57:44,345-[lfw][79482]Accuracy-Highest: 0.99350
Training: 2025-05-30 16:58:12,761-[cfp_fp][79482]XNorm: 19.056004
Training: 2025-05-30 16:58:12,761-[cfp_fp][79482]Accuracy-Flip: 0.93043+-0.00885
Training: 2025-05-30 16:58:12,762-[cfp_fp][79482]Accuracy-Highest: 0.93357
Training: 2025-05-30 16:58:37,068-[agedb_30][79482]XNorm: 21.057013
Training: 2025-05-30 16:58:37,068-[agedb_30][79482]Accuracy-Flip: 0.92733+-0.01417
Training: 2025-05-30 16:58:37,068-[agedb_30][79482]Accuracy-Highest: 0.93367
Training: 2025-05-30 16:59:01,451-[calfw][79482]XNorm: 20.445034
Training: 2025-05-30 16:59:01,451-[calfw][79482]Accuracy-Flip: 0.92300+-0.01206
Training: 2025-05-30 16:59:01,451-[calfw][79482]Accuracy-Highest: 0.93117
Training: 2025-05-30 16:59:25,833-[cplfw][79482]XNorm: 19.656013
Training: 2025-05-30 16:59:25,833-[cplfw][79482]Accuracy-Flip: 0.87317+-0.01674
Training: 2025-05-30 16:59:25,833-[cplfw][79482]Accuracy-Highest: 0.87700
Training: 2025-05-30 16:59:32,213-Speed 44.68 samples/sec   Loss 1.6067 Epoch: 39   Global Step: 79500   Required: 0 hours
Training: 2025-05-30 16:59:49,467-Speed 370.93 samples/sec   Loss 1.6117 Epoch: 39   Global Step: 79550   Required: 0 hours
Training: 2025-05-30 17:00:06,730-Speed 370.74 samples/sec   Loss 1.5364 Epoch: 39   Global Step: 79600   Required: 0 hours
Training: 2025-05-30 17:00:23,991-Speed 370.77 samples/sec   Loss 1.5429 Epoch: 39   Global Step: 79650   Required: 0 hours
Training: 2025-05-30 17:00:41,257-Speed 370.68 samples/sec   Loss 1.5668 Epoch: 39   Global Step: 79700   Required: 0 hours
Training: 2025-05-30 17:00:58,525-Speed 370.64 samples/sec   Loss 1.5426 Epoch: 39   Global Step: 79750   Required: 0 hours
Training: 2025-05-30 17:01:15,793-Speed 370.62 samples/sec   Loss 1.5607 Epoch: 39   Global Step: 79800   Required: 0 hours
Training: 2025-05-30 17:01:33,064-Speed 370.56 samples/sec   Loss 1.5461 Epoch: 39   Global Step: 79850   Required: 0 hours
Training: 2025-05-30 17:01:50,337-Speed 370.54 samples/sec   Loss 1.5369 Epoch: 39   Global Step: 79900   Required: 0 hours
Training: 2025-05-30 17:02:07,610-Speed 370.52 samples/sec   Loss 1.4996 Epoch: 39   Global Step: 79950   Required: 0 hours
Training: 2025-05-30 17:02:24,886-Speed 370.45 samples/sec   Loss 1.6091 Epoch: 39   Global Step: 80000   Required: 0 hours
Training: 2025-05-30 17:02:42,161-Speed 370.48 samples/sec   Loss 1.5367 Epoch: 39   Global Step: 80050   Required: 0 hours
Training: 2025-05-30 17:02:59,435-Speed 370.50 samples/sec   Loss 1.5383 Epoch: 39   Global Step: 80100   Required: 0 hours
Training: 2025-05-30 17:03:16,708-Speed 370.52 samples/sec   Loss 1.5528 Epoch: 39   Global Step: 80150   Required: 0 hours
Training: 2025-05-30 17:03:33,980-Speed 370.55 samples/sec   Loss 1.5426 Epoch: 39   Global Step: 80200   Required: 0 hours
Training: 2025-05-30 17:03:51,257-Speed 370.43 samples/sec   Loss 1.5062 Epoch: 39   Global Step: 80250   Required: 0 hours
Training: 2025-05-30 17:04:08,529-Speed 370.54 samples/sec   Loss 1.6069 Epoch: 39   Global Step: 80300   Required: 0 hours
Training: 2025-05-30 17:04:25,806-Speed 370.43 samples/sec   Loss 1.5109 Epoch: 39   Global Step: 80350   Required: 0 hours
Training: 2025-05-30 17:04:43,080-Speed 370.51 samples/sec   Loss 1.6218 Epoch: 39   Global Step: 80400   Required: 0 hours
Training: 2025-05-30 17:05:00,355-Speed 370.48 samples/sec   Loss 1.4293 Epoch: 39   Global Step: 80450   Required: 0 hours
Training: 2025-05-30 17:05:17,636-Speed 370.35 samples/sec   Loss 1.5774 Epoch: 39   Global Step: 80500   Required: 0 hours
Training: 2025-05-30 17:05:34,912-Speed 370.47 samples/sec   Loss 1.5349 Epoch: 39   Global Step: 80550   Required: 0 hours
Training: 2025-05-30 17:05:52,185-Speed 370.52 samples/sec   Loss 1.5310 Epoch: 39   Global Step: 80600   Required: 0 hours
Training: 2025-05-30 17:06:09,455-Speed 370.59 samples/sec   Loss 1.6352 Epoch: 39   Global Step: 80650   Required: 0 hours
Training: 2025-05-30 17:06:26,729-Speed 370.50 samples/sec   Loss 1.6749 Epoch: 39   Global Step: 80700   Required: 0 hours
Training: 2025-05-30 17:06:44,009-Speed 370.36 samples/sec   Loss 1.5731 Epoch: 39   Global Step: 80750   Required: 0 hours
Training: 2025-05-30 17:07:01,285-Speed 370.47 samples/sec   Loss 1.6159 Epoch: 39   Global Step: 80800   Required: 0 hours
Training: 2025-05-30 17:07:18,562-Speed 370.44 samples/sec   Loss 1.6466 Epoch: 39   Global Step: 80850   Required: 0 hours
Training: 2025-05-30 17:07:35,834-Speed 370.54 samples/sec   Loss 1.5116 Epoch: 39   Global Step: 80900   Required: 0 hours
Training: 2025-05-30 17:07:53,105-Speed 370.55 samples/sec   Loss 1.5653 Epoch: 39   Global Step: 80950   Required: 0 hours
Training: 2025-05-30 17:08:10,387-Speed 370.33 samples/sec   Loss 1.4688 Epoch: 39   Global Step: 81000   Required: 0 hours
Training: 2025-05-30 17:08:27,666-Speed 370.40 samples/sec   Loss 1.5189 Epoch: 39   Global Step: 81050   Required: 0 hours
Training: 2025-05-30 17:08:44,940-Speed 370.51 samples/sec   Loss 1.5390 Epoch: 39   Global Step: 81100   Required: 0 hours
Training: 2025-05-30 17:09:02,212-Speed 370.55 samples/sec   Loss 1.5263 Epoch: 39   Global Step: 81150   Required: 0 hours
Training: 2025-05-30 17:09:19,480-Speed 370.63 samples/sec   Loss 1.5043 Epoch: 39   Global Step: 81200   Required: 0 hours
Training: 2025-05-30 17:09:36,746-Speed 370.67 samples/sec   Loss 1.6062 Epoch: 39   Global Step: 81250   Required: 0 hours
Training: 2025-05-30 17:09:54,019-Speed 370.52 samples/sec   Loss 1.5589 Epoch: 39   Global Step: 81300   Required: 0 hours
Training: 2025-05-30 17:10:11,292-Speed 370.52 samples/sec   Loss 1.5208 Epoch: 39   Global Step: 81350   Required: 0 hours
Training: 2025-05-30 17:10:28,566-Speed 370.50 samples/sec   Loss 1.5896 Epoch: 39   Global Step: 81400   Required: 0 hours
Training: 2025-05-30 17:10:45,836-Speed 370.58 samples/sec   Loss 1.5911 Epoch: 39   Global Step: 81450   Required: 0 hours
Training: 2025-05-30 17:11:03,107-Speed 370.57 samples/sec   Loss 1.6386 Epoch: 39   Global Step: 81500   Required: 0 hours
Training: 2025-05-30 17:11:34,332-[lfw][81520]XNorm: 21.047526
Training: 2025-05-30 17:11:34,332-[lfw][81520]Accuracy-Flip: 0.99067+-0.00569
Training: 2025-05-30 17:11:34,332-[lfw][81520]Accuracy-Highest: 0.99350
Training: 2025-05-30 17:12:02,558-[cfp_fp][81520]XNorm: 19.186073
Training: 2025-05-30 17:12:02,558-[cfp_fp][81520]Accuracy-Flip: 0.92871+-0.01023
Training: 2025-05-30 17:12:02,558-[cfp_fp][81520]Accuracy-Highest: 0.93357
Training: 2025-05-30 17:12:26,847-[agedb_30][81520]XNorm: 21.191677
Training: 2025-05-30 17:12:26,847-[agedb_30][81520]Accuracy-Flip: 0.92567+-0.01367
Training: 2025-05-30 17:12:26,847-[agedb_30][81520]Accuracy-Highest: 0.93367
Training: 2025-05-30 17:12:51,221-[calfw][81520]XNorm: 20.575125
Training: 2025-05-30 17:12:51,221-[calfw][81520]Accuracy-Flip: 0.92333+-0.01143
Training: 2025-05-30 17:12:51,221-[calfw][81520]Accuracy-Highest: 0.93117
Training: 2025-05-30 17:13:15,596-[cplfw][81520]XNorm: 19.786719
Training: 2025-05-30 17:13:15,596-[cplfw][81520]Accuracy-Flip: 0.87083+-0.01665
Training: 2025-05-30 17:13:15,596-[cplfw][81520]Accuracy-Highest: 0.87700
